\documentclass{report}
\input{preamble}
\input{macros}
\input{letterfonts}
\input{special_environment}
\input{commutative_diagram_config}
\input{content_page_config}
\title{Suns}
\author{Eric Liu}
\date{}
\begin{document}
\maketitle
\newpage % or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}

\tableofcontents
\pagebreak
\chapter{Groups}

\section{Definition of Groups}
Let $M$ be a set equipped with a binary operation $M\times M \rightarrow M$. We say $M$ is a \textbf{monoid} if the binary operation is associative and there exists a two-sided identity $e \in M$. 
\begin{Example}{Identity of  monoids is required to be two-sided}{}
Defining $(x,y)\mapsto y$, we see that the operation is associative and every element is a left identity, but no element is a right identity unless $\abso{M}=1$. This is an example why identity must be two-sided.  
\end{Example}

Because the identity of a monoid is defined to be two-sided, clearly it must be unique.  Suppose every element of monoid $M$ has a left inverse. Fix $x \in M$. Let $x^{-1}\in M$ be a left inverse of $x$. To see that  $x^{-1}$ is also a right inverse of $x$, let  $(x^{-1})^{-1}\in M$ be a left inverse of $x^{-1}$ and use  
\begin{align*}
  (x^{-1})^{-1}=(x^{-1})^{-1}e=(x^{-1})^{-1}(x^{-1}x)= ((x^{-1})^{-1}x^{-1})x= ex=x
\end{align*}
to deduce
\begin{align*}
xx^{-1}=(x^{-1})^{-1}x^{-1}= e
\end{align*}
In other words, if we require every element of a monoid $M$ to has a left inverse, then immediately every left inverse upgrades to a right inverse. In such case, we call $M$ a  \textbf{group}. Notice that inverses of elements of a group are clearly unique. 
\begin{theorem}
\textbf{(Group criteria)} If a binary operation $G \times G \rightarrow G$ is associative, has a left identity, and always has a left inverse, then $G$ forms a group. 
\end{theorem}
\begin{proof}
If  $y \in G$ is  \textbf{idempotent}, then it must be identity, since $y=(y^{-1}y)y=y^{-1}y=e$. Because of such, we see a left inverse is also a right inverse, since $(xx^{-1})(xx^{-1})=xe x^{-1}=xx^{-1}$. This then shows that the left identity is also a right identity, since $xe=x(x^{-1}x)=x$. 
\end{proof}
\begin{theorem}
\label{THwc}
\textbf{(Group criteria for finite set)} Let $\abso{G}\inn$. If the binary operation $G \times G \rightarrow G$ is associative and both cancellation laws holds: 
\begin{align*}
au=aw \implies u=w \quad \text{ and }\quad ua=wa \implies  u=w
\end{align*}
then $G$ forms a group. 
\end{theorem}
\begin{proof}
Because the set is finite, for all $a$, we may attach it with an natural number $n(a)$ such that  $a^{n(a)+1}=a$. Clearly, 
\begin{align*}
aa^{n(a)}b= a^{n(a)+1}b=ab=ab^{n(b)+1}=ab^{n(b)}b
\end{align*}
This then by cancellation laws implies $a^{n(a)}=b^{n(b)}$, which can be easily checked to be the identity.  
\end{proof}
\begin{theorem}
\textbf{(Subgroup criteria for finite subset)} Let $G$ be a group and $S \subseteq G$ be finite. If $S$ is closed under the binary operation, then $S$ forms a group. 
\end{theorem}
\begin{proof}
 Because $S$ is finite, for all $a \in S$, there exists $n(a)\inn$ such that 
\begin{align*}
a^{n(a)}a=a
\end{align*}
Multiplying both side with $a^{-1}$, we see that $a^{n(a)}=e$ and $a^{-1}=a^{n(a)} \in S$. 
\end{proof}
\begin{Example}{Euler's totient function}{}
By \myref{theorem}{THwc}, we see that the set of nonzero integer relatively prime to $n$ and modulo $n$ forms a group under multiplication modulo $n$, called the \textbf{multiplicative group of integer modulo $n$}, or equivalently the unit group of the ring $\Z_n$. This immediately shows that 
\begin{align*}
a^{\pfi  (a)} \equiv 1 \pmod{n}
\end{align*}
for all $a\inn$ coprime with  $n$, where the \textbf{totient function} $\pfi (a)$ is the number of natural numbers $\leq a$ and coprime with $a$. We now have \textbf{Fermat's little theorem} as a special case.  
\end{Example}
Unlike the category of monoids, the category of groups behaves much better. Given two groups $G,H$ and a function  $\phi : G\rightarrow H$, if $\phi$ respects the binary operation, then $\phi$ also respects the identity:
\begin{align*}
e_H = (\phi (x)^{-1})\phi (x) = (\phi(x)^{-1}) \phi(x e_G) =  (\phi (x)^{-1} \phi (x)) \phi (e_G)=\phi (e_G)
\end{align*}
which implies that $\phi$ must also respect inverse. In such case, we call $\phi$ a \textbf{group homomorphism}. In this note, by a \textbf{subgroup} $H$ of $G$, we mean an injective group homomorphism $H \hookrightarrow G $. Clearly, a subset of $G$ forms a subgroup if and only if it is closed under both the binary operation and inverse. Note that one of the key basic property of subgroup $H \leq  G$ is that if $g \not \in H$, then $hg \not \in H$, since otherwise $g=h^{-1}hg \in H$. \\


Let $S$ be a subset of $G$. The group of \textbf{words} in $S$:
\begin{align*}
\set{s_1^{\epsilon_1}\cdots s_n^{\epsilon _n}\in G: n\inn \cup  \set{0}\text{ and }s_i \in S\text{ and }\epsilon_i = \pm 1}
\end{align*}
is clearly the smallest subgroup of $G$ containing $S$. We say this subgroup is \textbf{generated} by $S$. If $G$ is generated by a single element, we say $G$ is \textbf{cyclic}. Let $x \in G$. The \textbf{order} of $G$ is the cardinality of $G$, and the order of  $x$ is the cardinality of the cyclic subgroup $\langle x\rangle \subseteq G$, or equivalently the infimum of the set of natural numbers $n$ that makes $x^n=e$. \\

Let $G$ be a group and $H$ a subgroup of $G$. The \textbf{right cosets} $Hx$ are defined by $Hx\triangleq \set{hx \in G: h \in H}$. Clearly, when we define an equivalence relation in $G$ by setting: 
\begin{align*}
x\sim  y \overset{\triangle}{\iff } xy^{-1} \in H
\end{align*}
the equivalence class $[x]$ coincides with the right coset $Hx$. Note that if we partition $G$ using \textbf{left cosets}, the equivalence relation being $x\sim  y \iff  x^{-1}y\in H$, then the two partitions need not to be identical. 
\begin{Example}{An non-normal subgroup}{} 
Let $H\triangleq \set{e,(1,2)}\subseteq S_3$. The right cosets are 
\begin{align*}
H(2,3)=\set{(2,3),(1,2,3)}\quad \text{ and }\quad  H(1,3)=\set{(1,3),(1,3,2)}
\end{align*}
while the left cosets being
\begin{align*}
(2,3)H= \set{(2,3),(1,3,2)} \quad \text{ and }\quad (1,3)H= \set{(1,3),(1,2,3)}
\end{align*}
\end{Example}
However, as one may verify, we have a well-defined bijection $xH\mapsto Hx^{-1}$ between the sets of left cosets and right cosets of $H$. Therefore, we may define the \textbf{index} $[G:H]$ of $H$ in  $G$ to be the cardinality of the collection of left cosets of $H$, without falling into the discussion of left and right. Moreover, let $K$ be a subgroup of  $H$, by axiom of choice, clearly we have: 
\begin{align*}
[G:K]= [G:H] \cdot [H:K]
\end{align*}
which gives \textbf{Lagrange's theorem}  
\begin{align*}
o(G)= [G:H] \cdot o(H)
\end{align*}
as a corollary.  \label{THLt}
\begin{Example}{Isomorphic subgroups can have different indices}{}
Note that every nontrivial subgroups of $\Z$ are isomorphic, yet they are of distinct index. However, subgroups $H\leq G$ isomorphic through an automorphism $\phi \in \operatorname{Aut}(G)$ must have the same index, since $xH\mapsto \phi (x)\phi (H)$ forms a well-defined bijection. 
\end{Example}
\begin{theorem}
\label{THof}
\textbf{(Order formula)} Let $H, K \leq G$. Then  
\begin{align*}
\abso{HK}\cdot o (H \cap K)=o(H) \cdot o(K)
\end{align*}
and 
\begin{align*}
[G:H \cap K]\leq [G:H]\cdot [G:K]
\end{align*}
If moreover that $H,K$ both have finite index, then 
\begin{align*}
\operatorname{lcm} \left([G:H],[G,K] \right) \leq [G: H \cap K]
\end{align*}
\end{theorem}
\begin{proof}
The first formula follows from checking that the natural map from the left coset space $K \quotient H \cap K$ to the left coset space $HK \quotient H$ forms a well-defined bijection. The second formula follows from checking that the natural map from the left coset space  $G \quotient H \cap K$ to the product $G \quotient H \times G \quotient K$ of left coset spaces forms a well-defined injection. The third formula follows from
\begin{align*}
[G:H\cap K]= [G:H] \cdot [H : H \cap K]= [G:K]\cdot [K:H \cap K]
\end{align*}
\end{proof}
\section{Group Action}
Let $G$ be a group and $X$ a set. If we say  $G$ \textbf{acts on $X$ from left}, we are defining a function $G \times X\rightarrow X$ such that 
\begin{enumerate}[label=(\roman*)]
  \item $e\cdot x=x$ for all $x\in X$. 
  \item $(gh)\cdot x= g \cdot (h \cdot x)$ for all $g,h \in G$. 
\end{enumerate}
Note that there is a difference between left action and right action, as $gh$ means $g \circ h$ in left action and means $h \circ g$ in right action. Because groups admit inverses, a $G$-action is in fact a group homomorphism $G \rightarrow \operatorname{Bij}(X)$.\\

Let $x \in X$. We call the set $\Gamma \triangleq \set{g\cdot x \in X: g\in G }$ the \textbf{orbit} of $x$. Clearly the set $\operatorname{Stab}(x)$ of all elements of $G$ that fixes $x$ forms a group, called the \textbf{stabilizer subgroup}. Consider the action left, and let $G \quotient \operatorname{Stab}(x)$ denote the left coset space. The fact that the obvious mapping between $G\quotient \operatorname{Stab}(x)$ and $\Gamma $ forms a bijection is called the \textbf{orbit-stabilizer theorem}, which relates the index of $\operatorname{Stab}(x)$ and the length of $\Gamma $:   \label{THost}
\begin{align*}
[G:\operatorname{Stab}(x)]= \abso{\Gamma }
\end{align*}
The two most important group action are \textbf{left multiplication} and \textbf{left conjugation}:   
\begin{align*}
g \cdot A \triangleq \set{ga \in G: a \in A}\quad \text{ and }\quad g \cdot A \triangleq \set{gag^{-1} \in G : a\in A} 
\end{align*}
on the power set of $G$. Clearly, orbit of a subgroup under left multiplication is its left coset space.
\begin{theorem}
\textbf{(Cauchy's theorem for finite group)}  Let $G$ be a finite group and $p$ a prime number that divides  $o(G)$. Then the number of elements of order divided by $p$ is a positive multiple of  $p$.  
\end{theorem}
\begin{proof}
The set $X$ of $p$-tuples  $(x_1,\dots ,x_p)$ that satisfies $x_1\cdots x_p=e$ clearly has cardinality $o(G)^{p-1}$. Consider the group action $C_p \rightarrow \operatorname{Bij}(X)$ defined by 
\begin{align*}
g \cdot (x_1,\dots ,x_p) \triangleq (x_p,x_1,\dots ,x_{p-1}),\quad \text{ where }C_p = \langle g\rangle 
\end{align*}
Notice that $x^p=e$ if and only if  $(x,\dots ,x) \in X$. Therefore the number of cardinality $1$ orbit equals to number of solution to $x^p=e$. By \customref{THost}{orbit-stabilizer theorem}, an orbit in $X$ either has cardinality $p$ or  $1$. Therefore, we may write
\begin{align*}
p\mid  o(G)^{p-1}=m+kp
\end{align*}
with $m$ the number of cardinality $1$ orbits and $k$ the number of cardinality  $p$ orbits. Clearly we have $p\mid m$, as desired.
\end{proof}
\section{Normal Subgroups}
Because the inverse of an injective group homomorphism forms a group homomorphism, we know  $\operatorname{Aut}(G)$  forms a group. We say $\pfi \in \operatorname{Aut}(G)$ is an \textbf{inner automorphism} if  $\pfi $ takes the form $x\mapsto  gxg^{-1}$ for some fixed $g \in G$. We say two elements  $x,y \in G$ are \textbf{conjugated} if there exists some inner automorphism that maps $x$ to $y$. Clearly conjugacy forms an equivalence relation. We call its classes \textbf{conjugacy classes}. \\


From the point of view of inner automorphism, we see that it is well-defined whether an element $g\in G$ \textbf{normalize} a subset $S\subseteq G$:
\begin{align*}
g Sg^{-1} = S
\end{align*}
independent of left and right.  Because of the independence, for each subset $S\subseteq G$, we see that the set of elements $g\in G$ that normalize $S$ forms a group, called the \textbf{normalizer} of $S$, in fact the stabilizer subgroup $\operatorname{Stab}(S)$ under the conjugacy action. 
\begin{Example}{Conjugation can send subgroups to proper subgroup}{} 
  Consider $G\triangleq \operatorname{GL}_2(\R)$  and consider: 
\begin{align*}
H\triangleq \set{ \begin{pmatrix}
    1 & n \\
    0 & 1
\end{pmatrix} \in \operatorname{GL}_2(\R) : n \inz}  \quad \text{ and }\quad g\triangleq \begin{pmatrix} 
 2 & 0 \\
 0 & 1
\end{pmatrix} \in \operatorname{GL}_2(\R)
\end{align*}
Note that $gHg^{-1} < H $. \end{Example}
Given $x,y \in G$, the notation $[x,y]\in G$ is called the \textbf{commutator of  $x$ and $y$}. In this note, we take the convention:  
\begin{align*}
[x,y]\triangleq xyx^{-1}y^{-1}
\end{align*}
The other convention is $[x,y]=x^{-1}y^{-1}xy$, and the differences lies in sides. In our convention, we see that $[x,y]\in H$ if and only if $Hxy=Hyx$, while the other convention leads us to $[x,y] \in H \iff  xyH=yxH$. However, because $[x,y]$ in our convention is just $[x^{-1},y^{-1}]$ in the other convention, if $H,K\leq G$, then the set $[H,K]$ is defined the same using either. In general, $[H,K]$ doesn't form a group. In fact, we clearly have $[H,K]=[K,H]^{-1}$. 
\begin{equiv_def}
\label{EDns}
\textbf{(Normal subgroups)} Let $N \leq G$. We say $N$ is a \textbf{normal subgroup} of $G$ if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item $\pfi  (N) \subseteq N$  for all $\pfi  \in \operatorname{Inn}(G)$
  \item $\pfi  (N)=N$ for all $\pfi  \in \operatorname{Inn}(G)$ 
  \item $xN=Nx$ for all  $x \in G$.  
  \item The set of all left cosets of $N$ equals the set of all right cosets of $N$. 
  \item $N$ is a union of conjugacy classes. 
  \item $[N,G]\subseteq N$.   
  \item For all $x,y \in G$, we have $xy\in N \iff  yx \in N$. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
  (i)$\implies $(ii): Let $\pfi  \in \operatorname{Inn}(G)$. By premise, $\pfi  (N)\subseteq N$ and $\pfi ^{-1}(N)\subseteq N$. Applying  $\pfi $ to both side of $\pfi ^{-1}(N)\subseteq N$, we have $\pfi (N)\subseteq N \subseteq \pfi  (N)$, as desired. \\

(ii)$\implies $(iii): Consider the automorphisms:  
\begin{align*}
 \pfi_{L,x}(g)= xg\quad \text{ and }\quad \pfi _{L,x^{-1}}(g)=x^{-1}g \quad \text{ and }\quad \pfi _{R,x}(g)= gx
\end{align*}
 Because $\pfi _{L,x^{-1}}\circ \pfi _{R,x} \in \operatorname{Inn}(G)$, by premise we have:
\begin{align*}
xN= \pfi _{L,x}(N)= \pfi _{L,x}\circ \pfi _{L,x^{-1}}\circ \pfi _{R,x}(N)= \pfi _{R,x}(N)=Nx 
\end{align*}

(iii)$\implies $(iv) is clear. (iv)$\implies $(iii): Let $x\in G$. By premise, there exists some $y\in G$ that makes $xN=Ny$. Let $x=ny$. The proof then follows from noting 
\begin{align*}
xN=Ny=N(n^{-1}x)=Nx
\end{align*}
(iii)$\implies $(v): Let $n \in N$ and $x \in G$. We are required to show $xnx^{-1} \in N$. Because $xN=Nx$, we know  $xn=\tilde{n}x$ for some $\tilde{n}\in N$. This implies 
\begin{align*}
xnx^{-1}= \tilde{n}xx^{-1}=\tilde{n}\in N  
\end{align*}
(v)$\implies $(vi): Fix $n\in N$ and $x\in G$. By premise, $xn^{-1}x^{-1} \in N$. Therefore, $n(xn^{-1}x^{-1})\in N$, as desired.\\


(vi)$\implies $(vii): Let $xy \in N$. To see $yx$ also belong to $N$, observe: 
\begin{align*}
 (xy)^{-1}(yx) =(xy)^{-1}x^{-1}xyx=[xy,x] \in N
\end{align*}
(viii)$\implies $(i): Let $n \in N$ and $x\in G$. Because $(nx)x^{-1}=n \in N$, by premise we have $x^{-1}nx \in N$, as desired.
\end{proof}
Notably, since given the "conjugate by left" $\phi_g \in \operatorname{Inn}(G)$ and $\pfi  \in \operatorname{Aut}(G)$, we have $\pfi  \circ \phi_g \circ \pfi ^{-1}=\phi_{\pfi (g)}$, we see that $\operatorname{Inn}(G)\trianglelefteq \operatorname{Aut}(G)$. We call  $\operatorname{Aut}(G)\quotient \operatorname{Inn}(G)$ the \textbf{outer automorphism group} of $G$. 
\begin{Example}{Dedekind and Hamiltonian group}{}
A group is said to be \textbf{Dedekind} if all of its subgroups are normal. Clearly every abelian group is Dedekind. Non-abelian Dedekind groups are called \textbf{Hamiltonian}. The simplest Hamiltonian group is the \textbf{quaternion group} $Q_8$, which is the group of the quaternions under multiplication: 
\begin{align*}
Q_8 \triangleq \set{1,i,j,k,-1,-i,-j,-k}
\end{align*}
Note that $Q_8$ is Dedekind because every nontrivial element is of order $4$. Clearly, $Q_8$ has center $\set{\pm 1}$. Because $Z(Q_8)$ has index $4$, we know  $Q_8 \quotient Z(Q_8)$ is abelian. This then by  \customref{THtit}{correspondence theorem} implies  $Q_8^{(1)} \leq Z(Q_8)$. Because $Q_8$ is non-abelian, we now see  $Q_8^{(1)}=Z(Q_8)= \set{\pm 1}$. Note that $Q_8$ clearly has the conjugacy classes 
\begin{align*}
\set{1}\cup  \set{-1} \cup  \set{\pm i} \cup  \set{\pm j}\cup  \set{\pm k}
\end{align*}
Interestingly, $Q_8$ is a group that contains a smallest non-trivial subgroup. Every non-trivial subgroup of  $Q_8$ must contains the group  $\set{\pm 1}$. 
\end{Example}
\section{Isomorphism Theorems}
 Let $N\trianglelefteq   G$. We say a group homomorphism $ \pi :G \rightarrow   G\quotient N$ satisfies the \textbf{universal property of quotient group $G\quotient N$} if 
\begin{enumerate}[label=(\roman*)]
  \item $\pi $ vanishes on $N$. \textbf{(Group condition)}
  \item For all group homomorphism $f:G\rightarrow H$ that vanishes on $N$ there exist a unique group homomorphism $\tilde{f} :G\quotient N\rightarrow H$ that makes the diagram: 
% https://q.uiver.app/#q=WzAsMyxbMiwwLCJHXFxxdW90aWVudCBOICJdLFswLDAsIkciXSxbMiwyLCJMIl0sWzAsMiwiZyJdLFsxLDIsImYiLDJdLFsxLDAsIiIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dXQ==
\[\begin{tikzcd}
	G && {G\quotient N } \\
	\\
	&& H 
	\arrow["\pi",two heads, from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["\tilde{f} ", dashed,from=1-3, to=3-3]
\end{tikzcd}\]
commute. \textbf{(Universality)}
\end{enumerate}
\begin{theorem}
\label{THfit}
\textbf{(First isomorphism theorem for groups)} The group homomorphism $\pi : G \rightarrow G \quotient N$ is always surjective with kernel $N$. Let $f :G \rightarrow H$ be a group homomorphism. Then $\operatorname{ker}f$ is normal in $G$, and the induced homomorphism $\tilde{f}: G \quotient \operatorname{ker}f \rightarrow H$ is injective.   
\end{theorem}
\begin{proof}
They are consequences of the construction. 
\end{proof}
\begin{theorem}
\label{THtit}
\textbf{(Third isomorphism theorem and correspondence theorem for groups)} Let $N \trianglelefteq G$. The canonical projection $\pi : G \rightarrow G\quotient N$ gives rise to a bijection between the set of subgroups of $G$ that contains $N$ and the set of subgroups of $G \quotient N$. The bijection is moreover a bijection between the set of normal subgroups of $G$ that contains $N$ and the set of normal subgroups of $G \quotient N$. The bijection also maps normalizer of subgroups $\leq G$ that contains $N$ to the normalizer of the image of the subgroup.\\


In fact, given $K \trianglelefteq G$ that contains $N$, if we identify $K \quotient N$ as a subgroup of $G \quotient N$ the natural way: 
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJLIl0sWzIsMCwiXFxmcmFje0t9e059Il0sWzIsMiwiXFxmcmFje0d9e059Il0sWzAsMl0sWzEsMiwiIiwyLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMCwxLCJcXHBpIiwwLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoiZXBpIn19fV1d
\[\begin{tikzcd}
	K && {\frac{K}{N}} \\
	\\
	&& {\frac{G}{N}}
	\arrow["\pi", two heads, from=1-1, to=1-3]
	\arrow[from=1-1, to=3-3]
	\arrow[hook, from=1-3, to=3-3]
\end{tikzcd}\]
then $\frac{K}{N}\trianglelefteq  \frac{G}{N}$ is the normal subgroup that corresponds to $K\trianglelefteq G$, and we have a natural isomorphism  $\frac{G}{K} \cong  \frac{\frac{G}{N}}{\frac{K}{N}}$. 
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\label{THsitg}
\textbf{(Second isomorphism theorem for groups)} Let $H\leq G$. If $K\leq N_G(H)$, then their product: 
\begin{align*}
HK\triangleq  \set{hk \in G: h \in H\text{ and } k \in K}
\end{align*}
forms a group (in fact, the subgroup generated by $H\cup K$) and is defined independent of left and right. Moreover, $H\trianglelefteq HK$ with $hkH=Hk$, and $H\cap K \trianglelefteq K$ with 
\begin{align*}
HK \quotient H \cong  K \quotient H \cap K \quad \text{ via } \quad  kH  \longleftrightarrow k (H \cap K) 
\end{align*}
\end{theorem}
\begin{proof}
To see $HK \subseteq KH$, simply observe $hk=k(k^{-1}hk)$. The converse inclusion is proved similarly. The fact that $HK$ forms a group now follows. The rest are clear. 
\end{proof}
\begin{Example}{Product of two subgroups}{} 
In general, product of two subgroups needs not to form a group. For example, consider the product of the subgroup $H$ generated by $(1,2) \in S_3$ and the subgroup $K$ generated by  $(2,3) \in S_3$. Since $(2,3)(1,2)\not \in HK$, we see $HK$ isn't a group.  \\

On the other hand, given two normal subgroups $N,M \trianglelefteq G$. By the \customref{EDns}{preserved-by-conjugations definition of normal subgroups}, clearly both $NM$ and  $N \cap M$ are normal in $G$.  
\end{Example}
\section{Free Group and Presentation}
\begin{equiv_def}
\textbf{(Core of a subgroup)} Let $H\leq G$. The largest subgroup of $H$ normal in  $G$ exists, called the \textbf{core} of $H$.  Let $\phi : G \rightarrow \operatorname{Bij}(G \quotient H)$ be the left multiplicative action on the left coset space of $H$. It is exactly:  
\begin{align*}
\operatorname{ker} \phi = \bigcap_{g \in G} H^g, \quad \text{ where }H^g \triangleq gHg^{-1}
\end{align*}
\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}
As we will see, consideration of core is in fact useful in theory of finite group. 
\begin{theorem}
\textbf{(Properties of core)} Let $G$ be a finite group. Then 
\begin{enumerate}[label=(\roman*)]
  \item $[G:\operatorname{Core}(H)]$ divides $ \left([G:H] \right)!$, for all $H\leq G$ 
  \item Any proper subgroup of $G$ of smallest possible index is normal. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (i) is a consequence of \customref{THfit}{first isomorphism theorem}, since we have an injective group homomorphism $G\quotient \operatorname{Core}(H)\longhookrightarrow \operatorname{Bij}(G \quotient H)$. (ii) follows from (i), since we would get $\operatorname{Core}(H)=H$.   
\end{proof}
\begin{equiv_def}
\textbf{(Normal closure)} Let $S \subseteq G$. Then 
\begin{align*}
\langle \set{s^g \in G: s \in S,g \in G}\rangle  = \bigcap_{S \subseteq N \trianglelefteq G} N
\end{align*}
is the smallest normal subgroup of $G$ that contains $S$, called the \textbf{normal closure} of $S$ in  $G$.  
\end{equiv_def}
\begin{proof}
The latter expression is clearly the smallest normal subgroup of $G$ that contains $S$.  $\leq $ part is clear. The only part we need to prove is $\geq $, which requires us to prove the former expression is normal, which is a consequence of computing 
\begin{align*}
h(g_1s_1g_1^{-1})^{\epsilon_1} \cdots (g_ns_ng_n^{-1})^{\epsilon_n} h^{-1}= (x_1s_1x_1^{-1})^{\epsilon _1} \cdots (x_ns_nx_n^{-1})^{\epsilon _n}
\end{align*}
where $x_i\triangleq hg_1$ if $\epsilon _i=1$ and $hg_i^{-1}$ if $\epsilon _i=-1$. 
\end{proof}
Let $S$ be a set. By the \textbf{free group generated by $S$}, we mean a group $F_S$ together with an injective function  $\diota:S \hookrightarrow F_S $ such that for all group $G$ and function  $f:S\rightarrow G$, there exists a unique group homomorphism $\tilde{f}: F_S \rightarrow G$ that makes the diagram:   
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJTIl0sWzIsMCwiRl9TIl0sWzIsMiwiRyJdLFswLDEsIlxcaW90YSIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzAsMiwiZiIsMl0sWzEsMiwiXFx0aWxkZXtmfSIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
\[\begin{tikzcd}
	S && {F_S} \\
	\\
	&& G
	\arrow["\iota", hook, from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["{\tilde{f}}", dashed, from=1-3, to=3-3]
\end{tikzcd} \label{THp}\]
commutes. Given a set of \textbf{relators} $R \subseteq F_S$, by \textbf{presentation} $\langle S\mid R\rangle $, we mean the group $F_S \quotient \operatorname{ncl}_{F_S}(R)$. Since kernel is normal, such group clearly satisfies the universal property that for all group $G$ and function  $f:S \rightarrow G$ such that the kernel of induced group homomorphism $\tilde{f}:F_S \rightarrow G$ contains $R$, there exists a unique group homomorphism $\widehat{f}: \langle S \mid  R\rangle \rightarrow G$ that makes the diagram
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJTIl0sWzIsMCwiXFxsYW5nbGUgUyBcXG1pZCBSXFxyYW5nbGUiXSxbMiwyLCJHIl0sWzAsMSwiXFxwaSBcXGNpcmMgXFxpb3RhIl0sWzAsMiwiZiIsMl0sWzEsMiwiXFxoYXR7Zn0iLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	S && {\langle S \mid R\rangle} \\
	\\
	&& G
	\arrow["{\pi \circ \iota}", from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["{\widehat{f}}", dashed, from=1-3, to=3-3]
\end{tikzcd}\]
\begin{Example}{Dihedral group}{}
The \textbf{Dihedral group} $D_n$ is defined by 
\begin{align*}
D_n \triangleq \langle r,s \mid r^n =s^2=e, srs^{-1}=r^{-1}\rangle 
\end{align*} 
Clearly, every element can be written as $r^as^b$ with  $0\leq a \leq n-1$ and $b \in \set{0,1}$. This implies that $D_n$ has at most $2n$ number of elements. To see that $o(D_n)=2n$, one first consider the group homomorphism $D_n \rightarrow \operatorname{GL}_2(\C)$ induced by 
\begin{align*}
r \mapsto \begin{pmatrix} 
  \xi & 0 \\
  0 & \xi^{-1}
\end{pmatrix}\quad \text{ and }\quad s \mapsto \begin{pmatrix} 
  0 & 1 \\
  1 & 0
\end{pmatrix}
\end{align*}
where $\xi\triangleq \exp ( 2\pi i \quotient n)$. Because 
\begin{align*}
r^a= \begin{pmatrix} 
  \xi^a & 0 \\
  0 & \xi^{-a}
\end{pmatrix} \quad \text{ and }\quad  r^as = \begin{pmatrix} 
  0 & \xi^a \\
  \xi^{-a} & 0
\end{pmatrix}
\end{align*}
We now see that indeed $o(D_n)=2n$. Moreover, because from the relators, we have the formula 
\begin{align*}
  (r^as^b)(r^cs^d)= r^{a+(-1)^bc}s^{b+d}
\end{align*}
which by direct computation implies $D_n' = \langle r^{2}\rangle $. Suppose $r^as^b \in Z(D_{n})$ with $0 \leq a \leq n-1$ and $b \in \set{0,1}$. Then form the formula, we must have  
\begin{align}
\label{EQa-1b}
a+(-1)^b c\equiv c+(-1)^d a \pmod{n},\quad \text{ for all }c,d\inz 
\end{align}
Because $d$ can be arbitrary, this implies 
\begin{align*}
2a \equiv 0 \pmod{n}
\end{align*}
Clearly we have $D_1 \cong  C_2$ and $D_2 \cong  C_2 \times C_2$. Therefore, we from now on suppose $n\geq 3$. \\

Let $n$ be odd.  Then clearly  $a=0$. Since  $rs\neq sr$ in general, we see that we also must have $b=0$. We have shown that $D_n$ is centerless for odd $n\geq 3$. \\

Let $n$ be even. Then we must have $a \in \set{0,\frac{n}{2}}$. If $a=0$, then again because $rs \neq sr$ in general, we must have $b=0$. If  $a= \frac{n}{2}$, then from the \myref{equation}{EQa-1b}, regardless of $d$, we see 
\begin{align*}
  (-1)^b c \equiv c \pmod{n},\quad \text{ for all }c \inz
\end{align*}
which can only be true if $b=0$. We have shown that $D_n$ has center  $\set{e,r^{\frac{n}{2}}}$ for even $n\geq 3$. Note that again by direct computation, one can check that the pattern of conjugacy classes differ according to parity of $n$. Regardless of parity, for fixed $k\inz$, the set $\set{r^{\pm k} }$ form a conjugacy class. If $n$ is odd, then the rest  $\set{r^ts:1\leq t \leq n-1}$ forms a class. If $n$ is even, then the rest forms two classes: 
 \begin{align*}
\set{r^rs \in D_{n}: 1\leq t \leq n-1\text{ is even }}\cup  \set{r^ts \in D_{n}: 1 \leq t \leq n-1\text{ is odd }}
\end{align*}
\end{Example}
\section{Center and Commutator}
Let $S\subseteq G$. Clearly $N_G(S)$ is the largest subgroup in which $S$ is preserved by inner automorphism. Consider its \textbf{centralizer} $C_G(S)\triangleq \set{g \in G: gs=sg\text{ for all }s \in S}$. To see that $C_G(S)\trianglelefteq N_G(S)$, one simply observe that $C_G(S)$ is the kernel of the conjugacy action $N_G(S) \longrightarrow  \operatorname{Bij}(S)$, where $\operatorname{Bij}(S)$ can be replaced by $\operatorname{Aut}(S)$ if $S$ forms a subgroup  $G$. In such case, \customref{THfit}{first isomorphism theorem} gives us an injection 
\begin{align*}
N_G(S) \quotient C_G(S) \longhookrightarrow  \operatorname{Aut}(S)
\end{align*}
We call the centralizer of the whole group $Z(G)\triangleq C_G(G)$ \textbf{center}.  
\begin{equiv_def}
\label{EDpoc}
\textbf{(Property of center)} Let $S\subseteq G$. Then 
\begin{enumerate}[label=(\roman*)]
  \item $S \subseteq Z(G) \iff  C_G(S)=G$. \textbf{(Equivalent condition to lies in center)}
  \item  $o(G) = o(Z(G))+ \sum [G:C_G (x)]$  \textbf{(Class equation)}\label{THce} 
  \item Regardless of $G$, we always have a natural surjective group homomorphism  $G \longtwoheadrightarrow \operatorname{Inn}(G)$. Such group homomorphism is injective (and thus an isomorphism) if and only if $G$ is centerless. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
Routine. Class equation is a consequence of \customref{THost}{orbit-stabilizer theorem}. 
\end{proof}
Let $N \trianglelefteq G$. Because \customref{EDns}{$xy \in N$ if and only if $yx \in N$}, regardless of notation convention for commutator, we see that 
\begin{align*}
[g,h] \in N \iff gN,hN \in G \quotient N\text{ commutes }
\end{align*}
Therefore, the factor group  $G \quotient N$ is abelian if and only if $[G,G]\subseteq N$. In this note, we use $G^{(1)}$ to denote the  \textbf{commutator subgroup} of $G$, the subgroup generated by  $[G,G]$. From our observation, clearly $G^{(1)}$ is the smallest normal subgroup that makes the quotient abelian. In fact, any subgroup $H$ containing $G^{(1)}$  is normal, since if $ghg^{-1}h^{-1} \in H$, then we clearly have $ghg^{-1} \in H$. We call $G^{\operatorname{ab}}\triangleq G \quotient G^{(1)}$ the \textbf{abelianization} of $G$. 
\begin{Example}{$\operatorname{GL}_2(\R)^{(1)}=\operatorname{SL}_2(\R)$}{}
Clearly we have $ \operatorname{GL}_2(\R)^{(1)} \leq \operatorname{SL}_2(\R)$. The opposite relation requires computation. Compute  
\begin{align*}
\begin{pmatrix} 
  1 & x \\
  0 & 1 
\end{pmatrix} = \left[\begin{pmatrix} 
  2 & 0 \\
  0 & 1 
\end{pmatrix}, \begin{pmatrix} 
  1 & x \\
  0 & 1 
\end{pmatrix}\right],\quad \text{ for all }x\inr
\end{align*}
Compute that 
\begin{align*}
\begin{pmatrix} 
  x & 0 \\
  0 & x^{-1}
\end{pmatrix} = \left[ \begin{pmatrix} 
  x & 0 \\
  0 & 1 
\end{pmatrix}, \begin{pmatrix} 
  0 & 1 \\
  1 & 0 
\end{pmatrix} \right],\quad \text{ for all }x\inr^{\times}
\end{align*}
We now see that for $a\neq 0$, we have 
\begin{align*}
\begin{pmatrix} 
  a & b \\
  c & d 
\end{pmatrix}= \begin{pmatrix} 
  1 & 0 \\
  \frac{c}{a} & 1 
\end{pmatrix} \begin{pmatrix} 
  1 & ab \\
  0 & 1 
\end{pmatrix} \begin{pmatrix} 
  a & 0\\
  0 & \frac{1}{a}
\end{pmatrix} \in \operatorname{GL}_2(\R) ^{(1)} 
\end{align*}
Compute that 
\begin{align*}
\begin{pmatrix} 
  0 & 1\\
  -1 & 0 
\end{pmatrix} = \left[\begin{pmatrix} 
  1 & 2 \\
  0 & 1 
\end{pmatrix}, \begin{pmatrix} 
  -1 & 0 \\
  1 & 2
\end{pmatrix} \right] 
\end{align*}
We now see that for $a=0$, we have 
\begin{align*}
\begin{pmatrix} 
  0 & b \\
  c & d
\end{pmatrix} = \begin{pmatrix} 
  0 & 1 \\
  -1 & 0
\end{pmatrix} \begin{pmatrix} 
  1 & - \frac{d}{b}\\
  0 & 1
\end{pmatrix} \begin{pmatrix} 
  \frac{1}{b} & 0 \\
  0 & b
\end{pmatrix} \in   \operatorname{GL}_2(\R) ^{(1)} 
\end{align*}
\end{Example}
\begin{theorem}
\textbf{("Symmetry" between commutator subgroup and center)}  Let $G$ be a group and $N \trianglelefteq G$. We have:
\begin{enumerate}[label=(\roman*)]
  \item  If $N \cap G^{(1)} =1$, then $N \leq Z(G)$.  \label{THpcs} 
  \item  Let $C\subseteq G$ be the set of commutators.  If $[G:Z(G)]\triangleq n$, then
\begin{align*}
 \abso{C}\leq n^2 \quad \text{ and }\quad o\left(G^{(1)} \right) \leq n^{2n^3}
\end{align*}
 \item  Let $G\triangleq \langle g_1, \dots , g_m\rangle $ be finitely generated. If $o(G^{(1)})\triangleq n$, then 
\begin{align*}
[G:Z(G)] \leq n^m
\end{align*}
\end{enumerate}
The last two are called \textbf{Schur's upper bound}. 
\end{theorem}
\begin{proof}
(i): Fix $n \in N$ and $g\in G$. Because $N$ is normal, we know  $gng^{-1}n^{-1} \in N$. It then follows from $N \cap G^{(1)}=1$ that $gng^{-1}n^{-1}=e$, which implies $gn=ng$.  \\

(ii): To prove $\abso{C}\leq n^2$, we show that 
\begin{align*}
\vi{\begin{cases}
  aZ(G)=cZ(G) \\
  bZ(G)=dZ(G)
\end{cases}\implies [a,b]=[c,d]}
\end{align*}
The premise gives us $ac^{-1}\in Z(G)$ and $bd^{-1}\in Z(G)$. We then can compute 
\begin{align*}
aba^{-1}b^{-1}= aba^{-1}(cc^{-1})b^{-1}=cbc^{-1}b^{-1}= cbc^{-1}b^{-1}(dd^{-1})= cdc^{-1}d^{-1} \vdone
\end{align*}
Before proving the second part, we first prove a necessary lemma: 
\begin{align*}
\olive{[a,b]^{n+1}=[a,b^2]\cdot [bab^{-1},b]^{n-1},\quad \text{ for all }a,b \in G }  
\end{align*}
The premise $[G:Z(G)]=n$ implies $g^n \in Z(G)$ for all $g \in G$. Therefore, we may compute 
\begin{align*}
  [a,b]^{n+1}&= aba^{-1}[a,b]^n b^{-1}= ab^2a^{-1} b^{-1}[a,b]^{n-1}b^{-1}= [a,b^2]b[a,b]^{n-1}b^{-1} \\
  &= [a,b^2] \left(b [a,b]b^{-1} \right)^{n-1}= [a,b^2] \cdot [bab^{-1},b]^{n-1} \odone
\end{align*}



Recall that $C= \set{c^{-1} \in G: c\in C}$. Since $\abso{C}\leq n^2$, to prove $o \left(G^{(1)} \right)\leq n^{2n^3}$, we only have to show that 
\begin{center}
   \begin{minipage}{0.9\linewidth}  
     \blue{For all $g \in G^{(1)}$, when written in the form $g\triangleq c_1\cdots  c_m$, where $c_i \in C$, we may require $m \leq n^3$}.  
   \end{minipage}
\end{center}
Fix $g$. Let  $g\triangleq c_1 \cdots c_m$ with smallest $m$. We prove such by showing that each  $c_i$ can occurs at most $n$ times in the expression  $c_1 \cdots c_m$. Assume some $c_j$ occurs  $> n$ times in the expression. Because in general, we have 
\begin{align*}
z[x,y]= [zxz^{-1},zyz^{-1}]z^{-1}
\end{align*}
in groups, we may pull the $c_j$  to the most left in the expression. Then our lemma \olive{$[a,b]^{n+1}=[a,b^2]\cdot [bab^{-1},b]^{n-1}$} gives a contradiction, to the minimality of $m$. \bdone    \\

(iii): Clearly we have 
\begin{align*}
Z(G)= \bigcap_{i=1}^m C_G(g_i) 
\end{align*}
\customref{THost}{Orbit-stabilizer theorem} says that 
\begin{align*}
[G:C_G(g_i)]= \abso{\Gamma }
\end{align*}
where $\Gamma $ is the orbit of $g_i$ under the conjugacy action $G \longrightarrow \operatorname{Inn}(G)$. Since $xg_ix^{-1}=[x,g_i]g_i$, for all $x \in G$, we see $\abso{\Gamma }\leq n$. The proof then follows from \customref{THof}{order formula}: 
\begin{align*}
[G:Z(G)]=[G: \bigcap_{i=1}^m C_G(g_i)] \leq \prod_{i=1}^m [G: C_G(g_i)] \leq  n^m
\end{align*}
\end{proof}
\begin{equiv_def}
\label{EDAg}
\textbf{(Abelian group)} A group $G$ if \textbf{abelian} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item  $Z(G)=G$
  \item $G^{(1)}=1$ 
  \item $g\mapsto g^{-1}$ forms an automorphism.  
  \item $\operatorname{Inn}(G)$ is trivial. 
  \item $G\quotient Z(G)$ is cyclic.  
\end{enumerate}
\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}
\begin{Example}{Criteria for abelian group}{Cfa}
The cyclic criteria of $G \quotient Z(G)$ can not be weaken to that $G\quotient Z(G)$ being abelian. For example, consider $D_4$. Because  $o(Z(D_4))=2$, we know $D_4 \quotient Z(D_4)$ is abelian, but $D_4$ isn't. 
\end{Example}
\begin{corollary}
\textbf{(Finite group with order $\geq 3$ has a nontrivial automorphism)} If $o(G)\geq 3$, then $\operatorname{Aut}(G)$ is nontrivial. 
\end{corollary}
\begin{proof}
  If \customref{EDAg}{$G$ is non-abelian, then  $\operatorname{Inn}(G)$ is non-trivial}. If $G$ is abelian, then we have the inversion automorphism. Such inversion automorphism is non-trivial unless all nontrivial elements of $G$ has order $2$. In such case, $G$ forms a finite-dimensional $\F_2$-vector space, which allow us to easily find an inversion automorphism. 
\end{proof}
\begin{theorem}
\label{THcafg}
\textbf{(Abelian criteria for finite group)} Let $G$ be a finite group and $\phi \in \operatorname{Aut}(G)$ be an automorphism that satisfies 
\begin{align*}
\abso{\set{g \in G: \phi (g)=g^{-1}}} > \frac{3}{4}\cdot  o(G)
\end{align*}
Then $G$ is abelian.  
\end{theorem}
\begin{proof}
Denote $S \triangleq \set{x\in G: \phi (x)=x^{-1}}$. Because of consideration of order, we only have to prove $S \subseteq Z(G)$.  Fix $x \in S$. We prove that $C_G(x)=G$. Now, since 
\begin{align*}
y^{-1}x^{-1}= \phi (xy)=\phi(x)\phi (y)=x^{-1}y^{-1},\quad \text{ for all }y \in S \cap x^{-1}S
\end{align*}
we see that $S \cap x^{-1}S \subseteq C_G(x)$. The proof then follows from computing  
\begin{align*}
\abso{S \cap x^{-1}S}&= \abso{S} + \abso{x^{-1}S}- \abso{S \cup  x^{-1}S} \\
&\geq \frac{3}{2} \cdot o (G)+ 2 \epsilon  - o(G) > \frac{1}{2} \cdot o (G)
\end{align*}
and consideration of the order.
\end{proof}
\begin{Example}{Lower bound in \customref{THcafg}{our abelian criteria for finite group} is necessary}{}
Consider 
\begin{align*}
D_4  \triangleq \langle r,s \mid  r^4=s^2=e,srs^{-1}=r^{-1}\rangle 
\end{align*}
There are exactly three quarters of elements of order dividing $2$, i.e.,  $\set{e,r^2,rs,r^2s,r^3s}$. The identity automorphism send them to their inverse, but the group is not abelian. 
\end{Example}
\section{Characteristic Subgroups}

\begin{equiv_def}
\textbf{(Characteristic subgroup)} Let $G$ be a group. We say $K \leq  G$ is a \textbf{characteristic subgroup} and write $K\operatorname{char}G$ if any of the followings holds true: 
\begin{enumerate}[label=(\roman*)]
  \item $\phi (K)\leq K$ for all $\phi \in \operatorname{Aut}(G)$
  \item $\phi (K)=K$ for all $\phi \in \operatorname{Aut}(G)$.  
\end{enumerate}
\end{equiv_def}
\begin{proof}
(i)$\implies $(ii) follows from noting $\phi^{-1}(K)\leq K \leq \phi^{-1}(K)$. (ii)$\implies $(i) is clear. 
\end{proof}
\begin{theorem}
\label{THus}
\textbf{(Basic properties of characteristic subgroups)} Let $G$ be a group. Then: 
\begin{enumerate}[label=(\roman*)]
\item If there exists a unique subgroup $H \leq G$ of a fixed index, then $H$ is is characteristic. \textbf{(unique subgroup of fixed index is characteristic)} 
\item If $K\operatorname{char}H \trianglelefteq G$, then $K \trianglelefteq G$. \textbf{(characteristic subgroup is transitive)}
\item If $K\operatorname{char}H \operatorname{char}G$, then $K\operatorname{char}G$. 
\end{enumerate}   
\end{theorem}
\begin{proof}
(i): To show that $H$ is characteristic, we are required to prove $[G:H]=[G:\phi (H)]$ for all $\phi \in \operatorname{Aut}(H)$, which follows from checking that  $xH \mapsto \phi (x)\phi (H)$ forms a well-defined bijection between the left cosets spaces of $H$ and $\phi (H)$. \\

(ii) and (iii): Because $H \trianglelefteq G$, every inner automorphism can be restricted $\operatorname{Aut}(H)$. (ii) then follows. The proof for (iii) is the same, in which every automorphism of $G$ can be restricted automorphism of $H$. 
\end{proof}
\begin{Example}{A normal subgroup that isn't characteristic}{}
Consider the additive group of $\Q$.  $\Z \leq \Q$ is then normal but not characteristic, since $x \mapsto \frac{1}{2}$ is an automorphism that doesn't preserve $\Z$.   
\end{Example}
Note that even though normal subgroups need not be preserved by automorphisms, the property of being a normal subgroup is: Given $N \trianglelefteq G$ and $\phi\in \operatorname{Aut}(G)$, we have $\phi(N)\trianglelefteq G$. \\

A subgroup $H\leq G$ is said to be \textbf{strictly characteristic} if it is preserved by all surjective endomorphism. If $H$ is moreover preserved by all endomorphism, then we say it is \textbf{fully characteristic}. Clearly, centers are all strictly characteristic, and commutator subgroups are all fully characteristic. 
\begin{Example}{A center that isn't fully characteristic}{}
Consider $S_3\times C_2$. \customref{THzSn}{This group has center $1 \times C_2$}. The function:
\begin{align*}
(\pi  ,0)\mapsto \left(e ,0 \right)  \quad \text{ and }\quad (\pi ,1)\mapsto \left( (1,2),0 \right),\quad \text{ for all }\pi  \in S_3
\end{align*}
is clearly an endomorphism that doesn't preserve the center. 
\end{Example}
Notably, given a normal subgroup $N \trianglelefteq G$ and an endomorphism $f\in \operatorname{End}(G)$, in general we can't naturally induce an endomorphism on $G \quotient N$. If we were to require a subgroup to always allow us to induce endomorphism on its factor group, then we would need it to be fully characteristic. However, when we only want to induce automorphism from an automorphism $f \in \operatorname{Aut}(G)$, a characteristic subgroup clearly suffices. In fact, given a characteristic subgroup $K\operatorname{char}G$, this gives us a group homomorphism $\operatorname{Aut}(G) \longrightarrow  \operatorname{Aut}(G \quotient K)$. 
\section{Semi-Direct Product}
Let $N,H$ be two groups and  $\phi: H \rightarrow \operatorname{Aut}(N)$ be a group homomorphism. Clearly, when we define a binary operation on  $N\times H$ by 
\begin{align*}
  (n_1,h_1)\cdot (n_2,h_2)\triangleq (n_1 \phi_{h_1}(n_2),h_1h_2)
\end{align*}
We have the \textbf{external semidirect product group} $N \rtimes_\phi H$ in which the inverse of $(n,h)$ is $(\phi_{h^{-1}}(n^{-1}),h^{-1})$. Remarkably, the automorphism $\phi_h \in \operatorname{Aut}(N)$ is always the restriction of the inner automorphism $n \mapsto hnh^{-1}$ in the parent group $N\rtimes_{\phi}H$. In particular, given a group $G$, indeed, every automorphism $\psi \in \operatorname{Aut}(G)$ of $G$ is a restriction of the inner automorphism
\begin{align*}
(g,\phi) \mapsto (e,\psi)\cdot (g,\phi) \cdot (e,\psi)^{-1}
\end{align*}
of the \textbf{holomorph group} $\operatorname{Hol}(G)\triangleq G \rtimes_{\id }\operatorname{Aut}(G)$.  
\begin{theorem}
\textbf{(Universal property of semidirect product)} Let $N,H$ be two groups and  $\phi : H \rightarrow \operatorname{Aut}(N)$ be a group homomorphism. If group homomorphisms $f:N\rightarrow G,g:H\rightarrow G$ satisfy
\begin{align*}
f\left(\phi_h(n) \right) =g(h)f(n)g(h^{-1}),\quad \text{ for all }n\in N,h\in H
\end{align*}
then there exists a unique $k:N\rtimes_{\phi}H \rightarrow G$ that makes the diagram: 
% https://q.uiver.app/#q=WzAsNCxbMCwyLCJOIl0sWzIsMCwiSCJdLFsyLDIsIkciXSxbMCwwLCJOXFxydGltZXNfe1xccGhpfUgiXSxbMCwyLCJmIiwyXSxbMSwyLCJnIl0sWzMsMiwiayIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dLFsxLDMsIiIsMSx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoiYm90dG9tIn19fV0sWzAsMywiIiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJib3R0b20ifX19XV0=
\[\begin{tikzcd}
	{N\rtimes_{\phi}H} && H \\
	\\
	N && G
	\arrow["k", dashed, from=1-1, to=3-3]
	\arrow[hook', from=1-3, to=1-1]
	\arrow["g", from=1-3, to=3-3]
	\arrow[hook', from=3-1, to=1-1]
	\arrow["f"', from=3-1, to=3-3]
\end{tikzcd}\]
commutes. 
\end{theorem}
\begin{proof}
It is routine to check that $k(n,h)\triangleq f(n)g(h)$ suffices. The uniqueness follows from noting $(n,e)\cdot (e,h)=(n,h)$ for all $n \in N$ and $h \in H$.  
\end{proof}
It is worth mentioning here that direct product is a special case of semidirect product. If $\phi : H \rightarrow \operatorname{Aut}(N)$ is trivial, then $N \rtimes_{\phi}H\cong  N \times H$. Also, it is not true that every two distinct group homomorphism $\psi,\phi : H \rightarrow \operatorname{Aut}(N)$ must induce distinct semidirect product. For example, given $f \in  \operatorname{Aut}(H)$, we have 
\begin{align}
\label{EQfAutH}
N \rtimes_{\phi \circ f}  H \cong  N \rtimes_{\phi } H \quad \text{ via }\quad (n,f^{-1}(h)) \mapsto (n,h)
\end{align}
\begin{theorem}
\label{THposd}
\textbf{(Presentation of semidirect product)} Let $N\triangleq \langle X\mid R\rangle ,H \triangleq \langle Y\mid S\rangle $ and $\phi : H \rightarrow \operatorname{Aut}(N)$ be a group homomorphism. We have 
\begin{align*}
N \rtimes_{\phi} H = \langle X\cup  Y \mid R,S,yxy^{-1}=w_y(x)\text{ for all }x \in X,y \in Y\rangle 
\end{align*}
where $w_y(x)$ is a fixed word in $X$ that stands for $\phi_y(x) \in N$.  
\end{theorem}
\begin{proof}
  See \href{https://books.google.com.tw/books/about/Presentations_of_Groups.html?id=p0okzgEACAAJ&redir_esc=y}{Chapter 10, Section 1, Corollary 1 of the book Presentations of Groups (2nd ed.) by D.L. Johnson}. The proof is not difficult, but without his approach, can be rather lengthy and tedious.    
\end{proof}

\begin{Example}{Classification of semidirect product of $C_8 \rtimes C_2$}{}
Write $\operatorname{Aut}(C_{8})\triangleq \set{1,3,5,7}$, so there are four distinct action $C_2 \longrightarrow \operatorname{Aut}(C_8)$ giving us possibly four distinct semidirect product of $C_8 \rtimes C_2:$
\begin{align*}
\langle x,y \mid  x^8=y^2=e,yxy^{-1}=x^n\rangle ,\quad n \in \set{1,3,5,-1}
\end{align*}
Because every word clearly can be written as $x^ay^b$ with  $0 \leq a \leq 7$ and $b \in \set{0,1}$, regardless of $n$, and because as a priori, we are already aware that  $C_8 \rtimes C_2$ has order $16$, we know that indeed the elements $x^ay^b$ are nontrivial unless  $a=b=0$. To see that the four groups are non-isomorphic, one can first use the formula:
\begin{align*}
  (x^ay)^2=x^{a(n+1)}
\end{align*}
to count the number of elements of order $2$, and therefore confirm that the only possible isomorphism is between $n=1$ and  $n=5$, which is also impossible, since  $n=5$ is clearly non-abelian.  
\end{Example}

\begin{equiv_def}
\label{EDrip}
\textbf{(Recognition theorem for inner semidirect product)} Let $N\trianglelefteq G$ and $H \leq G$. The followings are equivalent 
\begin{enumerate}[label=(\roman*)]
  \item $G=NH$ and  $N\cap H=1$. 
  \item Every $g$ can be uniquely written as $g=nh$.  
  \item The composition of $\pi  : G \twoheadrightarrow G\quotient N$ and $\diota : H \hookrightarrow G $ forms an isomorphism $H \rightarrow  G \quotient N$. 
  \item There exists a homomorphism $r:G \rightarrow  H$, called the \textbf{retraction}, that is identity on $H$ and has kernel $N$. Such retraction then give us a right split sequence 
\begin{align*}
1 \longrightarrow N \longrightarrow G \overset{r}{\longrightarrow }H \longrightarrow 1
\end{align*}
since $r \circ \diota = \id _H$. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
  (i)$\implies $(ii) is clear. (ii)$\implies $(iii): Let $h \in N$. To prove that $H \longrightarrow G \quotient N$ is injective, we are required to show $h=e$. Because $h \in N$, we know $h=eh=he$ implies that  $h=e$. Surjectivity is clear. \\

  (iii)$\implies $(iv): Clearly $r\triangleq (\pi  \circ \diota   )^{-1}\circ \pi$ suffices. \\

(iv)$\implies $(i): $N \cap H=1$ is clear. To see that $G=NH$, just observe that  $g=gr(g^{-1})r(g)$, where $gr(g^{-1})\in N$, since $r(gr(g^{-1}))=r(g)r(r(g^{-1}))=r(g)r(g^{-1})=e$. 
\end{proof}
Suppose $N\trianglelefteq  G$ and $H \leq G$ satisfies the conditions in the \customref{EDrip}{recognition theorem for inner semidirect product}. Defining $\phi : H \rightarrow \operatorname{Aut}(N)$ by $\phi_h(n)\triangleq hnh^{-1}$, we see that the natural map $N \rtimes_{\phi} H \rightarrow G$ indeed forms a well-defined group isomorphism. Because of such, when the short exact sequence 
\begin{align*}
1 \longrightarrow N \longrightarrow G \longrightarrow G \quotient N \longrightarrow 1
\end{align*}
right splits, we know that 
\begin{align*}
G = N \rtimes_{\phi} (G \quotient N)
\end{align*}

\begin{Example}{Inner semidirect product}{}
Clearly we have a right split sequence:  
\begin{align*}
1 \longrightarrow A_n \longrightarrow S_n \overset{\operatorname{sgn}}{\longrightarrow } C_2 \longrightarrow 1
\end{align*} 
Since the sequence right splits via $g \mapsto (1,2)$, where $C_2 \triangleq  \langle g\rangle $, \customref{EDrip}{recognition theorem for inner semi-direct product implies}: 
\begin{align*}
A_n \rtimes_{\phi} C_2 \cong  S_n  ,\quad \text{ with }\phi_g (\sigma) \triangleq  (1,2)\sigma (1,2)^{-1}
\end{align*}
where the semi-direct product can be considered internal if we view  $C_2 \triangleq \langle (1,2)\rangle \leq S_n$. \\

Let $\F$ be a field, and view $\F^{\times}$ as a subgroup of $\operatorname{GL}_n(\F)$ by sending $c\mapsto \operatorname{diag}(c,1,\dots ,1)$. We see that we have a right split sequence: 
\begin{align*}
  1 \longrightarrow \operatorname{SL}_n(\F) \longrightarrow \operatorname{GL}_n(\F) \overset{\operatorname{det}}{\longrightarrow} \F^{\times} \longrightarrow 1
\end{align*}
Therefore, \customref{EDrip}{recognition theorem for inner semi-direct product implies}: 
\begin{align*}
\operatorname{SL}_n(\F) \rtimes_{\phi} \F^{\times} \cong  \operatorname{GL}_n(\F)  ,\quad \text{ with }\phi_c(A) \triangleq D(c) A  D(c^{-1}) \text{ and } D(c) \triangleq \operatorname{diag}(c,1,\dots,1)
\end{align*}
where the semi-direct product can be considered internal if we view  $\F^{\times}\triangleq \set{\operatorname{diag}(c,\dots ,1)} \leq \operatorname{GL}_n(\F)$.
\end{Example}
Note that if $H$ is also normal in $G$, then the action  $\phi_h(n)=hnh^{-1}$ become trivial, since we would have $[H,N]\subseteq H \cap N= 1$. This agrees with the \customref{EDidpfg}{recognition theorem for direct product}. 
\begin{equiv_def}
\label{EDidpfg}
  \textbf{(Recognition theorem for direct product)} Let $N_1,\dots ,N_k$ be normal subgroups of $G$. We say $G$ is an \textbf{internal direct  products of $N_i$} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item The natural map $N_1 \times \cdots \times N_k \rightarrow G$ forms a group isomorphism. 
  \item $N_1\cdots N_k=G$ and $N_i \cap \prod_{j\neq i}N_j=1$ for all $i$.  
  \item $N_1\cdots N_k=G$ and $N_i \cap  \prod_{j<i}N_j=1$ for all $i$. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
  (i)$\implies $(ii): Clearly we have $N_1 \cdots N_k = G$. Let $n_2 \cdots n_k \in N_1$. Because $n_2 \cdots n_k$ is both the image of $(n_2\cdots n_k,e,\dots ,e)$ and $(e,n_2,\dots ,n_k)$, by injectivity of the natural map, we know $n_2=\cdots =n_k =e$.  \\

  (ii)$\implies $(iii) is clear. It remains to show (iii)$\implies $(i). The proof relies on induction on $k$. We first prove the base case $k=2$. Because $\customref{EDns}{[N_1,N_2]\leq N_1 \cap N_2}=1$, we know the natural map forms homomorphism. Surjectivity is clear. For injectivity, if $n_1n_2=e$, then since  $n_1= n_2^{-1}\in N_2$, we know $n_1=n_2=e$. \\

We now prove the inductive case. By the base case, the natural map: 
\begin{align*}
  (N_1 \cdots N_k) \times N_{k+1}\longrightarrow N_1\cdots N_k N_{k+1}=G
\end{align*}
forms a group isomorphism. By inductive hypothesis, the natural map: 
\begin{align*}
N_1 \times \cdots \times N_k \longrightarrow N_1\cdots N_k
\end{align*}
also forms a group isomorphism. Composing the two together, we get the desired isomorphism. 
\end{proof}
It should be noted that we didn't define internal direct products for infinite index, since the original statement can not be naively generalized to the infinite case. The ill behavior can be seen from multiple aspect. For example,  we have 
\begin{align*}
\prod_{i \in I} N_i \trianglelefteq \prod_{i \in I} G_i\quad \text{ and }\quad  \frac{\prod G_i}{\prod N_i} \cong  \prod_{i \in I} \frac{G_i}{N_i}\quad \text{ and }\quad  Z\left(\prod_{i\in I} G_i\right)= \prod_{i\in I} Z(G_i)
\end{align*}
even if the index set $I$ is infinite, but we only have  
\begin{align*}
\left(\prod_{i \in I} G_i \right)^{(1)} \leq \prod_{i\in I} (G_i^{(1)})
\end{align*}
where the equality holds if $I$ is finite. \label{THcgi} 
\begin{equiv_def}
\label{EDdpfg}
\textbf{(Recognition theorem for direct product for finite group)} Let $G$ be  a finite group, and let  $N_1 ,\dots ,N_k \trianglelefteq G$ satisfy $G=N_1 \cdots N_k$ and $o(G)=o(N_1)\cdots o(N_k)$. Then $G$ is the internal direct product of $N_i$. 
\end{equiv_def}
\begin{proof}
The proof is done by induction on $k$. The base case $k=1$ is trivial. For the inductive case, one first use \customref{THof}{the order formula} to compute 
\begin{align*}
o(N_1)\cdots o (N_k)o(N_1 \cap (N_2 \cdots N_k))=o(G)o(N_1 \cap (N_2 \cdots N_k)) = o(N_1)o(N_2 \cdots N_k)
\end{align*}
which gives   
\begin{align*}
o(N_1 \cap  (N_2 \cdots N_k)) =  \frac{o(N_2 \cdots N_k)}{o(N_2)\cdots o(N_k)} \leq 1
\end{align*}
which by \customref{EDidpfg}{recognition theorem} implies $G$ is the internal direct product  $N_1 \times (N_2 \cdots N_k)$. The rest then follows from the inductive hypothesis. 
\end{proof}
\begin{Example}{The requirement in definitions of internal direct products for groups}{}
Let $G\triangleq C_4 \times C_2$. Clearly the direct product of $\langle (1,0)\rangle $ and $\langle (2,0)\rangle $ is isomorphic to $G$, but they do not form an internal direct product of  $G$. It is because of such, we must require  $N_1 \times \cdots \times N_k$ not only isomorphic to $G$, but moreover the natural way in \customref{EDidpfg}{definition of internal direct products for groups}.
\end{Example}
\begin{Example}{The requirement in definitions of internal direct products for groups}{tr}
Let $G\triangleq \Z \times \Z$. Clearly $N_1 \triangleq \Z \times \set{0},N_2 \triangleq \set{0} \times \Z,N_3 \triangleq \set{(x,x)\in G: x \inz}$ satisfies 
\begin{align*}
G=N_1N_2 N_3 \quad \text{ and }\quad N_1 \cap N_2 = N_1 \cap  N_3 = N_2 \cap  N_3 =1 
\end{align*}
Yet, later we will see that \customref{THfgag}{we can never have a group isomorphism $\Z\times \Z\cong  \Z \times \Z \times \Z$}. This is why we must require $N_i \cap \prod_{j\neq i}N_j=1$ in the definition internal direct product.  
\end{Example}
\begin{Example}{Subgroups are not products of intersections.}{sa}
In general, we don't have 
\begin{align*}
H \leq G_1 \times \cdots \times G_k \implies H = (G_1 \cap  H) \times \cdots \times (G_k \cap H)
\end{align*}
even in the category of abelian group. For example, consider $H \triangleq \set{(x,x)\in \Z^2 : x \inz}$. 
\end{Example}


\section{Structure Theorem for Finitely Generated Abelian Groups}

\begin{theorem}
\label{THcob}
\textbf{(Change of basis for finitely generated abelian group)} Let $k\inn$, $G= \langle x_1,\dots ,x_k\rangle $ be abelian and $c_1,\dots ,c_k \inn$ satisfies $\operatorname{gcd}(c_1,\dots ,c_k)=1$. Then there exists $y_1,\dots ,y_k \in G$ such that $G=\langle y_1,\dots ,y_k\rangle $ and $y_1=c_1x_1+\cdots + c_kx_k$. 
\end{theorem}
\begin{proof}
Such is proved via induction on $s\triangleq c_1 + \cdots + c_k$. The base case $s=k$ is clear. We now prove the inductive case. Because $\operatorname{gcd}(c_1,\dots ,c_k)=1$, by changing the order if necessary, we may write $c_1  > c_2 $. Now, because $\operatorname{gcd}(c_1-c_2,c_2,\dots,c_k)=1$ and $G= \langle x_1,x_2-x_1,x_3,\dots ,x_k\rangle $, we see by inductive hypothesis that there exists $y_1,\dots ,y_k$ such that $G=\langle y_1,\dots ,y_k\rangle $ and 
\begin{align*}
y_1&= (c_1 -c_2)x_1 + c_2(x_2+x_1) + \cdots + c_k x_k \\
&=c_1 x_1 + \cdots + c_kx_k
\end{align*}
as desired. 
\end{proof}
\begin{theorem}
\label{THfgag}
\textbf{(Structure theorem for finitely generated abelian group)} Let $G$ be a finitely generated abelian group. Then we may write: 
\begin{align*}
G  \cong  C_{n_1} \times \cdots \times C_{n_s} \times \Z^{r}
\end{align*}
for $n_i \geq 2$. Moreover, we know that 
\begin{enumerate}[label=(\roman*)]
  \item Such $r$ is unique, called the \textbf{rank} of $G$.  
  \item Under the assumption that $n_i$ each is a power of some prime, the expression exists and is unique, called the \textbf{primary decomposition form}.  
  \item Under the assumption that $n_i \mid n_{i+1}$ for all $i$, the expression exists and is unique, called the  \textbf{invariant factor form}. 
\end{enumerate}
\end{theorem}
\begin{proof}
We first show the \vi{existence} via induction on the number of generators. The base case is clear. Suppose that the existence holds true for any abelian group that has a generating set of cardinality $k-1$, and suppose that $G$ has a generating set $\set{x_1,\dots ,x_k}$ where $x_1$ has order smaller than any elements of any generating sets of cardinality $k$. \\

By inductive hypothesis, we only have to show that $G$ is an internal direct product of $\langle x_1\rangle $ and $\langle x_2,\dots ,x_k\rangle $. Assume not for a contradiction. Then there exists $m_1 \neq 0$ such that $m_1x_1+m_2x_2+ \cdots + m_kx_k=0$. By possibly changing sign of some of the $x_i$ and exchanging the order, we may suppose  $m_1< o(x_1)$ and $m_1,\dots ,m_t\inn$ and $m_{t+1}=\cdots = m_k=0$.\\

Let $c_i \triangleq \frac{m_i}{\operatorname{gcd}(m_1,\dots ,m_t)}$ for all $i \in \set{1,\dots ,t}$. By \myref{theorem}{THcob}, we know there exists $y_1,\dots ,y_t \in G$ such that $\langle y_1,\dots ,y_t\rangle = \langle x_1,\dots ,x_t\rangle $ with $y_1= c_1 x_1+ \cdots + c_t x_t$. Clearly, we have $G= \langle y_1,\dots ,y_t,x_{t+1},\dots ,x_k\rangle $. Compute 
\begin{align*}
\operatorname{gcd}(m_1, \dots, m_t) y_1= m_1 x_1 + \cdots + m_t x_t=0
\end{align*}
We now see $o(y_1) \leq m_1 < o(x_1)$, a contradiction to the choice that $x_1$ has the smallest order. $\vdone$ \\

(i): Fix an expression of $G$, and let $p$ be a prime that satisfies  $p \nmid n_i$ for all $i$. The rest then follows from checking that $G \quotient pG \cong  C_p^r$. \\ 


(ii): The existence follows from noting that 
\begin{align*}
\operatorname{gcd}(m,n)=1 \implies    C_{mn}\cong  C_m \times C_n
\end{align*}
The uniqueness follows from noting that given a primary decomposition form whose $p$-part has the form  $C_{p^{n_1}} \times \cdots \times C_{p^{n_k}}$, then the \textbf{torsion $p$-subgroup} $G_{T_p}$ of $G$ 
\begin{align*}
G_{T_p} \triangleq \set{x \in G: o(x)=p^n\text{ for some }n\geq 0}
\end{align*}
is 
\begin{align*}
G_{T_p} \cong  C_{p^{n_1}}\times \cdots \times C_{p^{n_k}}
\end{align*}
and that 
\begin{align*}
  \frac{p^{d-1}C_{p^{n_i}}}{p^{d}C_{p^{n_i}}}\cong \begin{cases}
    C_p & \text{ if }d-1 <n_i \\
    1& \text{ if }d-1 \geq n_i
  \end{cases}
\end{align*}
(iii): Both the existence and uniqueness of invariant factor form follows form that of primary decomposition form: Just consider that $C_{n_s}$ can only be $C_{p_1}^{d_1}\times \cdots \times C_{p_m}^{d_m}$, where $p_i$ non-repeatedly running through all the occurring prime with $d_i$ being the highest exponential.  
\end{proof}
\customref{THfgag}{Structure theorem for finitely generated abelian group} in fact also gives a structure theorem for automorphism group of finite abelian group. See \href{https://arxiv.org/pdf/math/0605185}{this paper}. A particular case is that 
\begin{align*}
\operatorname{Aut}(C_p^n)\cong \operatorname{GL}_n(\F_p) 
\end{align*}
\begin{corollary}
\label{COfao}
\textbf{(Finite abelian group has subgroups of all possible order)} Let $G$ be a finite abelian group with $m \mid  o(G)$. Then there exists subgroup of $G$ of order  $m$.  
\end{corollary}
\begin{proof}
The proof follows from the \customref{THfgag}{primary decomposition form} and the fact that for all $e<d\inn \cup  \set{0}$,  
\begin{align*}
\set{0,p^{d-e},\dots ,(p^e -1)p^{d-e}}\subseteq C_{p^{d}}
\end{align*}
is a subgroup of $C_{p^d}$ of order $p^e$. 
\end{proof}
\begin{theorem}
\textbf{(Subgroup of finitely generated abelian group)} Let $G$ be a finitely generated abelian group that has rank $r$ whose $p$-part is  
\begin{align*}
G_{T_p} \cong  C_{p^{n_1}}\times \cdots \times C_{p^{n_k}},\quad \text{ with }n_1 \geq \cdots \geq  n_k
\end{align*}
Then for any subgroup $H \leq G$, if we write 
\begin{align*}
H_{T_p}\cong  C_{p^{d_1}}\times \cdots \times C_{p^{d_s}},\quad \text{ with }d_1 \geq \cdots \geq  d_s
\end{align*}
then the rank of $H$ is  $\leq r$, and we have $s \leq k$ and $n_i \geq d_i$ for all $i$. 
\end{theorem}
\begin{proof}
Clearly we have $H_{T_p}\leq G_{T_p}$. Consider $\Omega_1 (H_{T_p})\triangleq  \set{h \in H_{T_p}: h^p=e}$. Clearly, we have 
\begin{align*}
C_p^s \cong  \Omega_1(H_{T_p}) \leq \Omega_1 (G_{T_p}) \cong  C_p^k
\end{align*}
Therefore, by counting order, we see that indeed $s\leq k$. The rest is 
\begin{align*}
C_{p}^{\operatorname{card}\set{\geq d_i}}\cong  \Omega_1 (p^{d_i-1}H_{T_p}) \leq  \Omega_1 (p^{d_i-1}G_{T_p}) \cong  C_p^{\operatorname{card}\set{\geq d_i}}
\end{align*}
We now prove that $H$ has rank  $\leq r$. Let $t$ be the rank of $H$ and $q$ be a prime not in the decomposition. Since 
\begin{align*}
\Z^t \cong  qH \leq qG \cong  \Z^r
\end{align*}
We have an injective group homomorphism $f:\Z^t\rightarrow \Z^r$. Denote the group homomorphism by a $r$-by-$t$ matrix $A\in M_{r \times t}(\Z)$. The injectivity of $f$ then means $Av=0 \implies  v=0$ for all $v\in \Z^s$. Let $w \in \Q^t$ and $m \gg 0$ be a natural number large enough so that $mw \in \Z^t$. We then see 
\begin{align*}
Aw=0 \implies Amw=mAw=0 \implies  mw=0 \implies  w=0 
\end{align*}
In other words, the matrix $A \in M_{r \times t}(\Q)$ has rank $r$, which is only possible given that  $t \leq r$. 
\end{proof}
\section{Sylow theorems}
\label{SECSt}
In this section, we prove \customref{THfSt}{Sylow theorems} using combinatorics. Note that \customref{THfSt}{first Sylow theorem} also shows that indeed as one might expect: \customref{COepc}{Every $p$-subgroup of a finite group is a subgroup of some Sylow  $p$-subgroup}. 
\begin{theorem}
\label{THCf}
\textbf{(Combinatorial facts)} Let $p$ be prime. Then: 
\begin{enumerate}[label=(\roman*)]
  \item Given $m\geq r \inn \cup \set{0}$ with $t\inn$ coprime with $p$, the natural number $\binom{p^mt}{p^r}$ has $p$-part  $p^{m-r}$.  
  \item We have 
\begin{align*}
\binom{m}{n} \equiv \prod_{i=0}^k \binom{m_i}{n_i}\pmod{p}
\end{align*}
when we write $m=m_kp^k + \cdots + m_0p^0$ and $n=n_kp^k + \cdots + n_0p^0$.  This is called \textbf{Lucas modulo binomial formula}. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (i) follows from noting that 
\begin{align*}
\binom{p^mt}{p^r}= \frac{p^mt (p^mt-1)\cdots (p^mt-(p^r-1))}{p^r (p^r -1)\cdots (p^r - (p^r-1))}
\end{align*}
and that for all $i \in \set{1,\dots ,p^r-1}$, the three natural number $\set{i,p^mt-i,p^r-i}$ share the same $p$-part.\\

(ii): Let $M$ be a set of  $m$ elements. Partition $M$ into $m_i$ cycles of length  $p^i$, i.e., 
 \begin{align*}
M \triangleq \bigcup_{i=0}^k \bigcup_{j=1}^{m_i} \Gamma _{i,j},\quad \text{ where }\abso{\Gamma _{i,j}}=p^i 
\end{align*}
Because of such, we see that $M$ can be acted on by the group 
\begin{align*}
G\triangleq \prod_{i=0}^k \overbrace{C_{p^i} \times \cdots \times C_{p^i}}^{m_i}
\end{align*}
Clearly, $G$ also acts on the set $X$ of the set of subsets of  $M$ that has  $n$ elements.  Because $G$ is a $p$-group, \customref{THost}{orbit-stabilizer theorem} tell us that 
\begin{align*}
\binom{m}{n}= \abso{X} \equiv \abso{\operatorname{Fix}(G)}\pmod{p}
\end{align*}
where $\operatorname{Fix}(G)$ is the set of elements of $X$ fixed by all $g \in G$. Because of uniqueness of representation in base $p$, we know that elements of $\operatorname{Fix}(G)$ are exactly those subsets of $X$ that contains $n_i$ cycles of length $p^i$. The proof now follows from directly computing that $\abso{\operatorname{Fix}(G)}= \prod_{i=0}^k \binom{m_i}{n_i}$. 
\end{proof}
\begin{theorem}
\label{THfSt}
\textbf{(First and Third Sylow theorem, Wielandt's proof)} Let $G$ be a finite group of order $p^mt$ with $\operatorname{gcd}(p,t)=1$. Let $1\leq r\leq m$. Then the number $n_p$ of $p$-subgroup with order $p^r$ satisfies 
\begin{align*}
n_p \equiv 1 \pmod{p}
\end{align*}
\end{theorem}
\begin{proof}
Let $X$ be the set of subset of  $G$ with cardinality $p^r$. Our goal is to find all elements of $X$ that forms a group. Clearly we may define a left $G$-action on  $X$ be setting 
 \begin{align*}
g \cdot \set{x_1,\dots ,x_{p^r}} \triangleq \set{gx_1,\dots ,gx_{p^r}}
\end{align*}
Let $\Gamma $ be an orbit. If $\Gamma $ contains a group, then we see that $\Gamma $ is the left coset space of that group,  containing exactly one group and satisfying $\abso{\Gamma }=p^{m-r}t$. If $\Gamma $ doesn't contain any group, there still exists some $S \in \Gamma $ such that $e \in S$, and clearly we will have $\operatorname{Stab}(S)\subseteq S$. Because $S$ isn't a group, we see  $p^r=\abso{S}>o(\operatorname{Stab}(S))$, which by \customref{THost}{orbit-stabilizer theorem} implies that $\abso{\Gamma }= [G: \operatorname{Stab}(S)]=p^{m-r+c}t$ for some $c\geq 1$. \\

In summary, by counting orbit, we have shown that: 
\begin{align*}
\binom{p^mt}{p^r} = \abso{X} = n_pp^{m-r}t + l p^{m-r+1}t ,\quad \text{ for some }l \inn
\end{align*}
Let $ut \equiv 1 \pmod{p}$. \customref{THCf}{Recalling that $\binom{p^mt}{p^r}$ has  $p$-power  $p^{m-r}$}, it remains to show 
\begin{align*}
u \cdot \frac{\binom{p^mt}{p^r}}{p^{m-r}}\equiv 1 \pmod{p}
\end{align*}
which follows from noting: 
\begin{align*}
u \cdot \frac{\binom{p^mt}{p^r}}{p^{m-r}}= ut \cdot \binom{p^mt-1}{p^r-1}  \equiv\binom{p^{m}t-1}{p^{r}-1}\equiv 1 \pmod{p}
\end{align*}
where the last equality follows from \customref{THCf}{Lucas modulo binomial formula} and the observation that 
\begin{align*}
p^mt-1 = t_kp^{m+k} + \cdots + (t_0-1)p^m + (p-1) p^{m-1} + \cdots + (p-1)p^0
\end{align*}
where $t=t_kp^k + \cdots + t_0 p^0$ with $t_0>0$.  
\end{proof}
\begin{corollary}
\label{COepc}
\textbf{(Every $p$-subgroup is contained by some Sylow $p$-subgroup)} Let $G$ be a finite group and $H\leq G$ a $p$-group. Then $H$ must be contained by some Sylow $p$-subgroup of $G$. 
\end{corollary}
\begin{proof}
Consider the conjugacy action $H \longrightarrow \operatorname{Bij}\left(\operatorname{Syl}_p(G) \right)$. \customref{THfSt}{First Sylow theorem} and \customref{THost}{orbit-stabilizer theorem} shows that there must be a singleton orbit. Let that singleton be $P$.\\

We claim $H\leq P$. Because $\set{P}$ is a singleton orbit of the conjugacy action, we know $H \leq N_G(P)$. Then by \customref{THsitg}{second isomorphism theorem}, we see that $HP$ is a group such that  $HP \quotient P\cong  H \quotient  H \cap P$. This implies that $HP$ is a  $p$-group. The fact $HP$ contains $P$ forces $P=HP$, which implies $H \leq P$. 
\end{proof}
Before \customref{THsSt}{proving Second Sylow theorem}, we need a lemma for actions of $p$-groups. 
\begin{lemma}
\label{THcl}
\textbf{(Counting lemma for $p$-group)} Let $G$ be a  $p$-group acting on a finite set $X$. Then 
\begin{align*}
\abso{X} \equiv \abso{\operatorname{Fix}(G)} \pmod{p}
\end{align*}
where $\operatorname{Fix}(G) \triangleq \set{x \in X: gx=x\text{ for all }g\in G}$ is the set of points fixed by all $g  \in G$.  
\end{lemma}
\begin{proof}
This is a consequence of \customref{THost}{orbit-stabilizer theorem}. 
\end{proof}
\begin{theorem}
\label{THsSt}
\textbf{(Second Sylow theorem)} Sylow $p$-subgroups are conjugated to each other.    
\end{theorem}
\begin{proof}
Let $H$ and $P$ be two Sylow $p$-subgroups of $G$, and let $H$ acts on left coset space of  $P$ by left multiplication. Because $P$ is Sylow, by \customref{THcl}{counting lemma for $p$-group}, we know the number of fixed points $gP$ is nonzero. Let $gP$ be a fixed point. We then see that, as desired, $g^{-1}hg  \in P$ for all $h \in H$, since  $hgP=gP$. 
\end{proof}
Even without \customref{THtSt}{third Sylow theorem}, \customref{THsSt}{second Sylow theorem} already gives some interesting applications.   
\begin{corollary}
\label{COnoS}
\textbf{(Normalizers of Sylow subgroups Don't satisfy normalizer condition)} Let $G$ be a finite group and  $P \in \operatorname{Syl}_p(G)$. Then 
\begin{align*}
N_G(P)=N_G(N_G(P))
\end{align*}
\end{corollary}
\begin{proof}
Let $x \in N_G(N_G(P))$. We are required to show $x \in N_G(P)$. By definition, we have 
\begin{align*}
xPx^{-1}\leq xN_G(P)x^{-1} =N_G(P)
\end{align*}
In other words, both $P$ and  $xPx^{-1}$ are Sylow $p$-subgroup of  $N_G(P)$. Therefore, by \customref{THsSt}{second Sylow theorem}, there exists some $y \in N_G(P)$ such that 
 \begin{align*}
xPx^{-1}=yPy^{-1}=P
\end{align*}
This then implies $x \in N_G(P)$. 
\end{proof}
\begin{corollary}
\textbf{(Restriction of conjugacy classes onto normalizer of Sylow subgroups, on element of center of Sylow subgroups)} Let $G$ be a finite group, $P \in \operatorname{Syl}_p(G)$, and $a,b \in Z(P)$. If  $a,b$ are conjugate in  $G$, then they are conjugate in  $N_G(P)$. 
\end{corollary}
\begin{proof}
Write $b=xax^{-1}$ with $x \in G$. By definition, we have 
\begin{align*}
  (x^{-1}gx)a (x^{-1}gx)^{-1}= x^{-1}gbg^{-1}x= x^{-1}bx = a,\quad \text{ for all }g \in P
\end{align*}
In other words, $x^{-1}Px \leq C_G(a)$. Then since both  $P$ and  $x^{-1}Px$ are Sylow $p$-subgroup of $C_G(a)$, by \customref{THsSt}{second Sylow theorem}, we know there exists $y \in C_G(a)$ such that $P=y^{-1}x^{-1}Pxy$. We now see that $xy \in N_G(P)$ and $(xy)a(xy)^{-1}=b$, as desired.      
\end{proof}
\customref{THsSt}{Second Sylow theorem} moreover stated that given $n_p>1$, the conjugacy action $G \longrightarrow  \operatorname{Bij}(\operatorname{Syl}_p(G))\cong  S_{n_p}$ is nontrivial, and thus injective when $G$ is simple. This is a trick particularly useful to classify finite simple group. 

\begin{theorem}
\label{THtSt}
\textbf{(Remaining part of third  Sylow theorem)} Let $G$ be a finite group, and let $n_p$ be the number of Sylow  $p$-subgroup of  $G$. For all Sylow  $p$-subgroup $P$ of  $G$, we have 
 \begin{align*}
n_p =  [G:N_G(P)]
\end{align*}
\end{theorem}
\begin{proof}
This is a consequence of \customref{THsSt}{second Sylow theorem} and \customref{THost}{orbit stabilizer theorem}, where we note that when $G$ acts on  $\operatorname{Syl}_p(G)$ by conjugation we have $\operatorname{Stab}(P)=N_G(P)$. 
\end{proof}
\section{Nilpotency and Solvability}
A \textbf{normal series} of a group $G$ is a finite chain of subgroups: 
\begin{align*}
1 \trianglelefteq \cdots \trianglelefteq  G_{n-1}    \trianglelefteq G_n \trianglelefteq G_{n+1} \trianglelefteq \cdots \trianglelefteq  G
\end{align*}
where each $G_n$ is normal only $G_{n+1}$, but not necessarily $G$. A \textbf{composition series} is a maximal normal series. 
\begin{Example}{Subgroups in normal series need not all be normal}{}
Consider 
\begin{align*}
 D_4 \triangleq \langle r,s \mid r^4=s^2=e,srs^{-1}=r^{-1} \rangle 
\end{align*}
We have normal series  
\begin{align*}
\langle s\rangle  \trianglelefteq \langle s,r^2\rangle  \trianglelefteq D_4
\end{align*}
where normality follows from index $2$. Clearly $\langle s\rangle $ is not normal in $D_4$.   
\end{Example}
\begin{equiv_def}
\textbf{(Solvable groups)} We say a group $G$ is \textbf{solvable} if any of the followings holds true: 
\begin{enumerate}[label=(\roman*)]
  \item $G$ admits a finite normal series whose factor  groups are all abelian. 
  \item The \textbf{derived series}
\begin{align*}
\cdots \trianglelefteq  G^{(2)} \trianglelefteq G^{(1)}\trianglelefteq G^{(0)} \triangleq  G,\quad \text{ where }G^{(k+1)}\triangleq \langle [G^{(k)},G^{(k)}]\rangle 
\end{align*}
reach to $1$. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
Routine. Note that if $1=G_n \trianglelefteq \cdots \trianglelefteq G_0 =G$ is a normal series whose factor groups are all abelian, then clearly we have $G^{(k)}\leq G_k$. 
\end{proof}
Clearly, solvable groups are closed under \textbf{group extension}. Given a short exact sequence of groups 
\begin{align*}
1 \longrightarrow A \longrightarrow G \longrightarrow B \longrightarrow 1
\end{align*}
If $A$ and $B$ are  both solvable, then $G$ is solvable. Conversely, let $G$ be solvable and $H\leq G$. Then clearly   
\begin{align*}
1= G^{(n)}\cap  H \trianglelefteq   \cdots \trianglelefteq  G^{(1)} \cap H \trianglelefteq  H 
\end{align*}
is normal series whose factor groups are all abelian. Because of such, we say solvable groups are \textbf{subgroup-closed}. Let $N\trianglelefteq G$ and $\pi : G \rightarrow G \quotient N$ be the natural projection. Since $\pi  \left(G^{(k)}\right)$ is the derived series of $G \quotient N$, we see that solvable groups are also \textbf{quotient-closed}. Since \customref{THcgi}{taking direct product and taking commutator subgroup commutes}, we moreover have 
\begin{align*}
\left(\prod_{i=1}^nG_i \right)^{(k)}  =\prod_{i=1}^n G_i^{(k)}
\end{align*}
Therefore, solvable groups are also \textbf{finite direct product-closed}. 
\begin{equiv_def}
\textbf{(Finite solvable groups)} A finite group $G$ is solvable if and only if it admits a composition series whose factor group are all cyclic of prime order. 
\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}

\begin{equiv_def}
\textbf{(Nilpotent groups)} We call a group $G$ \textbf{nilpotent} if $G$ admits a  \textbf{central series}, a normal series: 
\begin{align*}
1=G_0 \trianglelefteq \cdots \trianglelefteq G_n =G 
\end{align*}
such that 
\begin{align*}
[G,G_{k}]\leq G_{k-1},\quad \text{ for all }k \in \set{1,\dots ,n}
\end{align*}
Clearly, all $G_k$ are normal in  $G$. Given a series of normal subgroups, we then clearly see that it is central if and only if 
\begin{align*}
 \frac{G_{k}}{G_{k-1}} \leq Z\left(\frac{G}{G_{k-1}} \right),\quad \text{ for all }k\in \set{1,\dots ,n}
\end{align*}
A group is nilpotent if and only if its \textbf{lower central series}: 
\begin{align*}
\cdots \trianglelefteq G_{(2)} \trianglelefteq  G_{(1)}\trianglelefteq G_{(0)}\triangleq  G,\quad \text{ where }G_{(k)}\triangleq  [G,G_{(k-1)}]\text{ for all }k\inn
\end{align*}
reach to $1$. A group is  nilpotent if and only if its \textbf{upper central series}: 
\begin{align*}
  1\triangleq Z_{(0)}\trianglelefteq  Z_{(1)} \trianglelefteq  Z_{(2)} \trianglelefteq  \cdots, \quad \text{ where } \frac{Z_{(k+1)}}{Z_{(k)}} \triangleq Z\left(\frac{G}{Z_{(k)}} \right)\text{ for all }k\inn
\end{align*}
reach to $G$. The central series $1=G_0 \triangleleft \cdots \triangleleft G_n =G$ is said to have \textbf{length} $n$. The \textbf{nilpotency class} of a nilpotent group is the smallest length of its central series. If a group is nilpotent, then both its lower and upper central series has length of its nilpotent class.  
\end{equiv_def}
\begin{proof}
Clearly both lower and upper central series are central by definition. Suppose a central series 
\begin{align*}
1=G_0 \trianglelefteq \cdots \trianglelefteq G_n =G 
\end{align*}
exists. To see the lower central series reach to $1$ with smallest length, use induction to show  $G_{(k)}\leq G_{n-k}$ for all $k$. (thus the name \textbf{fastest descending series}). To see the upper central series reach to $G$ with smallest length, use induction to show $G_k \leq Z_{(k)}$ for all $k$. (thus the name \textbf{fastest ascending series}) 
\end{proof}
Clearly, every nilpotent group is solvable, but solvable group need not be nilpotent.  
\begin{Example}{A solvable group that isn't nilpotent}{}
Consider $S_3$. Because $S_3$ is the extension of  $C_3$ and  $C_2$: 
 \begin{align*}
1 \longrightarrow A_3 \longrightarrow S_3 \longrightarrow C_2 \longrightarrow 1
\end{align*}
We know $S_3$ is solvable. However, since $S_3$ clearly has $3$ Sylow $2$-subgroups and \customref{EDfng}{finite nilpotent group has normal Sylow subgroups}, we know $S_3$ isn't nilpotent.  
\end{Example}

Again, one can check that central series are closed under taking intersection with a subgroup, under taking finite direct product and under surjective group homomorphism, so nilpotency is also subgroup-closed, quotient-closed and finite-direct-product-closed. 
\begin{theorem}
\label{THsnnc}
\textbf{(Proper subgroups of nilpotent groups satisfy normalizer condition)} If $G$ is nilpotent, then any $H<G$ satisfies normalizer condition.  
\end{theorem}
\begin{proof}
Note that if $H$ doesn't contain $Z(G)$, then the elements of $Z(G)$ that lies outside $H$ complete the proof, so we only have to consider the case $Z(G)\leq H$.\\

This is proved by induction on nilpotency class $n$ of $G$. The base case $n=1$ is clear. The inductive case follows from \customref{THtit}{third isomorphism theorem for groups} and the observation $G \quotient Z(G)$ has the nilpotent class one smaller than that of $G$.
\end{proof}
\begin{theorem}
\label{THpp}
\textbf{(Properties of finite $p$-groups)} Let $P$ be a finite $p$-group. Then:  
\begin{enumerate}[label=(\roman*)]
  \item $P$ has nontrivial center. 
  \item $P$ is nilpotent.  
  \item Groups of order $p^2$ is either $C_p\times C_p$ or $C_{p^2}$.  
  \item Groups of order $p^3$, if not abelian, must satisfies $o(Z(G))=p$ and $Z(G)=G^{(1)}$.  
  \item Nontrivial normal subgroup $1 < N \trianglelefteq P$ satisfies $N \cap Z(P)>1$.  
\end{enumerate}
\end{theorem}
\begin{proof}
  (i) is a consequence of \customref{THce}{class equation}. Both (ii) and (iii) follows from (i). If the center of a group of order $p^2$ has order $p$, then \customref{EDAg}{a contradiction about abelian occurs}. Let $G$ be a group of order $p^3$. The fact $o(Z(G))=p$ also follows from (i) and \customref{EDAg}{same abelian contradiction}. The fact $G^{(1)}=Z(G)$ follows from \customref{EDAg}{definition of abelian group} and the fact that (ii) implies $G \quotient Z(G)$ is abelian. We have shown (iv).\\

Lastly, we prove (v). Let $P$ acts on $N$ by conjugation. By \customref{THcl}{our counting lemma for $p$-group}, we have 
\begin{align*}
0 \equiv o(N) \equiv \abso{\set{n \in N: gng^{-1}=n\text{ for all } g \in P}} \pmod{p} 
\end{align*}
Noting that the latter set $=N \cap Z(P)$, we now see $N \cap Z(P)>1$. 
\end{proof}
\begin{Example}{Infinite $p$-group}{}
The \textbf{Prfer group} $\Z(p^{\infty})$ is defined by 
\begin{align*}
\Z(p^{\infty})\triangleq \set{\exp (2\pi i m \quotient p^n)\inc: m \inz\text{ and }n\inn }
\end{align*}
It is an infinite group whose every nontrivial element has order $p^n$ for some  $n\inn$.    
\end{Example}

\begin{equiv_def}
\label{EDfng}
\textbf{(Finite nilpotent group)} Let $G$ be a finite group. The followings are equivalent: 
\begin{enumerate}[label=(\roman*)]
  \item $G$ is nilpotent.  
  \item Proper subgroups of $G$ satisfies normalizer condition.
  \item Sylow subgroups of $G$ are all normal. 
  \item  $G$ is the internal direct product of its Sylow subgroups. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
(i)$\implies $(ii): \customref{THsnnc}{This is true even if $G$ is infinite}.\\


(ii)$\implies $(iii): If $G$ is a  $p$-group, then the proof is trivial. Let $G$ not be a $p$-group and let  $P \in \operatorname{Syl}_p(G)$. To see $P$ is normal, just observe that since \customref{COnoS}{normalizers of Sylow subgroups don't satisfy normalizer condition}, the normalizer of $P$ must be  $G$. \\

(iii)$\implies $(iv): This follows from \customref{EDdpfg}{the definition of finite internal direct product}. \\

(iv)$\implies $(i): This follows from the fact that \customref{THpp}{$p$-groups is nilpotent} and that nilpotency is closed under taking finite direct product. 
\end{proof}
\section{Old Numbers}
\begin{abstract}
This section proves some elementary number theory that are in essence group theory. 
\end{abstract}
\begin{theorem}
\textbf{(Group property of totient function)} Let $\pfi $ be the Euler totient function. Then 
\begin{align*}
n \mid \pfi (a^n-1),\quad \text{ for all }a,n \inn
\end{align*}
\end{theorem}
\begin{proof}
This is a consequence of the fact that $a \in \Z_{a^n-1}^{\times}$ and  that $a$ has order $n$ in the group.  
\end{proof}
Before the first application, we first show that:  
\begin{theorem}
\label{THzpc}
\textbf{($\Z_p^{\times}$ is cyclic)} Let $p$ be prime. Then the unit group $\Z_p^{\times}$ is cyclic. 
\end{theorem}
\begin{proof}
We are required to show the existence of elements of order $p-1$. Let $l$ be the least common multiple of orders of all elements, so $x^l-1\in \Z_p[x]$ has $p-1$ distinct roots in  $\Z_p$. This implies  $l\geq p-1$. Because the group is abelian, we now see from \customref{THfgag}{its primary decomposition form} that indeed it is cyclic.  
\end{proof}
\begin{theorem}
\label{THWt}
\textbf{(Group theoretic side of Wilson's theorem)} Let $p$ be prime. Then 
\begin{align*}
(p-1)! \equiv -1\pmod{p}
\end{align*}
\end{theorem}
\begin{proof}
Consider the symmetric group $S_p$. The proof follows from $n_p \equiv 1\pmod{p}$ and directly counting that $n_p=(p-2)!$. This is easy to count, since the Sylow $p$-group of  $S_p$ are those generated by a single  $p$-cycle.   
\end{proof}
\begin{theorem}
\textbf{(Wolstenholme's theorem)} Let $p$ be an odd prime, and write 
\begin{align*}
H(p-1)\triangleq 1+ \frac{1}{2} + \cdots + \frac{1}{p-1}    \inq
\end{align*}
Then
\begin{align*}
H(p-1) \equiv 0\pmod{p^2}
\end{align*}
\end{theorem}
\begin{proof}
Because $p$ is odd, we can group the terms of $H(p-1)$ by pairs: 
\begin{align*}
H(p-1)= \left( 1+ \frac{1}{p-1} \right) + \left( \frac{1}{2} + \frac{1}{p-2} \right) + \cdots + \left( \frac{1}{\frac{p-1}{2}} + \frac{1}{p - \frac{p-1}{2}}\right)   
\end{align*}
Reduce each pair to a common denominator: 
\begin{align*}
H(p-1)= \frac{p}{p-1}+ \frac{p}{2(p-2)}+ \cdots + \frac{p}{\frac{p-1}{2}\cdot \left(p- \frac{p-1}{2} \right)}
\end{align*}
We then can write 
\begin{align}
\label{EQHp1}
H(p-1)\triangleq  p \cdot \frac{A}{(p-1)!}
\end{align}
where 
\begin{align*}
A\triangleq  \frac{(p-1)!}{p-1} + \frac{(p-1)!}{2(p-2)} + \cdots + \frac{(p-1)!}{\frac{p-1}{2}\cdot (p- \frac{p-1}{2})}
\end{align*}
Since $p\nmid  (p-1)!$, \myref{equation}{EQHp1} reduce the proof into proving $p \mid  A$. We first show that 
\begin{center}
   \begin{minipage}{0.9\linewidth}  
\vi{$\frac{(p-1)!}{a (p-a)} \equiv a^{-2}\pmod{p}$, for $a \in \set{1,\dots ,p-1}$, where the power $a^{-2}$ occurs in the cyclic group $\Z_p^\times\cong  C_{p-1}$.   }
   \end{minipage}
\end{center}
Denote $x \triangleq \frac{(p-1)!}{a(p-a)}\inz$, so by \customref{THWt}{Wilson's theorem}, we have 
\begin{align*}
a(p-a)x=(p-1)! \equiv -1\pmod{p}
\end{align*}
which gives us 
\begin{align*}
a^2x \equiv 1 \pmod{p} \vdone
\end{align*}
We may now write 
\begin{align*}
A \equiv 1^{-2} + \cdots + \left(\frac{p-1}{2}  \right)^{-2} \pmod{p}
\end{align*}
Because $p$ is odd, we only have to prove $2A \equiv 0\pmod{p}$: 
\begin{align*}
  2A&\equiv 1^{-2} + \cdots + \left(\frac{p-1}{2}  \right)^{-2} + 1^{-2} + \cdots + \left(\frac{p-1}{2}  \right)^{-2}  \\
  &\equiv   1^{-2} + \cdots + \left(\frac{p-1}{2}  \right)^{-2}  + (-1)^{-2} + \cdots + \left(-\frac{p-1}{2} \right)^{-2} \\
  &\equiv 1^{-2} + \cdots + \left(\frac{p-1}{2} \right)^{-2} + \left(\frac{p+1}{2} \right)^{-2} + \cdots + \left(p-1 \right)^{-2} 
\end{align*}
Since the inversion $x\mapsto x^{-1}$ forms a bijection in $\Z_p^{\times}$. Therefore, we have 
\begin{align*}
  2A &\equiv 1^2 + \cdots + (p-1)^2  \\
  &= \frac{p(p-1)(2p-1)}{6} \equiv 0 \pmod{p}
\end{align*}
\end{proof}
\section{Symmetric Groups}
\begin{abstract}
This section develop some common sense about symmetric groups.  
\end{abstract}
Given the \textbf{symmetric group} $S_n$, to define parity, the fastest way is to realize it as the  \textbf{group of permutation matrix}, and then call those that have determinant $1$  \textbf{even}, while those that have determinant  $-1$  \textbf{odd}. Clearly we have the \textbf{alternating group}
\begin{align*}
A_n \triangleq \set{g \in S_n: \operatorname{det}(g)=1}
\end{align*}
To see that  $[S_n:A_n]=2$ for all $n\geq 2$, just consider that for any $g\in S_n - A_n$, we have a bijection between $A_n$ and  $S_n- A_n$ defined by  
\begin{align*}
a \mapsto  ag
\end{align*}
By direct observation, we see that every permutation has a fixed \textbf{cycle type}.     Because  
\begin{align*}
\sigma \circ (a_1,\dots ,a_k) \circ \sigma^{-1} = \left(\sigma (a_1),\dots ,\sigma (a_k)\right)
\end{align*}
we see that the conjugacy classes of $S_n$ coincides with cycle type classes. \\

At this point, it is worth mentioning that, given $g \in S_n$, even though we are definitely aware of what its centralizer is, in the sense that given any $h \in S_n$, we can immediately tell whether $h \in C_{S_n}(g)$, but to actually describe $C_{S_n}(g)$ may be annoying. See this \href{https://math.stackexchange.com/questions/208790/centralizer-of-a-given-element-in-s-n}{MSE post}. 
\begin{Example}{Conjugacy classes of $A_n$ are either half a cycle type or all.}{}
Recall that conjugacy classes is just the orbit of conjugacy action, and \customref{THost}{orbit-stabilizer theorem} links the orbit $\Gamma $ of an element $x$ with its stabilizer group by
\begin{align*}
\abso{\Gamma } = [G:\operatorname{Stab}(x)]
\end{align*}
Now, since we clearly have 
\begin{align*}
\operatorname{Stab}_{A_n}(x)= A_n \cap \operatorname{Stab}_{S_n}(x)
\end{align*}
if $\operatorname{Stab}_{S_n}(x)\leq A_n$, then the conjugacy class of $x$ in $A_n$ is the half of its conjugacy class in $S_n$. On the other hand, if $\operatorname{Stab}_{S_n}(x)\not \leq A_n$, then since $A_n\cdot \operatorname{Stab}_{S_n}(x)=S_n$, by \customref{THof}{order formula}, we know $[A_n:\operatorname{Stab}_{A_n}(x)]=[S_n:\operatorname{Stab}_{S_n}(x)]$, which implies that the conjugacy class of $x$ in $A_n$ is the same as  in  $S_n$. 
\end{Example}
\begin{theorem}
\label{THzSn}
\textbf{($S_n$ is centerless for $n\geq 3$)} Let $n \geq 3$. Then $Z(S_n)=1$.
\end{theorem}
\begin{proof}
Let $\tau \neq e\in S_n$. Because $\tau$ is nontrivial, we know $\tau (i)=j$ for some $i \neq j$. Let $\sigma (i)=i$ and $\sigma (j) \neq j$. We now see $\sigma \circ \tau \circ \sigma^{-1}\neq \tau$, as desired. 
\end{proof}
\begin{theorem}
\label{THgos}
\textbf{(Generators of $S_n$)} Let $n\geq 2$. Then $S_n$ can be generated by any of the followings: 
\begin{enumerate}[label=(\roman*)]
  \item transpositions.
  \item  $\set{(1,k) \in S_n : 2 \leq k \leq n}$. 
  \item  $\set{(1,2),(1,\dots ,n)}$.
\end{enumerate}
\end{theorem}
\begin{proof}
(i) follows from: 
\begin{align*}
  (1,\dots ,k)= (2,3) (3,4) \cdots (k-2,k-1)(k-1,k)(1,k)
\end{align*}
(ii) then follows from: 
\begin{align*}
  (i,j)= (1,i)(1,j)(1,i)^{-1}
\end{align*}
To prove (iii), we then only have to prove that (ii) can be generated by (iii), which is done by two inductions, with one of them being 
\begin{align*}
  (k,k+1)(1,k)(k,k+1)^{-1}= (1,k+1)
\end{align*}
while the other being 
\begin{align*}
g(i,i+1)g^{-1} =(i+1,i+2),\quad \text{ for all }i\leq n-2
\end{align*}
where we denote $g\triangleq (1,\dots ,n)$.
\end{proof}
\begin{theorem}
\label{TH3c}
\textbf{($A_n$ are generated by  $3$-cycles for  $n\geq 3$)} Let $n\geq 3$. Then $A_n$ is generated by $3$-cycles. 
\end{theorem}
\begin{proof}
Such is proved via induction on $n$. The base case is clear. We now prove the inductive case. Let $\sigma \in A_{n}$. By inductive hypothesis, if $\sigma $ doesn't move $n$, then  $\sigma$ can be generated by $3$-cycles. If  $\sigma$ move $n$, then because inverse of a $3$-cycle is a $3$-cycle, and because there exists a  $3$-cycle  $\tau$ such that $\tau \circ \sigma$ fix $n$, we see  $\sigma$ can also be generated by $3$-cycles.  
\end{proof}
\begin{theorem}
\label{THcsS}
\textbf{($S_n^{(1)}=A_n$ for $n\geq 3$)} Let $n\geq 3$. Then $S_n^{(1)}=A_n$. 
\end{theorem}
\begin{proof}
$S^{(1)}_n \leq A_n$ follows from computation. Because \customref{TH3c}{$A_n$ is generated by $3$-cycles}, to show $S_n^{(1)}=A_n$, we only have to show $S_n^{(1)}$ contains all  $3$-cycles, which follows from computing 
\begin{align*}
  (a,b,c)=[(a,b),(a,c)]
\end{align*}
\end{proof}
We are now ready to prove that \customref{THsa}{$A_n$ is simple for  $n\geq 5$}.  
\begin{theorem}
\label{THsa}
\textbf{(Simplicity of $A_n$)} $A_3$ is a simple group. $A_4$ is not a simple group, since it has the characteristic $2$-Sylow subgroup: 
\begin{align}
\label{EQsa}
\set{e, (1,2)(3,4),(1,3)(2,4),(1,4)(2,3)}
\end{align}
Let $n\geq 5$. Then $A_n$ is simple. 
\end{theorem}
\begin{proof}
Simplicity of $A_3$ follows from  $o(A_3)=3$. We now prove (ii): There are three ways to partition $\set{1,2,3,4}$ into $2$ disjoint subsets, each of cardinality $2$, i.e., 
\begin{align*}
\Pi_1 \triangleq \set{\set{1,2},\set{3,4}}\quad \text{ and } \quad \Pi_2 \triangleq \set{\set{1,3},\set{2,4}}\quad \text{ and }\quad \Pi_3 \triangleq \set{\set{1,4},\set{2,3}}
\end{align*}
Clearly, $S_4$ acts on $\set{\Pi_1,\Pi_2,\Pi_3}$, that is, $S_4 \longrightarrow \operatorname{Sym}(\set{\Pi_1,\Pi_2,\Pi_3})\cong S_3$. Direct computation now shows that we have a surjective group homomorphism $A_4 \longtwoheadrightarrow A_3 $ with kernel is \myref{set}{EQsa}. \\


(iii): We first prove  \vi{$A_5$ is simple}. Because $A_5\trianglelefteq S_5$ is normal, we know $A_5$ is the union of the classes of cycle types 
\begin{align*}
  (1,2,3)\quad \text{ and }\quad (1,2)(3,4) \quad \text{ and }\quad (1,2,3,4,5)
\end{align*}
Direct computation shows that the first cycle type class has $20$ elements, that the second cycle type class has  $15$ elements, and that the third cycle type class has  $24$ elements. It now follows from \customref{THLt}{Lagrange's theorem} and from \customref{EDns}{normal subgroups are unions of conjugacy classes} that $A_5$ has no proper nontrivial subgroups. $\vdone$\\

Let $N \trianglelefteq A_n$, with $\tau \neq e \in N$ and $n>5$. We are required to show $N=A_n$.  Because $n\geq 5$, clearly for any pair of $3$-cycles $\set{(a_1,a_2,a_3),(b_1,b_2,b_3)}$, there exists some $\sigma \in A_n$ such that $(b_1,b_2,b_3)= \sigma \circ  (a_1,a_2,a_3)\circ  \sigma ^{-1}$. In other words, the class of $3$-cycles forms a conjugacy class of  $A_n$. This together with normality $N\trianglelefteq A_n$ and the fact that \customref{TH3c}{$A_n$ is generated by set of $3$-cycles} reduce the problem into proving $N$ contains a $3$-cycle.  \\

Consider $A_5$ as a subgroup of $A_n$ that fixes a particular set of $n-5$ numbers. Then clearly we have $N \cap A_5 \trianglelefteq A_5$. Because  $A_5$ is simple and contains a  $3$-cycle, we now only have to show  $ N \cap A_5>1$, that is, to show $N$ contains an element that fixes at least $n-5$ elements. \\

Let   $(a_1,a_2,a_3)$ be a $3$-cycle such that $\set{\tau (a_1),\tau (a_2),\tau (a_3)}, \set{a_1,a_2,a_3}$ overlap. We now see $\tau \circ (a_1,a_2,a_3)\circ \tau^{-1} \circ  (a_1,a_2,a_3)^{-1} \in N $ is an element that fixes at least $n-5$ elements.  
\end{proof}
\begin{theorem}
\label{THnSn}
\textbf{($A_n$ is the only proper nontrivial normal subgroup of $S_n$ for $n\geq 5$)} Let $n\geq 5$. Then $A_n$ is the only proper nontrivial subgroup of $S_n$.  
\end{theorem}
\begin{proof}
Let $N$ be a proper nontrivial subgroup of $S_n$. We are required to show $N=A_n$. Because $[S_n:A_n]=2$, we only have to show $A_n \leq N$. This boils down to showing $N\cap A_n>1$, since \customref{THsa}{$A_n$ is simple}. Assume for a contradiction that $N\cap A_n=1$. The contradiction $N=1$ then follows from \customref{THcsS}{$A_n = S_n^{(1)}$}  and \customref{THzSn}{$Z(S_n)=1$}, since \customref{THpcs}{normal subgroup that disjoint with the commutator subgroup must be contained by the center}.  
\end{proof}
A group is said to be \textbf{complete} if the group has no outer automorphism and centerless. In other words, the natural map $G \longrightarrow \operatorname{Inn}(G)$ forms an isomorphism between $G$ and  $\operatorname{Aut}(G)$.
\begin{theorem}
\textbf{($S_n$ is complete for $n\neq 2$ or $6$)} Let $n\geq 3$. Then $S_n$ is complete for  $n\neq 6$.  
\end{theorem}
\begin{proof}
Clearly, automorphism group $\operatorname{Aut}(G)$ in general acts on conjugacy classes of $G$. That is, we have a group homomorphism  $\operatorname{Aut}(G)\longrightarrow \operatorname{Bij}(\operatorname{cl}(G))$.\\

Let $\alpha  \in \operatorname{Aut}(S_n)$. We first show that \vi{$\alpha  \in \operatorname{Stab}(\operatorname{cl}((1,2)))\implies  \alpha \in \operatorname{Inn}(S_n)$}. Because \customref{THgos}{$S_n$ is generated by $\set{(1,k) \in S_n: 2 \leq k \leq n}$}, we only have to show the existence of some $\sigma \in S_n$ such that 
\begin{align*}
\alpha ((1,k))= \sigma (1,k) \sigma^{-1}= (\sigma (1),\sigma (k)),\quad \text{ for all }k\geq 2
\end{align*}
Because of the premise, we already know that $\alpha  ((1,k))$ is a $2$-cycle. Our first task is to show that the intersection of the $2$-cycles  $\set{\alpha ((1,k)): k\geq 2}$ is nonempty. Write 
\begin{align*}
\alpha ((1,2))\triangleq (a,b_2) 
\end{align*}
Because $(1,2)(1,3)$ is a $3$-cycle, we know  $\alpha ((1,2))\alpha  ((1,3))=\alpha ((1,2)(1,3))$ is of order $3$, which is only possible if the $2$-cycle $\alpha ((1,3))$ share exactly one element with the $2$-cycle  $(a,b_2)$. WLOG, let that element be $a$, and write 
\begin{align*}
\alpha  ((1,3))=(a,b_3),\quad \text{ where }b_3 \not \in \set{a,b_2}
\end{align*}
Applying the same logic to $\alpha ((1,4))$, we see that the $2$-cycle $\alpha ((1,4))$ must share exactly one element with $(a,b_2)$ and must share exactly one element with $(a,b_3)$. Therefore, we know $\alpha ((1,4))$ either is of the form 
\begin{align*}
  (a,b_4),\quad \text{ with }b_4 \not \in \set{a,b_2,b_3}
\end{align*}
or is of the form $(b_2,b_3)$. To see that the latter is impossible, simply compute the order of $(1,2)(1,3)(1,4)$ and $(a,b_2)(a,b_3)(b_2,b_3)$. Now, we apply the same logic to $\alpha ((1,5))$, and this time we can conclude that  $\alpha ((1,5))$ must be of the form $(a,b_5)$ with $b_5 \not\in \set{a,b_2,b_3,b_4}$. Repeating the process, we then see 
\begin{align*}
\sigma (1)\triangleq a \quad \text{ and }\quad \sigma (k)\triangleq b_k
\end{align*}
suffices. $\vdone$ \\

Ir remains to show every $\alpha  \in \operatorname{Aut}(S_n)$ fix the class of transposition. Since $\alpha $ must maps a transposition to an element of order $2$. We only have to prove 
\begin{center}
   \begin{minipage}{0.9\linewidth}  
     \blue{For $n \neq 6$, the class of transposition has unique cardinality, which is $\binom{n}{2}$,  among the conjugacy classes whose elements are of order $2$}.
   \end{minipage}
\end{center}
Clearly, the conjugacy classes whose elements has order $2$ are the classes of product of disjoint $2$-cycles. Assume for a contradiction that there really is such a class that has the same cardinality of the class of transposition, says, this class is the class of $k$ product of disjoint  $2$-cycle. We then would have 
\begin{align*}
\binom{n}{2}= \frac{1}{k!} \binom{n}{2} \binom{n-2}{2} \cdots \binom{n-2(k-1)}{2}
\end{align*}
Noticing the RHS is telescoping, we compute  
\begin{align}
\label{EQsn2}
\binom{n-2}{2k-2}=  \frac{k!(2^{k-1})}{(2k-2)!}
\end{align}
Because the RHS now is not an integer for $k\geq 4$, we now have $k \in \set{1,2,3}$. Direct computation now shows that for \myref{equation}{EQsn2} to holds, we must have $k=3$ and  $n=6$.  $\bdone$
\end{proof}
We say a group action $G \longrightarrow  \operatorname{Bij}(X)$ is \textbf{transitive} if for each $x,y \in X$, there exists some $g \in G$ such that $g\cdot x=y$. We say a subset $S\subseteq S_n$ is \textbf{transitive} if for each $i,j \in \set{1,\dots ,n}$ there exists some $s \in S$ such that $s (i)=j$  
\begin{theorem}
\textbf{($S_6$ is incomplete)}  $S_6$ is not complete. 
\end{theorem}
\begin{proof}
  \customref{SECSt}{Sylow theorems} shows that $S_5$ has $6$ Sylow  $5$-subgroups, and the conjugacy action $\pfi : S_5 \rightarrow \operatorname{Bij}(\operatorname{Syl}_5(S_5))\cong S_6$ is transitive. In particular, the $6$ Sylow  $5$-subgroups are the cyclic subgroups generated by the $6$ distinct  $5$-cycles. Because \customref{THnSn}{$A_5$ is the only proper nontrivial normal subgroup of $S_5$}, we know $\operatorname{ker}(\pfi )\in \set{1,A_5,S_5}$. Clearly it isn't  $S_5$. To see it isn't  $A_5$, just note that if it is, then its images would have all have order $2$, which just isn't the case, as one can observe that 
\begin{align*}
  (1,2,3)^2 \langle (2,3,4,5,6)\rangle   (1,2,3)^{-2} \neq \langle (2,3,4,5,6)\rangle 
\end{align*}
Therefore, the only possibility is that $\pfi $ is injective. Denote $H \triangleq \pfi  (S_5)\leq S_6$. The fact that $\pfi $ is transitive now means that $H\leq S_6$ is transitive. \\

Now, consider the left multiplication action $\sigma : S_6 \rightarrow \operatorname{Bij}(S_6 \quotient H)$ on the left coset spaces of $H$. Because \customref{THnSn}{$A_6$ is the only proper nontrivial normal subgroup of $S_6$} and $\operatorname{Core}(H)\leq H$, we know $\sigma $ must be injective. In other words, $\sigma$ is an automorphism. \\

Note that all elements of $\sigma (H)\leq S_6$ fix a point, i.e., $H \in S_6 \quotient H$ itself, while $H\leq S_6$, since being transitive, fix no points. If $\sigma$ is inner, this is clearly impossible, thus the proof.  
\end{proof}
\section{Commonsense in Finite Group Theory}
\begin{abstract}
This section develop some commonsense about finite groups. 
\end{abstract}
\begin{theorem}
\label{COzqp}
\textbf{(Classification of semidirect product of $C_q \rtimes C_p$ with $p\mid  q-1$)} Let $p,q$ be two primes. If $p \nmid q-1$, then the semidirect product $C_q \rtimes C_p$ must be a direct product. If $p \mid  q-1$, then the semidirect product $C_q \rtimes C_p$ has exactly two non-isomorphic meanings. 
\end{theorem}
\begin{proof}
Clearly, we have 
\begin{align*}
\operatorname{Aut}(C_q) \cong    \customref{THzpc}{\Z_q ^{\times}\cong C_{q-1}} 
\end{align*}
Let $x$ and $y$ each be the generators of  $C_p$ and $C_{q-1}$. Let $x\mapsto y^c$ defines a group homomorphism. Because $x^p=e$, we must have $q-1 \mid  pc$. Therefore, if $p\nmid q-1$, the only action  $\phi\in \operatorname{Hom}(C_p,\operatorname{Aut}(C_{q}))$ is trivial.  \\


Suppose $p \mid  q-1$. By the \customref{THp}{universal property of presentation}, we now see that the possible group homomorphism $\operatorname{Hom}(C_p,C_{q-1})$ are exactly  $x \mapsto  y^{\frac{q-1}{p}d}$ for $d\inz$. Let $\phi_d$ and $\phi:\Z_p\rightarrow \Z_{q-1}$ denote $x\mapsto y^{\frac{q-1}{p}d}$ and $x \mapsto y^{\frac{q-1}{p}}$ with $d\neq 0$. Clearly we have 
\begin{align*}
\phi_d = \phi \circ \psi 
\end{align*}
where $\psi\in \operatorname{Aut}(C_p)$ is defined by $\psi (x)\triangleq x^d$. Because \customref{EQfAutH}{two actions differs by a automorphism in front induces the same semidirect product}, we have shown that there can be at most two distinct semidirect product $C_q \rtimes C_p$.  \\

To see that they are distinct, we claim that the nontrivial one is not abelian, which follows from noting that  
\begin{align*}
  (n,e)\cdot (e,h) = (n,h)\quad  \text{ and }\quad (e,h)\cdot (n,e)= (\phi_h (n),h) 
\end{align*}
in general. 
\end{proof}
We now have enough tools to state and prove our result. Note that \customref{THus}{normal Sylow subgroups are clearly characteristic}, so we will use the word "characteristic Sylow subgroup" instead.  
\begin{theorem}
\label{COaSo}
\textbf{(Analysis of finite group of fixed prime structure)} Let $p,q,r$ be three distinct prime. Then, 
\begin{enumerate}[label=(\roman*)]
  \item Groups of order $pq$, where $p<q$, is always a semidirect product $C_q \rtimes C_p$, \customref{COzqp}{and we know there are at most $2$ of them}, depending on whether $p \mid  q-1$. 
  \item Groups of order $p^2q$ has a characteristic Sylow subgroup.   
  \item Groups of order $p^3q$ has a characteristic Sylow subgroup, given that $(p,q)\neq (2,3)$. 
  \item Groups of order $pqr$ has a characteristic $r$-Sylow subgroup and a normal subgroup of order $qr$, where $p<q<r$. If $q \nmid r-1$, then groups of order $pqr$ moreover has a characteristic $q$-Sylow subgroup. 
  \item Simple groups of order $p^am$, where $a,m \inn$ satisfies $p\nmid m>1$, must satisfies $o(G)\mid  n_p!$.   
\end{enumerate}
\end{theorem}
\begin{proof}
(i): Clearly $n_q=1$. Let $P\in \operatorname{Syl}_p(G)$. Clearly $P\cap Q=1$. This by \customref{THof}{order formula} implies $PQ=G$. The rest then follows from  \customref{EDrip}{recognition theorem for inner semidirect product}. \\ 


(ii): If $p>q$, then clearly  $n_p$ can only be  $1$. If  $p<q$, then we must have $n_q \in \set{1,p^2}$. If $n_q=1$, then we are done. If not, then from \customref{THfSt}{$n_q \equiv 1 \pmod{q}$}, we see $q=p+1$, which can only happens if $q=3$ and  $p=2$. We claim that in such case, i.e., $o(G)=12$, then either $n_3=1$ or  $G \cong  A_4$, which contains a characteristic $2$-Sylow subgroup. \\

If $n_3=4$, then for any $P \in \operatorname{Syl}_3(G)$, we have $N_G(P)=P$, since \customref{THtSt}{$4=n_3=[G:N_G(P)]$}.  Clearly, the conjugacy action $G \longrightarrow   \operatorname{Bij}(\operatorname{Syl}_3(G))$ has kernel contained by $N_G(P)=P$. This by non-normality of $P$ and $o(P)=3$ implies the conjugacy action  $G \longhookrightarrow \operatorname{Bij}(\operatorname{Syl}_3(G))\cong  S_4$ is injective. Note that $G$ has  $8$ elements of order  $3$. Since  $A_4$ is the only subgroup of  $S_4$ with order $12$ and  $8$ elements of order  $3$, we now see  $G\cong  A_4$.  \footnote{One may argue that the original assertion that groups of order $p^2q$ all have a normal Sylow subgroup holds true, but we don't know whether it is possible $n_3=4$. Such is possible, since  $A_4$ really makes $n_3=4$.} The proof then follows from recalling that \customref{THsa}{$A_4$ has a characteristic  $2$-Sylow subgroup}.\\


(iii): Suppose $G$ has no characteristic Sylow subgroup. We are required to show  $(p,q)=(2,3)$, which will follows from showing $q=p+1$. \\

 Now, since $G$ has no characteristic Sylow subgroup, we know  $n_p=q$, which by $n_p \equiv 1 \pmod{p}$ implies $p<q$, which further implies $n_q\in \set{p^2,p^3}$. Counting now give us $n_q=p^2$, which by $n_q \equiv 1 \pmod{p}$ and $p<q$ implies  $q=p+1$.\\



(iv): We first show $n_r=1$. By counting, we know $1 \in \set{n_p,n_q,n_r}$. If $n_p$ and  $n_q$ are both  $>1$, then we are done. We now show that $n_p=1 \implies n_r=1$, and the proof for $n_q=1 \implies n_r=1$ is similar.  \\

Denote $P$ the characteristic Sylow $p$-subgroup of $G$. Applying (i) on $\frac{G}{P}$, we see the existence of $H\trianglelefteq  G$ with order $pr$ containing $P$. Applying (i) on $H$, we see the existence of $K\operatorname{char}H$ with $o(K)=r$. It then follows from  \customref{THus}{transitive property of characteristic  subgroup} that $K$ is the characteristic  $r$-Sylow subgroup of  $G$ we are looking for.  \\

To see $G$ has a normal subgroup of order  $qr$, just apply  (i) on $G \quotient K$. Denote that normal subgroup by $T \trianglelefteq G$. If $q \nmid  r-1$, then again by (i), there exists $L\operatorname{char}T$ with $o(L)=r$. Because of the \customref{THus}{transitive property of characteristic  subgroup}, we now see that $L$ is the characteristic  $r$-Sylow subgroup of  $G$ we are looking for.\\

(v): Let $P \in \operatorname{Syl}_p(G)$. Non-normality of $P$ together with \customref{THsSt}{second Sylow theorem} implies that the  conjugacy action $G \longrightarrow \operatorname{Bij}(\operatorname{Syl}_p(G))\cong  S_{n_p}$ is nontrivial. Simplicity of $G$ then forces the action to be injective, as desired.
\end{proof}
\begin{theorem} \textbf{(Analysis of groups of fixed order)} We have: 
\begin{enumerate}[label=(\roman*)]
  \item There are exactly four groups of order $30$. Precisely, they are the four possible semidirect product of $C_{15}\rtimes C_2$ : 
\begin{align*}
\langle x,y\mid  x^{15}=y^2=e,yxy^{-1}=x^n\rangle  \quad \text{ where }n \in \set{1,4,11,-1}
\end{align*} 
\item The $11$-sylow subgroup of groups of order $231=3 \cdot 7 \cdot 11$ lies in the centers.   
\item The $7$-sylow subgroup of groups of order  $385=5\cdot 7 \cdot 11$ lies in the centers.
  \item No group of order $132=2^2\cdot 3 \cdot 11$ is simple. 
  \item Groups of order $108=2^2\cdot 3^3$ either has a normal subgroup of order $9$, or has a  normal subgroup of order $27$.  
  \item Simple groups of order $60$ must be $A_5$.  
\end{enumerate}
\end{theorem}
\begin{proof}
  (i): Since $30=2\cdot 3\cdot 5$, \customref{COaSo}{we know $G$ has a normal subgroup $N$ of order $15$}. This allows us to write $G \cong  N \rtimes C_2$. Since \customref{COaSo}{the only group of order $15$ is $C_{15}$}, we now see $G$ must be of the form: 
\begin{align*}
G\cong C_{15} \rtimes C_2
\end{align*}
To classify the possible semidirect product, one first compute $\operatorname{Aut}(C_{15})\cong C_4\times C_2$, \footnote{This can proved by noting $\operatorname{Aut}(C_{15})\cong  \Z_{15}^{\times}\cong  (\Z_5 \times \Z_3)^{\times} \cong  \Z_5^{\times}\times \Z_3 ^{\times}\cong C_4 \times C_2$. Of course, one can also just brute force the computation.} which show us that $\operatorname{Hom}(C_2,\operatorname{Aut}(C_{15}))$ has only $4$ elements, which can be easily checked to be $y \mapsto (x \mapsto x^n)$, where $C_2= \langle y\rangle ,C_{15}=\langle x\rangle $ and $n \in \set{1,4,11,14}$. To see that these four possibly distinct groups are really pairwise distinct, one can use \customref{THposd}{their presentation} to easily compute that the number of elements of order $2$ they contain are indeed pairwise different.  \\


(ii): Let $R$ be the characteristic  $11$-sylow subgroup of $G$.  \customref{THpoc}{We are required to prove $C_G(R)=G$}. Because $C_G(R)$ is exactly the kernel of the conjugacy action $G = N_G(R)\longrightarrow \operatorname{Aut}(R)$, by \customref{THfit}{first isomorphism theorem}, we have an injection $G \quotient C_G(R) \longhookrightarrow \customref{THzpc}{\operatorname{Aut}(R) \cong C_{10}}$. The proof then follows from counting order. \\


(iii): The proof is similar to that of (ii). \\   

(iv):  If $G$ is simple, then $n_2\geq 3,n_3\geq 4$, and $n_{11}\geq 12$, which is impossible by counting.  \\

(v): Let $n_3=4$. We are required to prove the existence of a normal subgroup of order  $9$. Let $P\in \operatorname{Syl}_3(G)$. Consider the left multiplicative action $G \longrightarrow \operatorname{Bij}(G\quotient P)\cong S_4$ on the left cosets space $G \quotient P$. The proof then follows from comparing orders and the observation that the kernel must lies in $P$.   \\

(vi): Because  \customref{THnSn}{the only proper nontrivial normal subgroup of $S_5$ is $A_5$} and because $o(G)=60$, to show $G \cong  A_5$, we only have to establish an injective group homomorphism $G\longhookrightarrow S_5$. \\

Let $P\in \operatorname{Syl}_2(G)$. By simplicity of $G$, we always have an injective group homomorphism $G \longhookrightarrow  \operatorname{Bij}(G \quotient N_G(P))\cong S_{[G:N_G(P)]}$, the left multiplicative action on the left coset space of $N_G(P)$. Since  \customref{THtSt}{$[G:N_G(P)]=n_2$}, it remains to show $n_2=5$. \\

Because $G$ is simple and $60\nmid 4!$, from $G \quotient \operatorname{Core}(H)\longhookrightarrow  \operatorname{Bij}(G \quotient H)$, where $G \quotient H$ is the left coset space of $H$, we know that $G$ can not have proper subgroup with index $<5$. This with  \customref{THtSt}{$[G:N_G(P)]=n_2$} in particular implies $n_2\geq 5$. Because $G$ is simple, we now have $n_2 \in \set{5,15}$. \\


Assume $n_2=15$ for a contradiction. Because $n_5=6$, by counting, we see that there must be a pair of distinct  $2$-Sylow subgroup  $Q,R\in \operatorname{Bij}_2(G)$ such that $o(Q\cap R)=2$. Let $M \triangleq N_G(Q\cap R)$. Since  $Q$ and $R$, of order $4$, is abelian, we know  $Q,R \leq  M$, which implies $4 \mid  o(M)$, that is, $o(M)\in \set{4,12,20,60}$. Simplicity of  $G$ forces $o(M)\neq 60$, $Q\neq R$ forces $o(M)\neq 4$, and the fact that $G$ has no proper subgroup of index $<5$ forces  $o(M)\neq 20$. Therefore, we must have $o(M)=12$. By simplicity of $G$, we now have an injective group homomorphism  $G \longhookrightarrow \operatorname{Bij}(G \quotient M)\cong  S_5$, the left multiplicative action on the left coset space of $M$, as desired.
\end{proof}

\section{Simplicity of $\operatorname{PSL}_n(\F)$} 
\begin{abstract}
This section shows that for $n\geq 3$, $\operatorname{PSL}_n(\F)$ is simple, and for $n=2$, $\operatorname{PSL}_n(\F)$ is simple if $\F$ has $\geq 4$ elements.  
\end{abstract}
An action $\phi : G \longrightarrow \operatorname{Bij}(X)$ is called \textbf{transitive} if for all $x,y \in X$, there exist some $g$ that takes $x$ to  $y$. We say $\phi$ is \textbf{doubly transitive} if the naturally induced action on $G \longrightarrow \operatorname{Bij}(X^2 - D)$, where $D \triangleq \set{(x,x)\in X^2 : x \in X}$ is the diagonal,  is transitive. 
\begin{theorem}
\label{THpdta}
\textbf{(Property of doubly transitive action)} Let $\phi : G \rightarrow  \operatorname{Bij}(X)$ be a doubly transitive action and $\abso{X}\geq 2$. Then 
\begin{enumerate}[label=(\roman*)]
  \item $\operatorname{Stab}(x) < G$ is maximal for all $x \in X$. 
  \item For all $N \trianglelefteq G$, the action  $\phi |_N:N \rightarrow  \operatorname{Bij}(X)$ is either trivial or transitive.  
\end{enumerate}
\end{theorem}
\begin{proof}
(i): Denote $H \triangleq \operatorname{Stab}(x)$. We first show that: 
\begin{align*}
\vi{G= H \cup  HgH,\quad \text{ for all }g \in G-H,\text{ where }HgH\triangleq \set{hg\tilde{h}\in G: h,\tilde{h}\in H  }}
\end{align*}
Fix $g \in G-H$. Let $\tilde{g}\in G-H$. We are required to show $\tilde{g} \in HgH$. Because $g, \tilde{g}\not \in H$, doubly transitivity of $\phi$ implies the existence of some element in $G$ that takes  $(x,gx)$ to $(x,\tilde{g}x)$. Such element is clearly in $H$. One then can check $\tilde{g} \in hgH$, where $h$ is the element that takes  $gx$ to  $\tilde{g}x$. \vdone\\

$H<G$ is clear. To see that $H$ is maximal, just observe that if a subgroup $K$ of $G$ properly contains  $H$, then the subgroup contains  $H \cup HgH=G$, where $g \in K-H$. \\

(ii): Suppose the action $N \longrightarrow \operatorname{Bij}(X)$ is nontrivial. We are required to show it is transitive. Fix $x \neq  y \in X$. Because $N$ is nontrivial, we know there exists some  $z \in X$ and $n \in N$ such that $nz \neq z$. Doubly transitivity of $\phi$ then implies the existence of some $g \in G$ such that $g(z,nz)=(x,y)$. The proof then follows from checking that $gng^{-1}$ takes $x$ to  $y$. 
\end{proof}

\begin{theorem}
\label{THIc}
\textbf{(Iwasawa criterion)} Let $\phi : G \rightarrow \operatorname{Bij}(X)$ be a doubly transitive action. If 
\begin{enumerate}[label=(\roman*)]
  \item $G$ is \textbf{perfect}, i.e., $G^{(1)}=G$. 
  \item There exists some $x \in X$ whose stabilizer subgroup has an abelian normal subgroup $U$ such that $\bigcup_{g \in G}gUg^{-1}$  generates $G$. 
\end{enumerate}
then $G \quotient \operatorname{ker}\phi$ is simple. 
\end{theorem}
\begin{proof}
Denote $K\triangleq \operatorname{ker}\phi$ and $H \triangleq \operatorname{Stab}(x)$. Let $N$ be a normal subgroup of $G$ that contains  $K$. We are required to prove $N=K\text{ or }G$. \customref{THpdta}{Maximality of $H$} splits the proof into two cases $NH=H$ or $NH=G$. We will prove that the case $NH=H$ leads to $N=K$, and the case  $NH=G$ leas to  $N=G$. \\

Case ($NH=H$): In such case, clearly $N \leq H$, and therefore \customref{THpdta}{$N$ acts trivially on $X$}, which implies $N \leq K$, as desired. \\

Case ($NH=G$): In such case, normality $U \trianglelefteq H$ implies $NU \trianglelefteq G$. This then implies that $gUg^{-1} \leq g(NU)g^{-1} = NU$ for all $g \in G$. Therefore by premise, $NU=G$. \customref{THsit}{Second isomorphism theorem} then shows that $G \quotient N \cong  NU \quotient N \cong  U \quotient  N \cap U$ is abelian, which by perfectness of $G$ implies that  $N=G$.    
\end{proof}
Let $\F$ be a field. The \textbf{general linear group} $\operatorname{GL}_n(\F)$ is the group of $n$-by-$n$  $\F$-valued matrices that has nonzero determinant. Clearly, $\operatorname{GL}_n(\F)$ acts naturally on the affine space $\A^n(\F)$, and moreover on the projective space $\P^{n-1}(\F)$. 
\begin{theorem}
\label{THkgl}
\textbf{(Kernel of general linear group acting on projective space)} The kernel of the group action $\operatorname{GL}_n(\F) \longrightarrow \operatorname{Bij}(\P^{n-1})$ is exactly the group of scalar diagonal:
\begin{align*}
\set{cI \in \operatorname{GL}_n(\F): c \in\F^{\times}}
\end{align*}
coinciding with its center $Z(\operatorname{GL}_n(\F))$. 
\end{theorem}
\begin{proof}
We first show that the group of the scalar diagonal $=$ the kernel. Clearly the group of scalar transformations lies in the kernel. To see the converse inclusion holds, let $A$ maps 
 \begin{align*}
v \mapsto  \ld  v\quad \text{ and }\quad w \mapsto \mu w
\end{align*}
and observes that if $\ld  \neq \mu$, then $A$ doesn't fix $[v+w]$. \\

It remains to show the center $=$ the group of scalar diagonal. Again, clearly the group of scalar diagonal lies in the center. Let $A \in Z\left(\operatorname{GL}_n(\F) \right)$. To prove that $A$ is scalar diagonal, one simply consider $E_{i,j}\triangleq I_n + e_{i,j}$, where $e_{i,j}\in M_n(\F)$ is the \textbf{matrix unit}. 
\end{proof}
Because \customref{THkgl}{the group action $\operatorname{GL}_n(\F)\rightarrow \operatorname{Bij}(\P^{n-1})$ has such kernel}, we define the \textbf{projective general linear group} $\operatorname{PGL}_n(\F)$ to be the quotient group
\begin{align*}
\operatorname{PGL}_n(\F)\triangleq \operatorname{GL}_n(\F) \quotient \set{cI_n \in \operatorname{GL}_n(\F): c \in \F^{\times}}  
\end{align*}
The \textbf{special linear group} $\operatorname{SL}_n(\F) \leq  \operatorname{GL}_n(\F)$ is the subgroup whose elements has determinant $1$, and \customref{THkgl}{the kernel of its action on $\P^{n-1}$ is clearly $\set{cI_n \in \operatorname{SL}_n(\F): c^n =1}$}, so we define the \textbf{projective special linear group} $\operatorname{PSL}_n(\F)$ to be 
\begin{align*}
\operatorname{PSL}_n(\F) \triangleq \operatorname{SL}_n(\F) \quotient \set{c I_n \in \operatorname{SL}_n(\F): c\in\F^{\times}\text{ is a $n$-th root of unity.}}
\end{align*}
\begin{theorem}
\label{THpslg}
\textbf{(Basic properties of special linear group)} Let $\F$ be an arbitrary field and  $n\geq 2$. Then,   
\begin{enumerate}[label=(\roman*)]
  \item $\operatorname{SL}_n(\F)$ acts doubly transitive on $\P^{n-1}$.  
  \item $\operatorname{SL}_n(\F)$ has center $\set{cI_n \in \operatorname{SL}_n(\F):c\in\F^{\times}\text{ is a $n$-th root of unity.}}$, thus equal to the kernel of its action on $\P^{n-1}$.
\end{enumerate}
\end{theorem}
\begin{proof}
  (i): Let $\left([v_1],[v_2] \right),\left([w_1],[w_2] \right) \in (\P^{n-1})^2$ be two pairs off the diagonal. We are required to show the existence of some $\widehat{L} \in \operatorname{SL}_n(\F)$ that send $[v_1]$ to  $[w_1]$ and  $[w_1]$ to  $[w_2]$. The proof then follows from extending them to two bases  $\set{v_1,\dots ,v_n}, \set{w_1,\dots ,w_n}$ for $\F^{n}$ and setting $\widehat{L}(v_i)\triangleq c_iw_i$ with 
\begin{align*}
\operatorname{det}(PQ^{-1})\cdot \left(\prod_{i=1}^n c_i    \right)= 1
\end{align*}
where $Q,P\in \operatorname{GL}_n(\F)$ are respectively the matrix whose $i$-th column is $v_i,w_i$.  (ii): \customref{THkgl}{The proof that computes $Z(\operatorname{GL}_n(\F))$} applies here, since $E_{i,j} \in \operatorname{SL}_n(\F)$. 
\end{proof}
To apply \customref{THIc}{Iwasawa criterion} on the projective special linear groups $\operatorname{PSL}_n(\F)$, it remains to show 
\begin{enumerate}[label=(\Roman*)]
  \item $\operatorname{SL}_n(\F)$ is perfect. 
  \item There exists some $x \in \P^{n-1}$ whose stabilizer subgroup $H \leq \operatorname{SL}_n(\F)$ has an abelian normal subgroup $U$ such that $\bigcup_{g \in G}gUg^{-1}$ generates $G$.  
\end{enumerate}
The reasons why simplicity of  $\operatorname{SL}_2(\F)$ requires $\F$ to have $\geq 4$ elements lies in the fact (I) may fails to be true if $\F$ has $\leq 3$ elements.  
\begin{Example}{$\operatorname{SL}_2(\F_2)$ and $\operatorname{SL}_2(\F_3)$ are not perfect}{}
By counting, we know 
\begin{align*}
o\left(\operatorname{GL}_n(\F_p) \right)=  (p^n-1)(p^n - p)\cdots  (p^n-p^{n-1})
\end{align*}
Since determinant function is a  surjective group homomorphism from $\operatorname{GL}_n(\F_p)$ to $\F_p^{\times}$  with kernel $\operatorname{SL}_n(\F_p)$, we know 
\begin{align*}
o \left(\operatorname{SL}_n(\F_p) \right) = \frac{1}{p-1} \cdot  (p^n-1)(p^n - p)\cdots  (p^n-p^{n-1})
\end{align*}
In particular, $\operatorname{SL}_2(\F_2)$ and $ \operatorname{SL}_2(\F_3)$ has order $6$ and $24$. Now, clearly $\operatorname{SL}_2(\F_2)$ has a faithful action on:   
  \begin{align*}
  \set{\begin{pmatrix} 
  1 \\
  0
\end{pmatrix} , \begin{pmatrix} 
0 \\
1
\end{pmatrix}, \begin{pmatrix} 
1 \\
1
\end{pmatrix}}
  \end{align*}
So by comparing order, we know $\operatorname{SL}_2(\F_2)\cong  S_3$. Therefore non-perfectness of $\operatorname{SL}_2(\F_2)$ then follows from \customref{THcsS}{$S_3^{(1)}=A_3$}. In fact, since $\operatorname{PSL}_2(\F_2) \cong  \operatorname{SL}_2(\F_2)$, we have shown that $\operatorname{PSL}_2(\F_2)$ is non-simple. \\ 

Now, recall that \customref{THpslg}{$\operatorname{PSL}_2(\F_3)$ acts faithfully on $\P^{1}(\F_3)$}, which has $\frac{3^2-1}{3-1}=4$ points, so we have an injective group homomorphism $\operatorname{PSL}_2(\F_3)\longhookrightarrow S_4$. Computing that $o \left(\operatorname{PSL}_2(\F_3) \right)=12$, we see that \href{https://groupprops.subwiki.org/wiki/Subgroup_structure_of_symmetric_group:S4}{since the only index $2$ subgroup of $S_4$ is  $A_4$}, we have the isomorphism $\operatorname{PSL}_2(\F_3) \cong  A_4$, \customref{THsa}{which is non-simple}. 
\end{Example}
Regardless of whether $n>2$,  the second condition is proved using the same $H$ and  $U$. We pick $x \triangleq [1:0 : \cdots :0 ]$, and therefore 
\begin{align*}
H= \set{\begin{pmatrix} 
    a & * \\
    \textbf{0} & M 
\end{pmatrix} : a \in \F^{\times}\text{ and }M\in \operatorname{GL}_{n-1}(\F)}
\end{align*}
and since: 
\begin{align*}
\begin{pmatrix} 
  a & * \\
  \textbf{0} & M
\end{pmatrix} \begin{pmatrix} 
  b & * \\
  \textbf{0} & J
\end{pmatrix} = \begin{pmatrix} 
  ab & * \\
  \textbf{0} & MJ
\end{pmatrix}
\end{align*}
We know 
\begin{align*}
U \triangleq \set{\begin{pmatrix} 
    1 & * \\
    \textbf{0} & I_{n-1}
\end{pmatrix}}\text{ is normal in }H.
\end{align*}
$U$ is abelian since 
\begin{align*}
\begin{pmatrix} 
    1 & \textbf{v} \\
    \textbf{0} & I_{n-1}
\end{pmatrix} \begin{pmatrix} 
    1 & \textbf{w} \\
    \textbf{0} & I_{n-1}
\end{pmatrix} = \begin{pmatrix} 
    1 & \textbf{v}+ \textbf{w} \\
    \textbf{0} & I_{n-1}
\end{pmatrix}
\end{align*}
Interestingly, both  (I) and (II) requires boring computations within $\operatorname{SL}_n(\F)$. 
\begin{theorem}
\label{THpsl2s}
\textbf{(One dimensional projective special linear group is simple over field that has $\geq 4$ elements)} If $\F$ has  $\geq 4$ elements, then $\operatorname{PSL}_2(\F)$ is simple.  
\end{theorem}
\begin{proof}
(II): Since 
\begin{align*}
 \begin{pmatrix} 
  0 & -1 \\
  1 & 0
 \end{pmatrix} \begin{pmatrix} 
  1 & \ld  \\
  0 & 1
 \end{pmatrix} \begin{pmatrix} 
  0 & -1 \\
  1 & 0
 \end{pmatrix}^{-1}= \begin{pmatrix} 
  1 & 0 \\
  -\ld  & 1 
 \end{pmatrix}
\end{align*}
We know the group of the lower triangular matrices:
\begin{align*}
\set{\begin{pmatrix} 
    1 & 0 \\
    * & 1 
\end{pmatrix}}
\end{align*}
is a conjugate of $U$. We prove that $\operatorname{SL}_2(\F)$ is generated by $U$ and the lower triangular matrices. To see such, just observe that if any of $b,c$ is nonzero, then by transposing the matrix if necessary, we have  
\begin{align*}
\begin{pmatrix} 
  a & b \\
  c & d
\end{pmatrix}= \begin{pmatrix} 
  1 & 0 \\
  (d-1)b^{-1} & 1
\end{pmatrix} \begin{pmatrix} 
  1 & b \\
  0 & 1 
\end{pmatrix} \begin{pmatrix} 
  1 & 0 \\
  (a-1)b^{-1} & 1 
\end{pmatrix},\quad \text{ where }b \neq 0
\end{align*}
and if both of them are zero, then $d=a^{-1}$ and we have 
\begin{align*}
\begin{pmatrix} 
  a & 0 \\
  0 & a^{-1}
\end{pmatrix}= \begin{pmatrix} 
  1 & 0 \\
  (1-a)a^{-1} & 1 
\end{pmatrix} \begin{pmatrix} 
  1 & 1 \\
  0 & 1
\end{pmatrix} \begin{pmatrix} 
  1 & 0 \\
  a-1 & 1 
\end{pmatrix} \begin{pmatrix} 
  1 & -a^{-1} \\
  0 & 1 
\end{pmatrix}
\end{align*}

(I): Compute 
\begin{align*}
\left[\begin{pmatrix} 
    a & 0\\
    0 & a^{-1}
\end{pmatrix}, \begin{pmatrix} 
    1 & b \\
    0 & 1 
\end{pmatrix} \right]= \begin{pmatrix} 
    1 & b(a^2-1) \\
    0 & 1 
\end{pmatrix} 
\end{align*}
Because $\F$ has  $\geq 4$ elements, we know that there exists some $a \in \F^{\times}$ such that $a^2 \neq 1$ (Consider $x^2-1 \in \F[x]$). Fix such $a$. We then see that  $U \leq \operatorname{SL}_2(\F)^{(1)}$ by letting $b$ run through  $\F$. Normality of $\operatorname{SL}_2(\F)^{(1)}$ and (II) then implies $\operatorname{SL}_2(\F)^{(1)}=\operatorname{SL}_2(\F)$
\end{proof}

\begin{theorem}
\textbf{($\geq 2$ dimensional projective special linear groups are all simple)} Let $n\geq  3$. Then we have: 
\begin{enumerate}[label=(\roman*)] 
  \item $I_n + \ld  e_{ij}$ is conjugate to $I_n+ e_{12}$ in $\operatorname{SL}_n(\F)$, for all $\ld \in \F^{\times}$ and $i\neq j$. 
  \item $\set{I_n + \ld e_{ij}:\ld \in\F\text{ and }i\neq j}$ generates $\operatorname{SL}_n(\F)$. 
\end{enumerate}
Since $I_n+ e_{12}\in U$, together they implies (II), and using them we may prove (I).   
\end{theorem}
\begin{proof}
(i): We are required to find some $P \in \operatorname{SL}_n(\F)$ such that $P(I_n+ \ld e_{ij})P^{-1}=I_n + e_{12}$. Note that $I_n+ \ld e_{ij}$ maps 
\begin{align*}
e_j\mapsto e_j+ \ld  e_i\quad\text{ and }e_k\mapsto e_k\text{ for all }k\neq j
\end{align*}
The construction of $P$ then follows from letting its first column to be  $\ld e_i$, its second column to be $e_j$, and the rest to be other basis vector unchanged by $I_n+ \ld e_{ij}$, where the third column is multiplied by $\ld ^{-1}$. (We used the fact $n\geq 3$ here) \\

(ii): This is proved via induction. We have proved the base case in our proof for \customref{THpsl2s}{simplicity of $\operatorname{PSL}_2(\F)$}. We now prove the inductive case. Let $A \in \operatorname{SL}_n(\F)$. We are required to show that 
\begin{align*}
PAQ = \begin{pmatrix} 
  1 & \textbf{0}\\
  \textbf{0} & \tilde{A} 
\end{pmatrix},\quad \text{ for some }P,Q\text{ generated by $I_n+ \ld e_{ij}$ }
\end{align*}
and the rest would follows the inductive hypothesis. The construction of $P,Q$ is obvious once one observe the effect of  multiplying $I_n+ \ld e_{ij}$ on a matrix. \\

(I):  By (i), (ii) and normality of commutator subgroup, we only have to prove  $I_n + e_{12} \in \operatorname{SL}_n(\F)^{(1)}$, which follows from computing 
\begin{align*}
I_n+ e_{12} = \left[ I_n + e_{13} , I_n + e_{32} \right]
\end{align*}
\end{proof}
\section{selection of advanced topics}
\begin{theorem}
\textbf{(Burnside's $p^aq^b$ theorem)} If $o(G)=p^aq^b$ for some primes  $p,q$, then  $G$ is solvable. 
\end{theorem}
\begin{proof}
\href{https://en.wikipedia.org/wiki/Burnside%27s_theorem}{Wikipedia has a detailed proof}. 
\end{proof}
\begin{theorem}
\textbf{(Schur-Zassenhaus theorem)} Let $G$ be a finite group and $N\trianglelefteq G$ be Hall. Then the short exact sequence 
\begin{align*}
1 \longrightarrow N \longrightarrow G \longrightarrow G \quotient N \longrightarrow 1
\end{align*}
right splits, and thus $G$ must be a semidirect product of $N\rtimes (G\quotient N)$.  
\end{theorem}
\begin{proof}
\href{https://en.wikipedia.org/wiki/SchurZassenhaus_theorem}{Wikipedia has a proof sketch that relies on group cohomology}
\end{proof}
\begin{theorem}
\textbf{(Thompson's fixed-point-free theorem)} Let $G$ be a finite group that admits a fixed-point-free automorphism of prime order. Then $G$ is nilpotent. 
\end{theorem}
\begin{proof}
\href{https://www.jstor.org/stable/90107?seq=1}{This is Thompson's proof}.
\end{proof}
\begin{theorem}
\textbf{(Nielsen-Schreier Theorem)} The subgroup of a free group is isomorphic to some free group. 
\end{theorem}
\begin{proof}
\href{https://en.wikipedia.org/wiki/NielsenSchreier_theorem}{Wikipedia has a proof based on Algebraic Topology}. 
\end{proof}
\begin{theorem}
\textbf{(Schreier conjecture, now a theorem)} Outer automorphism group of finite simple groups are solvable. 
\end{theorem}
\begin{proof}
\href{https://mathoverflow.net/questions/308496/schreier-conjecture-without-a-simple-proof-and-sporadic-simple-groups}{See this MO post}. 
\end{proof}
\begin{theorem}
\textbf{(Feit-Thompson theorem)} Finite groups of odd order are solvable. 
\end{theorem}
\begin{proof}
\href{https://en.wikipedia.org/wiki/FeitThompson_theorem}{Wikipedia has a proof sketch}. 
\end{proof}
\begin{theorem}
\textbf{(Frobenius theorem about equation in group)} Let $G$ be a finite group, and let  $n \mid  o(G)$. The number of solution to the equation
\begin{align*}
g^n = e 
\end{align*}
is a positive multiple of $n$. 
\end{theorem}
\begin{proof}
  \href{https://www.jstor.org/stable/2324902?seq=2}{Isaacs and Robinson gives a relatively simple proof of this}. 
\end{proof}
\begin{theorem}
\textbf{(Frobenius conjecture)} Let $G$ be a finite group, and let $n \mid  o (G)$. If the number of solution to the equation $g^n=e$ is exactly  $n$, then these  $n$ elements form a normal subgroup of  $G$. 
\end{theorem}
\begin{proof}
  \href{https://www.ams.org/journals/bull/1991-25-02/S0273-0979-1991-16084-2/S0273-0979-1991-16084-2.pdf}{Iiyori and Yamaki show that this is a corollary of classification of finite simple groups}. 
\end{proof}
\section{recreational exercises}
\begin{question}{Groups as unions of proper subgroups}{}
Show that a group can not be written as the union of two proper subgroup. 
\end{question}
\begin{proof}
  Let $G=H \cup K$. We are required to prove $G \in \set{H,K}$. We prove such by showing that one is contained by the other.  Assume not for a contradiction. Letting $h \in H-K$ and $k \in K-H$, we see that $hk \in G - H \cup K$, a contradiction. For more on this kind theorems, see the survey article \href{http://www.jstor.org/stable/40391117}{\emph{Groups as unions of proper subgroups}, by Bhargava, M. (2009)}
\end{proof}
\begin{question}{$n-1,n,n+1$-abelian implies abelian}{}
Let $n\inz$ satisfies 
\begin{align*}
  (ab)^n =a^nb^n\quad \text{ and }\quad (ab)^{n-1}=a^{n-1}b^{n-1}\quad \text{ and }\quad (ab)^{n+1}=a^{n+1}b^{n+1}
\end{align*}
for all $a,b \in G$. Show that $G$ is abelian.  
\end{question}
\begin{proof}
\begin{align*}
&a^nb^n ab=(ab)^n (ab)=(ab)^{n+1}=a^{n+1}b^{n+1} \\
\implies & b^na=ab^n \\
\implies  & (a^{n-1}b^{n-1})ba= a^nb^n= (a^{n-1}b^{n-1})ab \\
\implies& ba=ab
\end{align*}
\end{proof}
\begin{question}{finite $3$-abelian whose order is not divisible by  $3$ is abelian}{}
Let $G$ be a finite group whose order is not divisible by $3$. Suppose 
\begin{align*}
  (ab)^3 = a^3b^3,\quad \text{ for all }a,b \in G
\end{align*}
Show that $G$ is abelian. 
\end{question}
\begin{proof}
Because $3\nmid  o(G)$, we know if $g^3=e$, then  $g=e$. In other words, the endomorphism  $x\mapsto x^3$ is an automorphism. Because of such, we only have to prove $a^3b^3=b^3a^3$ for all  $a,b  \in G$. This then follows from 
\begin{align*}
&(ab)^3= a^3b^3,\quad \text{ for all }a,b \in G \\
\implies & baba=a^2b^2,\quad \text{ for all }a,b \in G \\
\implies &(ba)^2= a^2b^2,\quad \text{ for all }a,b \in G \\
\implies & (ab)^4= [(ab)^2]^2= [ b^2a^2]^2= a^4b^4,\quad \text{ for all }a,b \in G \\
\implies &(ab)^4 = a(ba)^3 b =ab^3a^3 b,\quad \text{ for all }a,b \in G \\
\implies & a^3b^3=b^3a^3 ,\quad \text{ for all }a,b \in G 
\end{align*}
\end{proof}
\begin{question}{}{}
Let $a,b \in G$ satisfies 
\begin{align*}
o(a)=5\quad \text{ and }\quad  aba^{-1}=b^2
\end{align*}
Find $o(b)$. 
\end{question}
\begin{proof}
\begin{align*}
&aba^{-1}=b^2  \\
\implies & a^2ba^{-2}=ab^2a^{-1}= (aba^{-1})^2= b^4 \\
\implies & b=a^5a^{-5}=a^4b^2a^{-4}= (a^2ba^{-2})^2=b^8
\end{align*}
Therefore $o(b)=7$. 
\end{proof}
\begin{question}{\customref{THfgag}{Structure theorem for finitely generated abelian group}}{}
Let $G$ be an abelian group, and $x,y \in G$ has order $m,n$. Show that  $G$ has an element of order $\operatorname{lcm}(m,n)$. 
\end{question}
\begin{proof}
The proof follows from noting that the fact that in general, given $(a_1,\dots ,a_n) \in G_1 \times \cdots \times G_n$, we have 
\begin{align*}
o((a_1,\dots ,a_n))= \operatorname{lcm}(o(a_1),\dots , o(a_n))
\end{align*}
and the fact that since $x,y \in \langle x\rangle + \langle y\rangle$, in the \customref{THfgag}{primary decomposition form} of $\langle x\rangle +\langle y\rangle $, there must be a component of high enough power. 
\end{proof}
\begin{question}{\customref{THfgag}{Structure theorem for finitely generated abelian group}}{}
Let $G$ be an abelian groups that has subgroups of order $m$ and $n$. Show that is has a subgroup of order $\operatorname{lcm}(m,n)$. 
\end{question}
\begin{proof}
Let the subgroups be $M,N$. The proof then follows from noting that  $\operatorname{lcm}(m,n)\mid  o (MN)$ and the fact that  \customref{COfao}{for every divisor $d$ of the order of a finite abelian group  $H$, there always exists a subgroup  $\leq H$ of order $d$}. 
\end{proof}
\begin{question}{\customref{THfgag}{Structure theorem for finitely generated abelian group}}{}
Let  $G$ be a finite abelian group in which the number of solution of the equation  $x^n=e$ is $\leq n$ for all  $n\inn$. Show that $G$ is cyclic. 
\end{question}
\begin{proof}
Write $G$ in its  \customref{THfgag}{primary decomposition form}. We are required to show that its $p$-torsion subgroup has at most one component. This follows from noting that for $d,e\geq 1$, the group $C_{p^d}\times C_{p^e}$ has $p^2$ number of solution to the equation $x^n=e$.  
\end{proof}
\begin{question}{}{}
Let $a \in G$. Show that the equation 
\begin{align*}
x^2ax=a^{-1}
\end{align*}
is solvable for $x \in G$ if and only if $a$ is the cube of some element.  
\end{question}
\begin{proof}
Suppose $x^2ax=a^{-1}$ for some $x \in G$. One can show that $a= (xa)^3$. If $a=y^3$, then  $x\triangleq y^{-2}$ is a solution. 
\end{proof}
\chapter{Commutative Algebra}
\section{Rings and Modules} 
The precise meaning of the term \textbf{ring} varies across different books. In this note, ring multiplication is always associative, commutative, and has an identity. The additive and multiplicative identity are denoted by $0$ and $1$. Let $A$ be a ring, clearly we have 
 \begin{align*}
x \cdot 0 =0 ,\quad \text{ for all }x \in A
\end{align*}
Consequently, $1 \neq 0$ unless the ring contain only one element, and we always have the \textbf{zero ideal}. If $1=0$, we call the ring  \textbf{zero ring}.\\

We say $a \in A$ is a  \textbf{zero-divisor} if $ab=0$ for some  $b \neq 0$. Clearly, both zero-divisors and non-zero-divisors are closed under multiplication, and non-zero-divisors moreover forms a monoid: 
\begin{center}
   \begin{minipage}{0.9\linewidth}  
       \centering
\includegraphics[height=8cm,width=18cm]{images/ring_element}
   \end{minipage}
\end{center}
We say $a \in A$ is  \textbf{nilpotent} if $a^n=0$ for some  $n>0$, and we call the multiplicative group $A^{\times}$ of elements that admits an inverse the \textbf{unit group} of $A$.
\begin{theorem}
\textbf{(Sum of nilpotents and unit is always a unit)} Let $x \in \operatorname{Nil}(A)$. Then $x+u \in A^{\times}$ for all $u \in A^{\times}$. 
\end{theorem}
\begin{proof}
Just observe 
\begin{align*}
  -(x+u)(x-u)(x^2+u^2)(x^4+u^4) \cdots (x^{2^n}+u^{2^n})=u^{2^{n+1}}-x^{2^{n+1}}
\end{align*}
for all $n\inn$, and therefore equals to $u^{2^{n+1}}\in A^{\times}$ for $n\gg  0$. This then implies $x+u \in A^{\times}$. 
\end{proof}
One should always be careful with zero-divising and unital properties, as they clearly depends on the ambient ring: 
\begin{Example}{Non-units and non-zero-divisors become units and zero-divisors in larger rings.}{}
Embedding a ring into a field, all non-units becomes a unit. In particular, $2 \in \Z$ is a unit in $\Q$. Let $A$ be a ring, $a \in A$ be a non-unit non-zero-divisor, and consider the embedding: 
\begin{align*}
A \longhookrightarrow A \times \left( A \quotient \mathfrak{a} \right)\quad \text{ and }\quad x \mapsto \left(x,x + \mathfrak{a}\right),\quad \text{ where }\mathfrak{a}\triangleq (a)
\end{align*}
Because $a$ is non-unit, we know $A \quotient \mathfrak{a}\neq 0$, and therefore $(0,1)\neq (0,0)$. Since 
\begin{align*}
(a,0)\cdot (0,1)=(0,0)
\end{align*}
We see  $a$ is a zero-divisor in $A \times (A \quotient \mathfrak{a})$. 
\end{Example}
A \textbf{ring homomorphisms} $f: A\rightarrow B$ is a function that respect $+$,  $\times$, and $1$. Clearly, $f$ must also respect $0$, $-1$, and units, $f(A)$ forms a subring of $B$, and if $f$ is injective, then the inverse $f^{-1}:f(A)\rightarrow A$ forms a ring homomorphism. An $A$\textbf{-module}  $M$ is an abelian group together with a compatible $A$-scalar structure, or equivalently, a ring homomorphism $A \longrightarrow \operatorname{End}(M)$, where $\operatorname{End}(M)$ is the endomorphism ring of the abelian group $M$. An $A$\textbf{-module homomorphism} $f:M \rightarrow N$ is a function that respect vector addition and multiplication.\\

Let $f:A \rightarrow B$ be a ring homomorphism and $N$ be a  $B$-module. Clearly, we can give $N$ an  $A$-module structure, called \textbf{restriction of scalar}, by setting $ax\triangleq f(a)x$ for all $a \in A$ and $x \in N$. \\

An \textbf{$A$-algebra} is an $A$-module $B$ together with a compatible ring structure, or equivalently, a ring homomorphism $f:A\rightarrow B$ that give  $B$ an  $A$-module structure by scalar restriction. An $A$\textbf{-algebra homomorphism} $f: B \rightarrow C$ is a function that is both ring homomorphism and $A$-module homomorphism. Clearly, a ring homomorphism $h:B \rightarrow C$ is an $A$-algebra homomorphism if and only if it makes the diagram: 
% https://q.uiver.app/#q=WzAsMyxbMSwwLCJBIl0sWzAsMiwiQiJdLFsyLDIsIkMiXSxbMCwxXSxbMSwyLCJoIl0sWzAsMl1d
\[\begin{tikzcd}
	& A \\
	\\
	B && C
	\arrow[from=1-2, to=3-1]
	\arrow[from=1-2, to=3-3]
	\arrow["h", from=3-1, to=3-3]
\end{tikzcd}\]
commute. In this note, \textbf{subrings, submodules and subalgebra} are then just injective ring (module, algebra) homomorphism. \\



Let $A$ be a ring. An  \textbf{ideal} $\mathfrak{a}\trianglelefteq   A$ is just a submodule. Since they play roughly the same role as normal subgroups in groups, we use the same notation. Let $f: A \rightarrow B$ be a ring homomorphism and  $\mathfrak{b}\trianglelefteq B$. Notably, since preimage $f^{-1}(\mathfrak{b})$ is the kernel of the ring homomorphism:
\begin{align*}
A \longrightarrow B \longrightarrow B \quotient \mathfrak{b}
\end{align*}
We see that, just like normal subgroups, preimages of ideals are ideals.\\

Let $M$ be an  $A$-module and  $X \subseteq M$. The set $(X)$ of finite linear combinations of $X$ is called the \textbf{submodule generated by $X$}. Let $S \subseteq A$. The \textbf{ideal $(S)$ generated by $S$} is then the submodule generated by $S$. Let $B$ be an $A$-algebra and  $Y \subseteq B$. The natural image of the polynomial ring $A[Y]$ is called the  \textbf{subalgebra  generated by $Y$}. Clearly, in the case of module, ring, and algebra, the generated objects are the smallest objects that contain the generators.   \\

At this point, we should point out that \textbf{finitely generated module} and \textbf{finitely generated algebra} are two different notions, and a \textbf{ring is finitely generated} if it is finitely generated as a $\Z$-algebra. 
\begin{Example}{Finitely generated algebras need not be finitely generated modules.}{}
Clearly, $A[x]$ is finitely generated as an $A$-algebra, but not finitely generated as an  $A$-module.   
\end{Example}
\section{Operations on Ideals and Modules}
\begin{equiv_def}
  \textbf{(Sum for modules and ideals)} Let $A$ be a ring, and $M$ an  $A$-module. The \textbf{sum $\sum M_i$ of} \emph{possibly infinite} \textbf{submodules} $M_i \leq M $ is the set of finite combinations of elements of $M_i$.
One can check that, in the form of \textbf{external direct sum},  coproduct always exists in the category of modules. Moreover, given a collection $M_i$ of submodules of  $M$, if $M_i \cap \sum_{j\neq i}M_j=0$ for all $i$, clearly we have a natural module isomorphism: 
 \begin{align*}
\bigoplus M_i \cong  \sum M_i 
\end{align*}
In such case, we say  $\sum M_i$ form an  \textbf{internal direct sum}. \\


  The \textbf{sum of} \emph{possibly infinite} \textbf{ideals $\mathfrak{a}_i\trianglelefteq  A$} is defined as their sum as submodules. Notably, finite sum of principal ideals satisfies: 
\begin{align*}
  (x) + (y) = (x+y),\quad \text{ for all }x,y \in A  
\end{align*}

\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}
Note that in general, condition $M_i \cap M_j =0$ for all $i \neq j$ isn't strong enough to make $\sum M_i$ an internal direct sum, and that submodules $N$ of $M_1 \times M_2$ need not take the form $N \cap M_1 \times N \cap  M_2$. See \myref{example}{ex:tr} and \myref{example}{ex:sa}.
\begin{equiv_def}
\textbf{(Quotient of module and ideals)} Let $A$ be a ring and $M$ an  $A$-module. Let $N,P \leq M$ be two submodules. Their \textbf{quotient} is the ideal of $A$ defined by: 
\begin{align*}
  (N:P)\triangleq  \set{a \in A: aP \leq  N} 
\end{align*}
The \textbf{annihilator} of $M$ is then defined by: 
 \begin{align*}
\operatorname{Ann}(M)\triangleq (0:M)
\end{align*}
The \textbf{ideal quotient and annihilator} is defined as their quotient and annihilator as submodules. We then have 
\begin{align*}
\set{d \in A:d \text{ is a zero-divisor}}= \bigcup_{x \neq 0 \in A} \operatorname{Ann}(x)
\end{align*}
We say $M$ is a  \textbf{faithful module} if $\operatorname{Ann}(M)=0$. Interestingly, if $\operatorname{Ann}(M)\leq \mathfrak{a}$, then $M$ has a well-defined natural  $A \quotient \mathfrak{a}$-module structure: 
\begin{align*}
\overline{a}\cdot m \triangleq am 
\end{align*}
\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\textbf{(Basic properties of module quotient)} Let $\mathfrak{a},\mathfrak{b},\mathfrak{c}\trianglelefteq  A$. We have 
\begin{align*}
\mathfrak{a}\leq (\mathfrak{a}:\mathfrak{b})\quad \text{ and }\quad (\mathfrak{a}:\mathfrak{b})\mathfrak{b}\leq \mathfrak{a}\quad \text{ and }\quad \left( \left(\mathfrak{a}:\mathfrak{b} \right):\mathfrak{c} \right)=\left(\mathfrak{a}:\mathfrak{b}\mathfrak{c} \right)= \left( \left(\mathfrak{a}:\mathfrak{c} \right): \mathfrak{b} \right)
\end{align*}
For \emph{possibly infinite} set of ideals $\mathfrak{a}_i,\mathfrak{b}_i \leq A$, we have 
\begin{align*}
\left( \bigcap \mathfrak{a}_i: \mathfrak{b} \right)=\bigcap \left(\mathfrak{a}_i :\mathfrak{b}  \right) \quad \text{ and }\quad \left(\mathfrak{a}: \sum \mathfrak{b}_i \right)=\bigcap \left(\mathfrak{a}:\mathfrak{b}_i \right) 
\end{align*}
Given three submodules $M,N,P$ of some  $A$-module, we have 
\begin{align*}
\operatorname{Ann}(M+N)=\operatorname{Ann}(M) \cap \operatorname{Ann}(N) \quad \text{ and }\quad (N:P)=\operatorname{Ann} \left(N+P \quotient N \right)
\end{align*}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\begin{equiv_def}
\textbf{(Product of ideals and modules)} The \textbf{product} of a \emph{finite} set of ideals $\mathfrak{a}_i$ is defined to be the set of all finite sums of products of elements: 
\begin{align*}
\prod_{i=1}^n \mathfrak{a}_i \triangleq \set{\sum_{\text{finite}} a_1 \cdots a_n\in A: a_{i}\in \mathfrak{a}_i}
\end{align*}
Even though product of two submodules can not be defined, we may define the \textbf{product} $\mathfrak{a}M\leq M$ as: 
\begin{align*}
\mathfrak{a}M \triangleq \set{\sum_{\text{finite}}a_im_i \in M: a_i \in \mathfrak{a}\text{ and }m_i \in M}
\end{align*}
\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\textbf{(Ideals in finite direct product of rings)} Let $\mathfrak{a}\trianglelefteq A_1 \times \cdots \times A_n$. Then 
\begin{align*}
\mathfrak{a}= \mathfrak{a}_1 \times \cdots \times \mathfrak{a}_n
\end{align*}
where $\mathfrak{a}_i\trianglelefteq  A_i$ is the set of $a_i \in A_i$ such that for some  $\prod_{j\neq i}a_j \in \prod_{j \neq i}A_j$, we have $(a_1,\dots ,a_n)\in \mathfrak{a}$. 
\end{theorem}
\begin{proof}
Clearly we have $\mathfrak{a}\leq \mathfrak{a}_1 \times \cdots \times \mathfrak{a}_n$. So we only have to prove the other way around. Let $(a_1,\dots ,a_n) \in \mathfrak{a}_1 \times \cdots \times \mathfrak{a}_n$. By definition, for all $i$, there exists some  $r^{(i)}\in \mathfrak{a}$ such that $r^{(i)}_i=a_i$. Consider 
\begin{align*}
e_i \triangleq (0,\dots ,\overset{i}{1},\dots ,0) \in A 
\end{align*}
We then see 
\begin{align*}
  (a_1,\dots , a_n)= \sum_{i=1}^n e_ir^{(i)} \in \mathfrak{a}
\end{align*}
\end{proof}
\section{Direct Limits}
From construction, immediately we see that direct limits have the properties:  
\begin{theorem}
\label{THpdl}
\textbf{(Basic properties of direct limit of $A$-modules)}  Let $A$ be a ring, $I$ a directed set, and $\set{M_i, \phi_{ij}}$ a directed system of $A$-modules. Then 
\begin{enumerate}[label=(\roman*)]
  \item Every element of $\directlimit M_i$ can be written in the form $\phi_i(x_i)$ for some $i \in I$ and $x_i \in M_i$. 
  \item If $\phi_i(x_i)=0$, then there exists some $j\geq i$ such that $\phi_{ij}(x_i)=0$. 
\end{enumerate}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\label{THdls}
\textbf{(Direct limit of submodules)} Let $M_i$ be a collection of submodules indexed by $I$. If for all  $i,j\in I$ there exists some $k \in I$ that makes  
\begin{align*}
M_i + M_j \leq M_k
\end{align*}
then by setting $i \leq  j \overset{\trinagle}{\iff } M_i \leq M_j$ and the canonical morphisms inclusion maps, $M_i$ forms a directed system whose  direct limit can be realized as  
\begin{align*}
\directlimit M_i = \sum M_i = \bigcup M_i
\end{align*}
Therefore, in particular, every module is the direct limit of its finitely generated submodules. 
\end{theorem}
\begin{proof}
Routine. 
\end{proof}


Let $I$ be a directed set. Consider the category $\operatorname{Func}(I,\mathbf{Mod}_A)$ of directed system of $A$-modules over  $I$, whose homomorphisms are the natural transformations, thus a family of module homomorphism $M_i \rightarrow N_i$. One can check that this category $\operatorname{Func}(I,\mathbf{Mod}_A)$ is abelian, and more importantly 
\begin{equiv_def}
\label{EDsm}
\textbf{(Sheaf morphism is exact if and only if exact componentwise if and only if exact at stalks)}   Let $I$ be a directed set and  $(M_i,\mu),(N_i,\nu ),(P_i,\ld )\in \operatorname{Func}(I,\mathbf{Mod}_A)$ two directed system. Consider two morphism 
\begin{align}
\label{EQMi}
  (M_i,\nu ) \overset{\Phi}{\longrightarrow } (N_i,\nu ) \overset{\Psi}{\longrightarrow }(P_1,\ld )
\end{align}
where the natural transformations are 
\begin{align}
\label{EQmi}
M_i \overset{\phi_i}{\longrightarrow }N_i \overset{\psi_i}{\longrightarrow }P_i
\end{align}
and the induced $A$-module morphisms are 
\begin{align}
\label{EQmI}
\directlimit M_i \overset{\phi}{\longrightarrow } \directlimit N_i \overset{\psi}{\longrightarrow } \directlimit P_i
\end{align}
then the followings statements are equivalent 
\begin{enumerate}[label=(\roman*)]
  \item \myref{Sequence}{EQMi} is exact. 
  \item \myref{Sequence}{EQmi} is exact for all $i$.  
  \item \myref{Sequence}{EQmI} is exact.   
\end{enumerate}
\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}
Let $(A_i,\phi )$ be a directed system of rings. Then it is a directed system of  $\Z$-modules. We can then make the $\Z$-module $\directlimit A_i$ a ring by giving it multiplication 
\begin{align*}
\phi_i (a_i) \cdot \phi_j(a_j) \triangleq \phi_k(\phi_{ik}(a_i)\phi_{jk}(a_j)),\quad \text{ for some }k \geq i,j
\end{align*}
Then we see $\directlimit A_i=0 \implies A_i=0$ for some $i$? The same direct system clearly restrict to direct system $(\operatorname{Nil}(A_i), \phi)$ of $\Z$-modules. Clearly, we then have $\directlimit \operatorname{Nil}(A_i)\leq \operatorname{Nil}\left(\directlimit A_i \right)$. The converse also holds, since if $\phi_i (a_i)^n=0$, then $\phi_i (a_i^n)=0$, and therefore for some $j\geq i$, we have $\phi_{ij}(a_i^n)=0$, which implies $\phi_{ij}(a_i) \in \operatorname{Nil}(A_i)$, where $\phi_{i}(a_i)=\phi_j \circ \phi_{ij}(a_i)$.  \\

This also implies that direct limit of integral domains are integral domains.  




\section{Prime and Maximal Ideals} 
We say a ring homomorphism $ \pi :A \twoheadrightarrow   A\quotient \mathfrak{a}$ satisfies the \textbf{universal property of quotient ring $A\quotient \mathfrak{a}$} if 
\begin{enumerate}[label=(\roman*)]
  \item $\pi $ vanishes on $\mathfrak{a}$. \textbf{(Ring condition)}
  \item For all ring homomorphism $f:A\rightarrow B$ that vanishes on $\mathfrak{a}$ there exist a unique ring homomorphism $\tilde{f} :A\quotient \mathfrak{a}\rightarrow B$ that makes the diagram: 
% https://q.uiver.app/#q=WzAsMyxbMiwwLCJHXFxxdW90aWVudCBOICJdLFswLDAsIkciXSxbMiwyLCJMIl0sWzAsMiwiZyJdLFsxLDIsImYiLDJdLFsxLDAsIiIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dXQ==
\[\begin{tikzcd}
	A && {A\quotient \mathfrak{a} } \\
	\\
	&& B 
	\arrow["\pi",two heads, from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["\tilde{f} ", dashed,from=1-3, to=3-3]
\end{tikzcd}\]
commute. \textbf{(Universality)}
\end{enumerate}
\begin{equiv_def}
\label{EDpi}
  \textbf{(Prime ideals and integral domains)} We say a \emph{nonzero} ring $D$ is an  \textbf{integral domain} if any of the followings hold true:
\begin{enumerate}[label=(\roman*)]
  \item $D$ has no nonzero zero divisor.  
  \item The zero ideal  $(0)$ is prime. 
  \item For any nonzero $a \in D$,  the cancellative law holds: $ab=ac \implies  b=c$.  
  \item For any nonzero $a \in D$, the map $D\longrightarrow D; x \mapsto xa$ is injective. 
  \item $D$ is isomorphic to a subring of a field. 
\end{enumerate}
Let $A$ be a ring, we say $\mathfrak{p}\triangleleft A$ is \textbf{prime} if whenever the product of two elements lies in $\mathfrak{p}$, one of them lies in $\mathfrak{p}$. Therefore, 
 \begin{align*}
\mathfrak{p}\trianglelefteq  A\text{ is prime }\iff A\quotient \mathfrak{p}\text{ is an integral domain }
\end{align*}
\end{equiv_def}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\label{THpp}
\textbf{(Basic properties of prime ideals)} Let $A$ be a ring. Then  
 \begin{enumerate}[label=(\roman*)]
   \item $\operatorname{Spec}(A)$ has minimal elements. In particular, by \customref{THtitr}{correspondence theorem for rings}, every ideal $\mathfrak{a}\trianglelefteq A$ admits a \textbf{minimal prime ideal over} $\mathfrak{a}$, a prime ideal minimal among the prime ideals containing $\mathfrak{a}$.
  \item Let $Z$ be the semigroup of zero-divisors of $A$ and $\Sigma $ be the set of ideals of $A$ that are contained by $Z$. Then maximal elements of $\Sigma$ exist and are prime, and their union $= Z$. 
  \item Let $\mathfrak{p}_1,\dots ,\mathfrak{p}_n \in \operatorname{Spec}(A)$. Then 
  \begin{align*}
 \mathfrak{a}\leq  \bigcup_{i=1}^n \mathfrak{p}_i \implies  \mathfrak{a}\leq  \mathfrak{p}_i\text{ for some }i
  \end{align*}
  \item Let $\mathfrak{a}_1,\dots ,\mathfrak{a}_n\trianglelefteq A$ and $\mathfrak{p}\in \operatorname{Spec}(A)$. Then 
    \begin{align*}
    \bigcap_{i=1}^n \mathfrak{a}_i \leq \mathfrak{p} \implies  \mathfrak{a}_i \leq  \mathfrak{p}\text{ for some }i
    \end{align*}
    and 
  \begin{align*}
  \bigcap_{i=1}^n \mathfrak{a}_i = \mathfrak{p} \implies  \mathfrak{a}_i= \mathfrak{p}\text{ for some }i
  \end{align*}
\end{enumerate}
\end{theorem}
\begin{proof}
(i): This is an application of Zorn's Lemma. We show that the ideal $\mathfrak{q}\triangleq  \bigcap _{i=1}^{\infty} \mathfrak{p}_i$ is prime, where $\set{\mathfrak{p}_i}$ is a decreasing sequence of prime ideals. Let $xy \in \mathfrak{q}$ and $x \not \in \mathfrak{q}$. We are required to show $y \in \mathfrak{q}$. The proof then follows from noting that since  $x \not \in \mathfrak{p}_i$ for some $i$, $x$ can't lies in any higher term, which forces $y$ to lie in all higher terms.\\


(ii): Clearly $\Sigma$ and $\Sigma_{\geq \mathfrak{a}}\triangleq \set{\mathfrak{b} \in \Sigma: \mathfrak{b} \geq \mathfrak{a}}$  satisfies the hypothesis of Zorn's lemma for all $\mathfrak{a}\in \Sigma$, so we know maximal elements of $\Sigma$ exist with union $=Z$. Let $\mathfrak{p} \in \Sigma$ be a maximal element. It remains to show $\mathfrak{p}$ is prime.\\

Let $x,y \not \in \mathfrak{p}$. We are required to show $xy \not \in \mathfrak{p}$. Because $x,y \not \in \mathfrak{p}$, we know $(x)+ \mathfrak{p}$ and $(y)+ \mathfrak{p}$ both contains some non-zero-divisors. The product of the two non-zero-divisors, which is a non-zero-divisor, then lies in $(xy)+ \mathfrak{p}$, which can only happen if $xy \not \in \mathfrak{p}$, as desired. \\

(iii): We prove 
\begin{align*}
\mathfrak{a}\not \leq \mathfrak{p}_i\text{ for all }i \implies \mathfrak{a} \not \leq  \bigcup_{i=1}^n \mathfrak{p}_i 
\end{align*}
by induction. The base case $n=1$ is clear. We now prove the inductive case. By inductive hypothesis, for all $1\leq i\leq n$, there exist some $x_i \in \mathfrak{a}-\bigcup_{j\neq i}\mathfrak{p}_j$. If there exists some $x_i \not \in \mathfrak{p}_i$, then we are done. If there isn't, then we have 
\begin{align*}
y \triangleq \sum_{i=1}^n x_1x_2 \cdots x_{i-1}x_{i+1}x_{i+2}\cdots x_n \in \mathfrak{a} - \bigcup_{i=1}^n \mathfrak{p}_i
\end{align*}
(iv): The first statement is proved by assuming for a contradiction that $x_i \in \mathfrak{a}_i - \mathfrak{p}$ for all $i$, and then observe that $\prod x_i \in \bigcap \mathfrak{a}_i -\mathfrak{p}$ since $\mathfrak{p}\in \operatorname{Spec}(A)$. Let $\bigcap_{i=1}^n \mathfrak{a}_i= \mathfrak{p}$. By first statement, $\mathfrak{a}_i\leq \mathfrak{p}$ for some $i$. We then see that the equality must holds, otherwise $\bigcap  \mathfrak{a}_i < \mathfrak{p}$. 


\end{proof}
\begin{equiv_def}
\label{EDmf}
  \textbf{(Maximal ideals and fields)} A proper ideal $\mathfrak{m} \triangleleft  A$ is said to be \textbf{maximal} if it is maximal among the proper ideals of $A$. We say a \emph{nonzero} ring $F$ is a  \textbf{field} if and of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item Every nonzero element of $F$ is a unit. 
  \item The only ideal of $F$ are  $0$ and  $(1)$. 
  \item Every homomorphism $F\longhookrightarrow  B\neq 0$ into a ring $\neq 0$ is injective. 
\end{enumerate}
Let $A$ be a ring. Therefore, by  \customref{THtitr}{correspondence theorem for rings}, 
\begin{align*}
   \mathfrak{m}\subseteq A\text{ is maximal }\iff  A \quotient \mathfrak{m}\text{ is a field }
\end{align*}
Because of such, maximal ideals are prime. 
\end{equiv_def}
\begin{proof}
Routine. We prove (iii)$\implies$ (i). Let $x\in F$ be a non-unit. We are required to prove that $x=0$. Because  $(x)\neq (1)$, $F \quotient (x)\neq 0$. Then the canonical projection $\pi : F  \rightarrow  F \quotient (x)$ is injective, which forces $x=0$, since $\pi (x)=0$. 
\end{proof}
\begin{theorem}
\label{THem}
\textbf{(Basic properties of maximal ideals)} Let $A$ be a ring. Then 
\begin{enumerate}[label=(\roman*)]
  \item Every proper ideal $\mathfrak{a}\neq (1)$ is contained by some maximal ideal. 
  \item Every non-unit is contained by some maximal ideal.  
  \item  If for all $x \in A$, there exists some $n>1$ that makes  $x^n=x$, then  $\operatorname{Spec}(A)=\operatorname{Max}(A)$. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (ii) follows from (i), since the ideal generated by a non-unit must be proper. (i) follows from applying \emph{Zorn's lemma} on the set of ideals in $A \quotient \mathfrak{a}$  and \customref{THtitr}{correspondence theorem for rings}. \\

  (iii): Let $\mathfrak{p} \in \operatorname{Spec}(A)$ and $x \in A-\mathfrak{p}$. We are required to show $(x+ \mathfrak{p})\in A \quotient \mathfrak{p}$ has an inverse.Because \customref{EDpi}{$A \quotient \mathfrak{p}$ is an integral domain, we may apply cancellation law on $(x+ \mathfrak{p})^n=(x+ \mathfrak{p})$ to see $(x+ \mathfrak{p})^{n-1}= 1+ \mathfrak{p}$ in $A \quotient \mathfrak{p}$}. This implies $(x+ \mathfrak{p})^{n-2}$ is the desired inverse of $x+ \mathfrak{p}$. 
\end{proof}
\begin{equiv_def}
\label{EDci}
\textbf{(Comaximal ideal pairs)} Let $A$ be a ring with  $\mathfrak{a},\mathfrak{b}\trianglelefteq  A$. We say $\mathfrak{a},\mathfrak{b}$ are \textbf{comaximal} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item $\mathfrak{a}+\mathfrak{b}=(1)$. 
  \item  $a+b=1$ for some  $a \in \mathfrak{a}$ and $b \in \mathfrak{b}$. 
\end{enumerate}
Let $\mathfrak{a}_1,\dots , \mathfrak{a}_n \trianglelefteq A$, and consider the natural ring homomorphism $A\overset{\pfi }{\longrightarrow} \prod A \quotient \mathfrak{a}_i$. Since $\operatorname{ker}\pfi = \bigcap \mathfrak{a}_i$, we know  $\pfi $ is injective if and only if $\bigcap \mathfrak{a}_i=0$. We also have: 
\begin{align}
\label{EQpf}
  \pfi\text{ is surjective }\iff  \mathfrak{a}_i\text{ are pairwise comaximal }
\end{align}
which implies \textbf{Chinese remainder theorem for integers} by counting cardinality. Moreover, we have:   
\begin{align}
\label{EQa1}
\mathfrak{a}_i\text{ are pairwise comaximal }\implies \prod_{i=1}^n \mathfrak{a}_i = \bigcap_{i=1}^n \mathfrak{a}_i
\end{align}
\end{equiv_def}
\begin{proof}
We first prove \myref{Statement}{EQpf} ($\implies $): We show $\mathfrak{a}_1,\mathfrak{a}_2$ are comaximal. Because $\pfi $ is surjective, we know there exists $x \in A$ such that    
\begin{align}
\label{EQx1}
x \equiv 1 \pmod{\mathfrak{a}_1}\quad \text{ and }\quad x \equiv 0 \pmod{\mathfrak{a}_i}\pmod{\mathfrak{a}_i}\text{ for all }i\geq 2
\end{align}
We now see that $1-x \in \mathfrak{a}_1$ and $x \in \mathfrak{a}_2$, as desired. \\

($\impliedby$): Clearly, we only have to show the existence of some $x \in A$ that satisfies  \myref{equation}{EQx1}. Because $\mathfrak{a}_1,\dots ,\mathfrak{a}_n$ are pairwise comaximal, for all $i\geq 2$, we may find $u_i \in \mathfrak{a}_1$ and $v_i \in \mathfrak{a}_i$ that makes $u_i+v_i=1$. Direct computation shows that $x\triangleq \prod_{i=2}^n v_i $ suffices.   \\

We now prove \myref{statement}{EQa1}, which relies on induction. Note that we always have $\leq $, so we only have to prove $\geq $. Let  $a_1+a_2\triangleq 1$ with $a_1 \in \mathfrak{a}_1$ and $a_2 \in \mathfrak{a}_2$. The base case $n=2$ then follows from noting that 
\begin{align*}
x \in \mathfrak{a}_1 \cap  \mathfrak{a}_2 \implies  x= xa_1+ xa_2 \in \mathfrak{a}_1\mathfrak{a}_2
\end{align*}
We now prove the inductive case. Let $x_i+y_i\triangleq 1$ with $x_i \in \mathfrak{a}_i$ and $y_i \in \mathfrak{a}_n$ for all $i \leq n-1$. We then have 
\begin{align*}
\prod_{i=1}^{n-1}x_i \equiv 1 \pmod{\mathfrak{a}_n}
\end{align*}
which implies $\mathfrak{a}_n$ and $\mathfrak{a}_1\cdots \mathfrak{a}_{n-1}$ are comaximal. Therefore, by inductive hypothesis, we have 
\begin{align*}
\prod_{i=1}^n \mathfrak{a}_i = (\mathfrak{a}_1 \cdots \mathfrak{a}_{n-1}) \cap  \mathfrak{a}_n = \bigcap_{i=1}^n \mathfrak{a}_i
\end{align*}
\end{proof}
\begin{theorem}
\label{THfitr} \label{THtitr}
\textbf{(Isomorphism theorems for rings)} Let $f: A \rightarrow B$ be a ring homomorphism. The first isomorphism theorem stated that the induced map $\tilde{f}: A \quotient \operatorname{ker}(f) \hookrightarrow  B$ is injective. Let $B$ be a subring of  $A$, and  $\mathfrak{a}\trianglelefteq A$. The second isomorphism theorem stated that:  
\begin{enumerate}[label=(\roman*)]
  \item $B+ \mathfrak{a}\triangleq \set{b+a\in A: b \in B,a \in \mathfrak{a}}$ forms a subring of $A$.  
  \item $B\cap \mathfrak{a}$ forms an ideal in $B$.  
  \item $(B+\mathfrak{a})\quotient \mathfrak{a}\cong B\quotient (B \cap \mathfrak{a})$ as rings.
\end{enumerate}
Let $\mathfrak{a}\trianglelefteq A$ and $\pi : A \twoheadrightarrow A \quotient \mathfrak{a}$ be the canonical ring homomorphism. The third isomorphism theorem stated that for all $\mathfrak{a}\leq \mathfrak{b}\trianglelefteq A$, the subset $\pi  (\mathfrak{b})\trianglelefteq A \quotient \mathfrak{a}$ forms an ideal, and the natural map 
\begin{align}
\label{EQaa}
  (A \quotient \mathfrak{a}) \quotient (\mathfrak{b}\quotient \mathfrak{a}) \cong  A \quotient  \mathfrak{b},\quad \text{ where }\mathfrak{b}\quotient \mathfrak{a}\triangleq \pi (\mathfrak{b})
\end{align}
forms a ring isomorphism. The \textbf{spectrum} $\operatorname{Spec}(A)$ is the set of prime ideals in $A$, and the \textbf{maximal spectrum}  $\operatorname{Max}(A)$ is the set of maximal ideals in $A$.\\


The correspondence theorem for rings stated that \myref{equation}{EQaa} forms a bijection between the collection of ideals of $A$ that contains  $\mathfrak{a}$ and ideals of $A \quotient \mathfrak{a}$, a bijection between the collection of prime ideals of $A$ that contains  $\mathfrak{a}$ and $\operatorname{Spec}(A \quotient \mathfrak{a})$, and a bijection between the collection of maximal ideals of $A$ that contains  $\mathfrak{a}$ and $\operatorname{Max}(A \quotient \mathfrak{a})$. \\

Also, given arbitrary $\mathfrak{c}\trianglelefteq  A$, we always have 
\begin{align*}
\pi  (\mathfrak{c})= (\mathfrak{c}+ \mathfrak{a}) \quotient \mathfrak{a}  
\end{align*}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}



\section{Radical Ideals}
\begin{equiv_def}
\label{EDfN}
\textbf{(Nilradical and Jacobson radical)} Let $A$ be a ring. The set $\operatorname{Nil}(A)$ of nilpotents in $A$ clearly forms an ideal, and is called the  \textbf{nilradical}. We have: 
\begin{align}
\label{EQna}
\operatorname{Nil}(A)=\bigcap \operatorname{Spec} (A)
\end{align}
Clearly, $A \quotient \operatorname{Nil}(A)$ has no nilpotent $\neq 0$. We define the \textbf{Jacobson radical} $\operatorname{Jac}(A)$ by 
\begin{align*}
\operatorname{Nil}(A)\leq \operatorname{Jac}(A) \triangleq \bigcap \operatorname{Max}(A) 
\end{align*}
For all $x \in A$, we have: 
\begin{align}
\label{EQxj}
x \in \operatorname{Jac}(A) \iff 1 - xy \in A^{\times},\quad \text{ for all }y\in A
\end{align}
\end{equiv_def}
\begin{proof}
\myref{Equation}{EQna}: $\operatorname{Nil}(A)\leq \bigcap \operatorname{Spec}A$ is clear. Assume $x \in \bigcap \operatorname{Spec}A -  \operatorname{Nil}(A)$ for a contradiction. Let $\Sigma$ be the set of ideals $\mathfrak{a}$ such that $x^n\not\in \mathfrak{a}$ for all $n>0$. Because unions of chains in $\Sigma$ belong to $\Sigma$ and because $0 \in \Sigma$, by Zorn's Lemma, there exists some maximal element $\mathfrak{a} \in \Sigma$. Because $x\not \in \mathfrak{a}$, to close out the proof, we only have to show $\mathfrak{a}$ is prime.\\

Let $yz \in \mathfrak{a}$. Assume for a contradiction that $y\not\in \mathfrak{a}$ and $z\not\in \mathfrak{a}$. By maximality of $\mathfrak{a}$, both  $\mathfrak{a}+ (y),\mathfrak{a}+(z)$ don't belong to $\Sigma$. This implies $x^n \in \mathfrak{a}+ (y)$ and $x^m \in \mathfrak{a} + (z)$ for some $n,m>0$, which cause a contradiction to $\mathfrak{a} \in \Sigma$, since $x^{n+m} \in \mathfrak{a} + (yz) =\mathfrak{a}$. \\

\myref{Statement}{EQxj}: 
$(\implies )$: Assume for a contradiction that $1-xy$ is a non-unit, and \customref{THem}{therefore contained by some maximal ideal $\mathfrak{m}$}. The contradiction then follows from noting that since $x \in \mathfrak{m}$, we have $1 \in \mathfrak{m}$, which is impossible. \\

$(\impliedby)$: Assume for a contradiction that $x \not \in \mathfrak{m}$ for some $\mathfrak{m}\in \operatorname{Max}(A)$. This forces $\mathfrak{m}+(x)=(1)$, which implies the existence of some $m \in \mathfrak{m}$ and $y \in A$ that makes $m+xy=1$. Therefore by premise, $m \in A^{\times}$, which contradicts to $m \in \mathfrak{m}$. 
\end{proof}
\begin{Example}{$\operatorname{Nil}(A)=\operatorname{Jac}(A)$ doesn't require $\operatorname{Spec}(A)=\operatorname{Max}(A)$.}{}
Let $A\triangleq \C[x]$. Fundamental theorem of algebra implies 
\begin{align*}
\operatorname{Spec}(A)= \set{(x-\ld )\trianglelefteq A: \ld \inc} \cup  \set{(0)}
\end{align*}
Therefore, we know 
\begin{align*}
\operatorname{Max}(A)= \set{(x-\ld )\trianglelefteq A: \ld  \in \C}
\end{align*}
and $\operatorname{Nil}(A)=\operatorname{Jac}(A)=0$. 
\end{Example}
\begin{theorem}
\textbf{(Criteria for $\operatorname{Nil}(A)=\operatorname{Jac}(A)$)} Let $A$ be a ring. If every ideal of  $A$ not contained by $\operatorname{Nil}(A)$ contains a nonzero idempotent, then $\operatorname{Nil}(A)=\operatorname{Jac}(A)$. 
\end{theorem}
\begin{proof}
Let  $x \in A- \operatorname{Nil}(A)$. Clearly $(x)\not \subseteq \operatorname{Nil}(A)$. Therefore, $(1-xa)xa=0$ for some $a \in A$ that makes $xa\neq 0$. This implies $1-xa$ is a zero-divisor, which implies  $x \not \in \operatorname{Jac}(A)$, as desired.  
\end{proof}
\begin{Example}{The set of zero-divisors doesn't form an ideal}{}
Consider the ring $\R \times \R$. The sum of the zero-divisors $(0,1)$ and $(1,0)$ isn't a zero-divisor.  
\end{Example}
\begin{equiv_def}
\label{EDr}
\textbf{(Radical and radical ideal)} Let $A$ be a ring and $\mathfrak{a}\trianglelefteq  A$. The followings are equivalent: 
\begin{enumerate}[label=(\roman*)]
  \item $\sqrt{\mathfrak{a}}\triangleq \set{x\in A: x^n \in \mathfrak{a}\text{ for some }n>0}$. 
  \item $\set{x \in A: x^n \in \mathfrak{a}\text{ for }n\gg  0 }$. 
  \item $\pi ^{-1}\left(\operatorname{Nil}(A \quotient \mathfrak{a}) \right)$, where $\pi  : A \twoheadrightarrow A \quotient \mathfrak{a}$  is the canonical projection. 
  \item $\bigcap V(\mathfrak{a})$, where $V(\mathfrak{a})\triangleq \set{\mathfrak{p}\in \operatorname{Spec}(A):\mathfrak{a}\leq \mathfrak{p}}$. 
\end{enumerate}
We say $\mathfrak{a}$ is a \textbf{radical ideal} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item $\mathfrak{a}= \sqrt{\mathfrak{a}} $.
  \item $\mathfrak{a}$ is an intersection of some set of prime ideals. 
\end{enumerate}
Therefore, both nilradical and Jacobson radical are radical ideals.  
\end{equiv_def}
\begin{proof}
The equivalent definition for radical ideal follows from (iv).   (i)$\iff $ (ii)$\iff $ (iii) is clear. (iii)$\iff $(iv) follows from computing 
\begin{align*}
&\pi \left( \bigcap \set{\mathfrak{p}\in \operatorname{Spec}(A): \mathfrak{a}\leq \mathfrak{p}} \right)\\
&= \bigcap \set{\pi  (\mathfrak{p})\in \operatorname{Spec}(A \quotient \mathfrak{p}): \mathfrak{a}\leq \mathfrak{p}\in \operatorname{Spec}(A)}\\
&= \customref{EDfN}{\bigcap \operatorname{Spec}(A \quotient \mathfrak{p})= \operatorname{Nil}(A \quotient \mathfrak{p})}
\end{align*}
where the second equality follows from \customref{THtitr}{correspondence theorem for rings}.  
\end{proof}
Clearly, prime ideals are radical, but radical ideals need not be prime: 
\begin{Example}{Radical ideals need not be prime.}{}
Since $(6)\trianglelefteq  \Z$ is the intersection of prime ideals $(2)$ and $(3)$, we know $(6)\trianglelefteq \Z$ is radical, but since $2\cdot 3 \in (6)$, we see $(6)\trianglelefteq \Z$ isn't prime.  
\end{Example}

\begin{theorem}
\label{THpr}
  \textbf{(Basic properties of radicals)} Let $\mathfrak{a}\trianglelefteq A$. Then  
\begin{align}
\label{EQva}
V(\mathfrak{a})= V (\sqrt{\mathfrak{a}})
\end{align}
In other words, $\mathfrak{a}$ and $\sqrt{\mathfrak{a}} $ share the same set of prime ideals containing them. Because of such, we also have: 
\begin{align*}
V(\mathfrak{a}) \subseteq V(\mathfrak{b}) \iff  \sqrt{\mathfrak{a}} \geq \sqrt{\mathfrak{b}} 
\end{align*}
We also have 
\begin{align*}
\sqrt{\sqrt{\mathfrak{a}}}=\sqrt{\mathfrak{a}}\quad \text{ and }\quad \sqrt{\mathfrak{a}}=(1)\iff  \mathfrak{a}=(1) 
\end{align*}
and the followings properties: 
\begin{enumerate}[label=(\roman*)]
  \item $\sqrt{\mathfrak{a}\mathfrak{b}}= \sqrt{\mathfrak{a}\cap \mathfrak{b}}= \sqrt{\mathfrak{a}} \cap \sqrt{\mathfrak{b}}    $. 
  \item $\sqrt{\mathfrak{a}+\mathfrak{b}} = \sqrt{\sqrt{\mathfrak{a}} + \sqrt{\mathfrak{b}} }  $. 
  \item If $\sqrt{\mathfrak{a}},\sqrt{\mathfrak{b}}$ are comaximal, then $\mathfrak{a},\mathfrak{b}$ are comaximal. 
  \item Given $\mathfrak{p}\in \operatorname{Spec}(A)$, we have $\sqrt{\mathfrak{p}^n}= \mathfrak{p} $ for all $n>0$.  
  \item The multiplicative semigroup of zero-divisors $= \bigcup _{x\neq 0}\sqrt{\operatorname{Ann}(x)} $. 
\end{enumerate}
\end{theorem}
\begin{proof}
Note that $V(\mathfrak{a})\supseteq V(\sqrt{\mathfrak{a}} )$ follows trivially form  $\mathfrak{a}\leq \sqrt{\mathfrak{a}}$, and that $V(\mathfrak{a})\subseteq V(\sqrt{\mathfrak{a}} )$ follows from  \customref{EDr}{$\sqrt{\mathfrak{a}} = \bigcap V(\mathfrak{a}) $}. Note that $V(\mathfrak{a})\subseteq V(\mathfrak{b})\implies  \sqrt{\mathfrak{a}} \geq \sqrt{\mathfrak{b}} $ follows from  \customref{EDr}{$\sqrt{\mathfrak{a}}=\bigcap V(\mathfrak{a})$}, while $\sqrt{\mathfrak{a}}\geq \sqrt{\mathfrak{b}}\implies V(\mathfrak{a})\subseteq V(\mathfrak{b}) $ follows trivially from \myref{equation}{EQva}. \\

(i): We prove $\sqrt{\mathfrak{a}}\cap \sqrt{\mathfrak{b}}\leq \sqrt{\mathfrak{a}\mathfrak{b}}   $. Let $x^n \in \mathfrak{a}\cap \mathfrak{b}$. Then $x^{2n}=x^nx^n \in \mathfrak{a}\mathfrak{b}$. \\

(ii): We prove $\sqrt{\sqrt{\mathfrak{a}} + \sqrt{\mathfrak{b}}} \leq \sqrt{\mathfrak{a}+\mathfrak{b}}  $. Let $x^n\triangleq y+z$ where $y^m \in \mathfrak{a}$ and $z^k \in \mathfrak{b}$. Then $x^{n(m+k)}=(y+z)^{m+k}\in \mathfrak{a}+\mathfrak{b}$. \\

(iii): This follows from computing $\sqrt{\mathfrak{a}+\mathfrak{b}}=\sqrt{\sqrt{\mathfrak{a}}+\sqrt{\mathfrak{b}} }= \sqrt{(1)}=(1)  $. \\

(iv): Clearly, we have $\mathfrak{p}\leq \sqrt{\mathfrak{p}^n}$. Let $x \in \sqrt{\mathfrak{p}^n} $. Then $x^m \in \mathfrak{p}^n \leq \mathfrak{p}$ for some $m$, which implies  $x \in \mathfrak{p}$ by primality of $\mathfrak{p}$. \\

(v): Let $x \neq 0$ and $y^n \in \operatorname{Ann}(x)$ with $y^{n-1}\not \in \operatorname{Ann}(x)$. Then $y(y^{n-1}x)=y^nx=0$ shows that $y$ is a zero-divisor. If $y\neq 0$ is a zero-divisor with $xy=0$ and $x \neq 0$. Then $y \in \sqrt{ \operatorname{Ann}(x)}$. 
\end{proof}
\section{Nakayama Lemmas}
We say an $A$-module homomorphism $ \pi :M \twoheadrightarrow   M\quotient N$ satisfies the \textbf{universal property of quotient module $M\quotient N$} if 
\begin{enumerate}[label=(\roman*)]
  \item $\pi $ vanishes on $N$. \textbf{(Module condition)}
  \item For all $A$-module homomorphism $f:M\rightarrow P$ that vanishes on $\mathfrak{a}$ there exist a unique ring homomorphism $\tilde{f} :M\quotient N\rightarrow P$ that makes the diagram: 
% https://q.uiver.app/#q=WzAsMyxbMiwwLCJHXFxxdW90aWVudCBOICJdLFswLDAsIkciXSxbMiwyLCJMIl0sWzAsMiwiZyJdLFsxLDIsImYiLDJdLFsxLDAsIiIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dXQ==
\[\begin{tikzcd}
	M && {M\quotient N} \\
	\\
	&& P 
	\arrow["\pi",two heads, from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["\tilde{f} ", dashed,from=1-3, to=3-3]
\end{tikzcd}\]
commute. \textbf{(Universality)}
\end{enumerate}

\begin{theorem}
\textbf{(Isomorphism theorems and correspondence theorems for modules)} \label{THitm} 
Let $f: M \rightarrow N$ be an $A$-module homomorphism. The first isomorphism theorem for modules stated that
\begin{align*}
M \quotient  \operatorname{ker}(f) \cong \operatorname{Im}(f)   
\end{align*}
Let $P,Q$ be two submodules of  $M$.  The second isomorphism theorem for modules stated that 
\begin{align*}
\frac{P+Q}{Q} \cong  \frac{P}{P \cap Q}  
\end{align*}
Let $M\leq  L$ be $A$-modules, and $\pi : L \twoheadrightarrow L \quotient M$ be the canonical $A$-module homomorphism. Denoting 
\begin{align*}
\frac{K}{M} \triangleq \pi  (K) \leq  \frac{L}{M}
\end{align*}
for all modules $K$ containing $M$, the third isomorphism theorem for modules stated that 
\begin{align*}
  (L \quotient M) \quotient (K \quotient M) \cong  L \quotient K
\end{align*}
The correspondence theorem for modules stated that the third isomorphism theorem induces a bijection between submodules of $L \quotient M$ and submodules of $L$ containing $M$. 
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\textbf{(Structure theorem for finitely generated modules)} Let $M$ be an $A$-module. Then
\begin{align*}
M\text{ is finitely generated }\iff  M\cong A^n\quotient \mathfrak{a}\text{ for some }n>0\text{ and }\mathfrak{a}\leq A^n
\end{align*}
\end{theorem}
\begin{proof}
$(\implies )$: Let $M\triangleq  (x_1,\dots ,x_n)$. Define $\pfi : A^n \rightarrow M$ by $\pfi (a_1,\dots ,a_n)\triangleq a_1x_1 + \cdots + a_nx_n$, which is clearly surjective. Then by \customref{THitm}{first isomorphism theorem for modules}, we see $M \cong  A^n \quotient \operatorname{ker}(\pfi )$. \\

  $(\impliedby)$: $M$ is clearly generated by $\set{e_i \in A^n \quotient \mathfrak{a}}$, where $e_i\triangleq (0,\dots ,0 ,1,0,\dots, 0)$ with $1$ being in the  $i$-th slot. 
\end{proof}
\begin{Example}{Submodules of finitely generated modules need not be finitely generated (over a non-noetherian ring)}{}
Let $A\triangleq \R[X_1,X_2,\dots ]$ and define $\mathfrak{a}\trianglelefteq A$ by 
\begin{align*}
\mathfrak{a}\triangleq (X_1,X_2,\dots)
\end{align*}
Because  $A=(1)$, we know $A$ as an  $A$-module is finitely generated. To see $(X_1,X_2, \dots )$ isn't finitely generated, assume for a contradiction that  $(X_1,X_2,\dots,)=(f_1,\dots ,f_m)$. Let $X_k$ be a variable that doesn't occur in any of $f_i$. Then since $X_k \in (f_1,\dots ,f_m)$, we may write $X_k= g_1f_1+\cdots +g_m f_m$ for some $\set{g_i \in A: 1\leq i\leq m}$. Therefore, $X_k$ must occur in some  $g_if_i$, which is only possible if $X_k$ occurs in  $g_i$ and $f_i$ has nonzero constant term. This then cause a contradiction to $f_i \in (X_1,X_2,\dots )$. 
\end{Example}
\begin{theorem}
\textbf{(Finitely generated modules are closed under extension)} Given a short exact sequence of module: 
\begin{align*}
0 \longrightarrow M' \longrightarrow M \longrightarrow M'' \longrightarrow 0
\end{align*}
If $M'$ and  $M''$ are finitely generated, then  $M$ is finitely generated. 
\end{theorem}
\begin{proof}
Let $M'\triangleq (x_1,\dots ,x_n)$, $M'' \triangleq (y_1,\dots ,y_m)$, and $x \in M$. To see that $x$ can be generated by $x_i$ and  $y_i$, just observe that since for some $b_j$ we have: 
\begin{align*}
x+ M' \triangleq \sum b_jy_j + M'
\end{align*}
we know for some $a_i$ we have  
\begin{align*}
x= \sum a_ix_i + \sum b_jy_j 
\end{align*}
\end{proof}
\begin{theorem}
  \textbf{(Basic properties of finitely generated modules)} Let $M$ be a finitely generated  $A$-module $(x_1,\dots ,x_m)$ and  $\pfi : M \twoheadrightarrow A^n$ be a surjective homomorphism. Then $\operatorname{ker}(\pfi )$ is finitely generated. 
\end{theorem}
\begin{proof}
Clearly, we have a short exact sequence 
\begin{align*}
0 \longrightarrow \operatorname{ker}(\pfi ) \longhookrightarrow M \overset{\pfi }{\longtwoheadrightarrow  } A^n \longrightarrow 0
\end{align*}
Let $e_1,\dots ,e_n$ be the basis for $A^n$, and let $u_i \in M$ satisfy $\pfi  (u_i)=e_i$. We then see that the sequence right splits via $s:A^n \rightarrow M$ defined by $s(e_i)\triangleq u_i$. Therefore, by  \customref{THsl}{splitting lemma}, we have $M \cong  \operatorname{ker}(\pfi )\oplus A^n$. Write 
\begin{align*}
x_i = t_i + \sum_{j=1}^n a_j u_j\text{ for all }1\leq i \leq m
\end{align*}
We now see $\operatorname{ker}(\pfi )=(t_1, \dots ,t_m)$. 
\end{proof}
\begin{theorem}
\label{THgCH}
\textbf{(Generalized Cayley-Hamilton theorem)} Let $M$ be a finitely generated $A$-module, $\mathfrak{a}\trianglelefteq M$, and $\pfi$ an $A$-module endomorphism of  $M$ such that $\pfi (M)\leq \mathfrak{a}M$. Then $\pfi $ satisfies an equation of the form 
\begin{align*}
  \pfi^n + a_1 \pfi ^{n-1}+ \cdots + a_n =0,\quad \text{ where }a_i \in \mathfrak{a}
\end{align*}
\end{theorem}
\begin{proof}
Let $M\triangleq  ( x_1,\dots, x_n) $. Because $\pfi  (M)\leq \mathfrak{a}M$, we may write $\pfi (x_i)\triangleq \sum_{j=1}^n a_{ij}x_j$ where $a_{i,j}\in \mathfrak{a}$. Therefore, for all $i$, we have 
\begin{align*}
\sum_{j=1}^n  \left(\delta_{ij} \pfi  - a_{ij} \right) x_j =0 
\end{align*}
Multiplying from the left the adjugate of the matrix  $\delta_{ij}\pfi - a_{ij} \in M_n(A[\pfi ])$, we now see that $\operatorname{det}(\delta_{ij}\pfi - a_{ij})\in A[\pfi ]$ is the polynomial we are looking for. 
\end{proof}
\begin{theorem}
\label{THfNl}
\textbf{(First version of Nakayama lemma)} Let $M$ be a finitely generated $A$-module and $\mathfrak{a}\trianglelefteq A$ satisfies $\mathfrak{a}M=M$. Then there exists $x \equiv 1 \pmod{\mathfrak{a}}$ that makes $xM=0$. 
\end{theorem}
\begin{proof}
Because $\mathfrak{a}M=M$, we know $1 \in \operatorname{End}(M)$ satisfies $1(M)\leq \mathfrak{a}M$. Therefore, we may \customref{THgCH}{generalized Cayley-Hamilton} to see that $x\triangleq  1+ a_1 \cdots + a_n$ suffices. 
\end{proof}
\begin{theorem}
\label{THsNl}
\textbf{(Second version of Nakayama lemma)} Let $M$ be a finitely generated  $A$-module and $\mathfrak{a}\trianglelefteq A$ satisfies $\mathfrak{a}M=M$. If $\mathfrak{a}\leq \operatorname{Jac}(A)$, then $M=0$. 
\end{theorem}
\begin{proof}
Because $\mathfrak{a}\leq \operatorname{Jac}(A)$, \customref{THfNl}{first version of Nakayama lemma} implies the existence of some $x \in A$ such that 
 \begin{align*}
x \equiv 1 \pmod{\operatorname{Jac}(A)}\quad \text{ and }\quad xM=0
\end{align*}
By \customref{EDfN}{definition of Jacobson radical}, $x\equiv 1\pmod{\operatorname{Jac}(A)}$ implies $x \in A^{\times}$. Therefore, we have $M=x^{-1}xM=0$, as desired. 
\end{proof}
\begin{theorem}
\label{THtNl}
\textbf{(Third version of Nakayama lemma)} Let $M$ be a finitely generated  $A$-module with $N\leq M$ and  $\mathfrak{a}\leq \operatorname{Jac}(A)$. If $M= \mathfrak{a}M+N$, then $M=N$. 
\end{theorem}
\begin{proof}
By \customref{THsNl}{second version of Nakayama lemma}, it suffices to show $\mathfrak{a}(M \quotient N)=M \quotient N$, which follows from computing 
\begin{align*}
\mathfrak{a}\left(M \quotient N \right)=\mathfrak{a}M+N \quotient N = M \quotient N
\end{align*}
\end{proof}
\begin{corollary}
  \textbf{(Algebraic consequences of Nakayama lemmas)} Let $A$ be a ring. Then  
\begin{enumerate}[label=(\roman*)]
  \item Let $(A,\mathfrak{m})$  be a local ring and $M$ be an  $A$-module.  If $\set{x_i+\mathfrak{m}M: 1 \leq i \leq n}$ forms a basis for the $A \quotient \mathfrak{m}$-vector space $M \quotient \mathfrak{m}M$, then $M= (x_1,\dots ,x_n)$.  
  \item Let $N,M$ be two $A$-modules with  $M$ finitely generated and $\mathfrak{a}\leq  \operatorname{Jac}(A)$. Let  $u: N\rightarrow M$ be a homomorphism. If the induced homomorphism $\tilde{u}:N \quotient \mathfrak{a}N \twoheadrightarrow  M \quotient \mathfrak{a}M $ is surjective, then $u$ is surjective. 
\end{enumerate}

\end{corollary}
\begin{proof}
  (i): Let $N \triangleq (x_1,\dots ,x_n)\leq M$. We are required to prove $N=M$, which follows \customref{THtNl}{third version of Nakayama lemma} and the fact that $N+ \mathfrak{m}M=M$. \\

(ii): The proof follows from \customref{THtNl}{third version of Nakayama lemma} and the observation that $M=u(N)+ \mathfrak{a}M$.  
\end{proof}
\section{Exact Sequence of Modules}
Let $M,N$ be two  $A$-modules. The hom-space $\operatorname{Hom}(M,N)$ has a natural $A$-module structure. Let $P$ be an $A$-module. Clearly, we have a \emph{covariant} functor $\Hom (P,-):\mathbf{Mod}_A \rightarrow \mathbf{Mod}_A$ defined by: 
\begin{align*}
M \rightarrow \Hom (P,M)\quad \text{ and }\quad F(f)(g)\triangleq f \circ g
\end{align*}
and a \emph{contravariant} functor   $\Hom (-,P):\mathbf{Mod}_A \rightarrow \mathbf{Mod}_A$ defined by:  
\begin{align*}
M \rightarrow \Hom (M,P)\quad \text{ and }\quad G(f)(g)\triangleq  g\circ f 
\end{align*}
We always have the natural isomorphism
\begin{align*}
\operatorname{Hom}(A,M)\cong  M\quad \text{ and }\quad f \mapsto f(1)  
\end{align*}
\begin{theorem}
\label{THhomp}
\textbf{(Both $\Hom (-,P)$ and $\Hom  (P,-)$ are left-exact)} Let $A$ be a ring, and denote the contravariant functor $\Hom (-,P)$ by $G$ and the covariant functor  $\Hom  (P,-)$ by $F$. Then 
\begin{enumerate}[label=(\roman*)]
   \item The sequence: 
\begin{align*}
M' \overset{u}{\longrightarrow } M \overset{v}{\longtwoheadrightarrow  } M'' \longrightarrow 0
\end{align*}
is exact $\iff $ For all $A$-module  $P$, the sequence: 
\begin{align*}
0 \longrightarrow \Hom (M'',P) \overset{G(v)}{\longhookrightarrow  } \Hom  (M,P) \overset{G(u)}{\longrightarrow } \Hom (M',P) 
\end{align*}
is exact.  
\item The sequence: 
\begin{align*}
0\longhookrightarrow  N' \overset{u}{\longrightarrow } N \overset{v}{\longrightarrow } N'' 
\end{align*}
is exact $\iff $ For all $A$-module $P$, the sequence: 
\begin{align*}
0 \longrightarrow \Hom (P,N') \overset{F(u)}{\longrightarrow } \Hom  (P,N) \overset{F(v)}{\longtwoheadrightarrow  } \Hom (P,N'') 
\end{align*}
is exact. 
\end{enumerate}
In particular, for all $A$-module  $P$, both the covariant functor $\Hom  (P,-)$ and the contravariant functor  $\Hom  (-,P)$ are \textbf{left-exact}.   
\end{theorem}
\begin{proof}
Since the proof for (i) and (ii) are similar, we only prove (i). We first prove ($\implies $), which requires to prove three statements: 
\begin{align*}
F(u)\circ F(v)=0\quad \text{ and }\quad F(v)\text{ is injective }\quad \text{ and }\quad \operatorname{ker}(F(u))\leq \operatorname{Im}(F(v))
\end{align*}
The first statement is clear
\begin{align*}
F(u) \circ F(v)= F(v \circ u)=F(0)=0
\end{align*}
To prove the second statement, let $g \in \Hom (M'',P)$ satisfies $F(v)(g)=0$, and we are required to prove that $g=0$, which follows from surjectivity of $v$ and the premise: 
\begin{align*}
g\circ v = F(v)(g)=0 
\end{align*}
To prove the third statement, let $f\in \operatorname{ker}(F(u))$, and we are required to show that  $f=F(v)(g)$ for some $g \in \Hom (M'',P)$. Now, since the premise stated that 
\begin{align*}
f\circ u= F(u)(f)=0
\end{align*}
we know 
\begin{align*}
\operatorname{ker}(f) \leq \operatorname{Im}(u)\leq \operatorname{ker}(v)
\end{align*}
Therefore, we have an induced map $g\triangleq \tilde{f} \in \Hom (M'',P)$: 
\[\begin{tikzcd}
	M && {M'' } \\
	\\
	&& P 
	\arrow["v",two heads, from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["\tilde{f} ", dashed,from=1-3, to=3-3]
\end{tikzcd}\]
which clearly suffices. We now prove ($\impliedby$), which requires us to prove three statements: 
\begin{align*}
v \circ u=0 \quad \text{ and }\quad v\text{ is surjective }\quad \text{ and }\quad \operatorname{ker}(v)\leq \operatorname{Im}(u)
\end{align*}
The first statement follows from setting $P \triangleq M''$ and consideration of  $\id_{M''}\in \Hom (M'',P)$. The second statement requires us to show $\pi  : M'' \twoheadrightarrow  M'' \quotient \operatorname{Im}(v)$ is $0$, which follows from setting $P\triangleq M'' \quotient \operatorname{Im}(v)$  
\begin{align*}
\Hom (M'', M '' \quotient \operatorname{Im}(v)) \overset{F(v)}{\longhookrightarrow } \Hom  (M, M'' \quotient \operatorname{Im}(v))
\end{align*}
and the consideration  
 \begin{align*}
 F(v) (\pi )=  \pi  \circ v = 0 \implies  \pi  =0 
\end{align*}
Let $p : M \twoheadrightarrow M \quotient \operatorname{Im}(u)$ be the canonical projection. Because $\operatorname{ker}(p )=\operatorname{Im}(u)$, the third statement requires us to show $\operatorname{ker}(v)\leq \operatorname{ker}(p )$. Put $P \triangleq M \quotient \operatorname{Im}(u)$. Because we clearly have $p \in \operatorname{ker}(F(u))=\operatorname{Im}(F(v))$, we know $p= \psi \circ v$ for some $\psi \in \Hom (M'',M \quotient \operatorname{Im}(u))$, which implies $\operatorname{ker}(v)\leq \operatorname{ker}(p)$, as desired. 
\end{proof}
Let $\mathcal{C}$ be a class of $A$-modules. A function $\ld :\mathcal{C}\rightarrow \Z$ is said to be \textbf{additive} if for all short exact sequence 
\begin{align*}
0 \longrightarrow M' \longhookrightarrow M \longtwoheadrightarrow M'' \longrightarrow 0
\end{align*}
in $\mathcal{C}$, the function $\ld$ satisfies 
\begin{align*}
\ld (M')- \ld  (M) + \ld (M'')=0 \quad \text{ and }\quad \ld (0)=0 
\end{align*}
\begin{theorem}
\textbf{(Additive functions on long exact sequences)} Let $\mathcal{C}$ be a class of $A$-modules and 
 \begin{align*}
0\longrightarrow M_0 \longrightarrow M_1 \longrightarrow \cdots \longrightarrow M_n  \longrightarrow 0
\end{align*}
be a exact sequence such that all terms, including the kernels, are in $\mathcal{C}$. Then for any additive function $\ld: \mathcal{C}\rightarrow \Z$, we have 
\begin{align*}
\sum_{i=0}^n (-1)^i \ld (M_i)=0 
\end{align*}
\end{theorem}
\begin{proof}
Let $N_i \leq M_i$ be the kernels. Then the proof follows from noting that for all $0\leq i\leq n$, we have a short exact sequence 
\begin{align*}
0 \longrightarrow N_i \longhookrightarrow M_i \longtwoheadrightarrow N_{i+1} \longrightarrow 0
\end{align*}
\end{proof}



\section{Tensor Products}
Given a \emph{finite} collection $M_1,\dots ,M_n$ of $A$-modules, their \textbf{tensor product} is an $A$-module $M_1 \otimes  \cdots \otimes  M_n$ together with a multilinear map $\otimes :M_1 \times \cdots \times M_n \rightarrow M_1 \otimes  \cdots \otimes  M_n$ that satisfies the \textbf{universal property for tensor product}: For each multilinear map $f:M _1 \times \cdots \times M_n \rightarrow P$, there exists an unique module homomorphism $\tilde{f}: M_1 \otimes  \cdots \otimes  M_n \rightarrow P$ such that the diagram 
% https://q.uiver.app/#q=WzAsMyxbMiwyLCJOIl0sWzAsMCwiXFxwcm9kIE1faSJdLFsyLDAsIlxcb3RpbWVzIE1faSJdLFsxLDIsIlxcb3RpbWVzIl0sWzEsMCwiZiIsMl0sWzIsMCwiZiIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
\[\begin{tikzcd}
	{\prod M_i} && {\bigotimes   M_i} \\
	\\
	&& P 
	\arrow["\otimes ", from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["\tilde{f} ", dashed, from=1-3, to=3-3]
\end{tikzcd}\]
commutes. 
\begin{Example}{Non-zero modules can have zero tensor product.}{}
Let $m,n \inn$ be coprime with $am+bn=1$. Then we have 
 \begin{align*}
\Z_m \otimes_{\Z}  \Z_n = 0
\end{align*}
since 
\begin{align*}
x \otimes  y = (am+bn)(x\otimes  y)=a (mx \otimes  y) + b (x\otimes  ny)= 0
\end{align*}
\end{Example}
Given two module homomorphisms $f:M \rightarrow M'$ and $g:N \rightarrow N'$, clearly we can induce another module homomorphism $f\otimes g :  M\otimes  N \rightarrow M'\otimes  N'$ by 
\begin{align*}
  (f\otimes  g )(m \otimes  n) \triangleq f(m) \otimes  g(n)
\end{align*}
In particular, for all $M_0 \leq M$ and $N_0 \leq N$, given $x\in M_0$ and $y \in N_0$ such that $x \otimes  y =0 \in M_0 \otimes  N_0$, the module homomorphism from $M_0 \otimes  N_0$ to $M \otimes  N$ tell us that $x \otimes  y$ must also be $0$ in  $M \otimes  N$. The converse however is not true: That is, given $x \in M_0$ and $y \in M_0$, 
\begin{align*}
x\otimes  y =0 \in M \otimes  N  \rlap{\(\quad\not\)}\implies  x \otimes  y =0 \in M_0 \otimes  N_0 
\end{align*}
\begin{Example}{Zero expression in $M \otimes  N$ can be nonzero in $M_0 \otimes  N_0$ for $M_0 \leq M$ and $N_0 \leq N$.}{}
Consider $A \triangleq \Z,M \triangleq \Z$, and $N\triangleq \Z_2$. Let $M_0 \triangleq 2\Z \leq M$ and $x \in N$ be the nonzero element. Then in $M \otimes  N$, we have 
\begin{align*}
2 \otimes  x = 2 (1 \otimes  x) = 1 \otimes  2x = 0 
\end{align*}
Yet in $M_0\otimes  N$, we can't have $2 \otimes  x=0$, since if so, then $M_0 \otimes  N=0$, but 
\begin{align*}
  M_0 \otimes  N \cong  \Z \otimes_\Z \Z_2 \customref{THidt}{\cong}  \Z_2 \neq 0
\end{align*}
\end{Example}
Note that because for generic $f':M' \rightarrow M''$ and $g':N' \rightarrow N''$, we clearly have:  
\begin{align*}
  (f' \circ f) \otimes  (g' \circ g) =(f' \otimes  g') \circ (f \circ g)
\end{align*}
For all $A$-module  $N$, we have a \emph{covariant} functor $T_N:\mathbf{Mod}_A \longrightarrow \mathbf{Mod}_A$ defined by 
\begin{align}
\label{EQtpm}
T_N(M)\triangleq M \otimes  N\quad \text{ and }\quad  T_N(f) \triangleq f \otimes  \id _N
\end{align}
\begin{theorem}
\label{THbpt}
\textbf{(Basic property of tensor products)} Let $M_1, \dots ,M_n$  be $A$-modules. Then  
\begin{enumerate}[label=(\roman*)]
  \item $M_1 \otimes \cdots \otimes  M_n$ is generated by \textbf{basic elements} $x_1 \otimes  \cdots \otimes  x_n$. 
  \item There is a natural isomorphism 
\begin{align*}
  \Hom (M \otimes  N ,P) \cong  \Hom  (M, \Hom  (N,P)) ,\quad f\mapsto  f',\quad \text{ where }f'(m)(n) \triangleq f(m \otimes  n)
\end{align*}
called the \textbf{tensor-hom adjunction}. In particular, they are both naturally bijective to the set of bilinear maps from  $M\times N$ to $P$.  
\item For all $A$-module  $N$, the covariant functor  $T_N$ is \emph{right-exact}, that is, given any exact sequence: 
\begin{align*}
M' \overset{u}{\longrightarrow } M \overset{v}{\longtwoheadrightarrow  } M'' \longrightarrow 0 
\end{align*}
of $A$-modules, the sequence 
\begin{align*}
M'' \otimes  N \overset{u\otimes  1}{\longrightarrow } M \otimes  N \overset{v\otimes  1}{\longtwoheadrightarrow  }  M'' \otimes  N \longrightarrow 0
\end{align*}
is exact. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (i): Let $E\leq M_1 \otimes  \cdots \otimes  M_n$ be the submodule generated by basic elements with quotient map $\pi  : M_1 \otimes  \cdots \otimes  M_n \twoheadrightarrow E$. The proof then follows from noting that since $\pi$ and $0: M_1 \otimes  \cdots \otimes  M_n \rightarrow (M_1 \otimes  \cdots \otimes  M_n)\quotient E$ are both homomorphism that makes the diagram:  
% https://q.uiver.app/#q=WzAsMyxbMiwyLCJOIl0sWzAsMCwiXFxwcm9kIE1faSJdLFsyLDAsIlxcb3RpbWVzIE1faSJdLFsxLDIsIlxcb3RpbWVzIl0sWzEsMCwiMCIsMl0sWzIsMCwiZiIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
\[\begin{tikzcd}
	{M_1 \times \cdots \times M_n} && {M_1 \otimes  \cdots \otimes  M_n} \\
	\\
	&& (M_1 \otimes  \cdots \otimes  M_n) \quotient E
	\arrow["\otimes", from=1-1, to=1-3]
	\arrow["0"', from=1-1, to=3-3]
	\arrow["\tilde{0} ", dashed, from=1-3, to=3-3]
\end{tikzcd}\]
commute, by uniqueness of universal property, we have $\pi  =0$, and therefore $E=M_1 \otimes  \cdots \otimes  M_n$. \\

(ii): Routine.\\ 


(iii): Let $P$ be an  $A$-module, and denote the contravariant functor $\Hom (-,P):\mathbf{Mod}_A \longrightarrow \mathbf{Mod}_A$ by $G_P$. By \customref{THhomp}{property of $G_P$}, we only have to prove 
\begin{align*}
0\longrightarrow \Hom  (M'' \otimes  N, P)\overset{G_P(T_N(v))}{\longrightarrow } \Hom (M\otimes  N ,P ) \overset{G_P(T_N(u))}{\longrightarrow } \Hom (M' \otimes  N , P)
\end{align*}
is exact. Now, since tensor-hom adjunction allows us to induce an equivalent sequence:   
\begin{align}
\label{EQonp}
0 \longrightarrow \Hom  (M'',\Hom (N,P)) \overset{\tilde{v}}{\longrightarrow } \Hom (M, \Hom  (N,P)) \overset{\tilde{w} }{\longrightarrow } \Hom (M',\Hom  (N,P))
\end{align}
We only have to prove \myref{sequence}{EQonp} is exact, where $\tilde{v},\tilde{u}$ are the compositions of $G_P(T_N(v))$, $G_P(T_N(u))$ and the tensor-hom adjunction isomorphisms. Denote the contravariant functor $\Hom  (-, \Hom (N,P)):\mathbf{Mod}_A \rightarrow \mathbf{Mod}_A$ by $G_{\Hom  (N,P)}$. The proof then follows from \customref{THhomp}{property of $G_{\Hom  (N,P)}$} and routine check of 
\begin{align*}
\tilde{v}= G_{\Hom  (N,P)}(v) 
\end{align*}









\end{proof}
\begin{Example}{Tensor product need not be left-exact}{}
Consider the exact sequence of $\Z$-modules: 
\begin{align*}
0 \longrightarrow 0 \longrightarrow \Z \overset{f}{\longrightarrow} \Z
\end{align*}
where $f(x)\triangleq 2x$. To see that the $\Z$-modules sequence 
\begin{align*}
0\longrightarrow 0\longrightarrow  \Z \otimes  \Z_2 \overset{f \otimes 1}{\longrightarrow } \Z \otimes  \Z_2
\end{align*}
isn't exact. Just observe that $1\otimes  1 \in \Z \otimes  \Z_2$ is nonzero, since if so, then $\Z \otimes  \Z_2 \customref{THidt}{\cong} \Z_2 \neq 0$ is zero, and observe that:  
\begin{align*}
  (f \otimes  \id_{\Z_2}) (1 \otimes  1) = 2 \otimes  1 = 2(1 \otimes  1) =1 \otimes 2  = 0  
\end{align*}
\end{Example}
Let $B$ and  $C$ be two  $A$-algebras with canonical homomorphisms $f: A \rightarrow B$ and $g:A \rightarrow C$. Consider the $A$-module  $B\otimes_A C$. From this $A$-module structure, we see that the $A$-modules diagram:  
% https://q.uiver.app/#q=WzAsNCxbMCwxLCJBIl0sWzIsMCwiQiJdLFsyLDIsIkMiXSxbNCwxLCJCXFxvdGltZXNfQSBDIl0sWzAsMSwiZiJdLFswLDIsImciLDJdLFsxLDMsImIgXFxtYXBzdG8gYlxcb3RpbWVzIDEiXSxbMiwzLCJjXFxtYXBzdG8gMSBcXG90aW1lcyBjIiwyXV0=
\[\begin{tikzcd}
	&& B \\
	A &&&& {B\otimes_A C} \\
	&& C
	\arrow["{b \mapsto b\otimes 1}", from=1-3, to=2-5]
	\arrow["f", from=2-1, to=1-3]
	\arrow["g"', from=2-1, to=3-3]
	\arrow["{c\mapsto 1 \otimes c}"', from=3-3, to=2-5]
\end{tikzcd}\]
commutes. Notably, we can define a multiplication on $B \otimes_A C$  to make it a ring: 
\begin{align*}
  (b \otimes  c) \cdot (b' \otimes  c') \triangleq bb' \otimes  cc'
\end{align*}
\footnote{It requires some argument to show that this multiplication is well-defined. The fastest way is to first well-define an $A$-module homomorphism  $B \otimes C \otimes  B \otimes  C \rightarrow B \otimes  C,\quad b \otimes  c \otimes  b' \otimes  c' \mapsto bb' \otimes  cc'$, and then use  \customref{THidt}{associativity of tensor product} and definition to construct the $A$-bilinear mapping that is our multiplication.}and in fact, an $A$-algebra, whose $A$-module structure clearly can be regained via the morphisms in above diagram, which are now ring homomorphisms. The $A$-algebra  $B \otimes_A C$ is called the \textbf{tensor product of $A$-algebra  $B$ and  $C$}. The \textbf{tensor product of two rings} is then their tensor product as $\Z$-algebras. 


\section{Identities for Tensor Products}


\begin{theorem}
\label{THidt}
\textbf{(Identities for tensor products)} Let $A$ be a ring and  $M$ an  $A$-module. Then  
\begin{enumerate}[label=(\roman*)]
 \item  We have a natural isomorphism
\begin{align*}
A \otimes  M \cong  M,\quad a \otimes  m \mapsto am
\end{align*}
 \item Let $\mathfrak{a}\trianglelefteq A$. We have a natural isomorphism 
\begin{align*}
  (A \quotient \mathfrak{a})\otimes  M \cong  M \quotient \mathfrak{a}M, \quad a \otimes  m \mapsto am
\end{align*}
\item  Let $N$ and  $P$ be two  $A$-modules. We have a natural isomorphism 
   \begin{align*}
     (M \otimes  N) \otimes  P \cong  M \otimes  N \otimes  P,\quad (m \otimes  n) \otimes  p \mapsto m \otimes  n \otimes  p
  \end{align*}
\item  Let $M_i$ be a directed system of $A$-modules with canonical morphism $\phi$. Then $M_i \otimes  M$ is a directed system with canonical morphism $\psi$ defined by $\psi_{ij}\triangleq \phi_{ij}\otimes \id_M$, and we have a natural isomorphism:  
  \begin{align*}
 \left(\directlimit M_i \right) \otimes  M  \cong  \directlimit \left( M_i \otimes  M \right),\quad \phi_i(m_i)\otimes  m \mapsto \psi_i (m_i \otimes  m)
  \end{align*}
  \item For \emph{possibly infinite} collection $M_i$ of $A$-module, we have a natural isomorphism 
    \begin{align*}
   N \otimes  \bigoplus M_i \cong  \bigoplus (N \otimes  M_i),\quad n \otimes  (m_1 \oplus \cdots \oplus  m_k) \mapsto (n \otimes  m_1) \oplus  \cdots \oplus  (n \otimes  m_k)
    \end{align*}
  \item  Let $(M_i,\phi)$ be a directed system of  $A$-modules over  directed set $\mathcal{P}$ and $(N_j,\psi)$ be a directed system of  $A$-modules over directed set  $\mathcal{Q}$. Then, we can make $M_i \otimes  N_j$ a directed system with index set $\mathcal{P}\times \mathcal{Q}$ directed by 
    \begin{align*}
      (i,j) \leq  (k,l)\overset{\triangle}{\iff } i \leq  k \quad \text{ and }\quad j\leq l 
    \end{align*}
and canonical homomorphisms $\ld $ defined by  
\begin{align*}
\ld_{(i,j)(k,l)}\triangleq \phi_{ik}\otimes  \psi_{jl} 
\end{align*}
Then the natural directed system of $M_i \otimes  N_j$ over $\mathcal{P}\times \mathcal{Q}$ has a natural isomorphism 
\begin{align*}
 \directlimit_{\mathcal{P}\times \mathcal{Q}}\left( M_i \otimes  N_j \right)  \cong  \directlimit_{\mathcal{P} } \left( M_i \right) \otimes  \directlimit_{\mathcal{Q} } \left(N_j   \right),\quad \ld_{(i,j)}(m_i \otimes  n_j )\mapsto \phi_i(m_i) \otimes  \psi_j (n_j)
\end{align*}

\end{enumerate}
\end{theorem}
\begin{proof}
(i), (iii),(iv), and (vi) are routine. (ii) is essentially a corollary of (i). In short, because \customref{THbpt}{tensor product is right exact}, tensoring the exact sequence  
\begin{align*}
 \mathfrak{a} \overset{\diota }{\longhookrightarrow } A \overset{\pi }{\longtwoheadrightarrow } A \quotient \mathfrak{a} \longrightarrow 0
\end{align*}
with $M$, we get an exact sequence 
\begin{align*}
\mathfrak{a}\otimes  M \overset{\diota \otimes  1  }{\longrightarrow } A \otimes  M \overset{\pi  \otimes  1}{\longtwoheadrightarrow } (A\quotient \mathfrak{a}) \otimes  M \longrightarrow 0
\end{align*}
which implies that 
 \begin{align*}
   (A \quotient \mathfrak{a}) \otimes  M \cong (A \otimes  M) \quotient \operatorname{Im}(\diota \otimes  1 ) 
\end{align*}
The proof for (ii) then follows from checking that the isomorphism $A \otimes  M \cong M$ maps $\operatorname{Im}(\diota \otimes  1 )$ to $\mathfrak{a}M$. (v) should be first proved in finite case, which is also routine. The infinite case then follows from finite case, (iii), and the fact that  \customref{THdls}{direct sum is the direct limit of finite direct sums}: 
\begin{align*}
  N \otimes \left( \bigoplus M_i \right) &\cong  N \otimes  \directlimit \left(\bigoplus _{\text{finite}} M_i\right)  \cong  \directlimit  \left(N \otimes  \left(\bigoplus_{\text{finite}} M_i \right)    \right) \\
  & \cong  \directlimit \left(  \bigoplus_{\text{finite}} N \otimes  M_i  \right) \cong  \bigoplus (N\otimes  M_i)
\end{align*}
in which one checks that the isomorphism one gets in the end has the desired form. 
\end{proof}
\begin{theorem}
\label{THfgz}
\textbf{(Existence of finitely generated submodules that makes an expression of zero remain zero)} Let  $A$ be a ring and  $M$ and  $N$ two  $A$-modules. Let $\sum x_i \otimes y_i =0$ in $M \otimes  N$. Then there exist two finitely generated submodules $M' \leq M$ and $N' \leq N$ that respectively contains $x_i$ and $y_i$ and makes
\begin{align*}
\sum  x_i \otimes  y_i= 0,\quad \text{ in }M' \otimes  N'
\end{align*}
\end{theorem}
\begin{proof}
Let $M_i$ and $N_j$ be the directed system of finitely generated submodules of $M$ and $N$. Then we have a natural isomorphism 
\begin{align*}
  M \otimes  N \customref{THdls}{\cong} \left(\directlimit M_i   \right) \otimes   \left(\directlimit N_j \right) \customref{THidt}{\cong}  \directlimit (M_i \otimes  N_j)  
\end{align*}
Let $M' \leq M$ and $N'\leq N$ be the submodules generated by $x_i$ and  $y_i$. Clearly, the isomorphism maps $\sum x_i \otimes  y_i \in M' \otimes N'$ to $0 \in M \otimes  N$ (from the right hand side to left). The proof then follows from the fact that  \customref{THpdl}{if something in a direct limit is zero then at a fixed stage it is already zero}. 
\end{proof}

\section{Extension of Scalars}
Let $N$ be an $A$-module. If we say $N$ is an  $(A,B)$\textbf{-bimodule} we mean that the abelian group $N$ has a $B$-module structure compatible with its $A$-module structure in the sense that 
 \begin{align*}
b\cdot (a \cdot n)= a \cdot (b \cdot n),\quad \text{ for all }a \in A,b \in B ,n \in N
\end{align*}
An $(A,B)$\textbf{-bimodule homomorphism} $g:N \rightarrow P$ is then a map that is simultaneously an $A$-module homomorphism and a  $B$-module homomorphism. Let $M$ be an $A$-module and $N$  an  $(A,B)$-bimodule. Clearly, by universal property, we can give $M \otimes  _A N$ a $B$-module structure by 
 \begin{align}
\label{EQbmn}
b(m \otimes  n)\triangleq m \otimes bn
\end{align}
which naturally makes $M \otimes_A  N$ an $(A,B)$-bimodule.
\begin{Example}{Lifting of module structures requires bimodules.}{}
Let $k$ be a field,  $A \triangleq k[x]$, $M\triangleq N \triangleq A$, and $B \triangleq k[y]$. Clearly, we may give $N$ a  $B$-module structure by 
 \begin{align*}
cy^n \cdot f \triangleq cf^{(n)},\quad \text{ for all }c \in k, f \in N
\end{align*}
It is clear that the $A$-module structure and the  $B$-module structure on  $N$ are not compatible. Therefore, we can't use universal property to give $M \otimes_A N$ a $B$-module structure as in \myref{equation}{EQbmn}. To see this \emph{as a hindsight}, first observe 
\begin{align*}
1 \otimes  x = x (1 \otimes  1) = 1 \otimes  x 
\end{align*}
So if there exists a $B$-module structure on  $M \otimes  _A N$ that agrees with \myref{equation}{EQbmn}, then we have
\begin{align*}
1\otimes  1 = y(1 \otimes  x)=y (x \otimes  1)= 0 
\end{align*}
This is clearly impossible, since it suggests $M \otimes  N=0$, but 
\begin{align*}
  M \otimes  N \cong  A \otimes  A \customref{THidt}{\cong}  A \neq 0 
\end{align*}
\end{Example} 
\begin{theorem}
\label{THatpb}
\textbf{(Associativity of tensor product up to bimodules)} Let $M$ be an  $A$-module,  $N$ an  $(A,B)$-bimodule, and $P$ a  $B$-module. Then we have a natural $(A,B)$-bimodule isomorphism 
\begin{align*}
  (M \otimes_A N) \otimes_B P \cong  M \otimes _A (N\otimes_B P),\quad (m\otimes n)\otimes  p \mapsto m \otimes (n \otimes  p)
\end{align*}
\end{theorem}
\begin{proof}
The proof is a routine construction and verification. Here, we give an outline of it.   First, for all $p \in P$, induce the natural $B$-module homomorphism  $g_p:M \otimes _A N \rightarrow M \otimes _A(N \otimes _B P)$. Second, check that $g_p$ is an  $(A,B)$-bimodule homomorphism. Third, induce $f:(M \otimes_A N)\otimes _B P \rightarrow M \otimes_A (N \otimes_B P)$ by 
\begin{align*}
f(x\otimes p)\triangleq g_p(x)
\end{align*}
Forth, check that $f$ is an $(A,B)$-bimodule homomorphism. Fifth, similarly induce $h:M \otimes_A (N \otimes_B P)\rightarrow (M \otimes _A N )\otimes  _B P $. The proof then follows from using universal property to check that the $(A,B)$-bimodule homomorphism $h$ and  $f$ are inverse to each other, and therefore concluding that $f$ is an $(A,B)$-module isomorphism. 
\end{proof}

In particular, given a ring homomorphism $f:A \rightarrow B$, restriction of scalars makes $B$ an  $(A,B)$-bimodules, and so for all $A$-module  $M$, we have an $(A,B)$-bimodule: 
\begin{align*}
M_B \triangleq M \otimes_A B
\end{align*}
called \textbf{extension of scalar}. 






\begin{theorem}
  \textbf{(Basic properties of scalar restriction)} Let $f:A \rightarrow B$ be a ring homomorphism, $N$ be a  $B$-module, and $N_B \triangleq B \otimes _A N$. Then we have an $A$-module homomorphisms $g:N \rightarrow N_B$ defined by 
 \begin{align*}
g(x)\triangleq 1 \otimes  x 
\end{align*}
and an $A$-module homomorphism  $p:N_B\rightarrow N$ defined by 
\begin{align*}
p(b \otimes  y) \triangleq by
\end{align*}
They form a short exact sequence: 
\begin{align*}
  0 \longrightarrow N \overset{g}{\longhookrightarrow} N_B \overset{p}{\longtwoheadrightarrow } N \longrightarrow 0
\end{align*}
in $\mathbf{Mod}_A$ that splits via
\begin{align*}
p \circ g = \id _N
\end{align*}
\end{theorem}
\begin{proof}
The fact that $g \in \mathbf{Mod}_A$ is clear. To prove $p \in \mathbf{Mod}_A$, one is required to check the map $B\times N \longrightarrow N$ defined by $(b,y)\mapsto by$ is $A$-bilinear, which is also clear. They clearly satisfies $p \circ g= \id _N$, and therefore the short sequence is exact.  
\end{proof}
\begin{Example}{$g$ in general isn't an $B$-module homomorphism}{}
Let $A\triangleq \R$ and $B \triangleq N\triangleq \C$. If we give $N_B\triangleq B \otimes_A N$ a $B$-module structure via scalar extension, then $g \not \in \mathbf{Mod}_B$, since  
\begin{align*}
g(i1)= 1 \otimes_A i \neq i \otimes_A  1 = ig(1)
\end{align*}
\end{Example}
\begin{theorem}
\label{THtfg}
\textbf{(Criteria for finite generation under extension and restriction of scalars)} Let $f:A \rightarrow B$ be a ring homomorphism and $M \in \mathbf{Mod}_A,N \in \mathbf{Mod}_B$. Then 
\begin{enumerate}[label=(\roman*)]
  \item If $N$ is finitely generated as a $B$-module and  $B$ is finitely generated as an  $A$-module, then  $N$ is finitely generated as an  $A$-module.  
  \item If $M$ is finitely generated as an  $A$-module,  then $M_B$ is finitely generated as a  $B$-module. 
\end{enumerate}
\end{theorem}
\begin{proof}
(i): If  $y_1,\dots ,y_m$  generate $N$ over $B$ and  $b_1,\dots ,b_n$ generate $B$ over  $A$, then clearly $\set{b_iy_j \in N: 1\leq i \leq n,1\leq j\leq m}$ generate $N$ over $A$. \\

(ii): If $x_1 ,\dots ,x_m$ generate $M$ over  $A$, then  $1 \otimes  x_i$ generate  $M_B$ over  $B$. In particular 
\begin{align*}
b \otimes  \sum a_ix_i= \sum b \otimes a_ix_i = \sum a_i(b \otimes  x_i)= \sum (b f(a_i)) \otimes  x_i
\end{align*}


\end{proof}
\begin{theorem}
\textbf{(Property of tensors over local rings)} Let $(A,\mathfrak{m},k)$ be a local ring, $M$ and $N$ be two finitely generated  $A$-modules. If $M \otimes N =0$, then $M=0$ or  $N=0$.  


\end{theorem}
\begin{proof}
  The first step of the proof is a \emph{routine verification using identities for tensor products} to show that:  
\begin{align}
\label{EQmak}
  \olive{(M\otimes_A k ) \otimes_k (k \otimes _A N) =0}
  \end{align}
Clearly, there are two ways to give $(M \otimes _A k) \otimes_k (k \otimes_A N)$ an $A$-module structure, which are identical since:  
 \begin{align*}
x\otimes_k (ay)=  \overline{a} (x\otimes_k y) = ax \otimes_k y
\end{align*}
This settles an $(A,k)$-bimodule structure on $(M\otimes_A k)\otimes_k (k \otimes _A N)$. Consider the $A$-module structure from left. Then by \customref{THatpb}{associativity}, we have an $(A,k)$-bimodule isomorphism: 
\begin{align}
\label{EQkkk}
  (M \otimes_A k) \otimes _k (k \otimes _A N) \cong M \otimes_A X_1 
\end{align}
where $X_1 \triangleq  k \otimes_k (k \otimes_A N)$ is an $(A,k)$-bimodule whose $A$-modules structure comes from the  $k$ on left. Again, by checking 
\begin{align*}
  \overline{b} \otimes_k (ax) = \overline{a} \cdot (\overline{b}\otimes_k x)= (a \cdot \overline{b}) \otimes _k x  
\end{align*}
We see that giving $X_1$ from left or right an $A$-module structure are identical.  Therefore by  \customref{THatpb}{associativity}, we have an $(A,k)$-bimodule isomorphism: 
\begin{align*}
X_1 \cong  X_2
\end{align*}
where $X_2 \triangleq (k \otimes _k k)\otimes _A N $ is an $(A,k)$-bimodule in which the  $A$-module structure of  $k \otimes_k k$ comes from right.\footnote{Again, one can check that giving  $k \otimes_k k$ an $A$-module structure from left or right are identical, but that's not necessary here.} Now, since  \customref{THidt}{we have a $k$-module isomorphism $k \otimes _k k \cong  k$}, which is clearly also an $A$-module isomorphism,  we have an $(A,k)$-bimodule isomorphism 
\begin{align*}
  X_2  \cong  k \otimes _A N 
\end{align*}
Therefore, by \myref{equation}{EQkkk}, we have an $(A,k)$-bimodule isomorphism 
\begin{align*}
  (M \otimes _A k) \otimes_k (k \otimes _A N) \cong  M \otimes_A (k \otimes _A N ) 
\end{align*}
This gives us  \customref{THidt}{an $A$-module isomorphism}: 
\begin{align*}
  (M \otimes _A k) \otimes_k (k \otimes _A N) \cong  (M\otimes _A N) \otimes_A k \cong  0   \odone
\end{align*}
Now, since \myref{tensor product}{EQmak} is \emph{over a field} with \customref{THtfg}{both sides finite dimensional}, we know either $M \otimes_A k$ or $N \otimes _A k$ equals to $0$. WLOG, let $M \otimes _A k =0$. Then we have: 
\begin{align*}
  M \quotient   \mathfrak{m}M \customref{THidt}{\cong}  M \otimes _A k =0 
\end{align*}
This implies $M=\mathfrak{m}M$, which by \customref{THsNl}{Nakayama lemma} implies $M=0$, as desired. 







\end{proof}

\section{Flat modules}
\begin{equiv_def}
\textbf{(Flat modules)} Let $N$ be an  $A$-module, and consider the covariant functor $T_N:\mathbf{Mod}_A \rightarrow \mathbf{Mod}_A $ defined by \myref{equation}{EQtpm}. We say $N$ is \textbf{flat} if any of the followings hold true 
\begin{enumerate}[label=(\roman*)]
  \item $T_N$ is an exact functor. 
  \item For all injective homomorphism $f:M' \hookrightarrow  M$ between finitely generated modules, the homomorphism $f \otimes  1:M' \otimes N \hookrightarrow  M \otimes  N $ is injective. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
  (i)$\implies $(ii) is clear, so we only have to prove (ii)$\implies $(i). In particular, since \customref{THbpt}{tensor product is right exact}, we only have to prove that given injective homomorphism $f: M' \hookrightarrow  M$, where $M'$ and  $M$ need not be finitely generated, the homomorphism $f \otimes  1: M' \otimes  N \rightarrow M \otimes  N$ remains injective.\\     

Let $u\in \operatorname{ker}(f \otimes  1)$. We are required to show $u=0$. Write $u \triangleq \sum x_i' \otimes  y_i$. Consider the submodule $M'_0 \triangleq (x_1',\dots ,x_n')\leq M'$ and $u_0 \triangleq \sum x_i'\otimes  y_i \in M'_0 \otimes  N$. Because the natural homomorphism from $M_0' \otimes  N$ to $M' \otimes  N$ maps $u_0$ to  $u$, we only have to prove $u_0 =0$.\\

Now, because $u\in \operatorname{ker}(f \otimes 1)$, we know $\sum f(x_i') \otimes  y_i=0$ in $M \otimes  N$. This implies  \customref{THfgz}{the existence of some finitely generated submodule $M_0 \leq M$ that makes $f(x_i')\in M_0$ for all $i$ and  $\sum f(x_i')\otimes  y_i=0 \in M_0 \otimes  N$}.\\

Clearly, $f$ maps $M_0'$ into  $M_0$, so we have the restriction maps $f|_{M'_0}: M'_0 \hookrightarrow  M_0 $ (Note that the codomain was shrunk). Because $f|_{M'_0}\otimes  1:M'_0 \otimes  N\rightarrow M_0 \otimes  N$ maps $u_0$ to $0$ by the last paragraph, and because both $M'_0$  and $M_0$ are finitely generated by construction, by premise $u_0=0$, as desired.   
\end{proof}
\begin{theorem}
\textbf{(Identities for flat modules)} Let $A$ be a ring. Then  
\begin{enumerate}[label=(\roman*)]
   \item Let $M_i$ be a  \emph{possibly infinite} collection of $A$-modules. Then  
\begin{align*}
\bigoplus M_i\text{ is flat }\iff  \text{ All }M_i\text{ are flat }
\end{align*}
   \item $A[x]$ is a flat $A$-algebra.  
   \item If  $M$ and $N$ are both flat  $A$-modules, then  $M\otimes  N$ is also flat. 
   \item If $B$  is a flat $A$-algebra and  $N$ is a flat  $B$-module, then  $N$ is flat as an  $A$-module. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (i): The proof from right to left is relatively simple. Just note that if one of $M_i$ is flat. Then clearly  $f \otimes  \id_{\bigoplus M_i}$ is not injective. The proof from left to right is much more lengthy. Recall that we have the identity 
  \begin{align*}
  N \otimes  \bigoplus_I M_i  \cong  \directlimit_{J \subseteq I} \bigoplus_{J} N \otimes  M_i
  \end{align*}
If all $f \otimes \id_{M_i}$ are injective, then clearly all $\bigoplus f\otimes  \id $ is injective. \customref{EDsm}{Passing to direct limit}, we see $f \otimes  \id_{\bigoplus M_i}=\bigoplus f \otimes  \id $ is injective.  \\

(ii): This follows from the observation the natural isomorphism $A \otimes  M \cong  M$ so that $A$ is a flat  $A$-module and a therefore by  (i), $A[x]\cong \bigoplus_{n\inn \cup  \set{0}} (x^n)$ is a flat $A$-module.


\end{proof}

\section{Extended and Contracted Ideals}
Unlike prime ideals, contraction of maximal ideals need not be maximal: 
\begin{Example}{Contraction of maximal ideals need not be maximal.}{}
Consider $\Z \longhookrightarrow \Q$. Clearly $(0)$ is maximal in $\Q$, but not maximal in  $\Z$.   
\end{Example}
Let $f:A \rightarrow B$ be a ring homomorphism. Even though $f^{-1}(\mathfrak{b})\trianglelefteq A$ is always an ideal, in general $f(\mathfrak{a})\subseteq B$ need not be an ideal:   
\begin{Example}{Image of ideals need not be an ideal}{}
Consider $\Z \longhookrightarrow  \Q$. Clearly no nonzero ideal in $\Z$ is an ideal in $\Q$. 
\end{Example}
We then define \textbf{extension and contraction ideal} by 
\begin{align*}
\mathfrak{a}^{e} \triangleq (f(\mathfrak{a}))\trianglelefteq B\quad \text{ and }\quad \mathfrak{b}^c \triangleq f^{-1}(\mathfrak{b})\trianglelefteq A
\end{align*}
\begin{theorem}
\label{THec}
\textbf{(Basic properties of extension and contradiction)} Let $f:A\rightarrow B$ be a ring homomorphism and $\mathfrak{a}\trianglelefteq A,\mathfrak{b} \trianglelefteq B$. Clearly, we have 
\begin{align*}
\mathfrak{a}\leq \mathfrak{a}^{ec}\quad \text{ and }\quad \mathfrak{b}^{ce}\leq \mathfrak{b}
\end{align*}
Because of such, we have 
\begin{align*}
\mathfrak{a}^e = \mathfrak{a}^{ece}\quad \text{ and }\quad \mathfrak{b}^c= \mathfrak{b}^{cec}
\end{align*}
Therefore, the set $C\triangleq \set{\mathfrak{b}^c\trianglelefteq A: \mathfrak{b}\trianglelefteq B}$ of \textbf{contracted ideals} in $A$ and the set $E\triangleq \set{\mathfrak{a}^c \trianglelefteq B: \mathfrak{a}\trianglelefteq A}$ of \textbf{extended ideals} in $B$ are  
\begin{align}
\label{EQdc}
C=\set{\mathfrak{a}\trianglelefteq A: \mathfrak{a}^{ec}=\mathfrak{a}}\quad \text{ and }\quad E= \set{\mathfrak{b}\trianglelefteq A: \mathfrak{b}^{ce}=\mathfrak{b}} 
\end{align}
From \myref{description}{EQdc}, we see that $\mathfrak{a}\mapsto \mathfrak{a}^e$ forms a bijection $C \longrightarrow E$ with inverse $\mathfrak{b}\mapsto \mathfrak{b}^c$. Moreover, since we always have: 
\begin{align*}
&(\mathfrak{a}_1+\mathfrak{a}_2)^e = \mathfrak{a}_1^e + \mathfrak{a}_2^e,& &(\mathfrak{b}_1+ \mathfrak{b}_2)^c \geq \mathfrak{b}_1^c + \mathfrak{b}_2^c \\
&(\mathfrak{a}_1 \cap \mathfrak{a}_2)^e \leq \mathfrak{a}_1^e \cap \mathfrak{a}_2^e, && (\mathfrak{b}_1 \cap  \mathfrak{b}_2)^c = \mathfrak{b}_1^c \cap \mathfrak{b}_2^c \\
&(\mathfrak{a}_1\mathfrak{a}_2)^e=\mathfrak{a}_1^e\mathfrak{a}_2^e,& &(\mathfrak{b}_1\mathfrak{b}_2)^c \geq \mathfrak{b}_1^c \mathfrak{b}_2^c \\
&(\mathfrak{a}_1:\mathfrak{a}_2)^e \leq  (\mathfrak{a}_1^e: \mathfrak{a}_2^e), && (\mathfrak{b}_1:\mathfrak{b}_2)^c \leq (\mathfrak{b}_1^c: \mathfrak{b}_2^c) \\
&\left(\sqrt{\mathfrak{a}} \right)^e \leq \sqrt{\mathfrak{a}^e},&&   (\sqrt{\mathfrak{b}})^c = \sqrt{\mathfrak{b}^c} 
\end{align*}
We see that $E$ is closed under taking sum and product, while  $C$ is closed under taking intersection, quotient, and radical. 
\end{theorem}
\begin{proof}
Routine.  
\end{proof}
It is worth mentioning that ideal extension have quite ill behavior. Even though \customref{THpp}{contraction of prime ideals are prime}, extension of prime ideal need not be prime: 
\begin{Example}{Extension of prime ideals need not be prime.}{}
Consider $\Z \longhookrightarrow \Q$. Clearly, $(p)^e= \Q$ for all prime $p$. 
\end{Example}


\section{Local Rings}
\begin{equiv_def}
\label{EDlr}
\textbf{(Local rings)} We say $A$ is a  \textbf{local ring} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item $\operatorname{Max}(A)=\set{\mathfrak{m}}$. We then call $A \quotient \mathfrak{m}$ the \textbf{residue field} of $A$.  
  \item Non-units of $A$ forms an ideal.  
  \item There exists a proper ideal containing all the non-units. 
  \item There exists some $\mathfrak{m} \in \operatorname{Max}(A)$ such that $1+ \mathfrak{m} \subseteq A^{\times}$. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
(i)$\iff $(ii)$\iff $(iii) all follow from the fact that \customref{THem}{every non-unit is contained by some maximal ideal}. (ii)$\implies $(iv) since if the non-units form an ideal $\mathfrak{m}$, then  $1+m$ can't be a non-unit, otherwise $1$ would have been a non-unit.\\


We now prove (iv)$\implies $(iii). Let $x \in A - \mathfrak{m}$. We are required to show $x \in A^{\times}$. Because $x \not \in \mathfrak{m}$, we know $(x)+ \mathfrak{m}=(1)$, which implies $xy=1-m \in A^{\times}$ for some $y \in A$ and $m \in \mathfrak{m}$, as desired. 
\end{proof}
\begin{theorem}
\label{THlc}
\textbf{(Local ring contains no non-trivial idempotents)} Local ring $(A,\mathfrak{m})$ must contains no \textbf{idempotent} $\neq 0,1$. 
\end{theorem}
\begin{proof}
Assume for a contradiction that $x\in A- \set{0,1}$ is an idempotent. Clearly the only idempotent unit is $1$. Therefore $x$ is a non-unit. Since $1-x$ is also an idempotent: 
\begin{align*}
 (1-x)^2=1-2x+x^2=1-x
\end{align*}
again we know it must be a non-unit, otherwise $x=0$. Because $A$ is local, we now see  $1=(1-x)+x \in \mathfrak{m}$ lies in the ideal of non-unit, a contradiction.   
\end{proof}
\begin{equiv_def}
\textbf{(Local ring with $\mathfrak{m}\triangleq \operatorname{Nil}(A)$)} If any of the followings hold true:  
\begin{enumerate}[label=(\roman*)]
  \item $A$ has exactly one prime ideal.  
  \item All non-units of $A$ are nilpotent. 
  \item $A \quotient \operatorname{Nil}(A)$ is a field. 
\end{enumerate}
then $A$ is a local ring with   $\mathfrak{m}=\operatorname{Nil}(A)$. Such ring satisfies $\operatorname{Nil}(A)=\operatorname{Jac}(A)$.
\end{equiv_def}
\begin{proof}
  (i)$\implies $(ii): Because $A$ has exactly one prime ideal, we know  $\operatorname{Nil}(A)=\bigcap \operatorname{Spec}(A)$ is prime. Assume for a contradiction that  there exists a non-unit $x  \not \in \operatorname{Nil}(A)$, then since \customref{THem}{$x$ is contained by some maximal ideal} and \customref{EDmf}{maximal ideals are prime}, we see $\operatorname{Nil}(A)$ isn't the unique prime ideal, a contradiction.\\

  (ii)$\implies $(iii): \customref{EDlr}{Because non-units forms the nilradical, we know $A$ is local with  $\mathfrak{m}=\operatorname{Nil}(A)$}. \\

  (iii)$\implies $(i): The premise implies $\operatorname{Nil}(A)$ is maximal. Therefore,  $\operatorname{Nil}(A)=\bigcap \operatorname{Spec}(A)$ implies $\operatorname{Nil}(A)$ is the unique prime of $A$.   
\end{proof}
\section{GCD Domain and Gauss Lemma}
\begin{abstract}
This section gives a proof of Gauss lemma in the setting of GCD domains. In this section, if we say $f \in D[x_1,\dots ,x_n]$ is irreducible, we mean that it is irreducible as an element of the integral domain $D[x_1,\dots ,x_n]$. 
\end{abstract}
Let $D$ be an integral domain and $x,y \in D$. We say $x$  \textbf{divides} $y$ if there exists some  $q \in D$ such that $y=xq$. In this section, given $x \mid  y$, we write $\frac{y}{x} \in D$ to denote the element that makes 
\begin{align*}
x \cdot \frac{y}{x}\triangleq  y 
\end{align*}
even if $x$ is a non-unit. A \emph{nonzero non-unit} element $d \in D$ is said to be \textbf{irreducible} if 
\begin{align*}
d=xy \implies x\text{ or }y \in D^{\times}
\end{align*}
A \emph{nonzero non-unit} element $p \in D$ is said to be \textbf{prime} if 
\begin{align*}
p \mid  xy \implies p \mid x\text{ or }p \mid  y
\end{align*}
Given a collection of elements $\set{x_i}$ in $D$, we say $d \in D$ is a  \textbf{greatest common divisor} if $d$ is a common divisor divisible by all common divisors of  $\set{x_i}$, and we say $l \in D$ is a \textbf{least common multiple} if $l$ is a common multiple of $\set{x_i}$ dividing all common multiples of $\set{x_i}$. Two elements $a,b \in D$ are said to be \textbf{associated} if $a=bu$ for some  $u \in D^{\times}$. Clearly, the notion of greatest common divisor, least common multiple,  primality, and irreducibility are all defined up to the equivalence relation of associations.  
\begin{theorem}
\label{Thpei}
\textbf{(Prime elements are irreducible)} Let $D$ be an integral domain and $p \in D$ be a prime element. Then $p$ is irreducible. 
\end{theorem}
\begin{proof}
Let $p\triangleq xy$. By primality, $p$ divides one of them. If $p$ divides $x$, then $y$ is a unit with inverse $\frac{x}{p}$. 
\end{proof}
\begin{theorem}
\label{THrbg}
\textbf{(Basic properties of greatest common divisors)} Let $D$ be an integral domain and  $x,y \in D$ be nonzero. Then
\begin{enumerate}[label=(\roman*)]
  \item $\operatorname{GCD}$ is \emph{associative and homogeneous}, that is, for all nonzero  $z \in D$, we have 
\begin{align*}
\operatorname{GCD}(x,y,z)=\operatorname{GCD}(\operatorname{GCD}(x,y),z)
\end{align*}
and
    \begin{align*}
 \operatorname{GCD}(zx,zy) \in D \implies \operatorname{GCD}(x,y)= \frac{\operatorname{GCD}(zx,zy)}{z} \in D
    \end{align*}
  \item We have  
\begin{align*}
\operatorname{LCM}(x,y)\text{ exists }\iff  \operatorname{GCD}(cx,cy)\text{ exists for all nonzero }c \in D
\end{align*}
In particular, if $\operatorname{LCM}(x,y)$ exists, then we have 
\begin{align*}
\operatorname{GCD}(x,y)=\frac{xy}{\operatorname{LCM}(x,y)}
\end{align*}
\end{enumerate}
\end{theorem}
\begin{proof}
(i) is routine. We prove (ii). ($\implies $): We first show that  
\begin{align*}
\vi{\text{ $\operatorname{GCD}(x,y)$ exists  }}
\end{align*}
Clearly,  $d \triangleq \frac{xy}{\operatorname{LCM}(x,y)} \in D$ exists. Our goal is to prove $d=\operatorname{GCD}(x,y)$. Let $d_0$ be a common divisor of $x$ and  $y$. Because $d_0 \mid  x$, we know $x \cdot \frac{y}{d_0}$ is a common multiple of $x$ and $y$, so we have 
 \begin{align*}
\operatorname{LCM}(x,y)d_0 \mid  x\cdot \frac{y}{d_0} \cdot d_0 = xy = \operatorname{LCM}(x,y)d,\quad \vdone
\end{align*}
It remains to show 
\begin{align*}
  \blue{\operatorname{LCM}(cx,cy)\text{ exists and equal } c\operatorname{LCM}(x,y)}
\end{align*}
Clearly $c\operatorname{LCM}(x,y)$ is a common multiple of $cx$ and  $cy$. Let $m$ be a common multiple of  $cx$ and  $cy$. Then  $\frac{m}{c} \in D$ exists.  Cancellation then shows $\frac{m}{c}$ is a common multiple of $x$ and $y$, so $\operatorname{LCM}(x,y)\mid  \frac{m}{c}$. This implies
\begin{align*}
c \operatorname{LCM}(x,y) \mid  c \cdot \frac{m}{c} = m,\quad \bdone
\end{align*}
  ($\impliedby$): Let $m$ be a common multiple of $a$ and  $b$. Clearly, $ab$ is a common divisor of  $ma$ and  $mb$. Therefore by homogeneous property of greatest common divisor, we have: 
\begin{align*}
ab\mid \operatorname{GCD}(ma,ma)=m\operatorname{GCD}(a,b)
\end{align*}
which by cancellation implies $\frac{ab}{\operatorname{GCD}(a,b)} \mid  m$, as desired.  
\end{proof}
\begin{equiv_def}
\textbf{(GCD domain)} We say an integral domain $D$ is a \textbf{GCD domain} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item Every pair of elements of $D$ admits a greatest common divisor.    
  \item Every pair of elements of $D$ admits a least common multiple.  
\end{enumerate}
\end{equiv_def}
\begin{proof}
This follows from \customref{THrbg}{the relationship between GCD and LCM}. 
\end{proof}
\begin{theorem}
\label{THbG}
\textbf{(Basic properties of GCD domains)} Let $D$ be a GCD domain. Then 
\begin{enumerate}[label=(\roman*)]
  \item $D$ is integrally closed.  
  \item Every irreducible element of  $D$ is prime.  
  \item Let $x,y,z \in D$ be nonzero. If $\operatorname{GCD}(x,y)=1$ and $x \mid  yz$, then $x \mid  z$. \textbf{(Euclid Lemma)} 
  \item Let $x,y,z \in D$ be nonzero. Then $\operatorname{GCD}(x,y)=\operatorname{GCD}(x,z)=1 \implies  \operatorname{GCD}(x,yz)=1$. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (iii): \customref{THrbg}{Since $\operatorname{GCD}(x,y)=1$, we have $\operatorname{LCM}(x,y)=xy$}.  The proof then follows from noting that since $yz$ is a common multiple of  $x$ and  $y$, we have 
\begin{align*}
xy = \operatorname{LCM}(x,y) \mid  yz  
\end{align*}
(iv): Let $g$ be a common divisor of  $x$ and  $yz$. Because common divisors of $g$ and  $y$ must also be common divisors of  $x$ and  $y$, from $\operatorname{GCD}(x,y)=1$, we know $\operatorname{GCD}(g,y)=1$. Therefore, by \customref{THbG}{Euclid lemma}, $g$ is a divisor of  $z$, thus a common divisor of $x$ and  $z$, which by  $\operatorname{GCD}(x,z)=1$ implies $g=1$.   
\end{proof}
\begin{theorem}
\label{THprai}
\textbf{(Polynomial rings are integral domain if and only if ground rings are integral domain)} Let $A$ be a ring. Then 
 \begin{align*}
A[x]\text{ is an integral domain } \iff A\text{ is an integral domain }
\end{align*}
\end{theorem}
\begin{proof}
Left to right follows from noting that $A$ is a subring of $A[x]$. Right to left follows from noting that the leading term of the product is the product of leading terms.  
\end{proof}
Let $A$ be a ring and $f \in A[x_1,\dots ,x_n]$. The \textbf{content of $f$} is the ideal of $A$ generated by the coefficients of  $f$, and we say $f$ is \textbf{primitive} if $\operatorname{cont}(f)=(1)$. Clearly, we may give a well-ordering on the set of monomials of $A[x_1,\dots ,x_n]$ by first comparing their powers on $x_1$, and if tie, then comparing their powers on $x_2$ and so on. Such ordering is called the \textbf{lexicographical monomials ordering}. Clearly, lexicographical monomials ordering satisfies 
\begin{align*}
m_1 > m_2 \implies  m_1m_3 > m_2m_3
\end{align*}
\begin{theorem}
\label{THdomo}
\textbf{(Divisors of monomials over integral domains must be either constants or monomials)} Let $D$ be an integral domain and  $m \in D[x_1,\dots ,x_n]$ a monomial. The divisors of $m$ are either constants or   monomials. 
\end{theorem}
\begin{proof}
Consider lexicographical monomials ordering. 
\end{proof}
\begin{theorem}
\textbf{(Gauss lemma: primitive statement)}  Let $A$ be a ring and $f,g \in A[x_1,\dots ,x_n]$. Then 
\begin{align*}
  \operatorname{cont}(fg)\leq \operatorname{cont}(f) \operatorname{cont}(g)\leq \sqrt{\operatorname{cont}(fg)}
\end{align*}
In particular, since \customref{THpr}{$\sqrt{\mathfrak{a}}=(1) \implies  \mathfrak{a}=(1)$}, we see that 
\begin{align*}
f,g\text{ are both primitive }\iff fg\text{ is primitive }
\end{align*}
\end{theorem}
\begin{proof}
The first inequality is clear. Let $\mathfrak{p}\geq \operatorname{cont}(fg) \trianglelefteq A$. The second inequality requires us to prove that $\mathfrak{p}\geq \operatorname{cont}(f)\operatorname{cont}(g)$. Because $\operatorname{cont}(fg)\leq \mathfrak{p}$, we know $fg$ is  $0$ in  $(A \quotient \mathfrak{p})[x_1, \dots ,x_n]$. Then because \customref{THprai}{$(A \quotient \mathfrak{p})[x_1,\dots ,x_n]$ is an integral domain}, we know either $f$ or  $g$ is  $0$ in $(A \quotient \mathfrak{p})[x_1,\dots, x_n]$. The proof then follows from noting that if $f$ is  $0$ in $(A \quotient \mathfrak{p}) [x_1, \dots ,x_n]$, then $\operatorname{cont}(f)\leq \mathfrak{p}$. 
\end{proof}
\begin{theorem}
\label{THGli1}
\textbf{(Gauss lemma: irreducibility statement, part 1)} Let $D$ be a GCD domain and $f,g \in D[x_1,\dots ,x_n]$. Then  
\begin{align*}
c(fg)=c(f)c(g)
\end{align*}
where $c(f)\triangleq $ the greatest common divisor of nonzero coefficients of $f$.  
\end{theorem}
\begin{proof}
The first step of the proof is noting that since \customref{THrbg}{$\operatorname{GCD}$ is homogeneous}, we may reduce the proof to the case $c(f)=c(g)=1$. The rest of the proof relies on induction on number $n$ of terms in $fg$. The base case $n=1$ follows from noting that \customref{THdomo}{divisors of monomials over integral domains must be either constants or monomials}. \\

We now prove the inductive case. Let $f_0$ and  $g_0$ be the highest degree term of $f$ and  $g$ with respect to lexicographical ordering. Clearly, $f_0g_0$ is also the highest degree term of $fg$. Therefore, $c(fg)$ divides $c(f_0g_0)$. Because of such, we only have to prove
\begin{align*}
\operatorname{gcd}(c(fg),c(f_0g_0))=1
\end{align*}
\customref{THbG}{In particular, we only have to prove}: 
\begin{align*}
\operatorname{gcd}\left(c(fg),c(f_0) \right)= \operatorname{gcd}\left( c(fg),c(g_0) \right)=1
\end{align*}
Assume $\operatorname{gcd}\left(c(fg),c(f_0)\right)=d \not\in D ^{\times}$ for a contradiction. Clearly, we have 
\begin{align*}
d \mid  c(fg-f_0g)=c\left(g(f-f_0)\right)= c(g)c(f-f_0)=c(f-f_0)
\end{align*}
where the second last equality follows from inductive hypothesis. Because $d \mid  c(f_0)$, this implies $d \mid  c(f)=1$, a contradiction.   
\end{proof}
\begin{theorem}
\label{THglisp2}
\textbf{(Gauss lemma: irreducibility statement, part 2)} Let $D$ be a GCD domain, $K \triangleq \operatorname{Frac}(D)$ its field of quotient, and $f \in D[x]$ be non-constant. Then 
\begin{align*}
f \in D[x]\text{ is irreducible }\iff  c(f)=1 \text{ and }f\in K[x]\text{ is irreducible }
\end{align*}
\end{theorem}
\begin{proof}
  ($\impliedby$) is routine. We only prove ($\implies$). $c(f)=1$ is clear. Assume for a contradiction that $f\triangleq gh \in K[x]$ where  $g,h \in K[x]$ are non-units and thus non-constants. Clearly, there exists $d, \tilde{d}\in D$ such that $dg ,\tilde{d}h \in D[x]$. We then have 
\begin{align*}
f=gh= \frac{b}{a}\cdot g'h',\quad \text{ with }g',h'\in D[x]\text{ non-constant and primitive }
\end{align*}
where $b\triangleq c(dg)c(\tilde{d}h) \in D$ and $a \triangleq d \tilde{d} \in D $. Because $g',h' \in D[x]$ are non-constant, to cause a contradiction to irreducibility of $f \in D[x]$, we only have to show $a \mid  b$.  Because $g',h'$ are primitive, this follows from \customref{THGli1}{part 1 of irreducibility statement of Gauss lemma} and taking content on both side of $af=bg'h'$. 
\end{proof}
\begin{theorem}
\textbf{(Eisenstein's criteria)} Let $D$ be an integral domain and 
 \begin{align*}
f\triangleq a_nx^n + \cdots + a_0 \in D[x]
\end{align*}
If there exists a prime ideal $\mathfrak{p}\trianglelefteq D$ such that 
\begin{enumerate}[label=(\roman*)]
  \item  $a_i \in \mathfrak{p}$ for all $i < n$. 
  \item $a_n \not \in \mathfrak{p}$. 
  \item $a_0 \not \in \mathfrak{p}^2$. 
\end{enumerate}
then $f$ can't be written as a product of two non-constant polynomials $\in D[x]$. 


\end{theorem}
\begin{proof}
Assume for a contradiction that $f=gh \in D[x]$ with $g,h \in D[x]$ non-constant. Because the leading coefficient of $f$ is not in $ \mathfrak{p}$, we know the leading coefficients of both $g$ and  $h$ are  not in $ \mathfrak{p}$. Therefore, we know $g,h \in (D \quotient \mathfrak{p})[x]$ are non-constants.  \\

Now, since $f \in (D \quotient \mathfrak{p})[x]$ is a monomial and \customref{THdomo}{divisors of monomials over integral domains must be either constants or monomials}, we see both $g,h \in (D \quotient \mathfrak{p})[x]$ are non-constant monomial, which implies that their constant terms are both in $\mathfrak{p}$, causing a contradiction to $a_0 \not \in \mathfrak{p}^2$. 
\end{proof}
\begin{theorem}
\textbf{(Consequences of Eisenstein's criteria)} Let $D$ be an integral domain and $f \in D[x]$ be a non-constant polynomial that can't be written as a product of two non-constant polynomials. Then 
\begin{enumerate}[label=(\roman*)]
  \item If $f$ is primitive, then $f \in D[x]$ is irreducible. 
  \item If $D$ is a GCD domain with $K\triangleq \operatorname{Frac}(D)$, then $f \in K[x]$ is irreducible.  
\end{enumerate}
\end{theorem}
\begin{proof}
  (i) is clear. By \customref{THglisp2}{Gauss lemma} and (i), $f \quotient c(f)$ is irreducible in $K[x]$, and therefore $f$ is irreducible in  $K[x]$. 
\end{proof}
\section{UFD PID ED}
\begin{equiv_def}
\textbf{(UFD)}  An integral domain $D$ is an \textbf{unique factorization domain} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item Every \emph{nonzero non-unit} element of $D$ can be written as finite product of irreducible elements, unique up to permutation and association.   
  \item Every \emph{nonzero non-unit} element of $D$ can be written as finite product of irreducible elements, and every irreducible element of $D$ is prime. 
  \item Every nonzero $\mathfrak{p}\neq 0 \in \operatorname{Spec}(D)$ contains a prime element. 
\end{enumerate}
\end{equiv_def}
\begin{proof}
(i)$\implies $(ii): Let $a\in D$ be irreducible and $a \mid  xy$. To prove $a$ is prime, we are required to prove $a$ divides one of $x,y$. Write 
\begin{align*}
a \pi_1 \cdots \pi _n =(p_1\cdots p_m)(q_1 \cdots q_k)=xy,\quad \text{ where }p_i,\pi _i,q_i\text{ are irreducible }
\end{align*}
The proof then follows from noting that by premise, $a$ must lies one of  $p_i,q_i$, up to association. \\

(ii)$\implies $(i): Consider two factorizations of same element:  
\begin{align*}
p_1 \cdots p_n = q_1 \cdots q_m,\quad \text{ where }p_i,q_i\text{ are irreducible }
\end{align*}
WLOG, we only need to prove that, up to association, $p_1 \in \set{q_1,\dots ,q_m}$. Primality of $p_1$ implies that $p_1\mid  q_i$ for some $i$. Write $q_i=p_1s$. Because $p_1$ is non-unit, irreducibility of  $q_i$ implies  $s \in D^{\times}$, as desired. \\




(ii)$\implies $(iii): Because $\mathfrak{p}$ is prime and nonzero, existence of factorization implies that $\mathfrak{p}$ contains an irreducible element, which is prime by premise. \\

 (iii)$\implies $(ii): We first prove a lemma: 
 \begin{center}
    \begin{minipage}{0.9\linewidth}  
      \olive{Let $S\subseteq A $ be a be multiplicatively closed subset with $0 \not \in S$. If $\mathfrak{a}\trianglelefteq A$ is disjoint with $S$, then 
  \begin{align*}
 \Sigma \triangleq \set{\mathfrak{b}\trianglelefteq A: \mathfrak{a}\leq \mathfrak{b}\text{ and }\mathfrak{b}\cap S=\varnothing }
 \end{align*}
has maximal elements, which are all prime.} 
    \end{minipage}
 \end{center}
The fact that $\Sigma$ has maximal elements is a consequence of Zorn's lemma. Let $\mathfrak{b}$ be a maximal element of $\Sigma$. Assume for a contradiction that $\mathfrak{b}$ is not prime. Then there exists $xy \in \mathfrak{b}$ such that $x,y \not \in \mathfrak{b}$. Maximality of $\mathfrak{b}$ then implies that both $\mathfrak{b}+(x)$ and $\mathfrak{b}+(y)$ intersect with $S$. Let $s_1 \in \left(\mathfrak{b}+(x) \right)\cap S$ and $s_2 \in \left(\mathfrak{b}+(y) \right)\cap S $. Because $xy \in \mathfrak{b}$, direct computation then shows $s_1s_2 \in \mathfrak{b}\cap S$, a contradiction. \odone\\

Let 
\begin{align*}
 S\triangleq \set{p_1 \cdots p_n \in D: n\geq 0 \text{ and } p_i\text{ are prime}}
\end{align*}
where $n=0$ means unit, so  $D^{\times}\subseteq S$. Because \customref{Thpei}{prime elements are irreducible}, to prove the existence of factorization, we only have to prove that $S$ contains all nonzero element of  $D$. Before such, we first prove that 
\begin{center}
   \begin{minipage}{0.9\linewidth}  
       \centering
       \vi{$S$ is divisor-closed. That is, if  $s \in S$ and $d \mid  s$, then $d \in S$.}
   \end{minipage}
\end{center}
Let $s\triangleq p_1 \cdots p_n$. This is proved via induction on $n$. Let $s\triangleq dq$. The base case is $n=0$, where $s \in D^{\times}$. In such case, we have $dqs^{-1}=1$, so $d \in D^{\times}\subseteq S$. We now prove the inductive case. Because we clearly have $p_1 \mid  dq$, primality of $p_1$ split the proof into two cases: 
\begin{align*}
p_1 \mid  d\quad \text{ or }\quad p_1 \mid q
\end{align*}
Case ($p_1 \mid d$): Let $d\triangleq  p_1q'$. Our goal is to prove $q' \in S$. Because $D$ is an integral domain, we have 
\begin{align*}
p_1 \cdots p_n= dq= p_1q'q \implies  d' \mid  p_2 \cdots p_n
\end{align*}
which by inductive hypothesis implies $q' \in S$. \\


Case ($p_1 \mid  q$): Let $q \triangleq p_1q''$. Again, because $D$ is an integral domain, we have 
\begin{align*}
p_1 \cdots p_n =dq= dp_1 p''  \implies d \mid  p_2 \cdots p_n 
\end{align*}
The proof then follows from inductive hypothesis. \vdone \\

We may now prove easily that $S$ contains all nonzero elements of  $D$. Assume for a contradiction that $a \neq 0\in D-S$. Because $S$ is divisor-closed, this implies  $(a)\cap S= \varnothing $. Therefore by our earlier lemma, there exists some prime ideal $\mathfrak{p}\geq (a)$ such that $\mathfrak{p} \cap S = \varnothing $. This is impossible, since by premise, there exists some prime $p \in \mathfrak{p}$. \\

Let $\pi \in D$ be irreducible. The fact that $\pi $ is prime then follows from factorizing $\pi  =p_1 \cdots p_n$ into prime elements and observing that by irreducibility of $\pi $, we must have $n=1$. 
\end{proof}
\begin{theorem}
\textbf{(Polynomial ring over UFD is UFD)} If $D$ is a UFD, then $D[x]$ is a UFD.  
\end{theorem}
\begin{proof}
We first prove the existence of factorization. Let $f \in D[x]$. Because $D$ is a UFD and irreducibles in $D$ remain irreducible in  $D[x]$, to factorize $f$, we only have to factorize $\frac{f}{c(f)}$. In other words, we may suppose $f$ is primitive.  \\

Clearly, $f  \in D[x]$ can be written as a finite product of non-constant polynomials $\in D[x]$ that can't be written as products of two non-constant polynomial. By  \customref{THGli1}{Gauss lemma}, these polynomials must be primitive, and therefore irreducibles. \\

We now prove that every irreducible $f \in D[x]$ must be prime. Clearly, $f$ must be primitive.\\  

Let  $g,h \in D[x]$ and  $gh$ be divisible by $f$ in $D[x]$. Let  $K \triangleq \operatorname{Frac}(D)$.  Because $K[x]$ is an Euclidean domain, we know $f \in K[x]$ is prime. Therefore, $f$ divides either  $g$ or $h$ in  $K[x]$. Suppose $fq=g$ with $q \in K[x]$. Write $q \triangleq \frac{Q}{d}$ with $Q\in D[x],d \in D$. Then 
\begin{align*}
fQ=dg
\end{align*}
Taking contents on both side, again by \customref{THGli1}{Gauss lemma}, we see 
\begin{align*}
c(Q)=d c(g)
\end{align*}
Therefore, $d \mid  c(Q)$, and $q \in D[x]$. 
\end{proof}

\begin{Example}{$\Z [\sqrt{5}i]$ isn't UFD.}{}
Because $\Z [ \sqrt{5}i]$ is a subring of $\C$, we know  it is an integral domain. If $\Z[\sqrt{5}i]$ is an UFD, then all irreducibles are prime. We prove this isn't the case by showing $2\in \Z[\sqrt{5} i]$ is irreducible but not prime. To see $2 \in \Z[\sqrt{5}i]$ is prime, just observe 
\begin{align*}
2 \mid  6= (1+ \sqrt{5}i)(1- \sqrt{5}i)
\end{align*}
and that $2$ clearly doesn't divide neither $1+ \sqrt{5}i$ nor $1-\sqrt{5}i$. The proof that $2 \in \Z[\sqrt{5}i]$ is irreducible is more tricky: Let 
\begin{align*}
2 \triangleq  (a+b \sqrt{5}i )(c+ d \sqrt{5}i )
\end{align*}
Then we have 
\begin{align*}
\begin{cases}
  ac-5bd=2\\
  bc+ad=0
\end{cases} \implies \begin{cases}
  acd-5bd^2 = 2d \\
  ad=-bc
\end{cases} \implies  2d= -b(c^2+5d^2)
\end{align*}
Then by comparing order of absolutes values of each side, we see that we must have $d=0$. This then implies $b=0$ and therefore $ac=2$, as desired.   
\end{Example}
An integral domain is said to be \textbf{PID} if in which all ideals are principal. 
\begin{theorem}
\textbf{()} $A[x]$ is a PID if and only if $A$ is a field. 
\end{theorem}
\begin{proof}
Clearly, we have an ring isomorphism 
\begin{align*}
  A[x]\quotient (x)\cong  A,\quad f \mapsto f(0)
\end{align*}

\end{proof}
\begin{Example}{$A[x,y]$ is not a PID}{}
Consider $(x,y)$. 
\end{Example}
\begin{theorem}
\textbf{(Basic properties of principal ideal in integral domain)} Let $D$ be an integral domain and   $\mathfrak{a}\trianglelefteq D$ an nonzero principal ideal. Clearly, the possible generators of $\mathfrak{a}$ forms an associative class, moreover 
\begin{enumerate}[label=(\roman*)]
  \item  $\mathfrak{a}\in \operatorname{Spec}(D)\iff $  the generator class is prime.
  \item $\mathfrak{a}$ is maximal among proper principal ideals $\iff $ the generator class is irreducible.     
\end{enumerate}
In particular, because of (i), we know PID are UFD, and because prime elements are irreducible, from  (ii) we see that if $D$ is a PID, then  $\operatorname{Spec}(D)=\operatorname{Max}(D)$. 
\end{theorem}
\begin{proof}
 Let $\mathfrak{a}\triangleq (a)$.  We prove (ii). ($\implies $): Let $a\triangleq xy$. If  $x$ and  $y$ are both non-units, then $(a)=(xy)<(y)<D$. \\

 $(\impliedby)$: Let $(b)\geq (a)$ be a proper ideal, so $a=bq$ for some  $q\in D$. Because $(b)$ is a proper ideal, we know the unit is $q$, so  $a\sim  q$ and $(b)=(a)$. 
\end{proof}



We say a divisor $x \in A$ of $a,b \in A$ is a \textbf{greatest common divisor} if $x$ is divided by all common divisors of $a,b$. 
\begin{Example}{}{}
Consider $6, 2 (1+ \sqrt{5}i) \in \Z [i]$. $6$ has divisors $1,2,3,1\pm \sqrt{5}i$, so they have common divisors  $2,1+ \sqrt{5}i$, but no greatest common divisor. 
\end{Example}

\begin{theorem}
\textbf{(Properties of $\Z[\sqrt{-d} ]$ for square-free $d\geq 3$)} Let $d \geq 3$ be square free. If $d+1$ is not prime, but divisible by prime  $p$, then 
\begin{enumerate}[label=(\roman*)]
  \item $p \in \Z[ \sqrt{-d} ] $ is irreducible but isn't prime. 
  \item $\operatorname{gcd}(p, 1+ \sqrt{-d})=1$, but $\operatorname{lcm}(p,1 + \sqrt{-d} )$ doesn't exist. 
\end{enumerate}
If $d+1$ is prime, then 
 \begin{enumerate}[label=(\roman*)]
  \item $2\in \Z[\sqrt{-d}]$ is irreducible but isn't prime. 
   \item $\operatorname{gcd}(2,2+ \sqrt{-d})=1$, but $\operatorname{lcm}(2,2+ \sqrt{-d} )$ doesn't exist. 
\end{enumerate}
\end{theorem}
\begin{proof}
\href{https://www.isibang.ac.in/~sury/content.pdf}{See this note}. 
\end{proof}
Let $D$ be an integral domain. We say $D$ is an \textbf{Euclidean domain} if there exists some function $f: D - \set{0}\rightarrow \Z_0^{+}$ that satisfies \textbf{division-algorithm property}: For all $a \in D$ and nonzero $b \in D$, there exists some $q,r \in D$ such that $a=qb+r$ and either  $r=0$ or  $f(r) < f(q)$. If $f$ moreover satisfies   
\begin{align*}
f(a)\leq f(ax)\text{ for all nonzero $a,x \in D$ }
\end{align*}
then we say $f$ is a \textbf{Euclidean norm}. 
\begin{theorem}
\textbf{(Every Euclidean domain admits an Euclidean norm)} If $D$ is a Euclidean domain with  $g: D - \set{0}\rightarrow \Z_0^+$ satisfying the division-algorithm property, then $f:D - \set{0}\rightarrow \Z_0^+$ defined by 
\begin{align*}
f(a) \triangleq \min_{x \in D - \set{0}} g(ax)
\end{align*}
is an Euclidean norm. 
\end{theorem}
\begin{proof}
Let $a,b \in D$ with $b$ nonzero satisfying  $b\nmid a$. Let $f(b)\triangleq g(bc)$. Applying $g$-division algorithm on  $ac$ and  $bc$, we get 
 \begin{align*}
ac= q \cdot bc + rc,\quad \text{ where }r \triangleq a-qb \neq 0
\end{align*}
which satisfies 
\begin{align*}
f(r) \leq g(rc) < g(bc)=f(b) 
\end{align*}
\end{proof}
Clearly, Euclidean domains are PID, since every ideal in Euclidean domain can be generated by any of its element of smallest norm. \\

$\Z$ is a Euclidean domain with Euclidean function  $f(x)\triangleq \abso{x}$. Gaussian integers ring $\Z[i]$ is a Euclidean domain with Euclidean function $f(a+b i)\triangleq a^2+b^2$. For each field $K$, $K[x]$ has Euclidean function $\operatorname{deg}$. $K$ itself is also Euclidean domain with Euclidean function $x \mapsto  1$.


\begin{Example}{$\Z [\frac{1}{2}(1+ \sqrt{-19})]$ is a PID that isn't Euclidean}{}
 
\end{Example}

\chapter{Algebraic Geometry}
\section{Spectrum}
\begin{equiv_def}
\label{EDZs}
\textbf{(Zariski topology on spectrum)} Let $A$ be a ring. For all  $E\subseteq A$ and $f \in A$, we define 
\begin{align*}
V(E)\triangleq \set{\mathfrak{p}\in \operatorname{Spec}(A):E \subseteq \mathfrak{p}}\quad \text{ and }\quad U_f \triangleq \set{\mathfrak{p}\in \operatorname{Spec}(A): f \in \mathfrak{p}}
\end{align*}
Since 
\begin{enumerate}[label=(\roman*)]
  \item $\operatorname{Spec}(A)=V(0)$ and $\varnothing  = V(1)$. 
  \item $V(\mathfrak{a})\cup  V(\mathfrak{b})=V(\mathfrak{a}\mathfrak{b})=V(\mathfrak{a}\cap \mathfrak{b})$. 
  \item $\bigcap_{i \in I}V(\mathfrak{a}_i)=V(\bigcup \mathfrak{a}_i)=V(\sum \mathfrak{a}_i)$ for possibly infinite $I$. 
\end{enumerate}
We see that the \textbf{Zariski topology} on $\operatorname{Spec}(A)$ is well-defined. Because
\begin{align*}
  V(E) = \customref{EDr}{V(\mathfrak{a})= V(\sqrt{\mathfrak{a}} )},\quad \text{ where }\mathfrak{a}\triangleq (E)
\end{align*}
Topology of $\operatorname{Spec}(A)$ is determined by ideals  $\trianglelefteq A$. Moreover, we have 
\begin{align*}
\mathfrak{a}\leq \operatorname{Nil}(A) \iff V(\mathfrak{a})= \operatorname{Spec}(A),\quad \text{ for all }\mathfrak{a}\trianglelefteq A
\end{align*}
\end{equiv_def}
\begin{proof}
Clearly, we have  
\begin{align*}
V(\mathfrak{a})\cup  V(\mathfrak{b}) \subseteq V(\mathfrak{a}\mathfrak{b}) \subseteq V(\mathfrak{a}\cap \mathfrak{b})
\end{align*}
The inequality $V(\mathfrak{a}\cap \mathfrak{b})\subseteq V(\mathfrak{a})\cup V(\mathfrak{b})$ follows from  \customref{THpp}{$\mathfrak{a}\cap \mathfrak{b}\leq \mathfrak{p}$ implies one of them is contained by $\mathfrak{p}$}.
\end{proof}
\begin{theorem}
\label{THbos}
\textbf{(Property of basic open sets)} Because  
\begin{align*}
  \operatorname{Spec}(A)- V(\mathfrak{a}) = \bigcup_{f\in \mathfrak{a}}U_f
\end{align*}
we know $\set{U_f\subseteq \operatorname{Spec}(A): f\in A}$ form a basis for $\operatorname{Spec}(A)$, thus the name \textbf{basic open sets}. Basic open sets have the properties: 
\begin{enumerate}[label=(\roman*)]
  \item $U_f = \varnothing  \iff  f \in \operatorname{Nil}(A)$. 
  \item $U_f = \operatorname{Spec}(A)\iff f \in A^{\times}$. 
  \item $U_{fg}=U_f \cap U_g$ for all $f,g \in A$. 
\end{enumerate}
\end{theorem}
\begin{proof}
 The first property of basic open sets follows from \customref{EQna}{$\operatorname{Nil}(A)=\bigcap \operatorname{Spec}(A)$}. The second property of basic open sets follows from the fact \customref{THem}{every non-unit must be contained by some maximal ideal}. The third property of basic open sets follows from definition of prime ideals.  
\end{proof}
\begin{theorem}
\label{THtps}
\textbf{(Topological property of $\operatorname{Spec}(A)$)} Let $Y \subseteq  \operatorname{Spec}(A)$. Then clearly we have: 
\begin{align*}
  \overline{Y}&= \bigcap_{Y \subseteq V(\mathfrak{a})} V(\mathfrak{a})= \customref{EDZs}{\bigcap_{\mathfrak{a}\leq \bigcap Y} V(\mathfrak{a})=V \left(\sum_{\mathfrak{a}\leq \bigcap Y} \mathfrak{a} \right)}= V\left(\bigcap Y \right)
\end{align*}
In particular, 
\begin{align*}
  \overline{\set{\mathfrak{p}}}= V(\mathfrak{p}),\quad \text{ for all }\mathfrak{p} \trianglelefteq A
\end{align*}
Because of such, we know: 
\begin{align}
\label{EQpop}
  \mathfrak{q} \in \overline{\set{\mathfrak{p}}} \iff  \mathfrak{p} \leq \mathfrak{q}
\end{align}
for all $\mathfrak{q}\in \operatorname{Spec}(A)$. In general, given a topological space $X$, we say $x \in X$ is a \textbf{closed point} if  $\set{x}$ is closed, we say $X$ is a \textbf{$T_0$-space} if for any pair $x\neq y \in X$, there exists an open set containing exactly of them, and we say $X$ is  \textbf{irreducible} if $X$ can not be written as union of two proper closed subset of $X$. Then, 
\begin{enumerate}[label=(\roman*)]
  \item $\mathfrak{p} \in \operatorname{Spec}(A)$ is a closed point $\iff  \mathfrak{p}\in \operatorname{Max}(A)$.  
  \item $\operatorname{Spec}(A)$ is $T_0$.  
  \item $\operatorname{Spec}(A)$ is irreducible $\iff \operatorname{Nil}(A)\trianglelefteq A$ is prime.   
  \item The irreducible closed subspaces of $\operatorname{Spec}(A)$ is exactly $\set{V(\mathfrak{p}): \mathfrak{p}\in \operatorname{Spec}(A)}$. Therefore, since \customref{THpr}{$V(\mathfrak{a})\subseteq V(\mathfrak{b})\iff  \sqrt{\mathfrak{a}}\geq \sqrt{\mathfrak{b}}$}, the irreducible components of $\operatorname{Spec}(A)$ is exactly $\set{V(\mathfrak{p}):\mathfrak{p}\text{ is a minimal prime ideal over }0}$. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (i) follows from \myref{statement}{EQpop}. For (ii), just observe that if $\mathfrak{p}\not \leq \mathfrak{q}$, then $\operatorname{Spec}(A)-V(\mathfrak{p})$ is an open set containing $\mathfrak{q}$ but not $\mathfrak{p}$. We now prove (iii). Because \customref{EDZs}{$V(\mathfrak{a})\cup V(\mathfrak{b})=V(\mathfrak{a}\cap \mathfrak{b})$} and because \customref{EDZs}{$V(\mathfrak{a})=\operatorname{Spec}(A)\iff  \mathfrak{a}\leq \operatorname{Nil}(A)$}, we know $\operatorname{Spec}(A)$ is irreducible if and only if: 
\begin{align}
\label{EQab}
\mathfrak{a}\cap \mathfrak{b}\leq \operatorname{Nil}(A) \implies  \mathfrak{a}\text{ or }\mathfrak{b}\leq \operatorname{Nil}(A),\quad \text{ for all }\mathfrak{a},\mathfrak{b}\trianglelefteq A
\end{align}
\customref{THpp}{This is apparently true if $\operatorname{Nil}(A)\trianglelefteq A$ is prime}. Conversely, if \myref{statement}{EQab} holds, then since $\mathfrak{a}\mathfrak{b}\leq \mathfrak{a}\cap \mathfrak{b}$, by considering principal ideals, we see $\operatorname{Nil}(A)$ is prime.  \\

(iv): Because we have homeomorphisms \customref{THpb}{$V(\mathfrak{a})\cong \operatorname{Spec}(A \quotient \mathfrak{a})$}, by (iii), we know $V(\mathfrak{a})$ is irreducible if and only if $\operatorname{Nil}(A\quotient \mathfrak{a})$ is prime. By \customref{THtitr}{correspondence theorem for rings}, we know $\operatorname{Nil}(A \quotient \mathfrak{a})$ is prime if and only if $\sqrt{\mathfrak{a}}\trianglelefteq A$ is prime. Therefore, the set of irreducible closed subspaces of $\operatorname{Spec}(A)$ is 
\begin{align*}
  \set{V(\mathfrak{a}): \mathfrak{a}\trianglelefteq A\text{ and }\sqrt{\mathfrak{a}}\in \operatorname{Spec}(A) }\customref{EDr}{=} \set{V(\mathfrak{p}): \mathfrak{p}\in \operatorname{Spec}(A)}
\end{align*}
\end{proof}
\begin{theorem}
\label{THpb}
  \textbf{(Basic properties of pullback)} Let $\pfi :A \rightarrow B$ be a ring homomorphism, because \customref{THpp}{preimage of prime ideals are prime}, the \textbf{pullback}  $\pfi^* : \operatorname{Spec}(B)\rightarrow \operatorname{Spec}(A)$ defined by $\pfi ^*(\mathfrak{b})\triangleq \mathfrak{b}^c$ is well-defined. Denote $X \triangleq \operatorname{Spec}(A)$ and $Y \triangleq \operatorname{Spec}(B)$. Then 
  \begin{enumerate}[label=(\roman*)]
    \item Because $(\pfi ^*)^{-1}(X_f)=Y_{\pfi  (f)}$, we see $\pfi ^*:Y \rightarrow X$ is continuous.  
    \item $(\pfi ^*)^{-1}(V(\mathfrak{a}))=V(\mathfrak{a}^e)$. 
    \item $\overline{\pfi^*(V(\mathfrak{b}))}=V(\mathfrak{b}^c)$. 
    \item If $\pfi $ is surjective, then $\pfi ^*$ is a homeomorphism of $Y$ onto $V(\operatorname{ker}(\pfi ))$. In particular, for all $\mathfrak{a}\trianglelefteq A$, we have a homeomorphism 
\begin{align*}
V(\mathfrak{a}) \cong  \operatorname{Spec}(A \quotient \mathfrak{a})
\end{align*}
    \item $\pfi ^*(Y)$ is dense in $X\iff \operatorname{ker}(\pfi )\leq \operatorname{Nil}(A)$. 
  \end{enumerate}
\end{theorem}
\begin{proof}
  (i) and (ii) are clear. For (iii), use the fact that \customref{THec}{contraction comutes with taking intersection and radical} to compute: 
\begin{align*}
&\customref{THtps}{\overline{\pfi ^*(V(\mathfrak{b}))}=  V\left(\bigcap \pfi ^* (V(\mathfrak{b}))\right)}\\
&= V \left(\bigcap_{\mathfrak{b}\leq \mathfrak{q}} \mathfrak{q}^c  \right) = V\left( (\bigcap_{\mathfrak{b}\leq \mathfrak{q}}\mathfrak{q} )^c  \right) = \customref{THpr}{V\left( (\sqrt{\mathfrak{b}})^c  \right)= V( \sqrt{\mathfrak{b}^c}  )=V(\mathfrak{b}^c)}
\end{align*}
(iv): The fact that $\pfi ^*:Y \rightarrow V(\operatorname{ker}(\pfi ))$ is bijective follows from \customref{THtitr}{correspondence theorem for rings}, and the fact that $\pfi ^*$ is a closed map follows from using  \customref{THtitr}{correspondence theorem for rings} to compute: 
\begin{align*}
  \pfi^*\left(V(\mathfrak{b}) \right) = V\left(\pfi^{-1}(\mathfrak{b}) \right),\quad \text{ for all }\mathfrak{b}\trianglelefteq B
\end{align*}
(v): Because \customref{EDfN}{$ \operatorname{Nil}(A)=\bigcap \operatorname{Spec}(A)$}, the proof follows from using (iii) to compute: 
\begin{align*}
  \customref{EDZs}{\overline{\pfi ^*(Y)} = \overline{\pfi ^* (V(0))}}= V(0^c) = V(\operatorname{ker}(\pfi ))
\end{align*}
\end{proof}
\begin{theorem}
\textbf{(Connectedness of spectrums)} Let $A\triangleq A_1 \times \cdots \times A_n$. Then we have a homeomorphism:  
\begin{align}
\label{EQsa}
\operatorname{Spec}(A) \cong    \coprod_{i=1}^n \operatorname{Spec}(A_i)  
\end{align}
Moreover, for any ring $B$, the followings are equivalent: 
 \begin{enumerate}[label=(\roman*)]
  \item $\operatorname{Spec}(B)$ is disconnected. 
  \item $B \cong  B_1\times B_2$ where neither $B_1$ nor  $B_2$ is the zero ring.  
  \item $B$ contains no idempotent $\neq 0,1$.  
\end{enumerate}
In particular, by (iii), \customref{THlc}{the spectrum of a local ring is always connected}. 
\end{theorem}
\begin{proof}
Denote $\mathfrak{a}_i \triangleq \operatorname{ker}(\pi _i)$, where $\pi_i : A \twoheadrightarrow A_i$ are the canonical projection. Because we have \customref{THpb}{homeomorphisms $\pi _i^*:\operatorname{Spec}(A_i)\longrightarrow V(\mathfrak{a}_i)$}, proof of \myref{statement}{EQsa} boils  down to showing that  $\operatorname{Spec}(A)$ is the disjoint union of $V(\mathfrak{a}_i)$. This is then clear from the forms of $\mathfrak{a}_i$, as we can compute
\begin{align*}
\customref{EDZs}{V(\mathfrak{a}_i)\cap V(\mathfrak{a}_j)= V(\mathfrak{a}_i+ \mathfrak{a}_j)}=V(A)= \varnothing,\quad \text{ for all }i\neq j
\end{align*}
and compute
\begin{align*}
  \customref{EDZs}{ \bigcup V(\mathfrak{a}_i)= V(\mathfrak{a}_1 \cap  \cdots \cap \mathfrak{a}_n)}= V(0)=\operatorname{Spec}(A)
\end{align*}
We have already shown (ii)$\implies $(i). We now prove (i)$\implies $ (iii). Write   \begin{align*}
\operatorname{Spec}(B)=V(\mathfrak{a}) \coprod  V(\mathfrak{b})
\end{align*}
where $V(\mathfrak{a}),V(\mathfrak{b})$ are nonempty. On one hand, by  \customref{THtitr}{correspondence theorem}, from 
\begin{align*}
\varnothing = \customref{EDZs}{V(\mathfrak{a})\cap V(\mathfrak{b}) = V(\mathfrak{a}+\mathfrak{b})}
\end{align*}
we know $\mathfrak{a}+\mathfrak{b}=(1)$, which by \customref{EDci}{definition of comaximal ideal pair} implies  $1=a+b$ for some  $a \in \mathfrak{a}$ and $b \in \mathfrak{b}$. On the other hand, from  
\begin{align*}
\operatorname{Spec}(B)= V(\mathfrak{a})\cup V(\mathfrak{b})= V(\mathfrak{a}\mathfrak{b})
\end{align*}
we know $\mathfrak{a}\mathfrak{b}\leq \operatorname{Nil}(B)$, which implies $a^nb^n=0$ for some $n>0$. Now, since $(a+b)^{2n}=1^{2n}=1$, we see $(a^n)+(b^n)=(1)$, which implies the existence of some $e \in (a^n)$ and $\tilde{e}\in (b^n) $ that makes $e+ \tilde{e}=1$. Computing:
\begin{align*}
e-e^2= e \tilde{e} \in (a^nb^n)=(0) 
\end{align*}
we see that $e$ is idempotent. To see $e \neq 0,1$, just observe that if so, then one of $V(\mathfrak{b}),V(\mathfrak{a})$ would be $\operatorname{Spec}(B)$. \\

(iii)$\implies $(i): Let $e \neq 0 ,1$ be idempotent. Clearly, $1-e$ is also idempotent. Because the only idempotent unit is  $1$, we know both $e$ and  $1-e$ are non-units. Therefore, $(e)$ and $(1-e)$ is a comaximal pair of proper ideals.  Clearly, we have 
\begin{align*}
  (e)\cap (1-e) \leq (e)(1-e)=0
\end{align*}
Therefore, by \customref{EDci}{definition of comaximal ideals}, we have an isomorphism 
\begin{align*}
B \cong  B \quotient (e) \times B \quotient (1-e)
\end{align*}
as desired. 
\end{proof}


\begin{theorem}
\label{THsac}
\textbf{(Spectrums are compact)} Let $A$ be a ring and $X \triangleq \operatorname{Spec}(A)$. Then open subset $U \subseteq X$ is compact if and only if $U$ is a finite union of basic open sets. In particular,  $X= U_0$  and $U_f$ are compact. 
\end{theorem}
\begin{proof}
  ($\implies $) is clear. Let $f \in A$. Because finite union of compact set is compact, to prove $(\impliedby)$, we only have to prove that $U_f$ is compact. This is proved by a sequence of observation of equivalence. Trivially, $\set{X- V(\mathfrak{a}_i): i \in I}$ covers $U_f$ if and only if 
 \begin{align*}
   \customref{EDZs}{V \left(\sum_{i \in I}\mathfrak{a}_i \right) = \bigcap_{i \in I} V (\mathfrak{a}_i)} \subseteq V(f)
\end{align*}
This is then   \customref{THpr}{equivalent} to: 
\begin{align}
\label{EQsf}
\sqrt{(f)} \leq \sqrt{\sum_{i \in I} \mathfrak{a}_i}   
\end{align}
Since \customref{THpr}{$\sqrt{ \sqrt{\mathfrak{a}}}=\sqrt{\mathfrak{a}}$}, we know \myref{equation}{EQsf} is  equivalent to: 
\begin{align*}
f^n \in \sum_{i \in I}  \mathfrak{a}_i\text{ for some }n>0
\end{align*}
The proof then follows from noting that we may select a finite subset $J\subseteq I$ such that $f^n \in \sum_{i \in J}\mathfrak{a}_i$ still holds. 
\end{proof}
\begin{theorem}
\textbf{(Compact Hausdorff space $X$ is naturally homeomorphic to the maximal spectrum of $C(X)$)} Let $X$ be a compact Hausdorff space and $C(X)$ the ring of continuous real-valued function on $X$. Give $\operatorname{Max}(C(X))$ the subspace topology of $\operatorname{Spec}(C(X))$. Because for all $x \in X$ the ring homomorphism $C(X)\rightarrow \R$ defined by $x \mapsto f(x)$ is surjective with kernel  
\begin{align*}
\mathfrak{m}_x \triangleq \set{f\in C(X):f(x)=0}
\end{align*}
We have a natural map 
\begin{align*}
X\longrightarrow \operatorname{Max}(C(X));\quad x \mapsto \mathfrak{m}_x
\end{align*}
Such map is a homeomorphism. 
\end{theorem}
\begin{proof}
Let $x \neq y$. To prove injectivity, we are required to prove $\mathfrak{m}_x\neq \mathfrak{m}_y$. Because $X$ is Hausdorff, we know $\set{x},\set{y}$ are both closed in $X$. Therefore, by \customref{EDnst}{Urysohn's lemma}, there exists some $f \in C(X)$ such that $f\in \mathfrak{m}_x - \mathfrak{m}_y$. \\

Let $\mathfrak{m}\in \operatorname{Max}(C(X))$. To prove surjectivity, we are required to find $x \in X$ such that $\mathfrak{m}=\mathfrak{m}_x$. Define 
\begin{align*}
V \triangleq \set{x \in X: f(x)=0\text{ for all }f \in \mathfrak{m}}
\end{align*}
Clearly, if $V$ is nonempty, then for all  $x \in V$, we have $\mathfrak{m}\leq  \mathfrak{m}_x$, which by maximality of $\mathfrak{m}$ implies $\mathfrak{m}=\mathfrak{m}_x$. Therefore, we only have to prove $V$ is nonempty. Assume for a contradiction that $V$ is empty. Then for all $x\in X$ there exists some $f_x\in \mathfrak{m}$ such that $f_x(x)\neq 0$. Because $X$ is compact, this gives us some 
\begin{align*}
f \triangleq f_{x_1}^2 + \cdots + f_{x_n}^2 \in \mathfrak{m}
\end{align*}
such that $f(x)\neq 0$ for all $x \in X$. Such $f$ is clearly a unit in $C(X)$, a contradiction. \\

It remains to prove that the natural map is continuous and an open map. For all $f \in C(X)$, define 
\begin{align*}
U_f \triangleq \set{x \in X: f(x)\neq 0}\quad \text{ and }\quad \tilde{U}_f\triangleq \set{\mathfrak{m}\in \operatorname{Max}(C(X)): f \not \in \mathfrak{m}} 
\end{align*}
Because $\operatorname{Max}(C(X))$ is given the subspace topology, we know that \customref{THbos}{$\set{\tilde{U}_f}$ is a basis for $\operatorname{Max}(C(X))$}. By \customref{EDnst}{Urysohn's lemma}, for all $x \in X$ with neighborhood  $W$, there exists some  $f\in C(X)$ such that $f(\set{x})=1$ and $f(X- W)= 0$. In other words, $x \in U_f \subseteq W$. We have shown that $\set{U_f}$ form a basis for $X$. The rest of the proof then follows from computing:
 \begin{align*}
x \in U_f \iff f(x)\neq 0 \iff f \not \in \mathfrak{m}_x \iff \mathfrak{m}_x \in \tilde{U}_f 
\end{align*}
\end{proof}
Let $k$ be an algebraically closed field. An \textbf{affine algebraic variety} $X\subseteq k^n$ is simply the solution set  to some subset of $k[x_1,\dots ,x_n]$. The \textbf{ideal $I(X)$ of the variety} $X$ is just the set of polynomial functions $f \in k[x_1,\dots ,x_n]$ that vanishes identically on $X$. The \textbf{coordinate function}  $\xi_i$ is simply the image of $x_i\in k[x_1,\dots ,x_n]$  onto the  \textbf{coordinate ring} $P(X)\triangleq k[x_1,\dots ,x_n]\quotient I(X) $. \\

For all $x \in X$, because the ideal
\begin{align*}
\mathfrak{m}_x \triangleq \set{f \in P(X):f(x)=0}
\end{align*}
is the kernel of the natural surjective ring homomorphism $P(X)\twoheadrightarrow k$, we know  $\mathfrak{m}_x$ are maximal. Therefore, we have a natural map $X \longrightarrow \operatorname{Max}(P(X))$. Such map is clearly injective, since if $x \neq y$, then $x_i \neq y_i$ for some $i$, which implies 
\begin{align*}
\xi_i-x_i \in \mathfrak{m}_x - \mathfrak{m}_y
\end{align*}


\section{Boolean rings}
A \textbf{Boolean ring} is a ring $A$ that makes  $x^2=x$ for all  $x \in A$. 
\begin{theorem}
\label{THBr}
\textbf{(Basic properties of Boolean rings)} Let $A$ be a Boolean ring. Then 
 \begin{enumerate}[label=(\roman*)]
  \item $2x=0$ for all  $x\in A$. 
  \item  $\operatorname{Spec}(A)=\operatorname{Max}(A)$, and moreover,  $A \quotient \mathfrak{p}\cong \Z_2$ for all $\mathfrak{p}\in \operatorname{Spec}(A)$. 
  \item Every finitely generated ideals  $\trianglelefteq A$ is principal. 
\end{enumerate}
\end{theorem}
\begin{proof}
(i) is a consequence of $(x+1)^2=x+1$. We now prove (ii). Because $0=x^2-x=x(x-1)$ for all $x\in A$ and because $A \quotient \mathfrak{p}$ is an integral domain, we see that for all $x\in A$, either $x + \mathfrak{p}=0$ or $(x-1)+ \mathfrak{p}=0 \in A \quotient \mathfrak{p}$. In other words, there are only two elements in $A \quotient \mathfrak{p}$, that is, $\mathfrak{p}$ and $1+ \mathfrak{p}$.\\



(iii) is proved by induction on number of generators. The base case of single generator is trivial. Let $\mathfrak{a}\triangleq (x_1,\dots ,x_n,y)\trianglelefteq A$. Inductive hypothesis stated that  $(x_1,\dots ,x_n)=(x)$ for some $x\in A$. Let $z \triangleq x+y -xy$. Because $x=xz$ and  $y=yz$,  we have
\begin{align*}
  \mathfrak{a}=(x,y)=(z)
\end{align*}
as desired. 
\end{proof}
\begin{theorem}
\label{THpsB}
\textbf{(Basic properties of spectrums of Boolean rings)} Let $A$ be a Boolean ring. Denote  $X \triangleq \operatorname{Spec}(A)$. Then: 
\begin{enumerate}[label=(\roman*)]
  \item The clopen subsets of $X$ are exactly the basic open subsets. 
  \item For all $f_1,\dots,f_n \in A$, there exists some $f \in A$ such that  $X_f=X_{f_1}\cup \cdots \cup  X_{f_n}$. 
  \item $X$ is compact Hausdorff.  
\end{enumerate}
\end{theorem}
\begin{proof}
(ii) is a consequence of the fact that \customref{THBr}{finitely generated ideals of Boolean rings are principal}. In particular, given $(f)\triangleq (f_1,\dots ,f_n)$, we have 
\begin{align*}
\bigcup X_{f_i}= X - \bigcap V(f_i)= X- V \left(\sum f_i\right)  = X- V(f)= X_f
\end{align*}
(i): To see basic open subsets $X_f$ are clopen, one simply use the fact that  \customref{THBr}{$2f=0$} to compute 
\begin{align*}
X= X_f \coprod X_{1+f}
\end{align*}
It remains to use (ii) to show all clopen subsets $Y \subseteq X$ are basic open subset. Because $Y$ is closed in  \customref{THsac}{compact $X$}, we know $Y$ is also compact, which implies that $Y$ is a finite union of basic open subsets, which by (ii) implies that $Y$ is a basic open subset. \\


(iii): \customref{THsac}{Recall that $X$ is compact even if $A$ is not Boolean}, so we only have to prove $X$ is Hausdorff. Let $\mathfrak{p},\mathfrak{q}\in X$ be two points such that every open set containing $\mathfrak{p}$ must also contains $\mathfrak{q}$. We are required to prove $\mathfrak{p}=\mathfrak{q}$, which follows from noting that for all $f\in A$, since $X=X_f \coprod X_{1+f}$, we have 
\begin{align*}
f \not \in \mathfrak{p} \iff \mathfrak{p}\in X_f \iff \mathfrak{q}\not \in X_{1+f} \iff 1+f \in \mathfrak{q} \iff f \not\in \mathfrak{q}
\end{align*} 
where the last equivalence follows from the fact \customref{THBr}{$A \quotient \mathfrak{q}\cong  \Z_2$}. 
\end{proof}
A \textbf{partial order}  on a set $L$ is a relation $\leq $ such that:
\begin{enumerate}[label=(\roman*)]
  \item $x \leq x$ for all $x \in L$ \textbf{(Reflexive)}
  \item $x\leq y$ and $y\leq x\implies x=y$ \textbf{(Antisymmetry)}
  \item $x\leq y \leq z\implies x\leq z$ \textbf{(Transitive)} 
\end{enumerate}
A \textbf{lattice} $L$ is then just a partial ordered set such that every pair of element $x,y$ of  $L$ there exists a  \textbf{least upper bound} $x \wedge  y$ and a \textbf{maximal lower bound} $x \vee y$. We say $L$ is a  \textbf{Boolean lattice} if 
\begin{enumerate}[label=(\roman*)]
  \item $L$ has a smallest element and a greatest element, denoted by $0$ and $1$.  
  \item $\wedge $ and $\vee$ are distributive over each other. 
  \item Every $x \in L$ has a unique \textbf{complement} $x'$ such that  $x \wedge  x'=1 $ and $x \vee x'=0$. 
\end{enumerate}
\begin{theorem}
\textbf{(One-to-one correspondence between Boolean lattice and Boolean rings)} Let $L$ be a Boolean lattice. We may define addition and multiplication on $L$ by: 
 \begin{align*}
x+ y \triangleq (x \wedge  y') \vee (x' \wedge  y ) \quad \text{ and }\quad xy \triangleq x \wedge  y 
\end{align*}
so that $L$ becomes a Boolean ring. Conversely, given a Boolean ring $A$, we may define an ordering on $A$ by 
 \begin{align*}
a\leq b \overset{\triangle}{\iff } a=ab
\end{align*}
so that $A$ become a Boolean lattice. The two correspondence are inverse to each other.  
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\begin{corollary}
\textbf{(Stone's theorem for Boolean lattice)} Every Boolean lattice $L$ is isomorphic to the lattice of clopen subsets of some compact Hausdorff space. 
\end{corollary}
\begin{proof}
Let $A$ be the Boolean ring induced by  $L$. It then follows from \customref{THpsB}{properties of spectrum of Boolean ring} that $\operatorname{Spec}(A)$ is the compact Hausdorff space we are looking for. 
\end{proof}
\section{Topological Preliminary}
\begin{equiv_def}
\label{EDnst}
\textbf{(Normal space)} We say a topological space $X$ is  \textbf{normal} if any of the followings hold true: 
\begin{enumerate}[label=(\roman*)]
  \item For every two disjoint closed subsets $A,B \subseteq X$, there exists a disjoint pair of open subsets  $\tilde{A},\tilde{B}\subseteq X $ such that $A \subseteq \tilde{A} $ and $B \subseteq \tilde{B}$. 
  \item For every two disjoint closed subsets $A,B \subseteq X$, there exists some continuous $f:X \rightarrow [0,1]$ such that $f(A)=0$ and $f(B)=1$. 
\end{enumerate}
The proof of their equivalence is called the \textbf{Urysohn's lemma}. 
\end{equiv_def}
\begin{proof}
\href{https://en.wikipedia.org/wiki/Urysohn%27s_lemma}{Wikipedia has a detailed proof}. 
\end{proof}
\begin{theorem}
\textbf{(Compact Hausdorff spaces are normal)} Let $X$ be a compact Hausdorff topological space. Then $X$ is normal. 
\end{theorem}
\begin{proof}
\href{https://math.stackexchange.com/questions/1329866/compact-hausdorff-spaces-are-normal}{See this proof on MSE}. 
\end{proof}
\chapter{Homological Algebra}
\section{Category}
In this note, a \textbf{category} $\mathcal{C} $ is 
\begin{enumerate}[label=(\roman*)]
  \item A \emph{class} $\operatorname{ob}(\mathcal{C} )$ of \textbf{objects}. 
  \item For each two objects  $A,B \in \mathcal{C}  $, a \emph{set} $\operatorname{Hom}(A,B)$ of \textbf{morphism}. 
  \item For every three objects $A,B,C \in \mathcal{C}$, a map 
    \begin{align*}
    \operatorname{Hom}_{\mathcal{C}}(B,C) \times \operatorname{Hom}_{\mathcal{C}}(B,A) \longrightarrow \operatorname{Hom}_{\mathcal{C} }(A,C)
    \end{align*}
    called the \textbf{composition}, 
\end{enumerate}
that satisfies two conditions:  
\begin{enumerate}[label=(\roman*)]
  \item For all $A \in \mathcal{C}$, there exists an \textbf{identity morphism} $\id_A \in \operatorname{End}(A)$ that makes $f=f \circ \id_A$ and $g=\id_A \circ g$ for all $f: A \rightarrow B$ and $g:B \rightarrow C$. \textbf{(Identity)}
  \item $(f \circ g)\circ h=f\circ (g \circ h)$ \textbf{(Associativity)}
\end{enumerate}
Let $\mathcal{C}$ be a category and $f: A \rightarrow B$ and $g: B \rightarrow A$ be two morphisms in $\mathcal{C}$. We say $g$ is a  \textbf{left inverse of} $f$ if 
\begin{align*}
g \circ f = \id _A
\end{align*}
and say $g$ is a \textbf{right inverse of} $f$ if 
 \begin{align*}
f \circ g= \id_B
\end{align*}
If simultaneously $g$ is both a left and right inverse of  $f$, then we say $f$ and $g$ are  \textbf{inverse to each other}, that they are both \textbf{isomorphisms}, and $A,B$ are  \textbf{isomorphic}. \\


Let $\mathcal{C}$ be a category. A morphism $f: A \hookrightarrow  B$ is said to be a \textbf{monomorphism} if for all $g,h: C \rightarrow A$, we have 
\begin{align*}
f \circ g = f \circ h \implies g=h
\end{align*}
A morphism $f: A \twoheadrightarrow   B$ is said to be an \textbf{epimorphism} if for all $g,h:B \rightarrow C$, we have 
\begin{align*}
g \circ f = h \circ  f \implies  g=h
\end{align*}
\begin{theorem}
\textbf{(Basic properties of morphisms)} Let $\mathcal{C}$ be a category and $f: A \rightarrow B$ be a morphism in $\mathcal{C}$. 
\begin{enumerate}[label=(\roman*)]
  \item If $f$ is a right inverse of some  $g:B \rightarrow A$, then $f$ is a monomorphism. 
  \item If $f$ is a left inverse of some  $g:B \rightarrow A$, then $f$ is an epimorphism. 
  \item Compositions of monomorphisms are monomorphisms. 
  \item Compositions of epimorphisms are epimorphisms. 
\end{enumerate}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
Let $B \in \mathcal{C}$. A \textbf{subobject of $B$} is an object $A$ together with a monomorphism  $\diota: A \hookrightarrow  B $, and a \textbf{quotient of $B$} is an object $C$ with an epimorphism $\pi  : B \twoheadrightarrow C $.

\section{Functors and Limits}
Let $\mathcal{C}$ and $\mathcal{D}$ be two categories. A \textbf{covariant functor} (or simply, a \textbf{functor}) $F: \mathcal{C}\rightarrow \mathcal{D}$ is a map of objects $F: \operatorname{ob}(\mathcal{C})\rightarrow \operatorname{ob}(\mathcal{D})$ together with a map of morphisms: 
\begin{align*}
F: \operatorname{Hom}_{\mathcal{C} }(A,B) \longrightarrow \operatorname{Hom}_{\mathcal{D}} (F(A),F(B))
\end{align*}
that satisfies  
\begin{align*}
F(\id _A)=\id_{F(A)}\quad \text{ and }\quad F(g\circ h)= F(g)\circ F(h)
\end{align*}
Let $\mathcal{X}$ be an arbitrary category and $F:\mathcal{X} \rightarrow \mathcal{C}$ a covariant functor. A \textbf{cone to $F$}  is an object $N\in \mathcal{C}$ together with a family of morphisms $\psi_X:N \rightarrow F(X)$ indexed by $\mathcal{X}$ such that for all $f: X \rightarrow Y$, the diagram 
% https://q.uiver.app/#q=WzAsMyxbMSwwLCJOIl0sWzAsMiwiRihYKSJdLFsyLDIsIkYoWSkiXSxbMCwxLCJcXHBzaV9YIiwyXSxbMCwyLCJcXHBzaV9ZIl0sWzEsMiwiRihmKSJdXQ==
\[\begin{tikzcd}
	& N \\
	\\
	{F(X)} && {F(Y)}
	\arrow["{\psi_X}"', from=1-2, to=3-1]
	\arrow["{\psi_Y}", from=1-2, to=3-3]
	\arrow["{F(f)}", from=3-1, to=3-3]
\end{tikzcd}\]
commutes. A cone $(\lim F,\pfi )$ to $F$ is said to satisfy the \textbf{universal property of limit} if for all cones $(N,\psi )$ to $F$ there exists a unique morphism $u: N \rightarrow \lim F$ such that $\psi_X= \pfi _X \circ u$ for all $X \in \mathcal{X} $. Therefore, given a limit $(\lim F, \psi)$, we have a commutative diagram: 
% https://q.uiver.app/#q=WzAsNCxbMSwyLCJcXGxpbSBGIl0sWzAsNCwiRihYKSJdLFsyLDQsIkYoWSkiXSxbMSwwLCJOIl0sWzAsMSwiXFxwaGlfWCIsMl0sWzAsMiwiXFxwaGlfWSJdLFsxLDIsIkYoZikiXSxbMywxLCJcXHBzaV9YIiwyLHsiY3VydmUiOjN9XSxbMywyLCJcXHBzaV9ZIiwwLHsiY3VydmUiOi0zfV0sWzMsMCwidSIsMSx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
\[\begin{tikzcd}
	& N \\
	\\
	& {\lim F} \\
	\\
	{F(X)} && {F(Y)}
	\arrow["u"{description}, dashed, from=1-2, to=3-2]
	\arrow["{\psi_X}"', curve={height=18pt}, from=1-2, to=5-1]
	\arrow["{\psi_Y}", curve={height=-18pt}, from=1-2, to=5-3]
	\arrow["{\pfi _X}"', from=3-2, to=5-1]
	\arrow["{\pfi _Y}", from=3-2, to=5-3]
	\arrow["{F(f)}", from=5-1, to=5-3]
\end{tikzcd}\]
A \textbf{directed set} is a partially ordered set in which every two elements have an upper bound. Let $I$ be an directed set and $\mathcal{C}$ a category. By an \textbf{inverse system in} $\mathcal{C}$, we mean a collection of object $\set{A_i}$ in $\mathcal{C}$ indexed by $I$ together with each relation $i \leq j$ (\emph{note the order}) a morphism $f_{ij}:A_j \rightarrow A_i$ in $\mathcal{C}$ such that: 
\begin{enumerate}[label=(\roman*)]
  \item $f_{ii}$ are the identities on $A_i$.  
  \item $f_{ik}=f_{ij}\circ f_{jk}$  for all $i\leq j \leq k$
\end{enumerate}
Clearly, an inverse system in $\mathcal{C}$ itself forms a category $\mathcal{I}$ the obvious way, and we have an obvious covariant functor $F:\mathcal{I}\rightarrow \mathcal{C}$. The limit of $F$ is then called the  \textbf{inverse limit of $\set{A_i}$} denoted by $\inverselimit A_i$ and $f_i:\inverselimit A_i \rightarrow A_i$.\\ 

 Let $\mathcal{X}$ be an arbitrary category and $F:\mathcal{X} \rightarrow \mathcal{C}$ a covariant functor. A \textbf{co-cone to} $F$ is an object $N \in \mathcal{C}$ together with a family of morphisms $\psi_X:F(X)\rightarrow N$ indexed by $\mathcal{X}$ such that for all $f: X \rightarrow Y$, the diagram 
% https://q.uiver.app/#q=WzAsMyxbMSwyLCJOIl0sWzAsMCwiRihYKSJdLFsyLDAsIkYoWSkiXSxbMSwwLCJcXHBzaV9YIiwyXSxbMiwwLCJcXHBzaV9ZIl0sWzIsMSwiRihmKSIsMl1d
\[\begin{tikzcd}
	{F(X)} && {F(Y)} \\
	\\
	& N
	\arrow["{\psi_X}"', from=1-1, to=3-2]
	\arrow["{F(f)}"', from=1-1, to=1-3]
	\arrow["{\psi_Y}", from=1-3, to=3-2]
\end{tikzcd}\]
commute. A co-cone $(\colim F,\pfi )$ to $F$ is said to satisfy the \textbf{universal property of colimit} if for all co-cones $(N,\psi )$ to $F$ there exists a unique morphism $u: \colim F \rightarrow N$ such that $\psi_X= u \circ \pfi _X$ for all $X \in \mathcal{X} $. Therefore, given a colimit $(\colim F, \psi)$, we have a commutative diagram: 
% https://q.uiver.app/#q=WzAsNCxbMSwyLCJcXGNvbGltIEYiXSxbMCwwLCJGKFgpIl0sWzIsMCwiRihZKSJdLFsxLDQsIk4iXSxbMSwwLCJcXHBoaV9YIl0sWzIsMCwiXFxwaGlfWSIsMl0sWzIsMSwiRihmKSIsMl0sWzEsMywiXFxwc2lfWCIsMix7ImN1cnZlIjozfV0sWzIsMywiXFxwc2lfWSIsMCx7ImN1cnZlIjotM31dLFswLDMsInUiLDEseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	{F(X)} && {F(Y)} \\
	\\
	& {\colim F} \\
	\\
	& N
	\arrow["{\pfi _X}", from=1-1, to=3-2]
	\arrow["{\psi_X}"', curve={height=18pt}, from=1-1, to=5-2]
	\arrow["{F(f)}"', from=1-1, to=1-3]
	\arrow["{\pfi_Y}"', from=1-3, to=3-2]
	\arrow["{\psi_Y}", curve={height=-18pt}, from=1-3, to=5-2]
	\arrow["u"{description}, dashed, from=3-2, to=5-2]
\end{tikzcd}\]
Let $I$ be a directed set. By a \textbf{directed system in} $\mathcal{C}$, we mean a collection of object $\set{A_i}$ in $\mathcal{C}$ indexed by $I$ together with each relation $i \leq j$ (again, \emph{note the order}) a morphism $f_{ij}:A_i \rightarrow A_j$ in $\mathcal{C}$ such that: 
\begin{enumerate}[label=(\roman*)]
  \item $f_{ii}$ are the identities on $A_i$.  
  \item $f_{ik}=f_{jk}\circ f_{ij}$  for all $i\leq j \leq k$
\end{enumerate}
Clearly, a directed system in $\mathcal{C}$ forms a category $\mathcal{D}$ the obvious way, and we have an obvious covariant functor $F:\mathcal{D}\rightarrow \mathcal{C}$. The colimit of $F$ is then called the  \textbf{direct limit of $\set{A_i}$} denoted by $\directlimit A_i$ and $f_i: A_i \rightarrow \directlimit A_i$. 
\begin{theorem}
\textbf{(Construction of direct limit in familiar categories)} Let $A$ be a ring, $I$ a directed set, and $\set{M_i, \phi_{ij}}$ a directed system of $A$-modules. One way to construct its direct limit is to first define the underlying set as: 
\begin{align*}
\directlimit M_i \triangleq \bigsqcup_i M_i \quotient \sim  
\end{align*}
where $x_i \in M_i$ and $x_j \in M_j$ are equivalence when: 
\begin{align*}
x_i \sim  x_j \overset{\triangle}{\iff } \phi_{ik}(x_i)=\phi_{jk}(x_j),\quad \text{ for some }k \geq i,j
\end{align*}
Addition is well-defined by 
\begin{align*}
[x_i]+ [x_j] \triangleq [\phi_{ik}(x_i)+\phi_{jk}(x_j)],\quad \text{ for any }k \geq i,j
\end{align*}
while scalar multiplication is well-defined by 
 \begin{align*}
c[x_i]\triangleq [cx_i]
\end{align*}
Lastly, the canonical morphism $\phi_i : M_i \rightarrow M$ maps elements to their equivalence class. One can now check that our construction in fact also shows that direct limit exists in $\mathbf{Set},\mathbf{Gp}$, and $\mathbf{Ab}$. Moreover, in $\mathbf{Ring}$ and $\mathbf{Alg}_A$, direct limit also exists if we define vector multiplication the same way we define addition.  
\end{theorem}
\begin{proof}
Routine. 
\end{proof}





\section{Additive Categories}
Let $A_i$ be a collection of objects in $\mathcal{C}$. Clearly, we can make it a category $\mathcal{J}$ by requiring it to have only the identity morphisms, and doing such, we have an obvious covariant functor $F:\mathcal{J}\rightarrow \mathcal{C}$. Its \emph{limit} is called the  \textbf{product of $A_i$} denoted by $\prod A_i$, with canonical morphism $p_i : \prod A_i \rightarrow A_i$ called the \textbf{projection map}, and its \emph{colimit} is called the \textbf{coproduct of $A_i$} denoted by $\coprod A_i$, whose canonical morphism $A_i \rightarrow \coprod A_i$ are often called the \textbf{coprojection map}. 
\begin{theorem}
\textbf{(Existence of products and coproduct in familiar categories)} Let $A$ be a ring. Product and coproduct always exists in $\mathbf{Set}$, in the form of Cartesian product and disjoint union. They also exists in $\mathbf{Mod}_A$, in the form of direct product and direct sum. Note that the underlying set of module direct sum in general have nothing to do with their disjoint union.  
\end{theorem}
\begin{proof}
Routine. Let $u(n)_i \triangleq \psi_i (n)$.  
\end{proof}
An \textbf{initial object} $I \in \mathcal{C}$ is an object such that for all $A \in \mathcal{C}$, there exists exactly one morphism from $I$ to  $A$. A \textbf{terminal object} $T\in \mathcal{C}$ is an object such that for all $A\in \mathcal{C}$, there exists exactly one morphism from $A$ to  $T$. Clearly, initial objects and terminal objects, even though may not always exists, are unique up to isomorphisms. A \textbf{zero object} is an object that is both an initial and terminal object. \\ 

An \textbf{additive category} $\mathcal{C} $ is a category such that $\Hom  (A,B)$ is an abelian group (thus a set) for all $A, B \in \mathcal{C}$ that satisfies 
\begin{align*}
  (f_1+ f_2 )\circ g= f_1 \circ g+ f_2 \circ g \quad \text{ and }\quad f \circ (g_1 +g_2)= f \circ g_1 + f \circ g_2
\end{align*}

and 
\begin{enumerate}[label=(\roman*)]
\item $\mathcal{C}$ admits zero object.  
\item $\mathcal{C}$ admits finite coproducts.  
\end{enumerate}
\begin{theorem}
\textbf{(Basic properties of additive categories)} Let $\mathcal{C}$ be an additive category. Then 
\begin{enumerate}[label=(\roman*)]
  \item Let $A$ and $B$ be a pair of objects in  $\mathcal{C}$, and $Z$ be a zero object in  $\mathcal{C}$ with  
\begin{align*}
A \overset{f}{\longrightarrow }   Z \overset{g}{\longrightarrow } B
\end{align*}
Then $g\circ f$ is the zero in the abelian group $\Hom (A,B)$.  
  \item Let $A_1, \dots ,A_n \in \mathcal{C}$. If for each $i$ we use the universal property of coproduct to define $p_i:\coprod A_i\rightarrow A_i$ by 
\begin{align*}
p_i \circ \diota_j \triangleq \begin{cases}
  \id_{A_i}& \text{ if $j=i$ }\\
  0& \text{ if $j\neq i$ }
\end{cases}  
\end{align*}
then $p_i$ satisfies the universal properties of product. 
\end{enumerate}
\end{theorem}
\begin{proof}
  (i): To prove that $g \circ f$ is the zero in the abelian group $\Hom (A,B)$, we only have to prove that it is idempotent, which follows from 
\begin{align*}
  (g \circ f)+ (g \circ f)= g \circ (f+f)= g \circ f
\end{align*}
(ii): The first step is to use universal property to check that $\sum \diota_i \circ p_i= \id _{\coprod A_i} $. The proof then follows from using the first step to check that given $f_i: X \rightarrow A_i$, indeed, $\sum \diota_i \circ f_i : X \rightarrow \coprod A_i $ is the unique map that makes the diagram 
\[\begin{tikzcd}
	& X \\
	\\
	& \coprod A_i \\
	\\
	{A_i} && 
	\arrow[ dashed, from=1-2, to=3-2]
	\arrow["{f_i}"', curve={height=18pt}, from=1-2, to=5-1]
	\arrow["{p_i}"', from=3-2, to=5-1]
\end{tikzcd}\]
commutes. 
\end{proof}
I would say that (i) above is very crucial. We get $g \circ f+ h=h$ only from the requirement that $\Hom  (A,B)$ is a group and bilinearity of $\Hom $ functor.
\section{Equalizer and Coequalizer}
Let $A,B \in \mathcal{C}$ and $f$ and  $g$ be morphism from  $A$ to  $B$. Again, they form a category  $\mathcal{I}$: 
% https://q.uiver.app/#q=WzAsMixbMCwwLCJBIl0sWzIsMCwiQiJdLFswLDEsImYiLDAseyJvZmZzZXQiOi0xfV0sWzAsMSwiZyIsMix7Im9mZnNldCI6MX1dXQ==
\[\begin{tikzcd}
	A && B
	\arrow["f", shift left, from=1-1, to=1-3]
	\arrow["g"', shift right, from=1-1, to=1-3]
\end{tikzcd}\]
whose limit is called the \textbf{equalizer} $\operatorname{eq}(f,g)$ and whose colimit is called the \textbf{coequalizer} $\operatorname{coeq}(f,g)$. Clearly, if the equalizer exists and the canonical morphism from $\operatorname{eq}(f,g)$ to $A$ is  $h$, then we must have $f \circ h=g \circ h$, since they are both the morphism of the right hand side arrow of the commutative diagram: 
% https://q.uiver.app/#q=WzAsMyxbMCwyLCJBIl0sWzIsMiwiQiJdLFsxLDAsIlxcYnVsbGV0Il0sWzAsMSwiZiIsMCx7Im9mZnNldCI6LTF9XSxbMCwxLCJnIiwyLHsib2Zmc2V0IjoxfV0sWzIsMCwiaCIsMl0sWzIsMV1d
\[\begin{tikzcd}
	& \operatorname{eq}(f,g) \\
	\\
	A && B
	\arrow["h"', from=1-2, to=3-1]
	\arrow[from=1-2, to=3-3]
	\arrow["f", shift left, from=3-1, to=3-3]
	\arrow["g"', shift right, from=3-1, to=3-3]
\end{tikzcd}\]
Similar statement holds true for coequalizer. If the canonical morphism from $B$ to $\operatorname{coeq}(f,g)$ is $k$, then the canonical morphism from $A$ to  $\operatorname{coeq}(f,g)$ is $k\circ g=k \circ f$ 
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJBIl0sWzIsMCwiQiJdLFsxLDIsIlxcYnVsbGV0Il0sWzAsMSwiZiIsMCx7Im9mZnNldCI6LTF9XSxbMCwxLCJnIiwyLHsib2Zmc2V0IjoxfV0sWzEsMiwiaCJdLFswLDJdXQ==
\[\begin{tikzcd}
	A && B \\
	\\
	& \operatorname{coeq}(f,g)
	\arrow["f", shift left, from=1-1, to=1-3]
	\arrow["g"', shift right, from=1-1, to=1-3]
	\arrow[from=1-1, to=3-2]
	\arrow["k", from=1-3, to=3-2]
\end{tikzcd}\]
\begin{theorem}
\label{THeac}
\textbf{(Equalizer and coequalizer in familiar categories)} Let $R$ be a ring. In $\mathbf{Set},\mathbf{Gp},\mathbf{Ab},\mathbf{Ring}$, and $\mathbf{Mod}_R$, the equalizer of two morphisms $f,g:A \rightarrow B$ is simply 
\begin{align*}
\operatorname{eq}(f,g)= \set{a \in A: f(a)=g(a)}
\end{align*}
In $\mathbf{Gp}$, their coequalizer is the quotient 
\begin{align*}
\operatorname{coeq}(f,g)= B \quotient \operatorname{ncl}_B\left(\set{f(a)g(a)^{-1}\in B: a\in A}\right)
\end{align*}
In $\mathbf{Ring}$, their coequalizer is 
\begin{align*}
\operatorname{coeq}(f,g)= B \quotient \mathfrak{b}
\end{align*}
where $\mathfrak{b}\trianglelefteq B$ is the ideal generated by $\set{f(a)-g(a)\in B : a \in A}$. In $\mathbf{Ab}$ and $\mathbf{Mod}_R$, we don't have to take normal closure. Their coequalizer is then  
\begin{align*}
\operatorname{coeq}(f,g) = \operatorname{Coker}(f-g)
\end{align*}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\textbf{(Canonical morphism of equalizer is a monomorphism, and the canonical morphism of coequalizer is an epimorphism)} Let $\mathcal{C}$ be a category in which we have a diagram 
% https://q.uiver.app/#q=WzAsMixbMCwwLCJBIl0sWzIsMCwiQiJdLFswLDEsImYiLDAseyJvZmZzZXQiOi0xfV0sWzAsMSwiZyIsMix7Im9mZnNldCI6MX1dXQ==
\[\begin{tikzcd}
	A && B
	\arrow["f", shift left, from=1-1, to=1-3]
	\arrow["g"', shift right, from=1-1, to=1-3]
\end{tikzcd}\]
If the equalizer $\operatorname{eq}(f,g)$ exists, then the canonical morphism $h:\operatorname{eq}(f,g) \rightarrow A$ is a monomorphism. If the coequalizer $\operatorname{coeq}(f,g)$ exists, then the canonical morphism $k :B \rightarrow \operatorname{coeq}(k)$ is an epimorphism.  
% https://q.uiver.app/#q=WzAsNCxbMiwwLCJBIl0sWzQsMCwiQiJdLFswLDAsIlxcYnVsbGV0Il0sWzYsMCwiXFxidWxsZXQiXSxbMCwxLCJmIiwwLHsib2Zmc2V0IjotMX1dLFswLDEsImciLDIseyJvZmZzZXQiOjF9XSxbMiwwXSxbMSwzXV0=
\[\begin{tikzcd}
	\operatorname{eq}(f,g) && A && B && \operatorname{coeq}(f,g)
	\arrow[hook, from=1-1, to=1-3]
	\arrow["f", shift left, from=1-3, to=1-5]
	\arrow["g"', shift right, from=1-3, to=1-5]
	\arrow[two heads ,from=1-5, to=1-7]
\end{tikzcd}\]
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\section{Kernel and Image}
In an additive category $\mathcal{C}$, the \textbf{kernel} and \textbf{cokernel} of a morphism $f: A \rightarrow B$ is then defined by 
\begin{align*}
\operatorname{ker}(f)\triangleq \operatorname{eq}(f,0)\quad \text{ and }\quad \operatorname{coker}(f)\triangleq \operatorname{coeq}(f,0)
\end{align*}
\begin{theorem}
\textbf{(Kernel and cokernel in familiar categories)}  Let $R$ be a ring. Example of additive categories includes $\mathbf{Ab}$ and $\mathbf{Mod}_R$, excluding $\mathbf{Set},\mathbf{Gp}$, and $\mathbf{Ring}$. Therefore, kernel and cokernel exist in $\mathbf{Ab}$ and $\mathbf{Mod}_R$ in the usual form. 
\end{theorem}
\begin{proof}
Routine. See \customref{THeac}{how we construct equalizer and coequalizer in familiar categories}. 
\end{proof}
Note that the notion of kernel and cokernel can be generalized to categories that are not additive, as long as the category admits \href{https://en.wikipedia.org/wiki/Zero_morphism}{zero morphism}. Therefore, even though $\mathbf{Gp}$ isn't additive due to the lack of abelian group structure on Hom-set, $\mathbf{Gp}$ still have categorical kernel. On the other hand, $\mathbf{Ring}$ isn't additive and there isn't a good way to define zero morphism in it, so $\mathbf{Ring}$ has no categorical kernel. Indeed, the "kernel" of a group homomorphism forms a group, and the "kernel" of a ring homomorphism don't always form a ring.   \\










Let $\mathcal{C}$ be a category in which we have a diagram: 
% https://q.uiver.app/#q=WzAsMyxbMCwyLCJBXzEiXSxbMiwyLCJBXzIiXSxbMSwwLCJCIl0sWzIsMSwiZl8yIl0sWzIsMCwiZl8xIiwyXV0=
\[\begin{tikzcd}
	& B \\
	\\
	{A_1} && {A_2}
	\arrow["{f_1}"', from=1-2, to=3-1]
	\arrow["{f_2}", from=1-2, to=3-3]
\end{tikzcd}\]
The diagram clearly forms a category $\mathcal{I}$ with an obvious covariant functor $F: \mathcal{I}\rightarrow \mathcal{C}$. The colimit of this covariant functor is then called the \textbf{fiber coproduct} $A_1 +_B A_2$  \textbf{over} $B$, or by some author, the \textbf{pushout of $A_1$ and  $A_2$ over  $B$}
% https://q.uiver.app/#q=WzAsNCxbMCwyLCJBXzEiXSxbMiwyLCJBXzIiXSxbMSwwLCJCIl0sWzEsNCwiQV8xICtfQiBBXzIiXSxbMiwxLCJmXzIiXSxbMiwwLCJmXzEiLDJdLFswLDMsIlxcZGlvdGFfMSIsMl0sWzEsMywiXFxkaW90YV8yIl0sWzIsM11d
\[\begin{tikzcd}
	& B \\
	\\
	{A_1} && {A_2} \\
	\\
	& {A_1 +_B A_2}
	\arrow["{f_1}"', from=1-2, to=3-1]
	\arrow["{f_2}", from=1-2, to=3-3]
	\arrow[from=1-2, to=5-2]
	\arrow["{\diota_1}"', from=3-1, to=5-2]
	\arrow["{\diota_2}", from=3-3, to=5-2]
\end{tikzcd}\]
\begin{theorem}
\label{THeof}
\textbf{(Existence of fiber coproduct in familiar categories)} Let $R$ be a ring. In $\mathbf{Gp}$, the fiber coproduct of $f_1: B \rightarrow A_1$ and $f_2:B \rightarrow A_2$ is 
\begin{align*}
A_1 +_B A_2 = A_1 * A_2 \quotient \operatorname{ncl}_{A_1 * A_2} \left( \set{f_1(b)f_2(b)^{-1}\in A_1 * A_2:b \in B} \right)
\end{align*}
where $A_1*A_2$ is the  \textbf{free product} defined by presentation 
\begin{align*}
A_1 * A_2 \triangleq  \langle S_{A_1} \cup    S_{A_2}\mid R_{A_1}\cup  R_{A_2}\rangle 
\end{align*}
given that 
\begin{align*}
A_1= \langle S_{A_1}\mid  R_{A_1}\rangle  \quad \text{ and }\quad A_2 = \langle S_{A_2}\mid  R_{A_2}\rangle 
\end{align*}
In $\mathbf{Ab}$ and $\mathbf{Mod}_R$, their fiber coproduct can be constructed as a quotient of their direct product    
\begin{align*}
A_1 +_B A_2= A_1 \times A_2 \quotient \set{(f_1(b),-f_2(b)) \in A_1 \times A_2: b \in B}
\end{align*}
In $\mathbf{Ring}$, their fiber coproduct is their tensor product as $B$-algebras: 
\begin{align*}
A_1 +_B A_2 = A_1 \otimes_B A_2
\end{align*}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
Let $f: A \rightarrow B$ be a morphism. Suppose the fiber coproduct $B+_A B $ exists: 
% https://q.uiver.app/#q=WzAsNCxbMCwyLCJCIl0sWzIsMiwiQiJdLFsxLDAsIkEiXSxbMSw0LCJCICtfQSBCIl0sWzIsMSwiZiJdLFsyLDAsImYiLDJdLFswLDMsIngiLDJdLFsxLDMsIngiXSxbMiwzXV0=
\[\begin{tikzcd}
	& A \\
	\\
	B && B \\
	\\
	& {B +_A B}
	\arrow["f"', from=1-2, to=3-1]
	\arrow["f", from=1-2, to=3-3]
	\arrow[from=1-2, to=5-2]
	\arrow["\diota_1 "', from=3-1, to=5-2]
	\arrow["\diota_2 ", from=3-3, to=5-2]
\end{tikzcd}\]
Then the \textbf{image} of $f:A \rightarrow B$ is then defined to be, if exists, the equalizer  $\operatorname{eq}(\diota_1,\diota_2)$ of the two canonical morphism of the fiber coproduct 
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJcXG9wZXJhdG9ybmFtZXtlcX0oeCx4KSJdLFsyLDAsIkIiXSxbNCwwLCJCK19BIEIiXSxbMCwxLCJqIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XSxbMSwyLCJ4IiwyLHsib2Zmc2V0IjoxfV0sWzEsMiwieCIsMCx7Im9mZnNldCI6LTF9XV0=
\[\begin{tikzcd}
	{\operatorname{eq}(\diota_1,\diota_2 )} && B && {B+_A B}
	\arrow["j", hook, from=1-1, to=1-3]
	\arrow["\diota_1 "', shift right, from=1-3, to=1-5]
	\arrow["\diota_2 ", shift left, from=1-3, to=1-5]
\end{tikzcd}\]
which comes with a canonical monomorphism $j:\operatorname{eq}(\diota_1 , \diota_2  )\hookrightarrow  B$ and induce by universal property of equalizer a unique morphism $\ld : A \rightarrow \operatorname{eq}(\diota_1,\diota_2 )$ that makes the diagram 
% https://q.uiver.app/#q=WzAsNSxbMiwyLCJCIl0sWzQsMiwiQiJdLFszLDAsIkEiXSxbMyw0LCJCICtfQSBCIl0sWzAsMiwieCJdLFsyLDEsImYiXSxbMiwwLCJmIiwyXSxbMCwzLCJ4IiwyXSxbMSwzLCJ4Il0sWzQsMCwiaiIsMl0sWzIsNCwiXFxsZCIsMl1d
\[\begin{tikzcd}
	&&& A \\
	\\
	\operatorname{Im}(f)\triangleq \operatorname{eq}(\diota_1,\diota_2  ) && B && B \\
	\\
	&&& {B +_A B}
	\arrow[dashed,"\ld"', from=1-4, to=3-1]
	\arrow["f"', from=1-4, to=3-3]
	\arrow["f", from=1-4, to=3-5]
	\arrow[hook,"j"', from=3-1, to=3-3]
	\arrow["\diota_1 "', from=3-3, to=5-4]
	\arrow["\diota_2 ", from=3-5, to=5-4]
\end{tikzcd}\]

\begin{theorem}
  \textbf{(Images in familiar categories)} Let $R$ be a ring. Image exists in $\mathbf{Gp},\mathbf{Ab},\mathbf{Ring}$, and $\mathbf{Mod}_R$ in the usual form. In other word, given a homomorphism $f: A \rightarrow B$ in any of these categories, the usual image $f(A)$ together with the obvious map $f(A)\rightarrow B$ indeed satisfies the universal property of equalizer $\operatorname{eq}(\diota_1,\diota_2)\hookrightarrow B$ in which $\diota_1,\diota_2$ are the canonical morphisms of the fiber coproduct $B+_A B$, which \customref{THeof}{we have proved indeed exists}.
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\begin{theorem}
\label{THmeia}
\textbf{(Monomorphisms and epimorphisms in abelian categories)} Let $f$ be a morphism in an additive category.  
\begin{enumerate}[label=(\roman*)]
  \item If $f$ admits kernel, then $f$ is a monomorphism if and only if $\operatorname{ker}(f)=0$. 
  \item If $f$ admits cokernel, then $f$ is an epimorphism if and only if $\operatorname{Coker}(f)=0$. 
\end{enumerate}
\end{theorem}
\begin{proof}

\end{proof}
\begin{theorem}
\textbf{(Existence of images and coimage in abelian categories)} Let $\mathcal{C}$ be an additive category that admits both kernel and cokernel. Then for all morphism $f: A \rightarrow B$ in  $\mathcal{C}$, its image and coimage exists:
\begin{align*}
\operatorname{Im}(f)\cong  \operatorname{ker}(B \rightarrow \operatorname{Coker}(f))\quad \text{ and }\quad \operatorname{Coim}(f)\cong \operatorname{Coker}(\operatorname{ker}(f)\rightarrow A)
\end{align*}
\end{theorem}
\begin{proof}

\end{proof}
\section{Abelian Category and Exact Sequences}
Let $\mathcal{C}$ be a category in which we have a diagram: 
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJBXzEiXSxbMiwwLCJBXzIiXSxbMSwyLCJCIl0sWzEsMiwiZl8yIl0sWzAsMiwiZl8xIiwyXV0=
\[\begin{tikzcd}
	{A_1} && {A_2} \\
	\\
	& B
	\arrow["{f_1}"', from=1-1, to=3-2]
	\arrow["{f_2}", from=1-3, to=3-2]
\end{tikzcd}\]
Clearly, this form a category  $\mathcal{I}$ with an obvious covariant functor $F:\mathcal{I}\rightarrow \mathcal{C}$. The limit of this covariant functor is then called the \textbf{fiber product} $A_1 \times_B A_2$ \textbf{over} $B$, or by some author, the \textbf{pullback of $A_1$ and $A_2$ over  $B$}.
% https://q.uiver.app/#q=WzAsNCxbMCwyLCJBXzEiXSxbMiwyLCJBXzIiXSxbMSw0LCJCIl0sWzEsMCwiQV8xXFx0aW1lc19CIEFfMiJdLFsxLDIsImZfMiJdLFswLDIsImZfMSIsMl0sWzMsMCwicF8xIiwyXSxbMywxLCJwXzIiXSxbMywyXV0=
\[\begin{tikzcd}
	& {A_1\times_B A_2} \\
	\\
	{A_1} && {A_2} \\
	\\
	& B
	\arrow["{p_1}"', from=1-2, to=3-1]
	\arrow["{p_2}", from=1-2, to=3-3]
	\arrow[from=1-2, to=5-2]
	\arrow["{f_1}"', from=3-1, to=5-2]
	\arrow["{f_2}", from=3-3, to=5-2]
\end{tikzcd}\]
\begin{theorem}
\textbf{(Existence of fiber product in familiar categories)} Let $R$ be a ring. In $\mathbf{Set},\mathbf{Gp},\mathbf{Ab},\mathbf{Ring}$, and $\mathbf{Mod}_R$, the fiber product of $f_1:A_1\rightarrow B$ and $f_2: A_2 \rightarrow B$ can be constructed as a subobject of the product $A_1 \times A_2$ by 
\begin{align*}
A_1 \times_B A_2 =\set{(a_1,a_2)\in A_1 \times A_2: f_1(a_1)=f_2(a_2)}
\end{align*}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
The \textbf{coimage} of a morphism $f:A \rightarrow B$ is then defined to be the coequalizer of the two canonical morphism in the fiber product $A \times_B A$. 
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJCIl0sWzIsMCwiQitfQSBCIl0sWzQsMCwiXFxidWxsZXQiXSxbMCwxLCJ4IiwyLHsib2Zmc2V0IjoxfV0sWzAsMSwieCIsMCx7Im9mZnNldCI6LTF9XSxbMSwyLCJzIiwwLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoiZXBpIn19fV1d
\[\begin{tikzcd}
	A && {A+_B A} && \operatorname{coeq}(p_1,p_2)
	\arrow["p_1"', shift right, from=1-1, to=1-3]
	\arrow["p_2", shift left, from=1-1, to=1-3]
	\arrow["s", two heads, from=1-3, to=1-5]
\end{tikzcd}\]
which comes with a canonical epimorphism $s:A \rightarrow \operatorname{coeq}(p_1,p_2)$ for coequalizer:  
% https://q.uiver.app/#q=WzAsNSxbMSwwLCJBXFx0aW1lc19CIEEiXSxbMCwyLCJBIl0sWzIsMiwiQSJdLFsxLDQsIkIiXSxbNCwyLCJzIl0sWzAsMSwicF8xIiwyXSxbMCwyLCJwXzIiXSxbMSwzLCJmIiwyXSxbMiwzLCJmIl0sWzIsNCwicyIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dXQ==
\[\begin{tikzcd}
	& {A\times_B A} \\
	\\
	A && A && \operatorname{coeq}(p_1,p_2)\triangleq \operatorname{coim}(f) \\
	\\
	& B
	\arrow["{p_1}"', from=1-2, to=3-1]
	\arrow["{p_2}", from=1-2, to=3-3]
	\arrow["f"', from=3-1, to=5-2]
	\arrow["s", two heads, from=3-3, to=3-5]
	\arrow["f", from=3-3, to=5-2]
\end{tikzcd}\]
Let morphism $f: A \rightarrow B$ admits both image and coimage, therefore both $A \times_B A$ and $B +_A B$ exists. Because $\diota_1 \circ f = \diota_2\circ f $ by definition of fiber coproduct, there exists a unique morphism $\ld : A \rightarrow \operatorname{Im}(f)$ such that $f=\ld  \circ j$ by universal property of image 
% https://q.uiver.app/#q=WzAsNixbMCwwLCJBXFx0aW1lc19CIEEiXSxbMSwwLCJBIl0sWzIsMCwiQiJdLFszLDAsIkIrX0EgQiJdLFsxLDIsIlxcb3BlcmF0b3JuYW1le2NvZXF9KHBfMSxwXzIpPVxcb3BlcmF0b3JuYW1le2NvaW19KGYpIl0sWzIsMiwiXFxvcGVyYXRvcm5hbWV7ZXF9KFxcZGlvdGFfMSxcXGRpb3RhXzIpPVxcb3BlcmF0b3JuYW1le0ltfShmKSJdLFswLDEsInBfMiIsMix7Im9mZnNldCI6MX1dLFswLDEsInBfMSIsMCx7Im9mZnNldCI6LTF9XSxbMiwzLCJcXGRpb3RhXzIiLDIseyJvZmZzZXQiOjF9XSxbMiwzLCJcXGRpb3RhXzEiLDAseyJvZmZzZXQiOi0xfV0sWzEsMiwiZiJdLFsxLDQsInMiLDIseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJlcGkifX19XSxbNSwyLCIiLDIseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFsxLDUsIlxcbGQiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	{A\times_B A} & A & B & {B+_A B} \\
	\\
	& {\operatorname{coeq}(p_1,p_2)=\operatorname{coim}(f)} & {\operatorname{eq}(\diota_1,\diota_2)=\operatorname{Im}(f)}
	\arrow["{p_2}"', shift right, from=1-1, to=1-2]
	\arrow["{p_1}", shift left, from=1-1, to=1-2]
	\arrow["f", from=1-2, to=1-3]
	\arrow["s"', two heads, from=1-2, to=3-2]
	\arrow["\ld"', dashed, from=1-2, to=3-3]
	\arrow["{\diota_2}"', shift right, from=1-3, to=1-4]
	\arrow["{\diota_1}", shift left, from=1-3, to=1-4]
	\arrow["j"',hook, from=3-3, to=1-3]
\end{tikzcd}\]
Now, because by definition of fiber product we have  $f\circ p_1=f \circ p_2$, we know $j \circ \ld  \circ p_1= j \circ \ld \circ p_2$ which by monicity of $j$ implies  $\ld  \circ p_1=\ld \circ p_2$, which by universal property of fiber product implies the existence and uniqueness of some morphism $u:\operatorname{coim}(f)\rightarrow \operatorname{Im}(f)$ that makes the diagram above commutes. \\

We say $f$ is \textbf{strict} if such $u$ is an isomorphism. We say an \emph{additive} category $\mathcal{C}$ is an \textbf{abelian category} if 
\begin{enumerate}[label=(\roman*)]
  \item every morphism admits kernel and a cokernel. 
  \item every morphism is strict.  
\end{enumerate}
Let $f:A \rightarrow B$ and $g: B \rightarrow C$ be morphisms in an abelian category such that $g \circ f=0$. Because $\ld =u \circ s$ and because  $u$ is an epimorphism by requirement of strictness of $f$ and, \customref{THmeia}{we know $\ld $ is also an epimorphism}. Then since 
\begin{align*}
 0 \circ \ld=0=g \circ f= g \circ j \circ \ld  
\end{align*}
We know $g \circ j=0$. Therefore, by universal property of kernel, there exists a unique morphism $\alpha : \operatorname{Im}(f)\rightarrow \operatorname{ker}(g)$ that makes $\beta = j \circ \alpha $, where $\beta :\operatorname{ker}(g) \hookrightarrow B$ is the canonical morphism of $\operatorname{ker}(g)$. The chain \textbf{homology} is then defined by $\operatorname{Coker}(\alpha )$, and we say the sequence is exact at this point if $\operatorname{Coker}(\alpha )=0$.   
\section{Lemmas for Abelian Categories}
\begin{theorem}
\label{THsl}
\textbf{(Splitting lemma)} Let  
\begin{align*}
0 \longrightarrow A  \overset{q}{\longhookrightarrow } B \overset{r}{\longtwoheadrightarrow   } C \longrightarrow 0
\end{align*}
be a short exact sequence in an abelian category $\mathcal{C}$. Then the followings are equivalent: 
\begin{enumerate}[label=(\roman*)]
  \item There exists a morphism $t: B \rightarrow A$ such that $t \circ  q= \id _A$. \textbf{(Left Splits)}    
  \item There exists a morphism $u:C \rightarrow B$ such that $r \circ u = \id_C$. \textbf{(Right Splits)} 
  \item There exists an isomorphism $h:B \rightarrow A \oplus  C$ such that $h \circ  q:A \rightarrow A \oplus C$ is the natural injection  and $r \circ h^{-1}: A \oplus C \rightarrow C$ is the natural projection.  \textbf{(Direct sum)}
\end{enumerate}
\end{theorem}
\begin{proof}

\end{proof}
\begin{theorem}
\textbf{(Snake lemma for modules)} Given a commutative diagram of $A$-modules: 
% https://q.uiver.app/#q=WzAsMTAsWzIsMCwiTSciXSxbMCwwLCIwIl0sWzQsMCwiTSJdLFs2LDAsIk0nJyJdLFs4LDAsIjAiXSxbMCwyLCIwIl0sWzIsMiwiTiciXSxbNCwyLCJOIl0sWzYsMiwiTicnIl0sWzgsMiwiMCJdLFsxLDBdLFswLDIsInUiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFsyLDMsInYiLDAseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJlcGkifX19XSxbMyw0XSxbNSw2XSxbMCw2LCJmJyIsMl0sWzIsNywiZiIsMl0sWzYsNywidSciLDIseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFszLDgsImYnJyJdLFs3LDgsInYnIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoiZXBpIn19fV0sWzgsOV1d
\[\begin{tikzcd}
	0 && {M'} && M && {M''} && 0 \\
	\\
	0 && {N'} && N && {N''} && 0
	\arrow[from=1-1, to=1-3]
	\arrow["u", hook, from=1-3, to=1-5]
	\arrow["{f'}"', from=1-3, to=3-3]
	\arrow["v", two heads, from=1-5, to=1-7]
	\arrow["f"', from=1-5, to=3-5]
	\arrow[from=1-7, to=1-9]
	\arrow["{f''}", from=1-7, to=3-7]
	\arrow[from=3-1, to=3-3]
	\arrow["{u'}"', hook, from=3-3, to=3-5]
	\arrow["{v'}"', two heads, from=3-5, to=3-7]
	\arrow[from=3-7, to=3-9]
\end{tikzcd}\]
with the rows exact, because the diagram commutes, we may induce: 
% https://q.uiver.app/#q=WzAsNixbMiwwLCJHXFxxdW90aWVudCBOICJdLFswLDAsIkciXSxbMiwyLCJMIl0sWzQsMCwiXFxidWxsZXQiXSxbNiwyLCJcXGJ1bGxldCJdLFs2LDAsIlxcYnVsbGV0Il0sWzAsMiwiZyIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dLFsxLDIsImYiLDJdLFsxLDAsIlxccGkiLDAseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJlcGkifX19XSxbMyw0LCJcXHBpIFxcY2lyYyB1JyIsMl0sWzMsNSwiXFxwaSIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6ImVwaSJ9fX1dLFs1LDQsInUiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	N' && \operatorname{Coker}(f') && N && \operatorname{Coker}(f) \\
	\\
	&& \operatorname{Coker}(f) &&&& \operatorname{Coker}(f'')
	\arrow["\pi", two heads, from=1-1, to=1-3]
	\arrow["u'"', from=1-1, to=3-3]
	\arrow["\tilde{u}'", dashed, from=1-3, to=3-3]
	\arrow["\pi", two heads, from=1-5, to=1-7]
	\arrow["{\pi \circ v'}"', from=1-5, to=3-7]
	\arrow["\tilde{v}'", dashed, from=1-7, to=3-7]
\end{tikzcd}\]
Let $x'' \in \operatorname{ker}(f'')$. Because $v$ is surjective, we know  $x''=v(x)$ for some $x \in M$. Therefore, $v' \circ  f(x)=f''\circ  v(x)=0$, which implies $f(x)\in \operatorname{ker}(v')=\operatorname{Im}(u')$, that is, $f(x)=u'(y')$ for some $y' \in N'$. The snake lemma says that if we define the \textbf{boundary homomorphism} 
$d:\operatorname{ker}(f'')\rightarrow  \operatorname{Coker}(f')$ by 
\begin{align*}
d(x'')\triangleq y' + \operatorname{Im}(f')
\end{align*}
then we have an exact sequence: 
\begin{align*}
  0 \longrightarrow \operatorname{ker}(f') \overset{u}{\longhookrightarrow  } \operatorname{ker}(f) \overset{v}{\longrightarrow } \operatorname{ker}(f'')\overset{d}{\longrightarrow }\operatorname{Coker}(f') \overset{\tilde{u}'}{\longrightarrow }\operatorname{Coker}(f) \overset{\tilde{v}' }{\longtwoheadrightarrow  }\operatorname{Coker}(f'')\longrightarrow 0
\end{align*}
\end{theorem}
\begin{proof}
Routine. 
\end{proof}
\section{Exact functor}
\begin{equiv_def}
\textbf{(Exactness of covariant functor)} Let $\mathbf{P}$ and $\mathbf{Q}$ be two abelian category. A covariant functor $F:\mathbf{P}\rightarrow \mathbf{Q}$ is said to be an \textbf{exact functor} if it maps exact sequence to exact sequence or equivalently it maps short exact sequence to short exact sequence.  
\end{equiv_def}
\begin{proof}
We are required to show that if  $F: \mathbf{P}\rightarrow \mathbf{Q}$ preserve short exact sequence, then it maps exact sequence to exact sequence. 


\end{proof}
\begin{equiv_def}
  \textbf{(Exactness of covariant functor)} Let $\mathbf{P},\mathbf{Q}$ be two abelian category. A covariant functor $F: \mathbf{P}\rightarrow \mathbf{Q}$ is said to be \textbf{right exact} if 
\begin{align*}
A \longrightarrow  B \longtwoheadrightarrow  C \longrightarrow  0 \text{ is exact }  \implies  F(A)\longrightarrow F(B)\longtwoheadrightarrow  F(C) \longrightarrow 0\text{ is exact }
\end{align*}
or equivalently, if 
\begin{align*}
0\longrightarrow A\longhookrightarrow B \longtwoheadrightarrow C \longrightarrow 0\text{ is exact }\implies  F(A) \longrightarrow  F(B) \longtwoheadrightarrow F(C)\longrightarrow 0\text{ is exact }  
\end{align*}
$F:\mathbf{P}\rightarrow \mathbf{Q}$ is said to be \textbf{left exact} if
\begin{align*}
0\longrightarrow A \longhookrightarrow B \longrightarrow C\text{ is exact }\implies 0 \longrightarrow F(A)\longhookrightarrow F(B) \longrightarrow F(C)\text{ is exact }
\end{align*}
or equivalently, if 
\begin{align*}
0\longrightarrow A \longhookrightarrow B \longtwoheadrightarrow C \longrightarrow 0\text{ is exact } \implies  0 \longrightarrow F(A)\longhookrightarrow F(B) \longrightarrow F(C)\text{ is exact }
\end{align*}
$F:\mathbf{P}\rightarrow \mathbf{Q}$ is then said to be \textbf{exact} if it is both left and right exact.  
\end{equiv_def}
\begin{proof}
\href{https://math.stackexchange.com/questions/292037/definition-of-left-right-exact-functors}{See this MSE post}
\end{proof}
A \textbf{contravariant functor} $G: \mathcal{C}\rightarrow \mathcal{D}  $ is a map of objects $G: \operatorname{ob}(\mathcal{C} )\rightarrow \operatorname{ob}(\mathcal{D} )$ together with a map of morphisms: 
\begin{align*}
G: \operatorname{Hom}_\mathcal{C}(A,B) \rightarrow \operatorname{Hom}_\mathcal{D}(G(B),G(A))  
\end{align*}
such that 
\begin{align*}
G(\id _A)=\id _{G(A)}\quad \text{ and }\quad G(g \circ h) = G(h)\circ G(g)
\end{align*}

\end{document}


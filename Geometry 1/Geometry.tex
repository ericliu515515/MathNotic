\documentclass{report}
\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{NCKU 112.2}\\
Geometry 1}
\author{\huge{Eric Liu}}
\date{}
\begin{document}
\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak
\chapter{Curve}
\section{Prerequiste}
\begin{mdframed}
In this section, we will use $I$ to denote an \textbf{bounded open interval}. By a \textbf{curve} in $\R^n$, we mean a function form an open interval $I$ to $\R^n$.  We say a curve is \textbf{differentiable} if it is infinitely differentiable (smooth). That is, $\gamma ^{(n)}(t)$ exists and are continuous for all $n\inn$ and $t \in I$.\\

We say a differentiable curve $\gamma  :I\rightarrow \R^n$ is \textbf{regular} if $\gamma '(t)\neq 0$ for all $t  \in I$. We say a differentiable curve $\gamma :I\rightarrow \R^n$ is a \textbf{parametrized by arc-length} if $\abso{\gamma '(t)}=1$ for all $t \in I$. 
\end{mdframed}
\begin{mdframed}
For a regular curve $\gamma $, we say $\gamma '(t)$ is the \textbf{tangent vector} of $\gamma $ at $t$, and we define the \textbf{unit tangent vector} $T$ by    
\begin{align*}
T(t)\triangleq \frac{\gamma '(t)}{\abso{\gamma '(t)}}
\end{align*}
We say $\gamma ''(t)$ is the \textbf{oriented curvature} (normal vector) of $\gamma $ at $t$, and we define the  \textbf{unit normal vector} $N$ by 
 \begin{align*}
N(t)\triangleq \frac{T'(t)}{\abso{T'(t)}}=\frac{\gamma ''(t)}{\abso{\gamma ''(t)}}
\end{align*}
If the curve is parametrized by arc-length, with some messy computation, we can observe 
\begin{align*}
T'(t)=\frac{\gamma ''(t)}{\abso{\gamma '(t)}}
\end{align*}
Some interesting facts can be observed from what we have deduced.
\begin{enumerate}[label=(\alph*)]
  \item $\gamma ',\gamma ''$ always exists. 
  \item $\gamma $ is parametrized by arc-length $\implies \gamma ' \perp \gamma ''$
  \item $\gamma $ is parametrized by arc-length $\implies \gamma $ is regular
  \item $T$ and $T'$ exists at $t$  $\iff $ $\gamma $ is regular at $t$ 
  \item $T=\gamma '\iff \gamma $ is parametrized by arc-length   
  \item $N$ exists at $t$ $\iff \gamma ''(t)\neq 0\iff  \kappa (t)\neq 0$  
  \item $N$ and  $T'$ point to the same direction $\gamma ''$.
  \item $\abso{T'}=\kappa\iff \gamma $ is paramterized by arc-length 
  \item $\gamma \perp \gamma '$ and $\gamma'' \perp \gamma '''$ are generally false even for curve $\gamma $ paramterized by arc-length. 
  \item Given a curve $\gamma $ parametrized by arc-length
\begin{align*}
  \gamma \text{ is a straight line on }[a,b]&\iff  \gamma '\text{ and }T\text{ are constant on $(a,b)$ }\\
  &\iff \gamma ''(t)=0\text{ on $(a,b)$ }\\
  &\iff \kappa (t)=0\text{ on $(a,b)$ }\\
  &\iff T'(t)=0\text{ on }(a,b)
\end{align*}
\end{enumerate}
Notice that the last fact is false if $\gamma $ is not paramtetrized by arc-length, since $\gamma $ can move in the straight line with changing speed $\gamma '$.  
\end{mdframed}

\begin{mdframed}
Given a curve $\gamma $, if $T(t)$ and $N(t)$ exists (regular and non-zero curvature), we define its \textbf{binormal} vector by 
\begin{align*}
B(t)=T(t) \times N(t)
\end{align*}
Fix $t$. We say 
\begin{align*}
\set{T(t),N(t),B(t)}\text{ form a \textbf{positively oriented orthonormal basis} of $\R^3$ }
\end{align*}
This basis in general is constantly changing, yet always form an orthonormal basis.\\

Also, we say 
\begin{align*}
\text{span}\Big( T(t),N(t)\Big)\text{ is the \textbf{osculating plane} of $\gamma $ at $t$ }
\end{align*}
Suppose $\gamma $ is parametrized by arc-length and always has non-zero curvature. With some geometric intuition, one shall note that $\abso{T'}$ measure how curved $\gamma $ is and that $\abso{B'}$ measure how fast  $\gamma $ leave the osculating plane.\\

Because $\abso{B}=1$ is a constant, we can deduce  
\begin{align*}
B'\perp B
\end{align*}
and the computation 
\begin{align*}
B'=T' \times N + T \times N'=T \times N' 
\end{align*}
give us 
\begin{align*}
B'\perp T
\end{align*}
This ultimately show us 
\begin{align*}
B',N,T'\text{ are all parallel where $N,T'$ even point to the same direction}
\end{align*}


Notice that if we parametrize the curve with opposite direction, then 
\begin{enumerate}[label=(\alph*)]
  \item $T,\gamma '$ change direction 
  \item $N,\gamma ''$ keep the same direction 
  \item $B$ change direction 
  \item $B'$ keep the same direction 
\end{enumerate}
Now, for a curve $\gamma $ parametrized by arc-length, we define the \textbf{curvature} $\kappa$ and \textbf{torsion} $\tau$ of $\gamma $ by 
\begin{align*}
\kappa(t)=\abso{\gamma ''(t)}\text{ and }\tau (t)=\frac{B'(t)}{N(t)}
\end{align*}
With unfortunately heavy computation, we can verify that the definition of curvature must stay in the framework of curve parametrized by arc-length, otherwise we will be given two different values of curvature of two curves that are equivalent in the sense of sets.\\

Now, notice that we already have $T'=\kappa N$ and $B'=\tau N$, and by basic identity, we have $N=B\times T$.\\

Then $\underline{\text{with some computation}}$, we have the \textbf{Frenet Formula}
\begin{align*}
\begin{cases}
  T'=\kappa N\\
  N'=B'\times T+B\times T'=-\tau B-\kappa T\\
  B'=\tau N
\end{cases}
\end{align*}
\end{mdframed}
\begin{mdframed}
Given two vectors $u,v \inr^n$, we use  \textbf{dot product} 
\begin{align*}
u\cdot v= u_1v_1+\cdots + u_nv_n
\end{align*}
to denote the Euclidean inner product, and we use \textbf{length} 
\begin{align*}
\abso{u}=\sqrt{\sum_{k=1}^n u_k^2} 
\end{align*}
to denote the Euclidean norm. Note that we clearly have 
\begin{align*}
\abso{u}=\sqrt{u\cdot u} 
\end{align*}
Given three vectors $u,v,w \inr^3$, we define \textbf{cross product} by 
\begin{align*}
  u\times v&\triangleq \begin{vmatrix} 
  \textbf{i} & \textbf{j} & \textbf{k}\\
  u_1 & u_2 & u_3 \\
  v_1 & v_2 & v_3
\end{vmatrix}\\
&=(u_2v_3-u_3v_2,u_3v_1-u_1v_3,u_1v_2-u_2v_1)
\end{align*}
With some simple computation, we have the following identity 
\begin{enumerate}[label=(\alph*)]
  \item $u\times v=-v \times u$ (anti-commutative)
  \item $(au+w)\times v=a(u\times v)+w \times v$ (Linearity)
  \item $u\times (aw+v)=a (u\times w)+ u \times v$
  \item $u \times v =0 \iff u=cv$ for some $c \inr$
  \item $(u\times v)\cdot w =\begin{vmatrix} 
      u_1 & u_2 & u_3 \\
      v_1 & v_2 & v_3 \\
      w_1 & w_2 & w_3   \end{vmatrix}=\begin{vmatrix}
      w_1 & w_2 & w_3 \\
      u_1 & u_2 & u_3 \\
      v_1 & v_2 & v_3 
  \end{vmatrix}$ 
  \item $(u \times v)\cdot v=0=(u \times v)\cdot u$
  \item $u \times v \perp u$ and $u\times v\perp v$
  \item $u \perp v \implies  \abso{u \times v}= \abso{u}\cdot \abso{v}$
  \item $(u \times v)\times w=(u \cdot w)v-(v \cdot w)u$
\end{enumerate}
All proofs except that of the last identity are merely manipulation of determinant. A simple proof of the last identity follows from the fact both side are linear in all $u,v,w$, and the observation 
\begin{align*}
  (e_1\times e_2)\times e_3=0=(e_1\cdot e_3)e_2-(e_2\cdot e_3)e_1
\end{align*}
\end{mdframed}
\begin{theorem}
\textbf{(Differentiate the Dot Product)} Given two parametrized curves $u,v:(a,b)\rightarrow \R^n$, such that $u,v$ are differentiable at  $t \in (a,b)$. We have 
\begin{align*}
\frac{d}{dt}\big(u(t)\cdot v(t) \big)= u'(t)\cdot v(t)+u(t)\cdot v'(t)
\end{align*}
\end{theorem}
\begin{proof}
\begin{align*}
\frac{d}{dt}\big(u(t)\cdot v(t) \big)&=\frac{d}{dt}\sum_{k=1}^n u_k(t)v_k(t)\\
&=\sum_{k=1}^n \frac{d}{dt} u_k(t)v_k(t)\\
&=\sum_{k=1}^n u_k'(t)v_k(t)+u_k(t)v_k'(t)\\
&=\sum_{k=1}^n u_k'(t)v_k(t)+\sum_{k=1}^n u_k(t)v_k'(t)\\
&=u'(t)\cdot v(t)+u(t)\cdot v'(t)
\end{align*}
\end{proof}
\begin{theorem}
\textbf{(Differentiate the Cross Product)} Given two curves $u,v:(a,b)\rightarrow \R^3$, such that $u,v$ are differentiable at  $t \in (a,b)$. We have 
\begin{align*}
\frac{d}{dt}\big(u (t)\times v(t) \big)=u'(t)\times v(t)+u(t)\times v'(t)
\end{align*}
\end{theorem}
\begin{proof}
\begin{align*}
  \frac{d}{dt}\big(u(t)\times v(t) \big)=&\frac{d}{dt}(u_2v_3-u_3v_2,u_3v_1-u_1v_3,u_1v_2-u_2v_1)\\
=&(u_2'v_3+u_2v_3'-u_3'v_2-u_3v_2',\\
 & u_3'v_1+u_3v_1'-u_1'v_3-u_1v_3',\\
 &u_1'v_2+u_1v_2'-u_2'v_1-u_1v_2')\\
=&(u_2'v_3-u_3'v_2,u_3'v_1-u_1'v_3,u_1'v_2-u_2'v_1)\\
+&(u_2v_3'-u_3v_2',u_3v_1'-u_1v_3',u_1v_2'-u_1v_2')\\
=&u'\times v+u \times v'
\end{align*}
\end{proof}
\begin{theorem}
\textbf{(Integrating the Dot Product)} Given a curve $u:[a,b]\rightarrow \R^n$ and a vector $v \in\R^n$, suppose 
\begin{enumerate}[label=(\alph*)]
  \item $u$ is differentiable on $(a,b)$ 
  \item $u$ is continuous on  $[a,b]$
\end{enumerate}
We have 
\begin{align*}
\int_a^b u'(t)\cdot v dt=
\Big(\int_a^b u'(t)dt \Big)\cdot v= \big(u(b)-u(a) \big)\cdot v
\end{align*}
\end{theorem}
\begin{proof}
\begin{align*}
\int_a^b u'(t)\cdot vdt&=\int_a^b \sum_{k=1}^n u'_k(t)\cdot v_k dt \\
&=\sum_{k=1}^n  \int_a^b u'_k(t)\cdot v_k dt\\
&=\sum_{k=1}^n v_k \int_a^b u'_k(t)dt\\
&=v\cdot \Big(\int_a^b u'(t)dt \Big)
\end{align*}
\end{proof}
\begin{mdframed}
For the result above, sometimes we write 
\begin{align*}
  (u\cdot v)'=u'\cdot v+ u \cdot v'\text{ and }(u\times v)'=u' \times v+u\times v'
\end{align*}
\end{mdframed}
\begin{theorem}
\textbf{(MVT for curve)} Given a curve $\alpha  : [a,b]\rightarrow \R^n$ such that 
\begin{enumerate}[label=(\alph*)]
  \item $\alpha  $ is differentaible on $(a,b)$ 
  \item $\alpha  $ is continuous on $[a,b]$
\end{enumerate}
there exists $ \xi  \in (a,b)$ such that 
\begin{align*}
\abso{\alpha  (b)-\alpha  (a)}\leq \abso{\alpha  '(\xi  )}(b-a)
\end{align*}
\end{theorem}
\begin{proof}
Define $\phi:[a,b]\rightarrow \R$ by 
\begin{align*}
\phi(t)=\alpha (t)\cdot \big(\alpha (b)-\alpha (a) \big) 
\end{align*}
Clearly $\phi$ satisfy the hypothesis of Lagrange's MVT, then we know there exists $\xi \in (a,b)$ such that 
\begin{align*}
\phi(b)-\phi (a)=\phi'(\xi )\cdot (b-a)
\end{align*}
Written the equation in $\alpha $, we have 
\begin{align*}
\abso{\alpha (b)-\alpha (a)}^2= (b-a)\alpha '(\xi)\cdot \big(\alpha (b)-\alpha (a) \big)
\end{align*}
Notice that Cauchy-Schwarz inequality give us 
\begin{align*}
  (b-a)\abso{\alpha '(\xi)}\cdot \abso{\alpha (b)-\alpha (a)}&\geq (b-a)\abso{\alpha ' (\xi)\cdot \big(\alpha (b)-\alpha (a) \big)} \\
  &=\abso{\alpha (b)-\alpha (a)}^2
\end{align*}
This then implies 
\begin{align*}
  (b-a)\abso{\alpha '(\xi)}\geq \abso{\alpha (b)-\alpha (a)}
\end{align*}
\end{proof}
\begin{corollary}
\label{MVI}
\textbf{(Mean Value Inequality)} Given a curve $\alpha :[a,b]\rightarrow \R^n$ such that 
\begin{enumerate}[label=(\alph*)]
  \item $\alpha $ is differentiable on $(a,b)$ 
  \item $\alpha $ is continuous on $[a,b]$
\end{enumerate}
we have 
\begin{align*}
\abso{\alpha (b)-\alpha (a)}\leq (b-a)\sup_{(a,b)}\abso{\alpha '}
\end{align*}
\end{corollary}
\begin{mdframed}
\textbf{Trick to parametrize by arc-length}.\\

Given a regular curve $\gamma :I\rightarrow \R^n$ and fix $t_0 \in I$. We use
\begin{align*}
  s(t)=\int_{t_0}^t \abso{\gamma  ' (x)}dx
\end{align*}
to define the arc-length of  $\gamma $ from $\gamma (t_0)$ to $\gamma (t)$. Because $\gamma $ is regular, by FTC, it is clear that $s$ is one-to-one.\\

Let $t(s)$ be the inverse of $s$. Define 
 \begin{align*}
\beta (s)\triangleq \alpha (t(s))
\end{align*}
We have by Chain rule 
\begin{align*}
\beta '(s)&=t'(s)\alpha '(t(s))\\
&=\frac{\alpha '(t(s))}{s'(t)}\\
&=\frac{\alpha '(t(s))}{\abso{\alpha '(t(s))}}
\end{align*}
\end{mdframed} 
\begin{mdframed}
\textbf{(Frenet Formula Summary)} \\

By definition, we are given 
\begin{align*}
\begin{cases}
  T'=\kappa N\\
  B'=\tau N
\end{cases}
\end{align*}
To compute $N'$, an identity should be first given 
 \begin{align*}
N=B\times T
\end{align*}
We can now complete the Frenet Formula 
\begin{align*}
N'&=B'\times T + B \times T'\\
&=\tau N \times T + B \times \kappa N\\
&=-\tau B-\kappa T
\end{align*}
In conclusion 
\begin{align*}
\begin{cases}
  T'=\kappa N
  B' =\tau N\\
  N'=-\tau B-\kappa T
\end{cases}
\end{align*}
Give very close attention to the fact the two definitions of curvature 
\begin{align*}
\kappa =\frac{T'}{N}\text{ and }\kappa = \abso{\gamma ''}
\end{align*}
coincides $\underline{\text{only when }}\gamma $ is parametrzied by arc-length. The first definition remain same for all parametrizaiton of the same curve, while the latter doesn't.\\

Some comment should be dropped for the computation of torsion. If you overlook the fact $\alpha $ is parametrized by arc-length and disregard Frenet Formula, it is very likely you will get a result that you can not even sure if it is valid (the nominator and denominator may end up not seem explicitly parallel), let alone an identity beautiful as below. 
\end{mdframed}
\section{Frenet Trihedron}
\begin{mdframed}
In this section, we are given a smooth curve $\alpha (s)\inr^3$ parametrized by arc-length and a smooth curve $\beta  (t)\inr^3$ with unknown parametrization. We seek to 
\begin{enumerate}[label=(\alph*)]
  \item define Frenet Trihedron for $\alpha $.
  \item prove Frenet-Serret Formula.
  \item give identity of torsion of $\alpha $.
  \item give identity of curvature of $\beta $.
\end{enumerate}
in particular, at the end of this section, using $(d)$, we prove that the curvature of a plane curve $\beta (t)=(x,y)$ with unknown parametrization is exactly 
\begin{align*}
\kappa(t)=\frac{\abso{x'y''-x''y'}}{\big((x')^{2}+(y')^{2} \big)^{\frac{3}{2}}}
\end{align*}
\end{mdframed}
\textbf{(a): Define Frenet Trihedron for $\alpha $}
\begin{mdframed}
We define the \textbf{tangent vector} $T$ of $\alpha $ at each $s$ by 
 \begin{align*}
T(s)\triangleq \alpha '(s)
\end{align*}
and we define its \textbf{normal vector} $N$ by
\begin{align*}
N(s)\triangleq \frac{T'(s)}{\abso{T'(s)}}
\end{align*}
Note that $N$ is well defined if and only if  $\alpha ''(s)\neq 0$. We define  \textbf{binormal vector} $B$ by 
 \begin{align*}
B(s)\triangleq T(s)\times N(s)
\end{align*}
Note that from $B'\perp B$ and $B'=\big( T \times N'\big) \perp T$, we have $B'\parallelsum  N$. This then justify our later definition of  \textbf{torsion}.\\

We define \textbf{curvature} $\kappa (s)$ and \textbf{torsion} $\tau(s)$ by 
\begin{align*}
\kappa(s)\triangleq \abso{T'(s)}\text{ and }\tau(s)\triangleq \frac{B'(s)}{N(s)}
\end{align*}
\end{mdframed}
\textbf{(b): Frenet-Serret Formula}
\begin{theorem}
\textbf{(Frenet-Serret Formula)} Given a smooth curve $\alpha(s)$ parametrized by arc-length, if $T'(s)\neq 0$, we have the following  
\begin{align*}
\begin{cases}
  T'=\kappa N\\
  N'=-\kappa T-\tau B\\
  B'=\tau N
\end{cases}
\end{align*}
\end{theorem}
\begin{proof}
The first and the third equations follows from that of definition. Now, see 
\begin{align*}
N'&=(B\times T)'\\
&=B' \times T +  B \times T'\\
&=\tau N \times T + B \times \kappa N\\
&=\tau (-B)+ \kappa (-T)=-\kappa T-\tau B
\end{align*}

\end{proof}
\begin{mdframed}
Note that in $\R^2$, the Frenet-Serret Formula still holds, in the sense 
 \begin{align*}
\begin{cases}
  T'=\kappa N\\
  N'= -\kappa T
\end{cases}
\end{align*}
This can be proved by setting the ambient space to be $\R^3$. 
\end{mdframed}
\textbf{(c): Identity of Torsion of $\alpha(s) $}
\begin{theorem}
\textbf{(Identity of Torsion)} Given a smooth curve $\alpha (s)\inr^3$ parametrized by arc-length, if $\kappa(s)\neq 0$, we have 
\begin{align*}
\tau (s)=-\frac{\alpha ' (s)\times \alpha ''(s)\cdot \alpha '''(s)}{\big(\alpha ''(s) \big)^2}
\end{align*}
\end{theorem}
\begin{proof}
By definition 
\begin{align*}
\alpha '(s)=T(s)
\end{align*}
Compute 
\begin{align*}
\alpha ''(s)=T'(s)= -\kappa N (s)
\end{align*}
Compute 
\begin{align*}
\alpha '''= (-\kappa N)'=-\kappa ' N+ \kappa^2 T +\kappa \tau B
\end{align*}
Compute 
\begin{align*}
\alpha' \times \alpha '' = T \times (- \kappa N)=-\kappa B
\end{align*}
Compute 
\begin{align*}
\alpha ' \times \alpha '' \cdot \alpha '''&=(-\kappa B)\cdot (-\kappa N+\kappa^2 T + \kappa \tau B)\\
&= -\kappa^2 \tau 
\end{align*}
The result then follows. 
\end{proof}
\textbf{(d): Identity of Curvature of $\beta(t)$} 
\begin{theorem}
\textbf{(Identity of Curvature)} Given a smooth curve $\beta (t)\inr^3$ with unknown parametrization, we have 
\begin{align*}
\kappa(t)=\frac{\abso{\beta '(t)\times \beta ''(t)}}{\abso{\beta '(t)}^3}
\end{align*}
\end{theorem}
\begin{proof}
Define $s$  (arc-length) by
\begin{align*}
s(t)=\int_{t_0}^{t} \abso{\beta '(t')}dt'
\end{align*}
We have $\frac{ds}{dt}=\abso{\beta' (t)}$. This then give us  
\begin{align*}
\kappa (t)= \abso{\frac{dT}{ds}}=\abso{\frac{dT}{dt}}\cdot \abso{\frac{dt}{ds}}=\abso{\frac{dT}{dt}}\cdot \frac{1}{\abso{\beta '(t)}}
\end{align*}
We then can reduce the problem into 
\begin{align*}
\vi{\text{ proving }\abso{\frac{dT}{dt}}=\frac{\abso{\beta '(t)\times \beta ''(t)}}{\abso{\beta '(t)}^2}}
\end{align*}
Note that we have 
\begin{enumerate}[label=(\alph*)]
  \item $\frac{ds}{dt}=\abso{\beta '(t)}$ 
  \item $T(t)=\frac{\beta '(t)}{\abso{\beta '(t)}}$
\end{enumerate}
Then we can deduce 
\begin{align*}
\beta '(t)\times \beta ''(t)&= \Big(\frac{ds}{dt}T(t) \Big)\times \Big( \frac{d^2s}{dt^2}T(t)+\frac{ds}{dt}T'(t) \Big)\\
&=\big(\frac{ds}{dt} \big)^2 \cdot \Big(T(t)\times T'(t) \Big)\\
&=\abso{\beta '(t)}^2 \cdot (\pm \abso{T'(t)})
\end{align*}
This then give us 
\begin{align*}
\abso{T'(t)}=\frac{\abso{\beta '(t)\times \beta ''(t)}}{\abso{\beta '(t)}^2}\vdone
\end{align*}
\end{proof}
\begin{corollary}
\textbf{(Curvature of Plane Curves with unknown parametrization)} Given a smooth curve $\beta (t)=(x,y)\inr^3$ with unknown parametrization, we have 
\begin{align*}
  \kappa(t)=\frac{\abso{x'y''-x''y'}}{\big((x')^2+(y')^2 \big)^{\frac{3}{2}}}
\end{align*}
\end{corollary}
\section{Fundamental Theorem of Local Curves}
\begin{mdframed}
Prerequisite facts:
\begin{enumerate}[label=(\alph*)]
  \item Suppose $T\in L(\R^n,\R^n)$ and $f:I\rightarrow \R^n$ has a limit at $t_0\in I$. We have 
    \begin{align*}
    \lim_{t\to t_0 } T (f(t))=T\big(\lim_{t\to t_0}f(t) \big)
    \end{align*}
\end{enumerate}
\end{mdframed}
\begin{theorem}
\textbf{(Rigid motion on Local space curves)} Let 
\begin{enumerate}[label=(\alph*)]
  \item $I$ be a bounded open interval 
  \item $\gamma : I \rightarrow \R^3$ be a smooth curve such that $\kappa_\gamma (t)\neq 0$ for all $t \in I$ 
  \item $\rho\in L(\R^3,\R^3)$ be an orthogonal linear transformation with positive determinant 
  \item $c\inr^3$ be a vector in $\R^3$
  \item $\alpha :I\rightarrow \R^3$ be defined by $\alpha(t) \triangleq \rho(\gamma(t)) $
  \item $\beta :I\rightarrow \R^3$ be defined by $\beta(t) \triangleq \alpha(t) + c $
\end{enumerate}
We have 
\begin{align*}
\hspace{2.5cm}\begin{cases}
  \kappa_\gamma (t)=\kappa_\alpha (t)=\kappa_\beta (t)\\
  \tau_\gamma (t)=\tau_\alpha (t)=\tau_\beta (t)
\end{cases}\hspace{1.5cm}(t \in I)
\end{align*}
\end{theorem}
\begin{proof}
We first show 
\begin{align*}
\vi{\hspace{2.5cm}(\rho v) \times (\rho w)=\rho (v\times w)\hspace{1.5cm}(v,w\inr^3)}
\end{align*}
Fix $v,w\inr^3$. We reduce the problem into proving 
\begin{align*}
  \vi{\hspace{2.5cm}(\rho v)\times (\rho w)\cdot z=\rho (v\times w)\cdot z\hspace{1.5cm}(z\inr^3)}
\end{align*}
Observe 
\begin{align*}
  (\rho v)\times (\rho w) \cdot z &= \begin{vmatrix} 
    \rho v & \rho w & \rho(\rho^{-1}(z) )
  \end{vmatrix}\\
  &=\begin{vmatrix} 
    v & w & \rho^{-1}(z)
  \end{vmatrix}\\
  &=v \times w \cdot \rho^{-1}(z)\\
  &=\rho (v\times w)\cdot z \vdone
\end{align*}
We first prove 
\begin{align*}
  \olive{\hspace{2.5cm}\kappa_\alpha (t)=\kappa_\gamma (t)\hspace{1.5cm}(t \in I)}
\end{align*}
Note that $\gamma ''$ exists, so we can compute 
\begin{align*}
\kappa_\alpha &= \frac{\abso{\alpha ' \times \alpha''}}{\abso{\alpha '}^3}\\
&=\frac{\abso{(\rho \gamma )'\times (\rho  \gamma )''}}{\abso{(\rho\gamma )'}^3}\\
&=\frac{\abso{\rho \gamma '\times \rho \gamma ''}}{\abso{\rho \gamma '}^3}\\
&=\frac{\abso{\rho (\gamma '\times \gamma '')}}{\abso{\rho \gamma '}^3}\\
&=\frac{\abso{\gamma '\times \gamma ''}}{\abso{\gamma '}^3}=\kappa_\gamma \odone
\end{align*}
We now prove 
\begin{align*}
  \vi{\hspace{2.5cm}\tau_\alpha (t)=\tau_\gamma (t)\hspace{1.5cm}(t \in I)}
\end{align*}
Compute 
\begin{align*}
\tau_\alpha &=-\frac{\alpha '\times \alpha '' \cdot \alpha '''}{\abso{\alpha '\times \alpha'' }}\\
&=-\frac{\rho \gamma  ' \times \rho \gamma '' \cdot \rho \gamma '''}{\abso{\rho \gamma '\times \rho \gamma ''}}\\
&=-\frac{\gamma '\times \gamma '' \cdot \gamma '''}{\abso{\gamma '\times \gamma ''}}=\tau_\gamma \vdone
\end{align*}


\end{proof}
\begin{theorem}
\textbf{(Fundamental Theorem of Local Curves)} Let 
\begin{enumerate}[label=(\alph*)]
  \item $I$ be a bounded open interval 
  \item $\kappa:I\rightarrow \R^+$ be a smooth function
  \item  $\tau:I\rightarrow \R$ be a smooth function
\end{enumerate}
And, let $E$  be the set of all space curves $\gamma $ such that  
\begin{enumerate}[label=(\alph*)]
  \item $\gamma $ has domain $I$
  \item $\abso{\gamma '(s)}=1$
   \item $\kappa_\gamma (s)=\kappa(s)$ 
    \item $\tau_{\gamma }(s)=\tau (s)$
\end{enumerate}
The following statement hold true. 
\begin{enumerate}[label=(\alph*)]
  \item $E$ is non-empty. \textbf{(existence part)}
  \item For each two $\gamma ,\alpha \in E$, there exists an orthogonal linear transformation $\rho \in L(\R^3,\R^3)$ with positive determinant and a vector $c\inr^3$ such that  $\gamma (s)=\rho \circ \alpha (s)+c$ for all $s \in I$. \textbf{(uniqueness part)}
\end{enumerate}
\end{theorem}
\begin{proof}
Fix $\gamma ,\alpha \in E$ and fix $s_0\in I$. There clearly exists a rigid motion $M$ such that if we denote 
\begin{align*}
\overline{\alpha }(s)\triangleq M\circ \alpha (s)
\end{align*}
Then 
\begin{align*}
\gamma (s_0)=\overline{\alpha }(s_0)\text{ and }\begin{cases}
  T_\gamma (s_0)=T_{\overline{\alpha }}(s_0)\\
  N_\gamma (s_0)=N_{\overline{\alpha }}(s_0)\\
  B_\gamma  (s_0)=B_{\overline{\alpha  }}(s_0)
\end{cases}
\end{align*}
We only wish to prove 
\begin{align*}
\vi{\hspace{2.5cm}T_\gamma (s)=T_{\overline{\alpha }}(s)\hspace{1.5cm}(s \in I)}
\end{align*}
Denote 
\begin{align*}
T\triangleq T_\gamma \text{ and }\overline{T}\triangleq T_{\overline{\alpha }\text{ and also similarly for $N,B$ }}
\end{align*}
Compute 
\begin{align*}
&\frac{d}{ds} \Big( \abso{T-\overline{T}}^2 + \abso{N-\overline{N}}^2+ \abso{B-\overline{B}}^2\Big)\\
  =&2\Big( \langle T'-\overline{T}',T-\overline{T}\rangle + \langle N'-\overline{N}' ,N-\overline{N}\rangle + \langle B'-\overline{B}', B-\overline{B}\rangle \Big)\\
  =&2\Big(\kappa \langle N-\overline{N},T-\overline{T}\rangle - \kappa\langle T-\overline{T},N-\overline{N}\rangle -\tau \langle B-\overline{B},N-\overline{N}\rangle + \tau\langle N- \overline{N},B-\overline{B}\rangle  \Big)\\
  =&0 
\end{align*}
This then implies 
\begin{align*}
\abso{T-\overline{T}}^2 + \abso{N-\overline{N}}^2 + \abso{B-\overline{B}}^2 \text{ is a fixed constant on $I$ }
\end{align*}
Note that 
\begin{align*}
T(s_0)=\overline{T}(s_0)\text{ and }N(s_0)=\overline{N}(s_0)\text{ and }B(s_0)=\overline{B}(s_0)
\end{align*}
Then we know that fixed constant is exactly $0$. This then let us deduce
 \begin{align*}
T=\overline{T}\text{ on $I$ }\vdone
\end{align*}









\end{proof}
\section{Isoperimetric Inequality and Four-Vertex Theorem}
\begin{mdframed}
  In this section, we are given a smooth plane curve $\alpha :[a,b]\rightarrow \R^2$ parametrized by arc-length. We say
\begin{enumerate}[label=(\alph*)]
  \item $\alpha $ is a \textbf{closed curve} if $\alpha ^{(k)}(a)=\alpha ^{(k)}(b)$ for all $k\inz_0^+$. 
\item  $\alpha $ is a \textbf{simple closed curve} if $\alpha $ is closed and $\alpha (t_1)\neq \alpha (t_2)$ for all $t_1,t_2 \in [a,b)$.
\item  $\alpha $ is \textbf{positively oriented} if $\alpha ' \times \alpha ''$ is always positive.  
\item $\alpha $ is \textbf{convex} the trace $\alpha ([a,b])$ always entirely lies on the same side of the closed half-plane determined by $T(s)$ for all $s$ 
\item $\alpha $ has \textbf{vertex} $\alpha (s_0)$ if $\kappa'(s_0)=0$ 
\end{enumerate}
The interior $D$ of a piece-wise smooth, simple closed plane curve $\alpha :[a,b]\rightarrow \R^2$ can be assigned a number to represent its area 
\begin{align}
\label{A(D)}
A(D)=\iint_D 1dxdy
\end{align}
that match with our geometric intuition, in the sense that if one compute the area of a rectangle or that of a circle, using \myref{Formula}{A(D)}, then one obtain number same as the number obtained using elementary geometric way (height $\times $ width, etc).\\ 

Note that by Green's Theorem, we know $A(D)$ equals to 
\begin{enumerate}[label=(\alph*)]
  \item $\int_a^b xy'dt$ 
  \item $-\int_a^b yx'dt$
  \item $\frac{1}{2}\int_a^b xy'-yx'dt=\frac{1}{2}\int_a^b (x,y)\times (x',y')dt$
\end{enumerate}







\end{mdframed}
\section{HW1}
\begin{question}{1-2: 2}{}

Let \(\alpha(t)\) be a parametrized curve which does not pass through the origin. If \(\alpha(t_0)\) is the point of the trace of \(\alpha\) closest to the origin and \(\alpha'(t_0) \neq 0\), show that the position vector \(\alpha(t_0)\) is orthogonal to \(\alpha'(t_0)\).
\end{question}
\begin{proof}
Define $g:I\rightarrow \R$ by 
\begin{align*}
g(t)\triangleq \abso{\alpha (t)}^2=(\alpha \cdot \alpha )(t)
\end{align*}
Notice that 
\begin{align*}
g'(t)=(2\alpha '\cdot \alpha )(t)\text{ if exists }
\end{align*}
From premise, we know $g$ attains minimum at $t_0$. This tell us 
\begin{align*}
0=g'(t_0)=(2\alpha '\cdot \alpha )(t_0)
\end{align*}
Then, we can deduce 
\begin{align*}
\alpha '(t_0)\cdot \alpha (t_0)=0
\end{align*}
This implies $\alpha (t_0)\perp \alpha '(t_0)$. 
\end{proof}
\begin{question}{1-2: 5}{}

Let \(\alpha : I \rightarrow \mathbb{R}^3\) be a parametrized curve, with \(\alpha''(t) \neq 0\) for all \(t \in I\). Show that \(|\alpha(t)|\) is a nonzero constant if and only if \(\alpha(t)\) is orthogonal to \(\alpha'(t)\) for all \(t \in I\).
\end{question}
\begin{proof}
We wish to prove 
\begin{align*}
\exists \beta  \inr^*,  \forall t \in I, \abso{\alpha (t)}=\beta  \iff \forall t \in I , (\alpha \cdot \alpha ')(t)=0
\end{align*}
Define $g:I\rightarrow \R$ by 
\begin{align*}
g(t)\triangleq \abso{\alpha (t)}^2=(\alpha \cdot \alpha )(t)
\end{align*}

Notice that 
\begin{align}
\label{1.2.5.1}
g'(t)=(2\alpha '\cdot \alpha )(t)
\end{align}
$(\longrightarrow)$\\

From premise, $g$ is a constant on  $I$. This implies  $g'(t)=0$  for all $t \in I$. Then, from \myref{Equation}{1.2.5.1}, we see 
\begin{align*}
  (\alpha \cdot \alpha ')(t)=0\text{ for all $t \in I$ }
\end{align*}
$(\longleftarrow)$\\

Again, from  \myref{Equation}{1.2.5.1}, we deduce 
\begin{align*}
\forall t \in I , (\alpha \cdot \alpha ')(t)=0 \implies \forall t \in I, g'(t)=0
\end{align*}

This implies $g$ is a constant, which implies $\abso{\alpha }$ is a constant, that is 
\begin{align*}
\exists \beta \inr, \abso{\alpha (t)}=\beta 
\end{align*}
Lastly, we have to show 
\begin{align*}
\vi{\text{ $\beta \neq 0$ }}
\end{align*}
\As{$\beta =0$}. Then, we see $\alpha (t)=0$ for all $t \in I$. This implies $\alpha ''(t)=0 $ for all $t \in I$, which \CaC to the premise. $\vdone$
\end{proof}
\begin{question}{1-3:2}{}
\includegraphics[height=10cm,width=18cm]{1.png}
\end{question}
\begin{proof}
The solution of the question \textbf{a} is 
\begin{align*}
\alpha (t)=(t-\sin t,1-\cos t)
\end{align*}
Compute 
\begin{align*}
\alpha'(t)=(1-\cos t,\sin t)
\end{align*}
and compute
\begin{align*}
\abso{\alpha '(t)}=\sqrt{1-2\cos t +\cos^2 t +\sin^2 t}  = \sqrt{2}\cdot \sqrt{1-\cos t}  
\end{align*}
This implies the singular points are 
\begin{align*}
  \set{2n\pi : n\inz}
\end{align*}


The solution of the question \textbf{b} is then 
\begin{align*}
\int_0^{2\pi} \abso{\alpha '(t)}dt&=\sqrt{2}\int_0^{2\pi} \sqrt{1-\cos t}dt \\
&=\sqrt{2} \int_{0}^{2\pi} \sqrt{2} \abso{\sin \frac{t}{2}}dt  \\
&=2\int_0^{2\pi}\abso{\sin \frac{t}{2}}dt\\
&=4 \int_{0}^{\pi}\sin (\frac{t}{2})dt\\
&=-8 \cos \frac{t}{2}\Big|_0^{\pi}
\end{align*}

\end{proof}
\begin{question}{1-3:4}{}
\includegraphics[height=4cm,width=18cm]{3.png}
\includegraphics[height=18cm,width=18cm]{2.png}
Typo correction: $\alpha (t)=(\sin t,\cos t + \ln \tan \frac{t}{2})$
\end{question}
\begin{proof}
\textbf{(a)}

Notice that the interval $I$ is  $(0,\pi)$. It is clear that 
\begin{enumerate}[label=(\alph*)]
  \item $\sin t$ is smooth on $\R$
  \item $\cos t$ is smooth on $\R$
  \item $\ln t$ is smooth on $\R$
  $\tan \frac{t}{2}$ is smooth on $I$
\end{enumerate}
Then it follows that $\alpha $ is a differentiable curve.\\

Compute 
\begin{align*}
\alpha '(t)=(\cos t,- \sin t + \frac{1}{\tan \frac{t}{2}} \cdot \sec^2 \frac{t}{2}\cdot \frac{1}{2})
\end{align*}
Because $\cos t=\alpha '_1(t)$ is $0$ on  $I$ only when  $t=\frac{\pi}{2}$, we know $\alpha $ is regular on $I$ except possibly at  $t=\frac{\pi}{2}$.\\

Compute 
\begin{align*}
\alpha '(\frac{\pi}{2})=(0,-1+\frac{1}{1}\cdot 2 \cdot \frac{1}{2} )=(0,0)
\end{align*}
We now conclude $\alpha $ is regular on $I$ except  $\frac{\pi}{2}$. \\

\textbf{(b)}

A useful Identity give us 
\begin{align*}
\alpha '(t)=(\cos t,-\sin t+ \csc t)
\end{align*}
From the following facts
\begin{enumerate}[label=(\alph*)]
  \item the first argument of the segment is from $0$ to  $\sin t =\alpha (t)$
  \item $\alpha_x'(t)=\cos t$
  \item $\frac{\sin t}{\cos t}=\tan t$
\end{enumerate}
We conclude that the length of the segment is 
\begin{align*}
\abso{\tan t}\cdot \abso{\alpha '(t)}&= \abso{\tan t} \cdot \sqrt{\cos ^2 t + \sin^2 t - 2 \sin t \csc t + \csc ^2 t }\\
&=\abso{\tan t} \cdot \sqrt{1-2+\csc ^2 t}\\
&=\abso{\tan t } \cdot \sqrt{\csc ^2 t-1}=\abso{\tan t } \cdot  \sqrt{\cot ^2 t} =1
\end{align*}



\end{proof}
\begin{question}{}{}
\includegraphics[height=14cm,width=18cm]{qu4}
\end{question}
\begin{proof}
\textbf{(a)}
Let $v=(0,1)$. Compute 
\begin{align*}
\frac{\alpha (t)-\alpha (0)}{\abso{\alpha (t)-\alpha (0)}}\cdot v=\frac{t^2}{\sqrt{t^6+t^4} }=\frac{1}{\sqrt{t^2+1} }\to 1\text{ as }t \to 1
\end{align*}
This implies $\alpha $ has a weak tangent at $t=0$. Now, if $\alpha $ has a strong tangent, we must have 
\begin{align*}
\frac{\alpha (h)-\alpha (-h)}{2h}\cdot v \to 1\text{ or }\to -1
\end{align*}
But this is clearly not the case as 
\begin{align*}
\frac{\alpha (h)-\alpha (-h)}{2h}\cdot v=0\text{ for all $h>0$ }
\end{align*}
So we have the conclusion that $\alpha $ has no strong tangent at $0$.\\


\textbf{(b)} 
By MVT, for each $h,k$ there exists a set of real numbers $\set{c_x,c_y,c_z}$ between $t+h$ and  $t+k$ such that 
 \begin{align*}
\frac{\alpha (t_0+h)-\alpha  (t_0+k)}{h-k}=\Big(x'(c_x),y'(c_y),z'(c_z) \Big)
\end{align*}
Then because 
\begin{align*}
h,k  \to 0 \implies t_0+h ,t_0+k \to t_0 \implies c_x,c_y,c_z \to t_0
\end{align*}
Then from the fact $\alpha $ is of class $C^1$ ($x',y',z'$ are all continuous), we can now deduce 
\begin{align}
\label{ahk}
\frac{\alpha (t_0+h)-\alpha (t_0+k)}{h-k}\to \alpha '(t_0)\text{ as $h,k \to 0$ }
\end{align}
Now, because $\alpha '(t_0)\neq 0$ as $\alpha $ is regular, we see 
\begin{align*}
\lim_{h,k\to 0}\frac{\alpha (t_0+h)-\alpha (t_0+k)}{h-k}\cdot \alpha '(t_0)= \abso{\alpha '(t_0)}^2
\end{align*}
This then implies 
\begin{align*}
\lim_{h,k\to 0}\frac{\alpha (t_0+h)-\alpha (t_0+k)}{\abso{\alpha (t_0+h)-\alpha (t_0+k)}}\cdot \frac{\alpha '(t_0)}{\abso{\alpha '(t_0)}}=1
\end{align*}
which implies the "strong tangent" must always converge to $\alpha '(t_0)$.\\

Notice that the last implication is backed by \myref{Equation}{ahk}\\


\textbf{(c)}\\

From 
\begin{align*}
\alpha (t)=\Big(t^2,\begin{cases}
  t^2& \text{ if $t\geq 0$ }\\
  -t^2& \text{ if $t\leq 0$ }
\end{cases} \Big)
\end{align*}
Compute 
\begin{align*}
\alpha '(t)=\Big(2t,\begin{cases}
  2t& \text{ if $t\geq 0$ }\\
  -2t& \text{ if $t\leq 0$ }
\end{cases} \Big)
\end{align*}
Notice that the derivative at $t=0$ is computed from definition instead of product rule.\\


Now, it is clear that $x',y'$ are continuous. This implies $\alpha  \in C^1$. Yet, we see $y'$ is not differentiable at  $t=0$. This implies  $\alpha \not \in C^2$.\\

The sketch:\includegraphics[height=8cm,width=15cm]{qsp}
\end{proof}
\begin{question}{}{}
\includegraphics[height=15cm,width=18cm]{qu8}
\includegraphics[height=3cm,width=18cm]{qu7}
\end{question}
\begin{proof}
We first prove 
\begin{align*}
\vi{\int_a^b \abso{\alpha '(t)}dt \geq  l(\alpha ,P)}
\end{align*}
By FTC, we have
\begin{align*}
  \abso{\alpha (t_i)-\alpha (t_{i-1})}&=\abso{\int_{t_{i-1}}^{t_i} \alpha '(t)dt}\\
&\leq \int_{t_{i-1}}^{t_i} \abso{\alpha '(t)}dt 
\end{align*}
This then implies 
\begin{align*}
l(\alpha ,P)=\sum \abso{\alpha (t_i)-\alpha (t_{i-1})}\leq \sum \int_{t_{i-1}}^{t_i}\abso{\alpha '(t)}dt=\int_a^b \abso{\alpha '(t)}dt \vdone
\end{align*}
We have reduced the problem into 
\begin{align*}
\blue{\text{ finding $\delta$ such that }\forall P: \abso{P}<\delta , \int_a^b \abso{\alpha '(t)}dt - l(\alpha ,P)<\epsilon }
\end{align*}


Because $\alpha '$ is uniformly continuous on $[a,b]$ ($\because$ continuous function on compact domain is uniformly continuous), we know there exists $\delta ' $ such that 
\begin{align*}
\abso{\alpha '(s)-\alpha '(t)}< \frac{\epsilon }{2(b-a)}\text{ if $\abso{s-t}<\delta'$ }
\end{align*}
We claim 
\begin{align*}
\blue{\text{ such $\delta'$ works }}
\end{align*}
Let $\abso{P}<\delta$, and let $s_i \in [t_{i-1},t_i]$. Because $\abso{s_i-t_i}<\delta$, we have
\begin{align}
\label{siti}
\abso{\alpha '(s_i)-\alpha '(t_i)}<\frac{\epsilon}{2(b-a)}
\end{align}
This give us 
\begin{align*}
\abso{\alpha '(s_i)}<\abso{\alpha '(t_i)} + \frac{\epsilon}{2(b-a)}
\end{align*}
Now, we can deduce 
\begin{align*}
  \int_{t_{i-1}}^{t_i} \abso{\alpha '(s)}ds&\leq   \abso{\alpha '(t_i)}\Delta t_i+ \frac{\epsilon }{2(b-a)}\Delta t_i\\
  &=\int_{t_{i-1}}^{t_i}\abso{\alpha '(t_i)}dt + \frac{\epsilon}{2(b-a)}\Delta t_i\\
 &=\abso{\int_{t_{i-1}}^{t_i} \alpha '(t_i)dt}+ \frac{\epsilon }{2(b-a)}\Delta t_i\\
  &=\abso{\int_{t_{i-1}}^{t_i} \alpha' (t_i)-\alpha '(t)dt + \int_{t_{i-1}}^{t_i} \alpha '(t)dt }+ \frac{\epsilon}{2(b-a)}\Delta t_i \\
  &\leq  \abso{\int_{t_{i-1}}^{t_i} \alpha '(t_i)-\alpha' (t)dt}+ \abso{\int_{t_{i-1}}^{t_i} \alpha '(t)dt}+\frac{\epsilon}{2(b-a)}\Delta t_i \\
  &\leq \frac{\epsilon}{2(b-a)}\Delta t_i + \abso{\alpha (t_i)-\alpha (t_{i-1})}+\frac{\epsilon}{2(b-a)}\Delta t_i\\
  &=\abso{\alpha (t_i)-\alpha (t_{i-1})}+ \frac{\epsilon }{b-a}\Delta t_i
\end{align*}
Notice that the last inequality follows from \myref{Equation}{siti}. The long deduction above then give us 
\begin{align*}
  \int_{a}^b \abso{\alpha '(t)}dt&\leq \sum \abso{\alpha (t_i)-\alpha (t_{i-1})}+ \frac{\epsilon}{b-a} (b-a)\\
&=l(\alpha ,P)+\epsilon 
\end{align*}
Then we have 
\begin{align*}
\int_a^b \abso{\alpha '(t)}dt -l(\alpha ,P)\leq \epsilon \bdone
\end{align*}
\end{proof}
\begin{question}{}{}
\includegraphics[height=7cm,width=18cm]{qu6}
\end{question}
\begin{proof}
\textbf{(a)} 
Suppose $I=[a,b]$. Define arc length by 
\begin{align*}
\sup_{P} l(P,\alpha )\text{ where $\sup $ runs over all partition $P$ of $[a,b]$  }
\end{align*}

\textbf{(b)}\\

Geometrically, we know the arc length of the portion of the curve corresponding to $t \in [\frac{1}{n+1},\frac{1}{n}]$ must be greater than 
\begin{align}
\label{19b}
\abso{\alpha \big(\frac{1}{n}\big)-\alpha \big(\frac{1}{n+\frac{1}{2}}\big)}+\abso{\alpha \big(\frac{1}{n+1} \big)-\alpha \big(\frac{1}{n+\frac{1}{2}} \big)}
\end{align}
WOLG of $n$ being odd or even, Compute 
\begin{align*}
\abso{\alpha \big(\frac{1}{n} \big)-\alpha \big(\frac{1}{n+\frac{1}{2}} \big)}&=\abso{(\frac{1}{n},0)-(\frac{1}{n+\frac{1}{2}},\frac{1}{n+\frac{1}{2}})}\\
&=\sqrt{\big(\frac{1}{n}-\frac{1}{n+\frac{1}{2}} \big)^2 +\big(\frac{1}{n+\frac{1}{2}} \big)^2} \\
&=\sqrt{\frac{1}{n^2}-\frac{4}{n(2n+1)}+\frac{8}{(2n+1)^2}} \\
&=\sqrt{\frac{(2n+1)^2-4n(2n+1)+8n^2}{n^2(2n+1)^2}} \\
&=\sqrt{\frac{4n^2+1}{n^2(2n+1)^2}}\\
&=\frac{\sqrt{4n^2+1} }{n(2n+1)}\geq \frac{\sqrt{4n^2} }{n(2n+1)}=\frac{2}{2n+1}
\end{align*}
and compute 
\begin{align*}
\abso{\alpha \big(\frac{1}{n+\frac{1}{2}} \big)-\alpha \big(\frac{1}{n} \big)}&=\abso{(\frac{1}{n+\frac{1}{2}},\frac{1}{n+\frac{1}{2}})-(\frac{1}{n+1},0)}\\
&=\sqrt{\big(\frac{1}{n+1}-\frac{1}{n+\frac{1}{2}} \big)^2 + \big(\frac{1}{n+\frac{1}{2}} \big)^2} \\
&=\sqrt{\frac{1}{(n+1)^2}-\frac{4}{(n+1)(2n+1)}+\frac{8}{(2n+1)^2}}\\
&=\sqrt{\frac{(2n+1)^2 -4(n+1)(2n+1)+8(n+1)^2}{(n+1)^2(2n+1)^2}}\\
&=\sqrt{\frac{4n^2+8n+5}{(n+1)^2(2n+1)^2}}\\
&\geq \frac{\sqrt{4n^2+8n+4} }{(n+1)(2n+1)}=\frac{2}{2n+1}
\end{align*}
From the computation and \myref{Equation}{19b}, it is now clear that the arc length of the portion of the curve corresponding to $ t \in [\frac{1}{n+1},\frac{1}{n}]$ is at least $\frac{2}{n+\frac{1}{2}}$. With simple addition, this then implies the arc length of the curve in the interval $[\frac{1}{N},1]$ is at least 
\begin{align*}
  \sum_{n=1}^{N-1} \frac{2}{2n+1}=2 \sum_{n=1}^{N-1}\frac{1}{2n+1}
\end{align*}
The number is clearly greater than 
\begin{align*}
2 \sum_{n=1}^{N-1}\frac{1}{2n+2}
\end{align*}
which equals to 
\begin{align*}
\sum_{n=1}^{N-1}\frac{1}{n+1}
\end{align*}
The series diverge to $+\infty$ as $N$ to  $\infty$. 
\end{proof}
\begin{theorem}
\label{IDP}
\textbf{(Integrating the Dot Product)} Given a curve $u:[a,b]\rightarrow \R^n$ and a vector $v \in\R^n$, suppose 
\begin{enumerate}[label=(\alph*)]
  \item $u$ is differentiable on $(a,b)$ 
  \item $u$ is continuous on  $[a,b]$
\end{enumerate}
We have 
\begin{align*}
\int_a^b u'(t)\cdot v dt=
\Big(\int_a^b u'(t)dt \Big)\cdot v= \big(u(b)-u(a) \big)\cdot v
\end{align*}
\end{theorem}
\begin{proof}
\begin{align*}
\int_a^b u'(t)\cdot vdt&=\int_a^b \sum_{k=1}^n u'_k(t)\cdot v_k dt \\
&=\sum_{k=1}^n  \int_a^b u'_k(t)\cdot v_k dt\\
&=\sum_{k=1}^n v_k \int_a^b u'_k(t)dt\\
&=v\cdot \Big(\int_a^b u'(t)dt \Big)
\end{align*}
\end{proof}
\begin{question}{}{}
\includegraphics[height=10cm,width=18cm]{qu5}
\end{question}
\begin{proof}
\textbf{(a)}\\


The first equality 
\begin{align*}
  (q-p)\cdot v=\int_a^b \alpha '(t)\cdot vdt
\end{align*}
follows directly from \myref{Theorem}{IDP}.\\

Now, by Cauchy-Schwarz inequality, we have 
\begin{align*}
  \abso{\alpha '(t)\cdot v} \leq \abso{\alpha '(t)}\cdot \abso{v}
\end{align*}
This then give us 
\begin{align*}
\alpha '(t)\cdot v\leq \abso{\alpha '(t)\cdot v}\leq \abso{\alpha '(t)}\cdot \abso{v}=\abso{\alpha '(t)}
\end{align*}
We now have 
\begin{align*}
\int_a^b \alpha '(t)\cdot v \leq \abso{\alpha '(t)}dt
\end{align*}
as desired.\\

\textbf{(b)}

The first inequality tell us that if $v$ is a constant and $\abso{v}=1$, we have 
\begin{align*}
  (q-p)\cdot v \leq \int_a^b \abso{\alpha '(t)}dt
\end{align*}
If $v=\frac{q-p}{\abso{q-p}}$, it is clear that $v$ is a constant and  $\abso{v}=1$, and at the same time, we have 
\begin{align*}
  (q-p)\cdot v=\frac{(q-p)\cdot (q-p)}{\abso{q-p}}=\frac{\abso{q-p}^2}{\abso{q-p}}=\abso{q-p}
\end{align*}
We now have 
\begin{align*}
\abso{q-p}=(q-p)\cdot v \leq \int_a^b \abso{\alpha '(t)}dt
\end{align*}
from the first inequality 
\end{proof}
\begin{question}{}{}
\includegraphics[height=2cm,width=18cm]{qu9}
\end{question}
\begin{proof}
Compute 
\begin{align*}
\begin{vmatrix} 
  1 & 4 \\
  3 & 2
\end{vmatrix}=-10
\end{align*}
and compute 
\begin{align*}
\begin{vmatrix}
  1& 2 & 4 \\
  3 & 3 & 8 \\
  5 & 7 & 3
\end{vmatrix}=-9
\end{align*}
Both bases are negatively oriented. 
\end{proof}
\begin{question}{}{}
\includegraphics[height=2cm,width=18cm]{qu10}
\end{question}
\begin{proof}
Arbitrarily pick two points $u,w$ in  $P$. We wish to show 
\begin{align*}
  \vi{v\cdot (u-w)=0}
\end{align*}
Because $v=(a,b,c)$ and 
\begin{align*}
\begin{cases}
  au_1+b u_2+cu_3=-d
  aw_1+b w_2+cw_3=-d
\end{cases}
\end{align*}
We see
\begin{align*}
v\cdot (u-w)&= a(u_1-w_2)+b(u_2-w_2)+c(u_3-w_2)\\
&=(-d)-(-d)=0\vdone
\end{align*}
To measure the distance between $P$ and the origin, we wish to find a vector $u$ such that  $u\perp P$ and $u \in P$. We know that $u$ must be linearly dependent with  $v=(a,b,c)$, since the dimension of  $P^\perp$ is $1$. Then, we can write
\begin{align*}
u=c_0(a,b,c)\text{ for some $c_0\inr$ }
\end{align*}
Because $u \in P$, we know 
\begin{align*}
c_0a^2+c_0b^2+c_0c^2+d=0
\end{align*}
This tell us 
\begin{align*}
c_0=\frac{-d}{a^2+b^2+c^2}
\end{align*}
We now see that the distance $\abso{u}$ between $P$ and origin is 
\begin{align*}
\abso{u}=\abso{c_0}\cdot \sqrt{a^2+b^2+c^2}= \frac{\abso{d}}{\sqrt{a^2+b^2+c^2} }
\end{align*}

\end{proof}
\begin{question}{}{}
\includegraphics[height=2cm,width=18cm]{qu11}
\end{question}
\begin{proof}
From last question, we know the two vectors $u,v$ that are respectively perpendicular to  $P:5x+3y+2z-4=0$ and  $Q:3x+4y-7z=0$ respectively have the direction 
 \begin{align*}
   (5,3,2)\text{ and }(3,4,-7)
\end{align*}
Then, we see the angle of the intersection are 
\begin{align*}
\arccos \frac{5\cdot 3+3\cdot 4 +2 \cdot (-7)}{\sqrt{5^2+3^2+2^2} \sqrt{3^2+4^2+7^2} }=\arccos \frac{13}{\sqrt{38}\sqrt{71}  }
\end{align*}
Notice that this angle is smaller than $\frac{\pi}{2}$ as we intend it to be. 
\end{proof}
\begin{question}{}{}
\includegraphics[height=4cm,width=18cm]{qu12}
\end{question}
\begin{proof}
Let $v=(x,y,z)$ be a point on the line of intersection.  We see the vector  $v-(x_0,y_0,z_0)$ lies on both planes, and thus must be perpendicular to $(a_1,b_1,c_1)=v_1$ and $(a_2,b_2,c_2)=v_2$ thus satisfying 
\begin{align*}
v-(x_0,y_0,z_0)=tv_1\times v_2=tu\text{ for some $t\inr$ }
\end{align*}
sine in $\R^3$, the only direction perpendicular to both  $v_1,v_2$ is  $v_1\times v_2$. We can rewrite the above equation of course into 
\begin{align*}
x-x_0=u_1t,y-y_0=u_2t,z-z_0=u_3t
\end{align*}
\end{proof}
\section{Fundamental Theorem of Local Curves}
\begin{mdframed}
In this section, by an \textbf{orthogonal transformation} we mean a linear transformation $M$ from  $\big(V,\langle \cdot,\cdot\rangle_V  \big)$ to $\big(W,\langle \cdot,\cdot\rangle_W  \big)$ such that 
\begin{align*}
\hspace{3cm}\langle v,w\rangle_V =\langle Mv,Mw\rangle_W\hspace{2cm}(v,w \in V)
\end{align*}
By a \textbf{rigid motion} $M$, we mean an orthogonal transformation from $\R^3$ to  $\R^3$ such that 
\begin{align*}
\text{det}\big([M]_{\set{e_1,e_2,e_3}} \big)>0
\end{align*}
\end{mdframed}
\begin{theorem}
\textbf{(Fundamental Theorem of Local Curves: Uniqueness Part 1)} Given an $\underline{\text{open}}$ interval $I \subseteq \R$, a parametrized by arc-length curve $\alpha :I \rightarrow \R^3$ with positive curvature, a rigid motion $M$ and a vector  $c \inr^3$, we see that the function  $\beta : I \rightarrow \R^3 $ defined by 
\begin{align*}
\beta (s)=(M \circ \gamma )(s)+c
\end{align*}
is a curve parametrized by arc-length such that 
\begin{align*}
\alpha \text{ and }\beta \text{ has the same curvature and torsion on all $s \in I$ }
\end{align*}
\end{theorem}
\begin{proof}
We first have to prove 
\begin{align*}
\vi{\beta :I\rightarrow \R^3\text{ is parametrized by arc-length }}
\end{align*}
Fix $s \in I$. We have to prove 
\begin{align*}
\vi{\abso{\beta '(s)}=1}
\end{align*}
Compute 
\begin{align*}
\abso{\beta '(s)}&=\abso{(M\circ \gamma )'(s)}\\
&=\abso{}\vdone
\end{align*}
We now prove 
\begin{align*}
\blue{\beta '(s)}
\end{align*}

Because we have the identity 
\begin{align*}
\kappa (s)=\abso{\alpha ''(s)}\text{ and }\tau (s)=-\frac{(\alpha '\times \alpha '')\cdot \alpha '''}{\kappa^2}
\end{align*}
\end{proof}
\begin{theorem}
\label{FTLCU}
\textbf{(Fundamental Theorem of Local Curves: Uniqueness Part 2)} Given an $\underline{\text{open}}$ interval $I \subseteq \R$ and two parametrized by arc-length curves $\alpha ,\overline{\alpha }:I\rightarrow \R^3$ such that 
\begin{align*}
\hspace{3cm}\kappa(s)=\overline{\kappa}(s)\text{ and }\tau(s)=\overline{\tau}(s)\hspace{2cm}(s \in I)
\end{align*}
Then there exists an rigid motion $M$ and a vector  $c \inr^3$ such that 
\begin{align*}
\hspace{3cm}\alpha (s)=M\big(\overline{\alpha }(s) \big)+c\hspace{2cm}(s \in I)
\end{align*}
\end{theorem} 
\begin{proof}
Fix distinct $s_0\in I$. We first have to 
\begin{align*}
  \vi{\text{ find a rigid motion $M:\R^3\rightarrow \R^3$ and some vector $c\inr^3$ }}\\
\vi{\text{ such that $\begin{cases}
  \alpha (s_0)=(M\circ \overline{\alpha })(s_0)+c\\
  T(s_0)=M\circ \overline{T}(s_0)\\
  N(s_0)=M\circ \overline{N}(s_0)\\
  B(s_0)=M\circ \overline{B}(s_0)
\end{cases}\vdone$}}
\end{align*}
Now, express 
\begin{align*}
T_M(s)=\text{ normal tangent of }M\circ \overline{\alpha }+c\text{ at $s$ }
\end{align*}
We show 
\begin{align*}
\blue{\begin{cases}
  T_M=T\\
  N_M=N\\
  B_M=B
\end{cases}\text{ on $I$ }}
\end{align*}
By Frenet Formula, compute 
\begin{align*}
&\frac{1}{2}\frac{d}{ds}\Big(\abso{T-T_M}^2+ \abso{N-N_M}^2+\abso{B-B_M}^2 \Big)\\
=&\frac{1}{2}\frac{d}{ds}\Big(\sum_{X=T,N,B} (X-X_M)\cdot (X-X_M)\Big)\\
=&\sum_{X=T,N,B} (X-X_M)'\cdot (X-X_M)\\
=&\sum_{X=T,N,B} (X'-X_M')\cdot (X-X_M)\\
=&(T'-T'_M)\cdot (T-T_M)+(N'-N'_M)\cdot (N-N_M)+(B'-B_M')\cdot (B-B_M)\\
 &\\
=&(\kappa N'-\kappa N'_M)\cdot (T-T_M)\\
+\Big)&\big(-\kappa T-\tau B+\kappa T_M'+\tau BT'_M \big)\cdot (N-N_M)\\
+\Big)& \big(\tau N-\tau N_M\big)\cdot (B-B_M)\hspace{1cm}(\because \text{ Frenet Formula and $\alpha ,\alpha _M$ same curvature and torsion})\\
=&0\hspace{1cm}(\because\text{ Elimination })
\end{align*}
We now know 
\begin{align*}
\abso{T-T_M}^2+\abso{N-N_M}^2+\abso{B-B_M}^2\text{ is a constant }
\end{align*}
Moreover, because by our setting  
\begin{align*}
\Big( \abso{T-T_M}^2+\abso{N-N_M}^2+\abso{B-B_M}^2\Big)(s_0)=0
\end{align*}
We know 
\begin{align*}
\hspace{3cm}\abso{T-T_M}^2+\abso{N-N_M}^2+\abso{B-B_M}^2=0\hspace{1cm}(s \in I)
\end{align*}
This implies 
\begin{align*}
\begin{cases}
  T=T_M\\
  N=N_M\\
  B=B_M
\end{cases}\text{ on $I\bdone$ }
\end{align*}
Because both  $\alpha $ and $\alpha _M$ are parametrized by arc-length and $\alpha (s_0)=\alpha _M(s_0)$, we now see 
\begin{align*}
\hspace{2cm}\alpha (s)=\int_{s_0}^s T(x)dx+ \alpha (s_0)=\int_{s_0}^s T_M(x)dx+ \alpha_M(s_0)=\alpha_M(s)\hspace{1cm}(s \in I)
\end{align*}
This finish the proof. 
\end{proof}

\section{Isoperimetric Inequality}
\begin{mdframed}
In this section, by \textbf{a closed plane curve}, we mean a regular parametrized curve $\alpha :[a,b]\rightarrow \R^2$ such that 
\begin{align*}
\alpha^{(n)}(a)=\alpha^{(n)}(b)\text{ for all $n\inz_0^+$ }
\end{align*}
If we say a closed plane curve $\alpha :[a,b]\rightarrow \R^2$ is \textbf{simple}, we mean 
\begin{align*}
\alpha (t_1)\neq \alpha (t_2)\text{ for all distinct pair $(t_1,t_2) \subseteq [a,b]$ except $(a,b)$}
\end{align*}
A closed plane curve must divide $\R^2$ into two separate subsets, in the sense that  $\R^2 \setminus \alpha \big[[a,b] \big]$ has two connected component. The one connected component that has finite area in the sense of Lebesgue outer measure is called the \textbf{interior} of the $\alpha $. If the interior is always on the left side of $\alpha $, we say $\alpha $ is \textbf{positively oriented}, in other words, $\alpha $ runs counter clockwise ($\begin{vmatrix} 
\alpha '\\
\alpha ''
\end{vmatrix} \geq 0$).
\end{mdframed}
\begin{theorem}
\textbf{(Green's Theorem)} Given a  $\underline{\text{positively oriented, piecewise smooth,}}$\\ $\underline{\text{simple closed plane}}$ curve $\alpha :[a,b]\rightarrow \R^2$, where $C$ is the image of $\alpha $  and $D$ is the region bounded by $C$, and two function  $L,M:D\rightarrow \R$ that has continuous partial derivative, we have 
\begin{align*}
\oint_C L dx+Mdy =\iint_D (M_x-L_y) dA
\end{align*}
\end{theorem}
\begin{mdframed}
If we $\underline{\text{define}}$ area for bounded \textbf{region} $D$ by 
\begin{align*}
A(D)\triangleq \iint_D 1dA
\end{align*}
Green's Theorem give us 
\begin{align*}
  A(D)&=\oint_C xdy =\oint_C -ydx =\oint_C \frac{-y}{2}dx+\frac{x}{2}dy\\
  &=\int_a^b x(t)y'(t)dt=\int_a^b -x'(t)y(t)dt =\frac{1}{2}\int_a^b (xy'-y'x)dt
\end{align*}
\end{mdframed}
\begin{theorem}
  \label{IIPI}
\textbf{(Isoperimetric Inequality: Part 1)} Let $C$ be a piece-wise $C^1$ simple closed curve with length  $l$, and let  $A$ be the area of the region bounded by  $C$. Then 
 \begin{align*}
A\leq \frac{l^2}{4\pi}
\end{align*}
\end{theorem}
\begin{proof}
Parametrize $C$  with $\big(x(t),y(t) \big):[a,b]\rightarrow \R^2$. Because $x:[a,b]\rightarrow \R$ is a continuous function, by EVT, we know there exists $c',d \in [a,b]$ such that 
\begin{align*}
x(c')=\min _{t\in [a,b]}x(t) \text{ and }x(d)=\max_{t\in [a,b]}x(t)
\end{align*}
Now, let $\gamma :[0,l]$ be a positively oriented arc-length parametrization such that 
\begin{align*}
\gamma (l)=\gamma (0)\triangleq x(d)
\end{align*}
Let $c \in [0,l]$ satisfy 
\begin{align*}
\gamma (c)\triangleq x(c')
\end{align*}
Let $S$ be a circle such that 
\begin{align*}
S\text{ has the radius }r=\frac{\gamma (0)-\gamma (c)}{2}
\end{align*}
We first show 
\begin{align}
  \vi{A+\pi r^2\leq lr}
\end{align}
We translate $S$ so that $S$ centers at origin, and translate  $C$ so that  $\gamma (0)$ has value $(r,0)$ .  Note that such translation does not change area, which can be verified using change of variable.\\

Now, we know $S=\set{(x,y):x^2+y^2=r^2}$. If we parametrize $S$ by  $(r\cos t, r\sin t)$, with Green's Theorem, we see 
\begin{align*}
A(S)&=\oint (r\cos t)(d r\sin t)\\
&=\int_0^{2\pi} (r^2\cos^2 t )dt\\
&=\int_0^{2\pi } r^2\cdot \frac{\cos 2t+1}{2}=r^2\pi 
\end{align*}
Now, express $\gamma (s)$ by
\begin{align*}
\gamma (s)=(x(s),y(s))
\end{align*}
We positively oriented parametrize $S$ by 
\begin{align*}
\alpha (t)\triangleq (x(t),\overline{y}(t)) 
\end{align*}
We now prove 
\begin{align}
\label{pir2}
  \olive{\pi r^2 = -\int_0^l \overline{y}x'ds  }
\end{align}
By Green's Theorem 
\begin{align*}
\pi r^2=A(S)=\oint -\overline{y}dx=\int_0^l -\overline{y}x'ds \odone
\end{align*}
We now prove 
\begin{align}
\label{sqxy}
\blue{(xy'-\overline{y}x')^2 \leq \big(x^2+(\overline{y})^2 \big)\big( (x')^2+(y')^2\big)}
\end{align}
Using Cauchy-Schwarz Inequality on $(x,\overline{y})$ and $(y',-x')$. We see
\begin{align}
  (xy'-\overline{y}x')^2&=\abso{(x,\overline{y})\cdot (y',-x')}^2\notag\\
                        &\leq \abso{(x,\overline{y})}^2 \cdot \abso{(y',-x')}^2\\ \label{CSxy}
  &=\big(x^2+(\overline{y})^2 \big)\big((x')^2+(y')^2 \big)\notag\bdone
\end{align}


Now, because 
\begin{enumerate}[label=(\alph*)]
  \item Green's Theorem
  \item \myref{Equation}{pir2}
  \item \myref{Equation}{sqxy}
  \item $C=(x,y)$ is parametrized by arc-length
  \item $S=(x,\overline{y})$ is a circle of radius $r$ 
\end{enumerate}
we have
\begin{align}
A+ \pi r^2 &= \int_0^l xdy -\int_0^l \overline{y}x'ds\notag\\
&=\int_0^l xy'-\overline{y}x'ds\notag\\
&\leq \int_0^l \sqrt{(xy'-\overline{y}x')^2}\notag ds\\
&\leq \int_0^l \sqrt{\big(x^2+(\overline{y})^2 \big)\big((x')^2+(y')^2 \big)}\notag ds \\
&\leq \int_0^l \sqrt{x^2+(\overline{y})^2}ds\notag \\
&\leq \int_0^l rds =rl \vdone \label{A+pi}
\end{align}
Lastly, we show 
\begin{align*}
  \blue{A\leq \frac{l^2}{4\pi}}
\end{align*}
By AM-GM inequality and \myref{Equation}{A+pi}, we now can deduce
\begin{align}
\label{AM}
  \sqrt{A\pi r^2}\leq \frac{A+\pi r^2}{2}\leq \frac{rl}{2}
\end{align}
This let us deduce 
\begin{align*}
A\leq \frac{l^2}{4\pi}\bdone
\end{align*}
\end{proof}
\begin{theorem}
\textbf{(Isoperimetric Inequality: Part 2)} Let $C$ be a piece-wise $C^1$ simple closed curve with length  $l$, and let  $A$ be the area of the region bounded by  $C$. We have 
\begin{align*}
A=\frac{l^2}{4\pi}\implies C\text{ is a circle }
\end{align*}
\end{theorem}
\begin{proof}
Do exactly the same thing in the proof of \myref{First part of Isoperimetric Inequality}{IIPI} on $C$.\\

We wish to prove 
\begin{align*}
  \vi{x^2+y^2=r^2}
\end{align*}
Because 
\begin{align*}
A=\frac{l^2}{4\pi}\implies A\pi r^2=(\frac{rl}{2})^2 \implies \sqrt{A\pi r^2}=\frac{rl}{2} 
\end{align*}
Then from \myref{Equation}{AM}, we deduce
\begin{align*}
\sqrt{A\pi r^2}=\frac{A+ \pi r^2 }{2}
\end{align*}
Then because AM-GM inequality become an equality only when two sides equals, we now have 
\begin{align*}
A=\pi r^2\text{ and }l=2\pi r
\end{align*}
This let us deduce 
\begin{align*}
A+\pi r^2=2\pi r^2=2rl
\end{align*}
Then by \myref{Equation}{A+pi}, we can deduce 
\begin{align*}
\abso{(x,\overline{y})\cdot (y',-x')}^2&=(xy'-\overline{y}x')^2\\
  &=\big(x^2+(\overline{y})^2 \big)\big((x')^2+(y')^2 \big)\\
  &=\abso{(x,\overline{y})}^2 \cdot \abso{(x',y')}^2
\end{align*}
Because Cauchy-Schwarz inequality become an equality only when two vectors are linearly independent, we know there exist $\ld \inr$ such that 
\begin{align*}
  (x,\overline{y})=\ld (y',-x')
\end{align*}
This let us deduce 
\begin{align}
\label{ldxy}
\ld =\frac{x}{y'}=\frac{\overline{y}}{-x'}\text{ and }\ld =\frac{\sqrt{x^2+(\overline{y})^2}
 }{\sqrt{(y')^2 + (x')^2}}
\end{align}
Now, because $\gamma =(x,y)$ is parametrized by arc-length and $(x, \overline{y})$ form the circle $S$ with radius $r$, from \myref{Equation}{ldxy}, we have 
\begin{align}
\label{ldsq}
\ld = \sqrt{x^2+(\overline{y})^2} =r
\end{align}
Then from \myref{Equation}{ldxy} and \myref{Equation}{ldsq}, we can deduce 
\begin{align*}
\frac{x}{y'}=\frac{\overline{y}}{-x'}=\ld  =r
\end{align*}
This then give us 
\begin{align*}
x=ry' 
\end{align*}
Now, do exactly the same thing in the proof of \myref{First part of Isoperimetric Inequality}{IIPI}, except, at this time, we parametrize $S$ by  $(\overline{x},y)$. The similar argument then went on and give us 
\begin{align*}
y=rx'
\end{align*}
Finally, because $\gamma =(x,y)$ is parametrized by arc-length, we have
\begin{align*}
x^2+y^2=r^2\big((y')^2+(x')^2 \big)=r^2\vdone
\end{align*}

\end{proof}
\section{Four Vertices Theorem}
\begin{mdframed}

\end{mdframed}

\section{HW2}

\begin{question}{}{}
\includegraphics[height=10cm,width=18cm]{hw2q5}
\end{question}
\begin{proof}
\textbf{(a)}
By computation 
\begin{align*}
\alpha '(s)=(\frac{-a}{c} \sin \frac{s}{c},\frac{a}{c}\cos \frac{s}{c},\frac{b}{c}) 
\end{align*}
So 
\begin{align*}
\abso{\alpha '(s)}=\sqrt{\frac{a^2+b^2}{c^2}}=1\hspace{3cm}(\because \text{ $\sin^2+\cos^2=1$ })
\end{align*}
This shows $\alpha $ is parametrized by arc-length.\\

\textbf{(b)}
By computation 
\begin{align*}
\alpha ''(s)=\Big(\frac{-a}{c^2} \cos \frac{s}{c}, \frac{-a}{c^2} \sin \frac{s}{c},0\Big)
\end{align*}
Then because $\alpha $ is parametrized by arc-length, we have 
\begin{align*}
\kappa(s)=\abso{\alpha ''(s)}&= \sqrt{\frac{a^2}{c^4}}\\
&=\frac{\abso{a}}{c^2}
\end{align*}
By computation 
\begin{align*}
\alpha '''(s)=\Big(\frac{a}{c^3}\sin \frac{s}{c}, \frac{-a}{c^3} \cos \frac{s}{c},0 \Big)
\end{align*}
Then using the identity of torsion, we have 
\begin{align*}
\tau (s)&=- \frac{- \big(\alpha '(s)\times \alpha ''(s) \big)\cdot \alpha '''(s)}{\abso{\kappa (s)}^2}\\
&=-\frac{\frac{a^2b}{c^6}}{\frac{a^2}{c^4}}\\
&=\frac{b}{-c^2}
\end{align*}
\textbf{(c)}
Fix $s$. Define a set $A$  by 
\begin{align*}
A=\text{span}\Big(\alpha '(s),\alpha ''(s) \Big)
\end{align*}
The osculating plane of $\alpha $ at $s$ is then exactly 
\begin{align*}
\set{a+\alpha (s): a \in A}
\end{align*}
\textbf{(d)}
Because $\alpha ''(s)$ by our computation is valued $0$ in  $z$-opponent, we know if the line containing  $N$ and passing through $\alpha $ meet the $z$ axis, it must be under a constant angle equal to  $\frac{\pi}{2}$. (use dot product to check this fact.).\\

Now, we only have to prove that the line does meet the $z$-axis. See that 
\begin{align*}
\alpha + c^2 \alpha ''=\Big(0,0,b\frac{s}{c} \Big)
\end{align*}
and we are done.

\textbf{(e)}
Observe that 
\begin{align*}
\alpha ' \cdot \Big(0,0,1 \Big)=\frac{b}{c}\text{ is a constant }
\end{align*}
This together with the fact $\abso{\alpha '}$ is a constant show that the angle between the tangent to $\alpha $ and $z$-axis is a constant.

\end{proof}
\begin{question}{}{}
\includegraphics[height=3cm,width=18cm]{hw2q4}
\end{question}
\begin{theorem}
\textbf{(Identity of Torsion)} Given a parametrized by arc-length cruve $\alpha  :I \rightarrow \R^3$, we have 
\begin{align*}
\tau(s)=-\frac{\big(\alpha '(s)\times \alpha ''(s) \big)\cdot \alpha '''(s)}{\kappa ^2 (s)}
\end{align*}
\end{theorem}
\begin{proof}
Because $\underline{\alpha  \text{ is parametrized by arc-length}}$, we have 
\begin{align*}
  \alpha '(s)=T(s)
\end{align*}
We first show 
\begin{align}
\label{A'''}
\vi{\alpha ''(s)=\kappa (s)N(s)}
\end{align}
Compute 
\begin{align*}
N(s)&=\frac{T'(s)}{\abso{T'(s)}}\\
&=\frac{\alpha ''(s)}{\abso{\alpha ''(s)}}=\frac{\alpha ''(s)}{\kappa (s)}\vdone
\end{align*}
We now show 
\begin{align*}
\blue{\alpha '''(s)=\kappa(s)\big(-(\tau B)(s)-(\kappa T)(s)\big)+\kappa'(s)N(s) }
\end{align*}
By \myref{Equation}{A'''} and Frenet Formula, we have 
\begin{align*}
\alpha '''(s)&=\kappa'(s)N(s)+\kappa(s)N'(s)\\
&=\kappa'(s)N(s)+\kappa(s)\big(- (\tau B)(s)-(\kappa T)(s) \big)\bdone
\end{align*}
Lastly, we verify 
\begin{align*}
-\frac{\big(\alpha '(s)\times \alpha ''(s) \big)\cdot \alpha '''(s)}{\kappa^2(s)}&=-\frac{(T\times \kappa N)\cdot \Big( \kappa \big(-\tau B-\kappa T \big)+\kappa ' N\Big) }{\kappa ^2}\\
&=-\frac{-\kappa^2 \tau (T\times N)\cdot B }{\kappa^2}\hspace{1cm}(\because T\times N \cdot (T\text{ or }N)=0)\\
&=\tau 
\end{align*}
\end{proof}
\begin{question}{}{}
\includegraphics[height=1.5cm,width=18cm]{hw2q3}
\includegraphics[height=4cm,width=18cm]{hw2q2}
\end{question}
\begin{proof}
\textbf{(a)}\\

The indicatrix of tangents $\gamma :I \rightarrow \R^2$ is defined by 
\begin{align*}
\gamma = \frac{\alpha '(s)}{\abso{\alpha '(s)}}
\end{align*}
Express $\alpha '(s)$ by 
\begin{align*}
\alpha ' \triangleq (x,y)
\end{align*}
To show $\gamma $ is regular. We wish to show 
\begin{align*}
  \vi{\gamma '(s)\neq 0\text{ for all $s \in I$ }}
\end{align*}
Express $\gamma $ by 
\begin{align*}
\gamma =\frac{(x,y)}{\sqrt{x^2+y^2} }
\end{align*}
Then, we see the $x$-component of  $\gamma '(s)$ is 
\begin{align*}
\gamma '(s)\Big|_x= \frac{x'y^2}{(x^2+y^2)^{\frac{3}{2}}}
\end{align*}
With similar computation on the $y$-component, we now arrive at 
 \begin{align*}
\gamma '(s)=\frac{\Big(x'y^2,y'x^2 \Big)}{(x^2+y^2)^{\frac{3}{2}}}
\end{align*}
Now, for a contradiction, \As{$\gamma '(s)=0$ for some $s$}. Then one of the three things below must happen 
\begin{enumerate}[label=(\alph*)]
  \item $x'=y'=0$ 
  \item $y^2=x^2=0$ 
  \item $x'=x^2=0$ WLOG
\end{enumerate}
Because $(x,y)=\alpha '$ and $\alpha $ is parametrized by arc-length and  curvature is non-zero by premise, we know it can not happen $\alpha ''=(x',y')=0$.\\

Because $(x,y)=\alpha '$ and $\alpha $ is parametrized by arc-length, we also know it can not happen $\alpha '=(x,y)=0$.\\

Now, we are given the hypothesis $x'=x^2=0$. Because $\alpha$ is parametrized by arc-length, from $x=0$, we know  $y=\pm 1$.  Then because $\abso{\alpha '}$ is constant, we can deduce
\begin{align*}
  0&=(x',y')\cdot (x,y)\\
  &=(0,y')\cdot (0,\pm 1)
\end{align*}
This show us $y'=0$, which is impossible, since if  $(x',y')=0$ then the curvature is $0\tCaC\vdone$\\

\textbf{(b)}
The functions $\theta : [0,l]\rightarrow \R$, is defined by  
\begin{align*}
 T= (x,y)\triangleq (\cos \theta, \sin \theta)
\end{align*}
By Frenet Formula, we have 
\begin{align}
\label{kN=}
\kappa N=T'= \theta' (- \sin \theta , \cos \theta)
\end{align}
Because $\abso{(-\sin \theta, \cos \theta)}=1$ and $(- \sin \theta ,\cos \theta)\cdot T=0$ and  
 \begin{align*}
\begin{vmatrix} 
  \cos \theta & \sin \theta\\
  - \sin \theta & \cos \theta
\end{vmatrix}=1
\end{align*}
we can identify $(-\sin \theta, \cos \theta)=N$. Then from \myref{Equation}{kN=}, we now can deduce 
\begin{align*}
\kappa =\theta' 
\end{align*}



\end{proof}
\begin{question}{}{}
\includegraphics[height=10cm,width=18cm]{hw2q1}
\end{question}
\begin{proof}
Let $A$ be a translation and $\rho$ be an orthogonal transformation.\\

\textbf{(a)}
Observe
\begin{align*}
\norm{v}&= \sqrt{ v \cdot  v} \\
&=\sqrt{\rho v \cdot \rho v}\\
&=\norm{\rho v}
\end{align*}
Because $\theta$ is given by 
\begin{align*}
\theta= \arccos \frac{v \cdot w}{ \abso{v}\cdot \abso{w}}
\end{align*}
and because norm is invariant under orthogonal transformation, from the definition of orthogonal transformation, we now see 
 \begin{align*}
\theta &= \arccos \frac{v \cdot w}{\abso{v}\cdot \abso{w}}\\
&=\arccos \frac{\rho v \cdot \rho w}{\abso{v}\cdot \abso{w}}\\
&=\arccos \frac{\rho v \cdot \rho w}{\abso{\rho v}\cdot \abso{\rho w}}=\theta_\rho\\
\end{align*}
where $\theta_\rho$ is the angle between $\rho v$ and $\rho w$. \\

\textbf{(b)}
Fix $v,w \inr^3$ and a positive determinant orthogonal transformation $\rho$. We wish to show 
\begin{align*}
\vi{\rho v \times \rho w = \rho(v \times w)}
\end{align*}
We can reduce the problem into proving 
\begin{align*}
\vi{\rho v \times \rho w \cdot z = \rho (v \times w) \cdot z\text{ for all $z \inr^3$ }}
\end{align*}
Fix $z \inr^3$. Because $\rho$ has non-zero determinant, we know there exists $z' \inr^3$ such that 
\begin{align*}
\rho z'=z
\end{align*}
Now, because orthogonal transformation has determinant  $\pm 1$ and we have know  $\rho$ has positive determinant, we know
\begin{align*}
\rho v \times \rho w \cdot z&=\rho v \times \rho w \cdot \rho z'\\
&=\begin{vmatrix} 
\rho v\\
\rho w\\
\rho z'\end{vmatrix} \\
&= \begin{vmatrix} 
  \rho v & \rho w & \rho z'
\end{vmatrix}\hspace{1cm}(\because \text{det}A=\text{det}A^t)\\
&=\abso{\rho} \cdot \begin{vmatrix} 
  v & w & z'
\end{vmatrix}\hspace{1cm}(\because \text{det}A\text{det}B=\text{det}AB)\\
&=\begin{vmatrix} 
v \\
w \\
z'
\end{vmatrix}\hspace{1cm}(\because \text{det}\rho=1)\\
&=v \times w \cdot z'\\
&=\rho (v \times w) \cdot \rho z'\\
&= \rho (v \times w)\cdot z \vdone
\end{align*}
The assertion is clearly false if the determinant is negative. One can check $v=(1,0,0)$ and $w=(0,1,0)$ and $\rho(x,y,z)=(-x,y,z)$. \\

\textbf{(c)}
We first show arc length is invariant under rigid motion. We first show 
\begin{align*}
\vi{\text{ arc length is invariant under orthogonal transformation }}
\end{align*}
To show such, we only have to show 
\begin{align*}
  \vi{\abso{(\rho \circ \gamma )'}=\abso{\gamma '}}
\end{align*}
\end{proof}
Fix $y \in I$. We have
\begin{align*}
\abso{\gamma '(y)}= \abso{\lim_{t\to y}\frac{\gamma (t)-\gamma (y)}{t-y}}=\lim_{t\to y} \abso{\frac{\gamma (t)-\gamma (y)}{t-y}} 
\end{align*}
Notice that in above deduction, we exchange limit and norm. Such exchange hold true because the function inside is continuous.\\

Similarly, we have 
\begin{align*}
\abso{(\rho \circ \gamma )'(y)}=\lim_{t\to y} \abso{\frac{\rho \circ \gamma (t)-\rho \circ  \gamma (y)}{t-y}}
\end{align*}
Then, we can reduce the problem into 
\begin{align*}
\vi{\text{proving} \abso{\gamma (t)-\gamma (y)}=\abso{\rho \circ \gamma (t)-\rho \circ \gamma (y)}}
\end{align*} 
Because $\rho:\R^3\rightarrow \R^3$ is an orthogonal transformation (a linear transformation too), we can deduce 
\begin{align*}
\abso{\rho \circ \gamma (t)-\rho \circ  \gamma (y)}&=\abso{\rho \big(\gamma (t)-\gamma (y) \big)}\\
&=\abso{\gamma (t)-\gamma (y)}\vdone
\end{align*}
We have proved arc-length is invariant under orthogonal transformation. With some simple computation, it is clear that arc-length is invariant under translation. This let us conclude arc length is invariant under rigid motion.\\

Now, to show curvature and torsion are also invariant under rigid motion. We first recall the following identities for curve parametrzied by arc-length 
\begin{align*}
\kappa = \abso{\gamma ''}\text{ and }\tau = -\frac{\gamma ' \times \gamma '' \cdot \gamma '''}{\kappa ^2}
\end{align*}
We now prove 
\begin{align*}
\blue{\text{ curvature is invariant under rigid motion }}
\end{align*}
Notice that $\gamma '$ is invariant under translation, so in fact, we only have to prove 
\begin{align*}
\blue{\text{ curvature is invariant under orthogonal transformation }}
\end{align*}
Observe 
\begin{align*}
\abso{\gamma ''(y)}=\abso{\lim_{t\to y}\frac{\gamma '(t)-\gamma '(y)}{t-y}}=\lim_{t\to y}\abso{\frac{\gamma '(t)-\gamma '(y)}{t-y}}
\end{align*}
and 
\begin{align*}
\abso{(\rho \circ \gamma )''(y)}&=\lim_{t\to y}\abso{\frac{(\rho \circ \gamma )'(t)-(\rho\circ \gamma )'(y)}{t-y}}
\end{align*}
We can now reduce the problem into proving 
\begin{align*}
  \blue{\abso{\gamma '(t)-\gamma '(y)}=\abso{(\rho \circ \gamma )'(t)-(\rho \circ \gamma )'(y)}}
\end{align*}
Because $\rho$ is a linear transformation, we can compute 
\begin{align}
\label{rho'}
(\rho \circ \gamma )'(t)&=\lim_{u\to t} \frac{\rho \circ \gamma (u)-\rho \circ \gamma (t)}{u-t}\notag\\
&=\lim_{u\to t}\rho\Big( \frac{\gamma (u)-\gamma (t)}{u-t}\Big)\notag\\
&=\rho\lim_{u\to t}\Big( \frac{\gamma (u)-\gamma (t)}{u-t}\Big)=\rho \circ \gamma '(t)
\end{align}
We now using the fact norm is invariant under orthogonal transformation to compute 
\begin{align*}
\abso{(\rho \circ  \gamma )'(t)-(\rho \circ \gamma )'(y)}&= \abso{\rho \circ \gamma '(t)-\rho \circ  \gamma '(y)}\\
&=\abso{\rho \big(\gamma '(t)-\gamma '(y) \big)}\\
&=\abso{\gamma '(t)-\gamma '(y)}\bdone
\end{align*}
Now, notice that in \myref{Equation}{rho'}, we just proved 
\begin{align*}
 (\rho \gamma )'=\rho \gamma '
\end{align*}
Iterating the same argument, we can show
\begin{align*}
  (\rho \gamma )''&=\big((\rho \gamma )' \big)'\\
  &=(\rho \gamma ')'\\
  &=\rho \gamma ''
\end{align*}
and also show
\begin{align*}
  (\rho \gamma )'''&= \big((\rho \gamma )'' \big)'\\
  &=(\rho \gamma '')'\\
  &=\rho \gamma '''
\end{align*}
We now using the fact that $\abso{\rho}=1$ to compute  
\begin{align*}
  (\rho \gamma )' \times (\rho \gamma )'' \cdot (\rho \gamma )'''&= \begin{vmatrix} 
    (\rho \gamma )' & (\rho \gamma )'' & (\rho \gamma )'''
  \end{vmatrix}\\
 &=\begin{vmatrix}  \rho \gamma ' & \rho \gamma '' & \rho \gamma'''\end{vmatrix}\\
 &=\begin{vmatrix} 
\rho \begin{bmatrix}
  \gamma ' & \gamma '' & \gamma '''
\end{bmatrix}
 \end{vmatrix}\\
 &=\abso{\rho}\cdot \begin{vmatrix} 
   \gamma ' & \gamma '' & \gamma '''
 \end{vmatrix}\\
 &=\gamma ' \times \gamma '' \cdot \gamma '''
\end{align*}
Above computation with identity of torsion and the fact curvature is invariant under orthogonal transformation with positive determinant then show that torsion is also invariant under orthogonal transformation with positive determinant.\\

Because $(\gamma +c)'=\gamma '$, together with what we have proved, it is easy to check torsion is also invariant under rigid motion. 
\begin{question}{}{}
\includegraphics[height=6cm,width=18cm]{hw2q18}
\end{question}
\begin{proof}
By Fundamental Theorem of Local Curves (you can think of our application as identifying $\tau=0$), we know if such curve exists then it is unique up to translation and rotation. This reduced our proof into showing 
\begin{align*}
\vi{\alpha \text{ has curvature $\kappa$ }}
\end{align*}
Compute 
\begin{align*}
\alpha '=(\cos \theta, \sin \theta)
\end{align*}
This shows that $\alpha $ is parametrized by arc-length, and shows that we can compute
\begin{align*}
\abso{\alpha ''}&=\abso{\theta ' (- \sin \theta, \cos \theta)}\\
&=\abso{\theta'}=\abso{\kappa}=\kappa \vdone
\end{align*}
\end{proof}
\begin{question}{}{}
\includegraphics[height=6cm,width=18cm]{hw2q17}
\end{question}
\begin{proof}
\textbf{(a)}

Parametrize by 
\begin{align*}
  \alpha (\theta)\triangleq (x,y)\triangleq (r \cos \theta, r \sin \theta)
\end{align*}
where $r(\theta)$ is a function. With respect to $\theta$, we compute 
\begin{align*}
  (x')^2+(y')^2&=(r'\cos \theta-r\sin \theta)^2+(r' \sin \theta + r \cos \theta)^2\\
  &=(r')^2 \cos ^2 \theta + r^2 \sin ^2 \theta + (r')^2 \sin ^2 \theta + r^2 \cos ^2 \theta \hspace{1cm}(\because \text{ elimination })\\
  &=r^2+(r')^2 
\end{align*}
We now see that the arc-length can be computed by 
\begin{align*}
\int_a^b \abso{\alpha '(\theta)}d\theta&= \int_a^b \sqrt{(x')^2+(y')^2}d\theta \\
&=\int_a^b \sqrt{r^2 +(r')^2}d\theta 
\end{align*}

\textbf{(b)}\\

Recall that 
\begin{align*}
\kappa(t) = \frac{x'y''-x''y'}{\big((x')^2 + (y')^2 \big)^{\frac{3}{2}}}
\end{align*}
plugin 
\begin{align*}
  (x',y')&=(r'\cos \theta -r \sin \theta, r' \sin \theta + r \cos \theta)\\
  (x'',y'')&=(r''\cos \theta -2r' \sin \theta -r\cos \theta, r'' \sin \theta + 2r' \cos \theta  -r \sin \theta)
\end{align*}
To compute 
\begin{align*}
x'y''&= r'r''\cos \theta \sin \theta + 2(r')^2 \cos ^2 \theta -rr'\cos \theta \sin \theta -r r'' \sin ^2 \theta -2rr' \cos \theta \sin \theta +r^2 \sin ^2 \theta\\
x''y'&=r'r''\sin \theta \cos \theta - 2(r')^2 \sin ^2 \theta -rr' \cos \theta \sin \theta +rr'' \cos ^2 \theta - 2rr' \cos \theta \sin \theta  -r^2 \cos ^2 \theta
\end{align*}
Eliminating the odd terms and using $\cos^2+\sin^2=1$, we now compute 
\begin{align*}
\kappa&=\frac{x'y''-x''y'}{\big((x')^2 +(y')^2\big)^{\frac{3}{2}}}\\
&=\frac{2(r')^2-2rr''+r^2}{\big(r^2+(r')^2 \big)^{\frac{3}{2}}}
\end{align*}
\end{proof}

\begin{question}{}{}
\includegraphics[height=8cm,width=18cm]{hw2q16}
\end{question}
\begin{proof}
\textbf{(a)}
$(\longrightarrow)$\\

Because $\alpha $ is a helix, we know there exists fixed unit $a \inr^3$ and $b \inr$ such that 
\begin{align*}
\alpha '  \cdot a =b \text{ for all $s$ }
\end{align*}
This then implies 
\begin{align*}
\alpha '' \cdot a = 0\text{ for all $s$ }
\end{align*}
which implies 
\begin{align*}
N\cdot a =0
\end{align*}
since $N$ is parallel with  $\alpha ''$. Because $\set{T,N,B}$ is an orthonormal basis, this $(N\cdot a =0)$ together with $a$ being unit then tell us we can express $a$ by
\begin{align*}
a= T \cos \theta + B \sin \theta \text{ for some fixed $\theta \inr$ }
\end{align*}
We now have the information $T \cos \theta + B \sin \theta$ is a constant function  in $s$. Then, using Frenet Formula, we can deduce 
\begin{align*}
  0=(T \cos \theta + B \sin \theta)'&= \kappa N \cos \theta + \tau N \sin \theta
\end{align*}
This them implies 
\begin{align*}
\frac{\kappa}{\tau}=\frac{-\sin \theta}{\cos \theta}\text{ is a constant since $\theta $ is fixed. }
\end{align*}
Notice that $\cos \theta \neq 0$ because $\tau \neq 0$ for all $s$.\\

$(\longleftarrow)$\\

Define $\theta\inr$ by 
\begin{align*}
\theta=\arctan \frac{-\kappa}{\tau}
\end{align*}
We wish to show 
\begin{align*}
  \vi{a=T \cos \theta + B \sin \theta \text{ suffice }}
\end{align*}
Because we have 
 \begin{align*}
T\cdot a= \cos \theta 
\end{align*}
We only wish to show 
\begin{align*}
  \vi{a\text{ is a constant function in $s$ }}
\end{align*}
Because $\theta=\arctan \frac{-\kappa}{\tau}$, we know 
\begin{align*}
\frac{\sin \theta}{\cos \theta}=\tan \theta = \frac{-\kappa}{\tau}
\end{align*}
This then tell us 
\begin{align*}
\tau \sin \theta + \kappa \cos \theta =0
\end{align*}
and implies 
\begin{align*}
\tau N \sin \theta + \kappa N \cos \theta =0
\end{align*}
Then 
\begin{align*}
a'&=(T\cos \theta+ N \sin \theta)'\\
&= \kappa N \cos \theta + \tau N \sin \theta =0 
\end{align*}
This implies $a$ is indeed a constant.  $\vdone$\\

\textbf{(b)}\\

$(\longrightarrow)$\\

Let $a\inr^3$ be the unit vector such that 
\begin{align*}
T\cdot a \text{ is fixed }
\end{align*}
We now see 
\begin{align*}
N\cdot a= (T\cdot a)'=0
\end{align*}
This implies 
\begin{align*}
\text{ the plane $\set{a}^{\perp}$ suffice }
\end{align*}

$(\longleftarrow)$\\

Observe that 
\begin{align*}
&0=N \cdot a= \frac{T'}{\abso{T'}} \cdot a \\
&\implies T' \cdot a =0\\
&\implies T\cdot a\text{ is fixed }
\end{align*}

\textbf{(c)}\\

$(\longrightarrow)$\\

Because $T \cdot a $ is fixed, we can deduce
\begin{align*}
\kappa N \cdot a =T'\cdot a=0
\end{align*}
Now observe from Frenet Formula that 
\begin{align*}
  (B \cdot a )'=- \tau N \cdot a =0 
\end{align*}
This implies $B \cdot a $ is fixed.\\

$(\longleftarrow)$\\

Because $B \cdot a$ is fixed, we can deduce
\begin{align*}
  &0= (B \cdot a)'=-\tau N \cdot a \\
 &\implies  N \cdot  a=0
\end{align*}
The proof then now follows from the result of  \textbf{(b)}.\\

\textbf{(d)}\\

First we have to notice the fucking typo correction $\frac{\kappa}{\tau}=\frac{a}{b}$.\\

Compute 
\begin{align*}
\alpha '(s)&=\Big(\frac{a}{c}\sin \theta, \frac{a}{c}\cos \theta, \frac{b}{c} \Big)\\
\alpha ''(s)&=\Big(\theta ' \frac{a}{c}\cos \theta , \theta ' \frac{-a}{c}\sin \theta, 0 \Big)\\
\alpha '''(s)&=\Big(\theta'' \frac{a}{c}\cos \theta + (\theta')^2 \frac{-a}{c}\sin \theta , \theta '' \frac{-a}{c}\sin \theta + (\theta ')^2 \frac{-a}{c}\cos \theta, 0 \Big)
\end{align*}
This give us 
\begin{align*}
&\alpha ' \times \alpha '' \cdot \alpha '''\\
&=\frac{b}{c}\Big[\theta ' \theta '' \frac{-a^2}{c^2}\cos \theta \sin \theta + (\theta ')^3 \frac{-a^2}{c^2}\cos ^2 \theta - \theta' \theta '' \frac{-a^2}{c}\sin \theta \cos \theta - (\theta ')^3 \frac{a^2}{c^2}\sin ^2 \theta \Big]\\
&=\frac{b}{c}\Big( (\theta ')^3 \frac{-a^2}{c^2} \Big)=\frac{-a^2b}{c^3}(\theta ')^3
\end{align*}
And give us 
\begin{align*}
\kappa = \theta' \frac{a}{c}
\end{align*}
We now compute 
\begin{align*}
\frac{\kappa}{\tau}&= \frac{\kappa}{-\frac{\alpha ' \times \alpha '' \cdot \alpha '''}{\kappa ^2}}\\
&=\frac{-\kappa ^3}{\alpha ' \times \alpha '' \cdot \alpha '''}\\
&=\frac{-(\theta')^3 \frac{a^3}{c^3}}{\frac{-a^2b}{c^3}(\theta ')^3}=\frac{a}{b}
\end{align*}



\end{proof}

\begin{question}{}{}
\includegraphics[height=4cm,width=18cm]{hw2q15}
\end{question}
\begin{proof}
Compute 
\begin{align*}
\begin{cases}
  x'=-a \sin t \text{ and }x''=-a\cos t\\
  y'=b \cos t \text{ and } y''=-b \sin t
\end{cases}
\end{align*}
Plugging the curvature formula 
\begin{align*}
\kappa =\frac{x'y''-x''y'}{\big((x')^2 +(y')^2 \big)^{\frac{3}{2}}}
\end{align*}
We now have 
\begin{align*}
\kappa = \frac{ab }{\big(a^2 \sin ^2 t + b^2 \cos ^2 t \big)^{\frac{3}{2}}}
\end{align*}
Compute 
\begin{align*}
\kappa' = (2a^2 \sin t \cos t -2b^2 \sin t \cos t)(a^2\sin ^2 t + b^2 \cos ^2 t)^{\frac{-5}{2}}\cdot (ab)
\end{align*}
We see that 
\begin{align*}
\kappa'=0 \iff  \sin 2t =0
\end{align*}
This only happens when $t \in \set{0,\frac{\pi}{2},\pi,\frac{3\pi}{2},2\pi}$ where $2 \pi$ is just $0$ in the sense of parametrizeation of closed curve. We have shown there are exactly four vertices 
 \begin{align*}
   (a,0),(-a,0),(0,b),(0,-b)
\end{align*}
\end{proof}


\begin{question}{}{}
\includegraphics[height=6cm,width=18cm]{hw2q14}
\end{question}
\begin{proof}
WOLG, let $p=(0,0)$, $T$ be the $x$-axis and some neighborhood around $p$ be above  $T$. Positively oriented  parametrize $C$ by arc-length using  $(x,y)$ and $(x,y)(0)=(0,0)$. Using Taylor Theorem about $y(0)$, we see 
\begin{align*}
y(s)=y(0)+y'(0)s + \frac{y''(0)}{2}s^2 + R_y\text{ where $\frac{R_y}{s^2}\to 0$ as $s\to 0$ }
\end{align*}
 Because $T$ the tangent is the $x$-axis, we know $x''(0)=0\hspace{0.5cm}(\because N=(0,1))$. This tell us 
 \begin{align*}
\abso{\kappa(0)}&=\sqrt{(x'')^2(0)+(y'')^2(0)} \\
 &=y''(0)\hspace{1cm}(\because N=(0,1) )
 \end{align*}
\end{proof} 
By our setting $(x,y)(0)=(0,0)$, we see 
\begin{align*}
\hspace{3cm}y(0)=y'(0)=0\hspace{1cm}(\because (x',y')=(1,0))
\end{align*}
We now see 
\begin{align*}
y''(0)= \frac{2\big(y(s)-R_y \big)}{s^2}\text{ for all $s\neq 0$ }
\end{align*}
This tell us 
\begin{align*}
y''(0)=\lim_{s\to 0}\frac{2\big(y(s)-R_y \big)}{s^2}=\lim_{s\to 0}\frac{2y(s)}{s^2}
\end{align*}
Using Taylor Theorem about $x(0)$, we see 
\begin{align*}
x(s)=x(0)+x'(0)s + R_x\text{ where }\frac{R_x}{s}\to 0\text{ as $x \to 0$ }
\end{align*}
Because $x(0)=0$ and $x'(0)=1$, we see 
\begin{align*}
\lim_{s\to 0}\frac{x(s)}{s}=\lim_{s\to 0} \frac{s+R_x}{s}=1
\end{align*}
This now give us 
\begin{align*}
\abso{\kappa (0)}=y''(0)=\lim_{s\to 0}\frac{2y(s)}{s^2}=\lim_{s\to 0}\frac{2y(s)}{x^2(s)}=\lim_{d\to 0}\frac{2h}{d^2}
\end{align*}



\begin{question}{}{}
\includegraphics[height=8cm,width=18cm]{hw2q13}
\end{question}
\begin{proof}
\textbf{(a)}\\

Using Frenet Formula to compute 
\begin{align*}
\beta '(s)=\alpha '(s)+r\kappa  T(s)
\end{align*}
Because $\alpha $ is parametrized by arc-length, we now know 
\begin{align*}
  \abso{\beta '}=\abso{(1+r\kappa)\alpha '}=\abso{1+r\kappa }=1+ r\kappa
\end{align*}
This now give us 
\begin{align*}
  \int_0^l \abso{\beta '} ds= l + r \int_0^l \kappa ds
\end{align*}
Because a closed convex curve must also be simple (Sec. 5-7, Prop. 1), we now can deduce 
\begin{align*}
\text{ Length of  }\beta &=l + r \int_0^l \kappa ds\\
&=\text{ Length of }\alpha +r(2\pi)
\end{align*}

\textbf{(b)}\\

Set 
\begin{align*}
\alpha =(x,y)\text{ and }\beta =(x-r N_1,y-rN_2)
\end{align*}
Because 
\begin{align*}
\beta '=(1+ r\kappa)\alpha ' 
\end{align*}
We know 
\begin{align*}
\beta ' =\Big((1+r\kappa)x',(1+r\kappa)y' \Big)
\end{align*}
Now, we use Green's Theorem to compute the Area 
\begin{align*}
A(\beta )&=\frac{1}{2}\int_0^l (x-rN_1)(1+r\kappa)y' -(y-rN_2)(1+r\kappa)x'ds\\
         &=\frac{1}{2}\int_0^l (xy'-yx') ds + \frac{r}{2}\int_0^l (\kappa xy' + \kappa x'y) ds \\
&+ \frac{r}{2}\int_0^l -(N_1y'+N_2x')ds + \frac{r^2}{2}\int_0^l (-N_1y'\kappa+N_2x'\kappa)ds
\end{align*}
Notice that by Frenet Formula, we have
\begin{align*}
N'=- \kappa (x',y')
\end{align*}
so in fact we know 
\begin{align*}
\kappa xy'+\kappa x'y=N'\cdot (-y,x)
\end{align*}
Now using integral by part and the fact $\alpha =(x,y)$ is closed, we know  
\begin{align*}
\int_0^l (\kappa xy'+\kappa x'y)ds&=\int_0^l N' \cdot (-y,x)ds\\
&=\int_0^l N\cdot (-y',x')ds
\end{align*}
Then now we have 
\begin{align*}
  \frac{r}{2}\int_0^l (\kappa xy'+\kappa x'y)ds+\frac{r}{2}\int_0^l -N_1y'+N_2x'ds&=\frac{r}{2}\int_0^l 2N\cdot (-y',x')ds
\end{align*}
Using positive orientation and the fact $\abso{N}=1=\abso{(-y',x')}$ to identify that $N=(-y',x')$, we now have 
\begin{align*}
\frac{r}{2}\int_0^l 2N \cdot (-y',x')ds=rl
\end{align*}
and have 
\begin{align*}
\frac{r^2}{2}\int_0^l (-N_1y'\kappa+N_2x' \kappa)ds=\frac{r^2}{2}\int_0^l \kappa ds =r^2 \pi 
\end{align*}
since $(x,y)$ is simple closed. This finishes the proof. \\

\textbf{(c)}\\

Recall that 
\begin{align*}
\kappa (a,b) = \frac{a'b''-a''b'}{\big((a')^2+(b')^2 \big)^{\frac{3}{2}}}
\end{align*}
We use this formula on $\beta$ to compute
\begin{align*}
\kappa_\beta &= \frac{(1+r\kappa)x'\big((1+r\kappa)y' \big)'-\big((1+r\kappa)x' \big)'(1+r\kappa)y'}{(1+r\kappa)^3}\\
&=\frac{(1+r\kappa)^2 (x'y''-x''y')}{(1+r\kappa)^3}\\
&=\frac{x'y''-x''y'}{1+r \kappa}=\frac{\kappa}{1+r\kappa}\hspace{1cm}(\because (x')^2+(y')^2=1)
\end{align*}
\end{proof}


\begin{question}{}{}
\includegraphics[height=6cm,width=18cm]{hw2q12}
\end{question}
\begin{proof}
\textbf{(a)}\\

Because $\alpha $ is simple closed and $\kappa \leq c$, we know 
\begin{align*}
cl=\int_0^l cds\geq \int_0^l \kappa ds=2\pi
\end{align*}
This then implies 
\begin{align*}
\text{ Length of }\alpha =l\geq \frac{2\pi }{c}
\end{align*}
\textbf{(b)}\\

Because $\alpha $ has rotation index $N$ and  $\kappa \leq c$, we know 
\begin{align*}
cl=\int_0^l cds\geq \int_0^l \kappa ds=N2\pi
\end{align*}
This the implies
\begin{align*}
\text{ Length of }\alpha =l\geq \frac{2\pi N}{c}
\end{align*}
\end{proof}
\begin{question}{}{}
\includegraphics[height=4cm,width=18cm]{hw2q11}

\includegraphics[height=4cm,width=18cm]{hw2q10}
\end{question}
\begin{proof}
Suppose we have proved that a convex closed curve must satisfy the isoperimetric inequality. Let $C$ be an arbitrary closed plane curve, and let  $H$ be its convex hull. Now, because straight line is the shortest curve between two point and because we know $H$, a convex curve, must satisfy isoperimetric inequality, we now see 
 \begin{align*}
4 \pi A(C)\leq 4 \pi A(H)\leq l_H^2 \leq l_C^2
\end{align*}
If the equality hold true, we can deduce from $l_H=l_C$ that  $H=C$ and use the argument for isoperimetric inequality of convex curve to argue that $C=H$ must be a circle.
\end{proof}
\begin{question}{}{}
\includegraphics[height=2cm,width=18cm]{hw2q9}
\end{question}
\begin{proof}
Let $S=\set{(x,y,z)\inr^3:x^2+y^2-z^2=0}$. It is clear $S$ contain  $(0,0,0)$. To show $S$ is not regular, we only wish to find a neighborhood $V$ around  $(0,0,0)$ in $S$ such that  $V$ can not expressed as graph of differentiable functions from $\R^2$ to  $\R$. This is trivially true, as all neighborhood ought to contain some open ball $B_\epsilon (0)$, and in this open ball, if we fix, say $(x,y)\in B_\epsilon (0)$ such that $(x,y,\sqrt{x^2+y^2}) \in B_\epsilon (0)$, we see that $z=-\sqrt{x^2+y^2} $ is also in $B_\epsilon (0)$ and $S$. The same argument applies to when $(x,z)$ and $(y,z)$ are fixed. 
\end{proof}
\begin{question}{}{}
\includegraphics[height=1cm,width=18cm]{hw2q8}
\end{question}
\begin{proof}
Because $f$ is differentiable, we see $f_x,f_y$ are all continuous on $U$. This then implies 
 \begin{align*}
h_x(x,y,z)=f_x(x,y),h_y(x,y,z)=f_y(x,y),h_z=-1\text{ are all continuous on $U$ }
\end{align*}
We have shown $h$ is differentiable. Now that observe 
\begin{align*}
h(x,y,z)=0 \implies (x,y,z)=(x,y,f(x,y))
\end{align*}
The converse of course hold true. This then implies 
\begin{align*}
  f[U]=h^{-1}[0]
\end{align*}
Fix arbitrary $(x,y) \in U$. We see 
 \begin{align*}
\textbf{d}h\big(x,y,f(x,y) \big)=\begin{bmatrix} 
  h_x & h_y & h_z
\end{bmatrix}\Big|_{(x,y,f(x,y))}=\begin{bmatrix}
  f_x(x,y) & f_y(x,y) & -1 
\end{bmatrix}
\end{align*}
which is clearly not onto. This show 
\begin{align*}
  (x,y,f(x,y))\text{ is not a critical point }
\end{align*}
Because $(x,y) \in U $ is arbitrary, we have shown $f[U]$ contain no critical point. Now it follows $0$ is a regular value and $f[U]=h^{-1}[0]$ is a regular surface.
\end{proof}
\begin{question}{}{}
\includegraphics[height=3cm,width=18cm]{hw2q7}
\end{question}
\begin{proof}
\textbf{(a)}\\

Compute 
\begin{align*}
f_x=f_y=f_z=2(x+y+z-1)
\end{align*}
This implies the set of critical points are 
\begin{align*}
\set{(x,y,z)\inr^3:x+y+z=1}
\end{align*}
Then it follows from simple computation the set of  critical values is exactly 
\begin{align*}
\set{0}
\end{align*}
\textbf{(b)}\\

For all $c>0$,  the set $f^{-1}[c]$ is a regular surface, and for all $c<0$, the set  $f^{-1}[c]$ is empty (thus trivially regular).\\

\textbf{(c)}\\

Compute 
\begin{align*}
f_x=yz^2\text{ and }f_y=xz^2\text{ and }f_z=2xyz
\end{align*}
This implies the set of critical points is 
\begin{align*}
\set{(x,y,z):z=0\text{ or }x=y=0}
\end{align*}
With simple computation, we see the set of  critical values is exactly 
\begin{align*}
\set{0}
\end{align*}
The set of regular values are exactly $\R^*$, so all  $c\neq 0$ suffice.
\end{proof}
\begin{question}{}{}
\includegraphics[height=3cm,width=18cm]{Ghw2b}
\end{question}
\begin{proof}
Note that 
\begin{align*}
dx_q=\begin{bmatrix}
  \partial_u x & \partial_v x
\end{bmatrix}
\end{align*} 
This give us 
\begin{align*}
dx_q:\R^2 \rightarrow \R^3\text{ is one-to-one }\iff \partial_ux, \partial_vx \inr^3 \text{ is linearly independent everywhere }
\end{align*}
Then we can reduce the problem into proving 
\begin{align*}
\partial _u x, \partial_v x\inr^3 \text{ is linearly independent everywhere }\iff \partial_ux\times\partial_v x\neq 0\text{ everywhere }
\end{align*}
This then follows from \myref{Theorem}{CtcL} at the next page, as one can see that each component of the output of cross product is exactly the three determinant. 
\end{proof}
\begin{theorem}
\label{CtcL}
  \textbf{(Computation to check Linearly Independence)} 
\begin{align*}
\begin{bmatrix}
  v_1 & w_1\\
  v_2 & w_2 \\
  v_3 & w_3
\end{bmatrix}\text{ is linearly independent }\iff \begin{vmatrix} 
  v_1 & w_1\\
  v_2 & w_2
\end{vmatrix}\neq 0\text{ or }\begin{vmatrix} 
  v_2 & w_2\\
  v_3 & w_3
\end{vmatrix}\neq 0\text{ or }\begin{vmatrix} 
  v_1 & w_1\\
  v_3 & w_3
\end{vmatrix}\neq 0
\end{align*}
\end{theorem}
\begin{proof}
$(\longleftarrow)$\\

\As{$v,w$ are linearly dependent}. Fix $w_k=cv_k$. We see 
\begin{align*}
\begin{vmatrix} 
  v_1 & w_1 \\
  v_2 & w_2
\end{vmatrix}=cv_1v_2-cv_1v_2=0\tCaC
\end{align*}

$(\longrightarrow)$\\

\As{all determinant are $0$}. Pick $k$ such that $v_k$ is non-zero. Define 
\begin{align*}
c\triangleq \frac{w_k}{v_k}
\end{align*}
WOLG, suppose 
\begin{align*}
w_1=cv_1\text{ and }v_1\neq 0
\end{align*}
We then can deduce
\begin{align*}
\begin{vmatrix} 
  v_1 & w_1 \\
  v_2 & w_2
\end{vmatrix}\implies cv_1v_2=v_1w_2 \implies w_2=cv_2
\end{align*}
The same arguement implies $w_3=cv_3\tCaC$
\end{proof}
\section{HW3}
\begin{question}{}{}
\includegraphics[height=5cm,width=18cm]{HW312}
\end{question}
\begin{proof}
We are required to show 
\begin{enumerate}[label=(\alph*)]
  \item range of $\textbf{x}$ lies in the ellipsoid
  \item $\textbf{x}$ is smooth 
  \item $d\textbf{x}$ is one-to-one everywhere on $U\triangleq (0,\pi)\times (0,2\pi)$ 
  \item $\textbf{x}$ is a homeomorphism
\end{enumerate}
Compute 
\begin{align*}
\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}&=\sin^2 u \cos^2 v + \sin^2 u \sin^2 v + \cos^2 u=1
\end{align*}
This shows that the range of  $\textbf{x}$ indeed lies in the ellipsoid.\\

It is clear that $\textbf{x}$ is smooth.\\

Compute 
\begin{align*}
d\textbf{x}=\begin{bmatrix}
  a\cos u \cos v & -a \sin u \sin v\\
  b \cos u \sin v & b \sin u \cos v \\
  -c \sin u & 0 
\end{bmatrix}
\end{align*}
Then compute
\begin{align*}
\frac{\partial (y,z)}{\partial (u,v)}=bc \sin^2 u \cos v\text{ and }\frac{\partial (x,z)}{\partial (u,v)}=-ac \sin^2 u \sin v
\end{align*}
Because $u \in (0,\pi)$ and $v \in (0,2\pi)$, and $b,c\neq 0$, we now can deduce
\begin{align*}
&\frac{\partial (y,z)}{\partial (u,v)}=0\iff v\in \set{\frac{\pi}{2},\frac{3}{2}\pi}\\
&\frac{\partial (y,z)}{\partial (u,v)}=0\iff v=\pi 
\end{align*}
This then let us deduce 
\begin{align*}
d\textbf{x}\text{ is one-to-one everywhere on }(0,\pi)\times (0,2\pi)
\end{align*}
Traditionally, the function $\arctan$ is defined on $\R$ and have codomaiin $(-\frac{\pi}{2},\frac{\pi}{2})$.\\

Deduce first from the $z$-component of  $\textbf{x}$. We see
\begin{align*}
\textbf{x}^{-1}(x,y,z)=
  \Big(\arccos \frac{z}{c}, \begin{cases}
    \arctan \frac{ay}{bx}& \text{ if $x,y\inr^+$ (first quadrant) }\\
    \frac{\pi}{2}& \text{ if $x=0,y\inr^+$ }\\
    \frac{3\pi}{2}+\arctan \frac{ay}{bx}& \text{ if $x\inr^-,y\inr^+$ (second quadrant) }\\
    \pi + \arctan \frac{ay}{bx}& \text{ if $x\inr^-,y\inr^-_0$ (third quadrant) }\\ 
    \frac{3\pi }{2}& \text{ if $x=0,y\inr^-$ }\\
    \frac{4\pi }{2}+\arctan \frac{ay}{bx}& \text{ if $x\inr^+,y\inr^-$ (forth quadrant) }
  \end{cases}\Big)
\end{align*}
Now it follows that $\textbf{x}$ is indeed a homeomorphism. 
\end{proof}
\begin{definition}
\textbf{(Definition of regular plane curve)} We say $C\subseteq \R^2$ is a regular plane curve if for all $p\in  C$ there exists 
\begin{enumerate}[label=(\alph*)]
  \item an open neighborhood $p \in V \subseteq \R^2$ 
  \item an open set $U\subseteq \R$
  \item a function $\textbf{x}:U \rightarrow V\cap C $
\end{enumerate}
such that $\textbf{x}$ satisfy
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}$ is smooth 
  \item $\textbf{x}$ is a homoeomorphism between $U$ and  $V\cap C$
  \item $d\textbf{x}_q\in L(\R,\R^2)$ is one-to-one for all $q \in U$
\end{enumerate}
\end{definition}
\begin{definition}
\textbf{(Definition of regular space curve)} We say $C\subseteq \R^3$ is a regular space curve if for all $p\in  C$ there exists 
\begin{enumerate}[label=(\alph*)]
  \item an open neighborhood $p \in V \subseteq \R^3$ 
  \item an open set $U\subseteq \R$
  \item a function $\textbf{x}:U \rightarrow V\cap C $
\end{enumerate}
such that $\textbf{x}$ satisfy
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}$ is smooth 
  \item $\textbf{x}$ is a homoeomorphism between $U$ and  $V\cap C$
  \item $d\textbf{x}_q\in L(\R,\R^3)$ is one-to-one for all $q \in U$
\end{enumerate}
\end{definition}
\begin{question}{}{}
\includegraphics[height=8cm,width=18cm]{HW317}
\end{question}
\begin{proof}
\textbf{(a)}\\

Suppose $f:U\subseteq \R^2\rightarrow \R$ is a smooth function and $c$ is a regular value. We wish to prove 
\begin{align*}
  \vi{C\triangleq f^{-1}[c]\text{ is a regular plane curve }}
\end{align*}
Fix $p \in f^{-1}[c]$. We wish 
\begin{align*}
\vi{\text{ to find a local parametrization $\textbf{x}: I \subseteq \R \rightarrow  C$ around $p$}}
\end{align*}
Because $c$ is a regular value, we know $df_p$ is one-to-one. Then, WOLG, we can let $\partial_y F(p)\neq c$. Define $F:U\rightarrow \R^2$ by 
\begin{align*}
F(x,y)\triangleq \Big(x,f(x,y)\Big)
\end{align*}
Compute 
\begin{align*}
dF=\begin{bmatrix}
  1 & 0 \\
  \partial_x f & \partial _yf 
\end{bmatrix}
\end{align*}
It is now clear that  $\text{det}(dF_p)\neq 0$. Now, because $f$ is smooth, we can use inverse function Theorem and obtain a diffeoemorphism $F$ between open neighborhood around $p$ and open neighborhoood around $f(p)$. Now, note that $f[C]=\set{c}$. This tell us 
\begin{align*}
F[C]\subseteq \set{(x,c)\inr^2:x\inr}
\end{align*}
we now claim
\begin{align*}
 \vi{\textbf{x}(u)\triangleq F^{-1}(u,c)\text{ is the desired local parametrization around $p$ }}
\end{align*}
The fact that $\textbf{x}$ is smooth and homeomorphism follows from 
\begin{enumerate}[label=(\alph*)]
  \item $F$ is a diffeomorphism around $p$ 
  \item $\textbf{x}$ can be identified as restriction of $F^{-1}$
\end{enumerate}
Note that $d(F^{-1})_p=\big(dF_{F^{-1}(p)} \big)^{-1}\neq 0$. Now, because $\textbf{x}$ is restriction of $F^{-1}$, we see $d\textbf{x}$ must not be $0$ around  $p$. $\vdone$ \\

An example is $f(x,y)=(y-1)^2 -x^2$.\\

\includegraphics[height=10cm,width=18cm]{HW3pic1}


\textbf{(b)}\\

Suppose $F:U\subseteq \R^3\rightarrow \R^2$ is a smooth function and $(c_0,c_1)$ is a regular value. We wish to prove 
\begin{align*}
\vi{C\triangleq F^{-1}[(c_0,c_1)]\text{ is a regular space curve }}
\end{align*}
Fix $p\in  F^{-1}[(c_0,c_1)]$. We wish 
\begin{align*}
\vi{\text{ to find a local parametrization $\textbf{x}:I\subseteq \R\rightarrow C$  around $p$ }}
\end{align*}
Define $G:U\rightarrow \R^3$ by
\begin{align*}
G(x,y,z)\triangleq \Big(x,F(x,y,z) \Big)
\end{align*}
Compute 
\begin{align*}
dG=\begin{bmatrix}
  1 & 0 & 0 \\
  \partial_x F_1 & \partial_y F_1 & \partial_z F_1\\
  \partial_x F_2 & \partial_y F_2 & \partial_z F_2
\end{bmatrix}
\end{align*}
Because $p$ is a regular point of $F$, we can WOLG, suppose 
\begin{align*}
\text{det}\big( dG_p\big)=\text{det}\Big( \frac{\partial (F_1,F_2)}{\partial (y,z)}\Big|_p\Big)\neq 0
\end{align*}
This Then, by Inverse function Theorem, $G$ is locally a diffeomorphism around $p$. We now see 
\begin{align*}
\textbf{x}(t)\triangleq G^{-1}(t,c_0,c_1)\text{ is the desired local parametrization around $p\vdone$}
\end{align*}
Suppose we are given two function $A,B:\R^3\rightarrow \R$, and suppose  $A^{-1}[c_0],B^{-1}[c_1]$ are two surfaces. Define $F:\R^3\rightarrow \R^2$ by  
\begin{align*}
F(p)\triangleq (A(p),B(p))
\end{align*}
We see that 
\begin{align*}
\text{ the intersection }A^{-1}[c_0]\cap B^{-1}[c_1]\text{ is exactly }F^{-1}[(c_0,c_1)]
\end{align*}

\textbf{(c)}\\

\As{for a contradiction, $C$ is a regular curve}. Note that $(0,0)\in C$. We know there exists an open-neighborhood $N\subseteq \R^2$ around $(0,0)$ such that $N\cap C$ is the graph of some differentiable function in $x$ or  $y$. However, this is impossible, since if one view $N\cap C$ as a function in $x$, the function  $y=x^{\frac{2}{3}}$ is not differetaible at $x=0$, and one can not even view $N\cap C$ as a function in $y$ as each  $y$ correspond to two $x$, namely  $x=\pm y^{\frac{3}{2}}$. $\tCaC$ 

\end{proof}
\begin{question}{}{}
\includegraphics[height=3cm,width=18cm]{HW3a6}
\end{question}
\begin{proof}
Yes. Fix $p$ in  $S$. We wish to prove 
 \begin{align*}
\vi{\pi\text{ is differentiable at $p$ in the sense of manifold }}
\end{align*}
Let $\textbf{x}_1:U_1\subseteq \R^2 \rightarrow V_1 \cap  S\subseteq \R^3$ be a local parametrization around $p$. Define a local parametrization $\textbf{x}_2:U_2 \subseteq \R^2 \rightarrow \R^2 $ around $\pi(p)$ by 
\begin{align*}
\textbf{x}_2\triangleq \textbf{id}_{U_2}
\end{align*}
We are require to prove 
\begin{align*}
  \vi{\textbf{x}_2^{-1}\circ \pi \circ \textbf{x}_1\text{ is differentiable at $\textbf{x}_1^{-1}(p)$ }}
\end{align*}
Notice that 
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_1:U_1 \rightarrow \R^3$ is differentiable at $p$ by definition 
  \item $\pi :\R^3 \rightarrow \R^2$ is clearly differntiable, with derivative $\begin{bmatrix}
      1 & 0 &0 \\
      0 & 1 &0 \\
      0 & 0 &0 
  \end{bmatrix}$
  \item $\textbf{x}_2^{-1}=\textbf{id}_{U_2}:U_2 \rightarrow \R^2$ is clearly differntiable. 
\end{enumerate}
This shows that $\textbf{x}_2^{-1}\circ  \pi \circ  \textbf{x}_1$ is differentiable at $p$. $\vdone$ 
\end{proof}


\begin{question}{}{}
\includegraphics[height=1.5cm,width=18cm]{HW3a5}
\end{question}
\begin{proof}
Let $S$ be the paraboloid. We show 
\begin{align*}
\vi{S\text{ is diffeomorphic to }\set{(x,y,0):x,y\inr}}
\end{align*}
Define 
\begin{align*}
\pi:S\rightarrow \set{(x,y,0):x,y\inr}\text{ by }\pi(x,y,z)\triangleq (x,y,0)
\end{align*}
We wish to show 
\begin{align*}
\vi{\pi\text{ and }\pi^{-1}\text{ is differentiable everywhere in the sense of manifold }}
\end{align*}
Define global parametrizaitons $\textbf{x}_1$ of $S$ and global parametrization  $\textbf{x}_2$ of $\set{(x,y,0):x,y\inr}$ by
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_1:\R^2 \rightarrow S$ and $\textbf{x}_1(x,y)\triangleq (x,y,x^2+y^2)$ 
  \item $\textbf{x}_2:\R^2 \rightarrow \set{(x,y,0):x,y \inr}$ and $\textbf{x}_2\triangleq \textbf{id}_{\R^2}$
\end{enumerate}
We now reword the problem into proving 
\begin{align*}
  \vi{\textbf{x}_2^{-1}\circ \pi \circ \textbf{x}_1:\R^2 \rightarrow \R^2\text{ and }\textbf{x}_1^{-1}\circ \pi^{-1}\circ \textbf{x}_2:\R^2 \rightarrow \R^2\text{ both are differentiable }}
\end{align*}
Because $\pi,\textbf{x}_1,\textbf{x}_2,\textbf{x}_2^{-1}$ are clearly differentiable, we only have to prove 
\begin{align*}
  \vi{\pi^{-1}: \set{(x,y,0):x,y\inr}\rightarrow \R^3\text{ is differentiable and }\textbf{x}_1^{-1}:\R^3\cap S\rightarrow \R^2 \text{ is differnetiable on $S$ }}
\end{align*}
Observe 
\begin{align*}
\pi^{-1}(x,y,0)\equiv(x,y,x^2+y^2)\text{ and }\textbf{x}_1(x,y,z)\equiv(x,y)
\end{align*}
It is now clear that $\pi^{-1}$ and $\textbf{x}_1^{-1}$ are both differentiable. $\vdone$
\end{proof}

\begin{question}{}{}
\includegraphics[height=3cm,width=18cm]{HW3a4}
\end{question}
\begin{proof}
Suppose we are given a map $\pi:S_1\rightarrow S_2$ differentiable in the sense of manifold. We know for $\underline{\text{arbitrary}}$ $p$ in  $S_1$, there exists 
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_1:U_1\rightarrow S_1$ (a local parametrization around $p$)
  \item $\textbf{x}_2:U_2\rightarrow S_2$ (a local parametrization around $\pi(p)$)
\end{enumerate}
such that 
\begin{align}
\label{dife}
\Big(\textbf{x}_2^{-1}\circ \pi \circ \textbf{x}_1 \Big):U_1\subseteq \R^2\rightarrow U_2\subseteq \R^2\text{ is a diffeomorphism }
\end{align}
Now, fix two arbitrary 
\begin{enumerate}[label=(\alph*)]
  \item  $\textbf{x}_1':U_1'\rightarrow S_1$ (a local parametrization around $p$)
  \item $\textbf{x}_2':U_2'\rightarrow S_2$ (a local parametrization around $\pi(p)$)
\end{enumerate}
We are required to prove (Note that the domain of each composited function may be smaller, but this does not undermine the validity of our argument, since we only care about the differentiablity at $p$) 
\begin{align*}
\vi{\Big((\textbf{x}_2')^{-1}\circ \pi \circ \textbf{x}_1' \Big):U_1'\subseteq \R^2\rightarrow U_2'\subseteq \R^2\text{ is a diffeomorphism  }}
\end{align*}
Note that 
\begin{align*}
  (\textbf{x}_2')^{-1}\circ \pi \circ \textbf{x}_1' &=(\textbf{x}_2')^{-1}\circ \big( \textbf{x}_2 \circ  \textbf{x}_2^{-1} \big)\circ \pi \circ \big( \textbf{x}_1 \circ \textbf{x}_1^{-1}  \big)\circ  \textbf{x}_1'\\
  &=(\textbf{x}_2')^{-1}\circ \textbf{x}_2 \circ  \textbf{x}_2^{-1} \circ \pi \circ  \textbf{x}_1 \circ \textbf{x}_1^{-1} \circ  \textbf{x}_1'\\\
  &=h_2\circ \textbf{x}_2^{-1} \circ  \pi \circ \textbf{x}_1 \circ h_1
\end{align*}
where
\begin{align*}
\begin{cases}
 h_1\equiv\textbf{x}_1^{-1}\circ \textbf{x}_1':U_1'\rightarrow U_1 \\
 h_2\equiv (\textbf{x}_2')^{-1}\circ \textbf{x}_2:U_2\rightarrow U_2'
\end{cases}\text{ are changes of coordinate }
\end{align*}
Now, because changes of coordinates are diffeomorhphism, and $\textbf{x}_2^{-1}\circ \pi \circ \textbf{x}_1$ is diffeomorphism by \myref{Equation}{dife} (definition), we see that 
\begin{align*}
  (\textbf{x}_2')^{-1}\circ \pi \circ \textbf{x}_1'=h_2\circ \big(\textbf{x}_2^{-1}\circ \pi \circ \textbf{x}_1 \big)\circ h_1\text{ is a diffeomorphism at $(\textbf{x}_1')^{-1}(p)$ }
\end{align*}
This then conclude the proof, since $p$ is arbitrary picked from $S_1$. $\vdone$
\end{proof}
\begin{definition}
\textbf{(Definition of Differentiable function on a regular curve)} Given two regular curve $C_1,C_2$, we say the function $f:C_1\rightarrow C_2$ is differentiable at $p$ if for all local parametrizations  $\textbf{x}_1:I\rightarrow C_1\ni p,\textbf{x}_2:I\rightarrow C_2\ni f(p)$,  we have 
\begin{align*}
\textbf{x}_2^{-1}\circ f\circ \textbf{x}_1\text{ is differentaible as a real to real function }
\end{align*}
\end{definition}
\begin{question}{}{}
\includegraphics[height=5cm,width=18cm]{HW3a3}
\end{question}
\begin{proof}
Fix $t_0 \inr$. We wish to prove 
\begin{align*}
\vi{E\text{ is differentaible at $t_0$ in the sense of manifold }}
\end{align*}
Locally parametize $t_0$ and $E(t_0)$ by 
\begin{align*}
\textbf{x}_1(t)\triangleq t\text{ and }\textbf{x}_2(t)\triangleq (\cos t,\sin t)
\end{align*}
Now, see that 
\begin{align*}
\textbf{x}_2^{-1}\circ E\circ \textbf{x}_1(t)=t\text{ is clearly differentiable $\vdone$}
\end{align*}
\end{proof}

\begin{question}{}{}
\includegraphics[height=3cm,width=18cm]{HW3a2}
\end{question}
\begin{proof}
$(\longleftarrow)$\\

Fix $a \in A$. Because $a \in S$, we know there exists a local parametrization $\textbf{x}_1:E\rightarrow V\cap S$ around $a$. Suppose 
\begin{align*}
  E'\triangleq \textbf{x}_1^{-1}[V\cap U\cap S]
\end{align*}
We see 
\begin{align*}
\text{ the restriction }\textbf{x}_1|_{E'}\text{ is clearly a local parametrizaiton around $a$ contained by $A$ }
\end{align*}
Because $a$ is arbitrary, this established that $A$ is a regular surface.\\

$(\longrightarrow)$\\

Suppose $A$ is a regular surface. \As{$A$ is not open in $S$, for a contradiction}. Then, there exists $a \in A$ such that 
\begin{align}
\label{epsa}
\forall \epsilon, B_\epsilon (a)\cap S \not\subseteq A
\end{align}
Because $A$ is a regular surface, we know there exists a local parametrization $\textbf{x}_1:U\subseteq\R^2 \rightarrow V\subseteq A$ around $a$. We know 
\begin{align*}
\textbf{x}_1^{-1}:V\rightarrow U\text{ is continuous }
\end{align*}
Let $M\subseteq  U$ be an open neighborhood around $\textbf{x}_1^{-1}(a)$, such that $M\neq U$. Because $\textbf{x}_1^{-1}$ is continuous, we know there exists an open neighborhood $N\subseteq V$ around $a$ such that 
 \begin{align*}
\textbf{x}_1^{-1}[N]\subseteq M
\end{align*}
Yet, by \myref{Equation}{epsa}, the only open-neighborhood $N\subseteq V$ is exactly $N=V$. Then, we see 
 \begin{align*}
\textbf{x}_1^{-1}[N]=\textbf{x}_1^{-1}[V]=U\subseteq M
\end{align*}
this then implies $M=U\tCaC$. 
\end{proof}

\begin{question}{}{}
\includegraphics[height=10cm,width=18cm]{HW3a1}
\end{question}
\begin{proof}
We first prove 
\begin{align*}
 \vi{F \text{ is differentiable on $S^2\setminus N$ }}
\end{align*}
Fix $p \in S^2 \setminus N$. We wish to prove 
\begin{align*}
\vi{F\text{ is differentiable at $p$ }}
\end{align*}
Because composition of differentiable functions is again differentiable (\myref{Theorem}{CoD}), we can reduce our problem into proving  
\begin{align*}
\vi{\begin{cases}
  \pi_N:S^2\setminus N \rightarrow \overline{\R^2}\\
  P:\overline{\R^2}\rightarrow \overline{\R^2}\\
 \pi_N^{-1}:\overline{\R^2}\rightarrow S^2 
\end{cases}\text{ are differentiable where $\overline{\R}^2\equiv \set{(x,y,-1)\inr^3:x,y\inr}$ }}
\end{align*}
Note that 
\begin{align*}
\pi_N(x,y,z)=(\frac{2x}{1-z},\frac{2y}{1-z})\text{ and }\pi_N^{-1}(u,v)=(\frac{4u}{u^2+v^2+4},\frac{4v}{u^2+v^2+4},\frac{u^2+v^2-4}{u^2+v^2+4})
\end{align*}



\end{proof}
\chpater{HWs}

\chapter{Surface}
\section{Prerequisite}
\begin{theorem}
  \textbf{(Computation to check Linearly Independence)} 
\begin{align*}
\begin{bmatrix}
  v_1 & w_1\\
  v_2 & w_2 \\
  v_3 & w_3
\end{bmatrix}\text{ is linearly independent }\iff \begin{vmatrix} 
  v_1 & w_1\\
  v_2 & w_2
\end{vmatrix}\neq 0\text{ or }\begin{vmatrix} 
  v_2 & w_2\\
  v_3 & w_3
\end{vmatrix}\neq 0\text{ or }\begin{vmatrix} 
  v_1 & w_1\\
  v_3 & w_3
\end{vmatrix}\neq 0
\end{align*}
\end{theorem}
\begin{proof}
$(\longleftarrow)$\\

\As{$v,w$ are linearly dependent}. Fix $w_k=cv_k$. We see 
\begin{align*}
\begin{vmatrix} 
  v_1 & w_1 \\
  v_2 & w_2
\end{vmatrix}=cv_1v_2-cv_1v_2=0\tCaC
\end{align*}

$(\longrightarrow)$\\

\As{all determinant are $0$}. Pick $k$ such that $v_k$ is non-zero. Define 
\begin{align*}
c\triangleq \frac{w_k}{v_k}
\end{align*}
WOLG, suppose 
\begin{align*}
w_1=cv_1\text{ and }v_1\neq 0
\end{align*}
We then can deduce
\begin{align*}
\begin{vmatrix} 
  v_1 & w_1 \\
  v_2 & w_2
\end{vmatrix}\implies cv_1v_2=v_1w_2 \implies w_2=cv_2
\end{align*}
The same arguement implies $w_3=cv_3\tCaC$
\end{proof}
\begin{theorem}
\textbf{(Inverse function Theorem)} Given a map $f$ from open $E \subseteq \R^n$ to $\R^n$, if 
\begin{enumerate}[label=(\alph*)]
  \item $f$ is continuously differentiable on $E$ 
  \item $df_a$ is one-to-one 
\end{enumerate}
Then there exists open neighborhood $U\subseteq E$ around $a$ and  open  $V\subseteq \R^n$ such that 
\begin{align*}
f|_U:U\to V\text{ is a diffeomorphism }
\end{align*}
\end{theorem}
\begin{theorem}
\textbf{(Implicit function Theorem)} Given a map $f$ from an open neighborhood around $(a,b) \in E \subseteq \R^{n+m}\to \R^n$ such that 
\begin{enumerate}[label=(\alph*)]
  \item $f$ is continuously differentiable on $E$
  \item the linear transformation $df_{(a,b)}|_{\R^n}:\R^n \to \R^n$ is one-to-one
  \item $f(a,b)=0$
\end{enumerate}
Then there exists open neighborhood $U$ around $(a,b)\in U \subseteq \R^{n+m}$ and open neighborhood $V$ around  $b  \in V \subseteq \R^m$ such that we can uniquely define a function $g:V \to U$ by 
\begin{align*}
&f(g(y),y)=0\text{ for all $y \in V$}\\
&\text{ and }g\text{ is continuously differentiable with }dg_b=- (df_{(a,b)}|_{\R^n})^{-1}\circ df_{(a,b)}|_{\R^m}
\end{align*}
\end{theorem}
\section{Equivalent Definition of Regular Surface}
\begin{definition}
\textbf{(Definition of Regular Surface: Local Parametrization)} We say a set $S\subseteq \R^3$ is a regular surface if for all $p \in S$ there exists 
\begin{enumerate}[label=(\alph*)]
  \item an open neighborhood $p \in V\subseteq \R^3$
  \item an open set $U\subseteq \R^2$
  \item a function $\textbf{x}:U\rightarrow V\cap S$
\end{enumerate}
such that $\textbf{x}$ satisfy
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}$ is smooth 
  \item $\textbf{x}$ is a homemomorphism between $U$ and  $V\cap S$
  \item $d\textbf{x}_q \in L(\R^2,\R^3)$ is one-to-one for all $q\in U$ 
\end{enumerate}
\end{definition}
\begin{definition}
\textbf{(Definition of Regular Surface: Implicit function)} We say a set $S\subseteq \R^3$ is a regular surface if for all $p \in S$ there exists 
\begin{enumerate}[label=(\alph*)]
  \item an open neighborhood $p \in V\subseteq \R^3$ 
  \item a function $F:V\rightarrow \R$ 
\end{enumerate}
such that $F$ satisfy
\begin{enumerate}[label=(\alph*)]
  \item $\text{det}(dF_q)\neq 0$ for all $q\in V\cap S$
  \item $F$ is smooth on  $V$
  \item $\exists c_0\inr, V\cap S=\bset{(x,y,z)\in V:F(x,y,z)=c_0}$
\end{enumerate}
\end{definition}
\begin{mdframed}
We now verify the equivalency between the two definitions. 
\end{mdframed}
\begin{theorem}
\textbf{(Implicit function definition $\longrightarrow$ Local parametrization definition)} 
\end{theorem}
\begin{proof}
Fix $p \in S$. We are given an open neighborhood $p \in V \subseteq \R^3$ and a function $F:V\rightarrow \R$ such that, WOLG, 
\begin{enumerate}[label=(\alph*)]
  \item $\text{det}(dF_q)\neq 0$ for all $q\in V\cap S$
  \item $F$ is smooth on  $V$
  \item $V\cap S=\bset{(x,y,z)\in V: F(x,y,z)=0}$ 
\end{enumerate}


We wish to find 
\begin{align*}
\vi{\text{ a local parametrization $\textbf{x}$ around $p$ }}
\end{align*}
Define $f:V \rightarrow \R^3$ by 
\begin{align*}
f(x,y,z)=(x,y,F(x,y,z))
\end{align*}
Because $dF_p\neq 0$, WOLG, we can suppose $\partial _zF(p)\neq 0$. Now, see 
\begin{align*}
\text{det}(df)=\begin{vmatrix}
  1 & 0 & 0\\
  0 & 1 & 0\\
  \partial_x F & \partial_y F & \partial _z F
\end{vmatrix}\neq 0
\end{align*}
Now, note that 
\begin{enumerate}[label=(\alph*)]
  \item $f$ is smooth on $V\hspace{0.5cm}(\because \text{ $F$ is smooth on $V$ })$  
  \item $df_p$ is one-to-one $\hspace{0.5cm}(\because \partial_zF(p)\neq 0)$  
\end{enumerate}
Then, by inverse function Theorem, we know  
\begin{align*}
f\big|_{V'}\to U'\text{ is a local diffeomorphism around $V'\ni p$ and around $U'\ni f(p)$}
\end{align*}
Let $U\subseteq \set{(x,y,0):(x,y)\inr^2}$ be an open-neighborhood around $f(p)$ contained by $U'$. We claim  
\begin{align*}
  \vi{\textbf{x}\triangleq f^{-1}\big|_U\text{ suffices }}
\end{align*}
Note that $\textbf{x}$ is well-defined since $U\subseteq U'$ and $f$ is a bijective between  $V'$ and $U'$.\\


Also, note that $\textbf{x}$ do maps points in $U$ to points in $V\cap S$, since $V\cap S=\bset{(x,y,z)\in V:F(x,y,z)=0}$.\\

Suppose that 
\begin{align*}
\begin{bmatrix}
  \alpha_{1,1} & \alpha_{1,2} & \alpha _{1,3}\\
  \alpha _{2,1} & \alpha _{2,2} & \alpha _{2,3}\\
  \alpha _{3,1} & \alpha _{3,2} & \alpha _{3,3}
\end{bmatrix}\triangleq df^{-1}_\alpha  =\big(df_{f^{-1}(\alpha )} \big)^{-1}\text{ for all $\alpha \in U$ }
\end{align*}
We clearly have 
\begin{align*}
d\textbf{x}=\begin{bmatrix}
  \alpha_{1,1} & \alpha _{1,2}\\
  \alpha _{2,1} & \alpha _{2,2}\\
  \alpha_{3,1} & \alpha_{3,2}
\end{bmatrix}
\end{align*}
Now, one can use the premise 
\begin{align*}
\text{det}(dF_q)\neq 0 \text{ for all } q\in V\cap S
\end{align*}
to check $\textbf{x}$ do satisfy the regular condition. (Compute $\text{det}(df_{\alpha }^{-1})$ using co-factor formula on the third column) $\vdone$
\end{proof}
\begin{mdframed}

\end{mdframed}
\begin{definition}
\textbf{(Definition of Regular surface: Monge Patches)} We say a set $S\subseteq \R^3$ is a regular surface if for all $p \in S$ there exists some open neighborhood $ p \in V\subseteq \R^3$ such that 
\begin{center}
   \begin{minipage}{0.9\linewidth}  

$V\cap S$   can be expressed as the graph of some smooth function $f:O\subseteq \R^2 \rightarrow \R$ in the sense that one of the followings hold 
   \end{minipage}
\end{center}
\begin{enumerate}[label=(\alph*)]
  \item $V\cap S=\set{(x,y,f):(x,y)\in O}$ for some smooth $f:O \subseteq \R^2 \rightarrow \R$
  \item $V\cap S=\set{(x,f,z):(x,z)\in O}$ for some smooth $f:O \subseteq \R^2 \rightarrow \R$
  \item $V\cap S=\set{(f,y,z):(y,z)\in O}$ for some smooth $f:O \subseteq \R^2 \rightarrow \R$
\end{enumerate}
\end{definition}
\section{Examples of Regular Surfaces}
\begin{mdframed}
Among all regular surfaces, the most classic one is perhaps the $S^2$. Here, we show some local parametriatoin of $S^2$.\\


Note that because  $S^2=F^{-1}[0]$, where $F(x,y,z)=x^2+y^2+z^2-1$ clearly has non-zero derivative everywhere on $\R^3 \setminus 0$, we know $S^2$ is a regular surface. 
\end{mdframed}
\begin{mdframed}
\begin{Example}{\textbf{(Graph Coordinates of $S^2$)}}{}
\begin{align*}
U=\set{(u,v):u^2+v^2<1}\text{ and }S^2=\set{(x,y,z):x^2+y^2+z^2=1}
\end{align*}
\begin{enumerate}[label=(\alph*)]
    \item $f_1:B_{1}(0)\subseteq \R^2 \rightarrow \R^3$ by $f_1(x,y)=(x,y,\sqrt{1-x^2-y^2})$  
    \item $f_2:B_{1}(0)\subseteq \R^2 \rightarrow \R^3$ by $f_2(x,y)=(x,y,-\sqrt{1-x^2-y^2})$  
    \item $f_3:B_{1}(0)\subseteq \R^2 \rightarrow \R^3$ by $f_3(x,z)=(x,\sqrt{1-x^2-z^2},z)$  
    \item $f_4:B_{1}(0)\subseteq \R^2 \rightarrow \R^3$ by $f_4(x,z)=(x,-\sqrt{1-x^2-z^2},z)$  
    \item $f_5:B_{1}(0)\subseteq \R^2 \rightarrow \R^3$ by $f_5(y,z)=(\sqrt{1-y^2-z^2},y,z)$  
    \item $f_6:B_{1}(0)\subseteq \R^2 \rightarrow \R^3$ by $f_6(y,z)=(-\sqrt{1-y^2-z^2},y,z)$  
\end{enumerate}
\end{Example}  
\begin{Example}{\textbf{(Spherical Coordinates of $S^2$)}}{}
\begin{align*}
S^2=\set{(x,y,z):x^2+y^2+z^2=1}
\end{align*}
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_1:(0,\pi)\times (0,2\pi)\rightarrow S^2 $ by $\textbf{x}_1(\theta,\phi)=(\sin \theta \cos \phi,\sin \theta \sin \phi,\cos \theta)$
  \item $\textbf{x}_2:(0,\pi)\times (0,2\pi)\rightarrow S^2$ by $\textbf{x}_2(\theta,\phi)=(-\sin \theta\cos \phi  ,\cos \theta,\sin \theta \sin \phi )$
\end{enumerate}
Note that 
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_1$ does not contain $\set{(x,0,z)\in S^2: \begin{cases}
    x^2+z^2=1\\
    x\geq 0
  \end{cases}}$ 
\item $\textbf{x}_2$ does not contain $\set{(x,y,0)\in S^2: \begin{cases}
  x^2+y^2=1\\
  x\leq 0
\end{cases}}$
\end{enumerate}
\end{Example}

\begin{Example}{\textbf{(Stereographical Coordinates of $S^2$: Projection Plane be the Equator)}}{}
\begin{align*}
U=\R^2\text{ and }S^2=\set{(x,y,z):x^2+y^2+z^2=1}
\end{align*}
Note that
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_N^{-1}(x,y,z)\equiv (\frac{x}{1-z},\frac{y}{1-z})$ 
  \item $\textbf{x}_S^{-1}(x,y,z)\equiv (\frac{x}{z+1},\frac{y}{z+1}) $
\end{enumerate}
For explicit expression of $\textbf{x}_N$, Use the trick 
\begin{align*}
u^2+v^2=\frac{x^2+y^2}{(1-z)^2}=\frac{1-z^2}{(1-z)^2}\text{ and }x=u(1-z),y=v(1-z)
\end{align*}
to first solve for $z$, then solve for $x,y$.\\

Now, we have 
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_N(u,v)=\big(\frac{2u}{u^2+v^2+1},\frac{2v}{u^2+v^2+1},\frac{u^2+v^2-1}{u^2+v^2+1} \big)$
  \item $\textbf{x}_S(u,v)=\big(\frac{2u}{u^2+v^2+1},\frac{2v}{u^2+v^2+1},\frac{1-u^2-v^2}{1+u^2+v^2} \big)$
\end{enumerate}
Let
\begin{align*}
\textbf{x}_N(u,v)=(x,y,z)
\end{align*}
Compute 
\begin{align*}
  \frac{\partial (x,y)}{\partial (u,v)}&=\frac{4(-u^2 - v^2 + 1)}{u^6 + 3u^4v^2 + 3u^4 + 3u^2v^4 + 6u^2v^2 + 3u^2 + v^6 + 3v^4 + 3v^2 + 1}\\
  \frac{\partial (y,z)}{\partial (u,v)}&=\frac{-8u}{u^6 + 3u^4v^2 + 3u^4 + 3u^2v^4 + 6u^2v^2 + 3u^2 + v^6 + 3v^4 + 3v^2 + 1}\\
  \frac{\partial (x,z)}{\partial (u,v)}&=\frac{8v}{u^6 + 3u^4v^2 + 3u^4 + 3u^2v^4 + 6u^2v^2 + 3u^2 + v^6 + 3v^4 + 3v^2 + 1}
\end{align*}
This shows $\textbf{x}_N$ is indeed a local parametrization.   
\end{Example}
Note that 
\begin{align*}
\textbf{x}^{-1}_S \circ \textbf{x}_N (u,v)=\big( \frac{u}{u^2+v^2},\frac{v}{u^2+v^2}\big)
\end{align*}
is a diffeomorphism on $\R^2\setminus 0$, since $\text{det}\Big( d(\textbf{x}_S^{-1}\circ \textbf{x}_N)\Big)=\frac{-1}{(u^2+v^2)^2}$.\\

Also, note that if we identify $(u,v)\equiv u+iv\triangleq \xi$, we have 
\begin{align*}
\textbf{x}_S^{-1}\circ \textbf{x}_N (\xi)=\frac{\overline{\xi}}{\abso{\xi}^2}
\end{align*}
\end{mdframed}
\begin{mdframed}
\begin{Example}{\textbf{(Stereographical Coordinates of $S^2$: Projection Plane at the Bottom)}}{}
\begin{align*}
U=\R^2\text{ and }S^2=\set{(x,y,z):x^2+y^2+z^2}
\end{align*}
\end{Example}
\end{mdframed}
\section{Change of Parameter}
\begin{mdframed}
Given two regular surfaces $S_1,S_2$, an open neighborhood $V_1\subseteq \R^3$ around $p$, and a continuous function  $f:V_1\cap S_1\rightarrow S_2$, we say $f$ is differentiable at $p\in V_1$ if there exists local parametrizations 
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_1:U_1\subseteq \R^2\rightarrow V_1'\cap S_1$ around $p$
  \item $\textbf{x}_2:U_2\subseteq \R^2 \rightarrow V_2\cap  S_2$ around $f(p)$
\end{enumerate}
such that 
\begin{align*}
\textbf{x}_2^{-1}\circ f \circ \textbf{x}_1\text{ is differentaible at $\textbf{x}_1^{-1}(p)$ }
\end{align*}
Note the our definition of differentiablity of function between regular surface is well-defined, in the sense that if $f$ differentiable, all local parametrizations suffice to check. This fact is backed by \myref{Theorem}{CoP} 
\end{mdframed}
\begin{theorem}
\label{CoP}
\textbf{(Change of Parameter is a diffeomorphism)} Let $p$ be a point of a regular surface $S$, and let $\textbf{x}:U_1\rightarrow V_1\cap S$ and $\textbf{y}:U_2\rightarrow V_2\cap S$ be two local parametrization around $p$. Define $W\triangleq V_1\cap V_2 \cap S$. Then 
\begin{align*}
  \text{ The \textbf{change of coordinate} $h=\textbf{x}^{-1}\circ \textbf{y}:\textbf{y}^{-1}(W)\to \textbf{x}^{-1}(W)$ is a diffoeomorphism }
\end{align*}
\end{theorem}
\begin{proof}
It is clear that $h$ is a homeomorphism, since $\textbf{x},\textbf{y}$ both are. \\

Note the symmetry $h^{-1}=\textbf{y}^{-1}\circ \textbf{x}$. WOLG, we only have to prove 
\begin{align*}
\vi{h:\textbf{y}^{-1}(W)\subseteq U_2\rightarrow \textbf{x}^{-1}(W)\subseteq U_1\text{ is differentiable }}
\end{align*}
Fix $r \in \textbf{y}^{-1}(W)$. We prove 
\begin{align*}
  \vi{h\text{ is differentiable at $r$ }}
\end{align*}
Define $q\triangleq h(r) \in \textbf{x}^{-1}(W)\subseteq \R^2$. Let's write $\textbf{x}$ by 
\begin{align*}
\textbf{x}(u,v)=(x,y,z)
\end{align*}
By definition, we know $d\textbf{x}_q$ is one-to-one. This, WOLG, let us have 
\begin{align*}
\begin{vmatrix} 
  \partial_u x & \partial_v x\\
  \partial_u y & \partial_v y
\end{vmatrix}(q)\neq 0
\end{align*}
Now, define $F:\textbf{x}^{-1}(W)\times \R\rightarrow \R^3$ by  
\begin{align}
\label{CC1}
F(u,v,t)\triangleq  \Big(x(u,v),y(u,v),z(u,v)+t \Big)
\end{align}
Compute 
\begin{align*}
  \text{det}(dF_{(q,0)})=\begin{vmatrix}
  \partial_u x & \partial_v x & 0\\
  \partial_u y & \partial_v y & 0\\
  \partial_u z & \partial_v z & 1 
\end{vmatrix}(q,0)\neq 0 
\end{align*}
Then by Inverse function Theorem, we see that there exists an open neighborhood $M\subseteq \R^3$ around $F(q,0)$ such that $F^{-1}$ exists and is differentiable on $M$.\\

Now, from \myref{Equation}{CC1}, note that 
\begin{align*}
F(u,v,0)=\textbf{x}(u,v)
\end{align*}
Recall the definition $h$, we now have 
\begin{align*}
h\equiv \textbf{x}^{-1}\circ \textbf{y}=F^{-1}\circ \textbf{y}
\end{align*}
Then because 
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{y}$ is differentiable at $r$ 
   \item $F^{-1}$ is differentiable at $F(q,0)=\textbf{x}(q)=\textbf{y}(r)$ 
\end{enumerate}
We see $h$ is indeed differentiable at $r\vdone$
\end{proof}
\begin{mdframed}

\end{mdframed}
\begin{theorem}
\label{CoD}
\textbf{(Composition of Differentiable functions is differentiable)} Given three regular surfaces $\set{S_1,S_2,S_3}$, two differentiable functions $f_1:S_1\rightarrow S_2$ and $f_2:S_2\rightarrow S_3$, we see 
\begin{align*}
f_2\circ f_1\text{ is differentiable on $S_1$ }
\end{align*}
\end{theorem}
\begin{proof}
Fix $p_1\in S_1 $. We wish to prove 
\begin{align*}
  \vi{f_2\circ f_1\text{ is differentiable at $p_1$ }}
\end{align*}
Set 
\begin{enumerate}[label=(\alph*)]
  \item $p_2\triangleq f_1(p_1)$ 
  \item $p_3\triangleq f_2(p_2)$
\end{enumerate}
Let 
\begin{enumerate}[label=(\alph*)]
  \item $\textbf{x}_1:U_1 \rightarrow V_1\cap S_1 \ni p_1 $ be a local parametrzaiton 
   \item $\textbf{x}_2:U_2\rightarrow V_2\cap S_2\ni p_2$ be a local parametrizaiton 
    \item $\textbf{x}_3:U_3\rightarrow V_3\cap S_3\ni p_3$ be a local parametrizaiton 
\end{enumerate}
We wish to prove 
\begin{align*}
  \vi{\textbf{x}_3^{-1}\circ f_2\circ f_1 \circ \textbf{x}_1\text{ is differentiable at $p_1$ }}
\end{align*}
Observe that 
\begin{align*}
\textbf{x}_3^{-1}\circ f_2\circ f_1\circ \textbf{x}_1&=\textbf{x}_3^{-1}\circ f_2 \circ \textbf{x}_2 \circ \textbf{x}_2^{-1} \circ f_1 \circ \textbf{x}_1\\
&=\Big(\textbf{x}_3^{-1}\circ f_2\circ \textbf{x}_2 \Big)\circ \Big(\textbf{x}_2^{-1}\circ f_1\circ \textbf{x}_1 \Big)\text{ is differentiable $\vdone$}
\end{align*}
\end{proof}

\section{Tangent Plane}
\end{document}

\documentclass{report}
\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{NCKU 112.1}\\Introduction to Analysis}
\author{\huge{Eric Liu}}
\date{}
\begin{document}
\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak
\setcounter{chapter}{-1}
\chapter{Basic Topology} 
\section{Different but Equivalent Ways to Define A Topology}
\fbox{\begin{minipage}{39em}
This section illustrates three methods to define a topology. However, in practice, the approach using open sets is predominantly employed.
\end{minipage}}
\begin{definition}
\label{0.1.1}
\textbf{(Definition of Topology, via Open Set)} Given a set $X$, which called a topological space, if we say a family $\mathfrak{O}$  of subsets of $X$ is a topology on $X$, then we mean
\begin{gather}
X, \varnothing \in \mathfrak{O}\\
A,B\in\mathfrak{O}\implies A\cap B\in\mathfrak{O}\\
\mathfrak{U}\subseteq \mathfrak{O}\implies \bigcup \mathfrak{U}\in \mathfrak{O}
\end{gather}
If a subset of $X$ belong to  $\mathfrak{O}$, we say it is an open set, and if a subset of $X$ is an complement of an open set, we say it is an closed set.
\end{definition}
\fbox{\begin{minipage}{39em}
The method above is the usual way to define a topology. Next, we'll look at some properties of closed sets. Keep in mind that the related properties for open sets are basic axioms
\end{minipage}}
\begin{theorem}
\label{0.1.2}
\textbf{(Property of Closed Sets)} Let $\mathfrak{F}$ be the family of precisely all closed sets in a topological space. We have
\begin{gather}
X,\varnothing \in \mathfrak{F}\\
A,B\in\mathfrak{F}\implies A\cup  B\in\mathfrak{F}\\
\mathfrak{B}\subseteq \mathfrak{F}\implies \bigcap \mathfrak{B}\in \mathfrak{F}
\end{gather}
\end{theorem}
\begin{proof}
\begin{equation}
X=\varnothing^c\text{ and }\varnothing=X^c\in \mathfrak{F}
\end{equation}
\begin{equation}
A,B\in \mathfrak{F}\implies A^c,B^c \in \mathfrak{O}\implies A^c \cap B^c=(A\cup B)^c \in \mathfrak{O} \implies A\cup  B \in \mathfrak{F}
\end{equation}
\begin{equation}
\mathfrak{B}\subseteq \mathfrak{F}\implies \set{F^c:F \in \mathfrak{B}}\subseteq \mathfrak{O}\implies \bigcup_{F\in \mathfrak{B}}F^c \in \mathfrak{O}\implies \bigcap \mathfrak{B}= (\bigcup_{F \in\mathfrak{B}} F^c)^c \in \mathfrak{F}
\end{equation}
\end{proof}
\begin{theorem}
\label{0.1.3}
\textbf{(Equivalent Ways to Define The Same Topology, Part 1)} Define $f$ on $\power{\power{X}}$ by 
\begin{equation}
f(\mathfrak{A})=\set{A^c:A\in \mathfrak{A}}
\end{equation}
If $\mathfrak{O}$ is a topology on $X$, then  $f(\mathfrak{O})$ are the family of precisely all closed sets on $X$. Also, we have
\begin{equation}
f=f^{-1}
\end{equation}
This mean if we are given a family of closed sets, the family of closed sets given by the topology induced by our original family is our original family.   
\end{theorem}
\begin{proof}
Trivial. 
\end{proof}
\fbox{\begin{minipage}{39em}
Let's move on to the axioms for the neighborhood system. After covering that, we'll demonstrate that these axioms and those for open sets aren't just interconnected â€“ they're essentially the same thing. Notice the proof below uses Zorn's Lemma. 
\end{minipage}}
\begin{definition}
\label{0.1.4}
\textbf{(Definition of Neighborhood Function)} We say a function $\mathcal{N}:X\rightarrow \power{\power{X}}$ is neighborhood function if 
\begin{gather}
\forall x \in X,\mathcal{N}(x)\neq \varnothing\text{ (Existence) }\\
N \in \mathcal{N}(x)\implies x \in N\text{ (Around) }\\
\exists N \in \mathcal{N}(x), N\subseteq M\implies M\in \mathcal{N}(x)\text{ (Super set) }\\
N,M \in \mathcal{N}(x)\implies N \cap M\in \mathcal{N}(x)\text{ (Intersection) }\\
\forall N\in \mathcal{N}(x),\exists M\in \mathcal{N}(x), M \subseteq N\text{ and }\forall y \in M, N \in \mathcal{N}(y)
\end{gather}
The last property reads: every neighborhood $N$ around arbitrary point $x$ contain a neighborhood $M$ around $x$ such that $N$ is a neighborhood of each points of $M$.
\end{definition}
\begin{theorem}
\label{0.1.5}
\textbf{(Equivalent Ways to Define The Same Topology, Part 2)} There exists a one-to-one correspondence between the class of all topology on $X$ and the class of all neighborhood function on $X$.\\

The correspondence can be written in the form of 
\begin{equation} (g(\mathfrak{O}))(x)=\set{N\subseteq X: \exists O\in \mathfrak{O},x\in O\subseteq N}
\end{equation}
The inverse of $g$ will be proved to be
 \begin{equation}
g^{-1}(\mathcal{N})=\set{O:\forall x \in O, O\in \mathcal{N}(x)}
\end{equation}
\end{theorem}
\begin{proof}
  We first prove \vi{$g$ do map topology to neighborhood function}.\\

$g(\mathfrak{O})(x)$ is always nonempty because
\begin{equation}
X \in \mathfrak{O}\implies X\in (g(\mathfrak{O}))(x)
\end{equation}
By definition of $g$, every defined neighborhood around $x$ do contain  $x$. A super set of $N\in (g(\mathfrak{O}))(x)$ belong to $(g(\mathfrak{O}))(x)$, since an open set containing $x$ contained by  $N$ is also contained by the super set.\\

Let $N,M \in (g(\mathfrak{O}))(x)$ and $x \in O_N \subseteq N, x\in O_M \subseteq M$. We have 
\begin{equation}
x \in O_N\cap O_M\subseteq N\cap M
\end{equation}
For each neighborhood $N$ around $x$, the open set containing  $x$ contained by the neighborhood is also a neighborhood around  $x$, since it contain itself and it is an open set.  Then we see $N$ is a neighborhood around each point of the open set, since each point is contained by the open set contained by $N$ $\vdone$\\

We now prove  \blue{$g^{-1}$ do map neighborhood function to topology}.\\

Proving $\varnothing \in g^{-1}(\mathcal{N})$ is trivial. We have $X \in g^{-1}(\mathcal{N})$ because  $\mathcal{N}(x)$ is nonempty for all $x$ and  $X$ is a super set of any neighborhood.\\



Let $A,B\in g^{-1}(\mathcal{N})$. Arbitrarily pick $x$ in $A\cap B$, we know by definition of $g^{-1}$,  $A$ is a neighborhood of  $x$ and so is  $B$. Then by definition of neighborhood function, we know $A\cap B\in \mathcal{N}(x)$. Because $x$ is arbitrary picked from $A\cap B$,  we have proved $A\cap B\in g^{-1}(\mathcal{N})$.\\

Let $\mathfrak{A}\subseteq g^{-1}(\mathcal{N})$. We deduce
\begin{equation}
x \in \bigcup \mathfrak{A}\implies \exists O \in \mathfrak{A}, x \in O \in \mathfrak{A}\subseteq g^{-1}(\mathcal{N})\implies O \in \mathcal{N}(x)\implies O \subseteq \bigcup \mathfrak{A} \in \mathcal{N}(x)
\end{equation}
By definition of $g^{-1}(\mathcal{N})$, the above deduction shows $\bigcup \mathfrak{A}\in g^{-1}(\mathcal{N})\bdone$\\


Lastly, we prove \teal{$g^{-1}$ is the inverse of $g$}. To prove such, we have to first prove \vi{$g^{-1}(g(\mathfrak{O}))=\mathfrak{O}$}. \\


Arbitrarily pick $Z\in \mathfrak{O}$. Deduce 
\begin{equation}
x\in Z \implies \exists Z\in \mathfrak{O},x \in Z\subseteq Z\implies Z\in (g(\mathfrak{O}))(x)
\end{equation}
By definition of $g^{-1}$, our deduction give us $Z\in g^{-1}(g(\mathfrak{O}))$. Because $Z$ is arbitrarily picked from  $\mathfrak{O}$, we have $\mathfrak{O}\subseteq g^{-1}(g(\mathfrak{O}))$.\\

Arbitrarily pick $Y \in g^{-1}(g(\mathfrak{O}))$. Define $\mathfrak{S}:=\set{O\in \mathfrak{O}: O \subseteq Y}$. By definition of $g^{-1}\text{ and }g$, we have
\begin{equation}
y \in Y\implies Y \in (g(\mathfrak{O}))(y)\implies \exists O\in\mathfrak{O}, y \in O\subseteq Y\implies y \in \bigcup \mathfrak{S}
\end{equation}
The last implication hold true because $O\in \mathfrak{S}$ by definition of $\mathfrak{S}$. We have proved $Y\subseteq \bigcup \mathfrak{S}$. Also, trivially by definition of  $\mathfrak{S}$, we have $\bigcup \mathfrak{S}\subseteq Y$. Then we have $Y=\bigcup \mathfrak{S} \in \mathfrak{O}$. Because $Y$ is arbitrarily picked from $g^{-1}(g(\mathfrak{O}))$, we have proved $g^{-1}(g(\mathfrak{O}))\subseteq \mathfrak{O}\vdone$\\

We now prove \blue{$g(g^{-1}(\mathcal{N}))=\mathcal{N}$. More precisely, we want to prove $\forall x, g(g^{-1}(\mathcal{N}))(x)=\mathcal{N}(x)$}\\

Let $x\in X$. Observe
\begin{equation}
Y \in g(g^{-1}(\mathcal{N}))(x)\implies \exists O \in g^{-1}(\mathcal{N}),x \in O \subseteq Y
\end{equation}
Bydefinition of $g^{-1}$, we see $O\in \mathcal{N}(x)$. Then by super set property, we know $Y \in \mathcal{N}(x)$. We have proved $ g(g^{-1}(\mathcal{N}))(x)\subseteq \mathcal{N}(x)$.\\

Arbitrarily pick $N\in \mathcal{N}(x)$. Let 
\begin{equation}
U:=\set{y\in N: N \in \mathcal{N}(y)}
\end{equation}
Deduce
\begin{gather}
y \in U \implies N \in\mathcal{N}(y)\\
\implies \exists M \in \mathcal{N}(y), M \subseteq N, \forall z \in M, N \in \mathcal{N}(z)\\
\implies \forall z\in M, z\in N\text{ and }N\in\mathcal{N}(z)\\
\implies \forall z\in M, z \in U\implies M \subseteq U\implies U\in \mathcal{N}(y)
\end{gather}
We have proved
\begin{equation}
\forall y\in U, U\in \mathcal{N}(y)
\end{equation}
which means
\begin{equation}
U\in g^{-1}(\mathcal{N})
\end{equation}
By definition of $U$, we know
 \begin{equation}
U\subseteq N
\end{equation}
The fact $N$ is chosen from $\mathcal{N}(x)$ let us know $x\in U\subseteq N$, so we can deduce 
\begin{equation}
N\in g(g^{-1}(\mathcal{N}))(x)
\end{equation}
Because $N$ is arbitrarily picked from $\mathcal{N}(x)$, we have $\mathcal{N}(x)\subseteq g(g^{-1}(\mathcal{N}))(x)\bdone\tdone$
\end{proof}
\fbox{\begin{minipage}{39em}
We now give the formal definition of neighborhood while a topology is given, and translate \myref{Theorem}{1.12.5} into language without neighborhood function. 
\end{minipage}}
\begin{definition}
\label{0.1.6}
\textbf{(Definition of Neighborhood)} We say a set $E$ is a neighborhood around a point $x$, if  $E$ contains an  open set containing $x$.
\end{definition}
\begin{corollary}
\label{0.1.7}
\textbf{(Property of Neighborhood, Part 1)} 
\begin{enumerate}[label=(\alph*)]
  \item For all points $x$, there exists a neighborhood around $x$.\\
  \item The super set of a neighborhood around  $x$ is a neighborhood around $x$.\\
  \item The intersection of two neighborhood around  $x$ is a neighborhood around $x$.\\
  \item 
For each neighborhood $N$ around $x$, there exists a smaller neighborhood $M$ around $x$ such that  $N$ is a neighborhood around all points in $N$.
\end{enumerate}
\end{corollary}
\begin{theorem}
\label{0.1.8}
\textbf{(Property of Neighborhood, Part 2)} 
\begin{equation}
  \text{ $E$ is open $\iff E$ is an neighborhood around all points in $E$}
\end{equation}
\end{theorem}
\begin{proof}
From left to right, it trivially follows from our definition of neighborhood.\\

From right to left, we know every point $x$ in  $E$ is contained by an open set contained by $E$. By axiom, the union of such open sets is an open set and contained by $E$. Also, every point in $E$ belong to an open set contained by by $E$, so belong to the union. We have proved  $E$ is the union. 
\end{proof}
\section{Closure and Interior Operator}
\fbox{\begin{minipage}{39em}
This section won't go into any detailed general topology. It merely work as a comparison for the next section. 
\end{minipage}}
\begin{definition}
\label{0.2.1}
\textbf{(Definition of Closure and Interior Operator)} We define the closure $\overline{E}$ of $E$ to be smallest closed set containing $E$
\begin{equation}
  \overline{E}:=\bigcap \set{F\in\mathfrak{F}:E\subseteq F}
\end{equation}
and define the interior $E^\circ$ of  $E$ to be the largest open set contained by  $E$ 
\begin{equation}
E^\circ :=\bigcup  \set{O\in\mathfrak{O}:O \subseteq E}
\end{equation}
\end{definition}
\begin{theorem}
\label{0.2.2}
\textbf{(Basic Property of Closure and Interior Operator)} We have
\begin{gather}
  \overline{E}=E\iff E\in\mathfrak{F}\text{ and }E^\circ=E\iff E\in\mathfrak{O}\\
\overline{(\overline{E})}=\overline{E}\text{ and }(E^\circ)^\circ=E^\circ\\
  S\subseteq T \implies S^\circ \subseteq T^\circ\text{ and }\overline{S}\subseteq \overline{T}
\end{gather}
\end{theorem}
\begin{theorem}
\label{0.2.3}
\textbf{(Basic Property of Closure and Interior Operator)} We have 
\begin{equation}
   \overline{E\cup F}=\overline{E}\cup \overline{F}\text{ and }(E\cap F)^\circ=E^\circ \cap F^\circ
\end{equation}
\end{theorem}
\fbox{\begin{minipage}{39em}
Now, we define interior point and limit point without referencing interior and closure. We'll also demonstrate that the interior, described as the largest open set within $E$, can in turn define interior points.\\ 

Aside from the last section, this is another example in general topology where definitions can be expressed in several ways, yet they remain equivalent.
\end{minipage}}
\begin{definition}
\label{0.2.4}
\textbf{(Definition of Interior Point)} A point $p$ is an interior point of $E$ if
\begin{equation}
E\in \mathcal{N}(p)
\end{equation}
\end{definition}
\begin{definition}
\label{0.2.5}
\textbf{(Definition of Limit and Isolated Point)} A point $p \in X$ is a limit point of a subset $E$ of $X$, if 
\begin{equation}
\forall O\in \mathfrak{O}:p \in O, \exists u\neq p, u \in O\cap E
\end{equation}
or equivalently
\begin{equation}
\forall O\in\mathfrak{O}:p\in O, O\cap E\setminus \set{p}\neq \varnothing
\end{equation}
or equivalently
\begin{equation}
\forall N\in \mathcal{N}(p), N\cap E\setminus \set{p}\neq \varnothing
\end{equation}
We denote the set of limit point of $E$ by  $E'$. 
\end{definition}
\begin{theorem}
\label{0.2.6}
\textbf{(Interior Contain Exactly All Interior Points)} We have
\begin{equation}
E^\circ = \set{p:E\in \mathcal{N}(p)}
\end{equation}
\end{theorem}
\begin{proof}
Arbitrarily pick $p$ from $\set{p: E \in \mathcal{N}(p)}$. By definition, we have 
\begin{equation}
\exists O\in \mathfrak{O}, p \in O \subseteq E\text{ where }O\subseteq E^\circ 
\end{equation}
Then we have $p \in E^\circ $. Because $p$ is arbitrarily picked from $\set{p:E \in \mathcal{N}(p)}$, we now have $\set{p:E \in\mathcal{N}(p)}\subseteq E^\circ $. Arbitrarily pick $p'$ from $E^\circ$. We deduce
\begin{equation}
p' \in E^\circ \subseteq E\implies E\in \mathcal{N}(p')\implies p' \in \set{p: E\in \mathcal{N}(p)}
\end{equation}

Because $p'$ is arbitrarily picked from  $E^\circ $, we have $E^\circ \subseteq \set{p:E\in \mathcal{N}(p)}$ 
\end{proof}
\begin{theorem}
\label{0.2.7}
\textbf{(Closure Contain Exactly All Limit Points of $E$ and Points in $E$)} We have
\begin{equation}
\overline{E}= E' \cup  E
\end{equation}
\end{theorem}
\begin{proof}
  Arbitrarily pick $p\in (E'\cup E)^c$. Because $p$ is neither an limit point nor in  $E$, we know there exists an open set $O$ containing $p$ and disjoint with $E$. We know $O$ doesn't contain a limit point of $E$, otherwise  $O$ intersect with  $E$. We have constructed an open set containing  $p$ in  $(E'\cup E)^c$, so we have proved $(E'\cup E)^c$ is open. Then we know $E'\cup E$ is closed.\\

  Let $F$ be a closed set containing  $E$. Arbitrarily pick  $p\in F^c$. Clearly $p$ is not in $E$,  and we can see $p$ is not a limit point of $E$, otherwise the open set  $F^c$ would have  intersect with $E$. We have proved  $F^c\subseteq (E'\cup E)^c$. In other words, we have proved $E'\cup E$ is the smallest closed set containing $E$. 
\end{proof}
\begin{corollary}
\label{0.2.8}
\textbf{(Every Point in Closure And Not in the Set is a Limit Point)}
\begin{equation}
\overline{E}\setminus E\subseteq E'
\end{equation}
\end{corollary}
\fbox{\begin{minipage}{39em}
    Above illustrate two different but equivalent way to define closure and interior. One must be familiar with both of them.\\

    We now give some useful facts that shall later be compared with.
\end{minipage}}
\begin{theorem}
\label{0.2.9}
\textbf{(Point in Closure if and only if No Neighborhood is Disjoint)} We have
\begin{equation}
\overline{E}=\set{p: \forall M\in \mathcal{N}(p), M\cap E\neq \varnothing}
\end{equation}
\end{theorem}
\begin{proof}
  There are two possibilities for $p\in \overline{E}$
  \begin{equation}
  p\in E\text{ or }p\in E'
  \end{equation}
  There are two possibilities for point have no disjoint neighborhood
  \begin{equation}
  p\in E\text{ or }p\not\in E
  \end{equation}
  Notice each first possibilities are identical, and each second possibilities are equivalent.
\end{proof}
\begin{theorem}
\label{0.2.10}
\textbf{(Point is Limit Point if and only if In the Closure of Set Excluding The Point)} We have  
\begin{equation}
E'=\set{p:p \in \overline{E\setminus \set{p}}}
\end{equation}
\end{theorem}
\begin{proof}
  Notice each limit point $p\in  E'$ is still a limit point of $E\setminus \set{p}$, and notice each limit point of  $E$ is a limit point of $E\cup \set{p}$.
\end{proof}
\section{Three Non-Equivalent Compactness and Separable}
\fbox{\begin{minipage}{39em}
In this section, we will first give two equivalent definition of base and prove they are equivalent.
\end{minipage}}
\begin{definition}
\label{0.3.1}
\textbf{(Definition of Base)} We say a sub-collection $\mathcal{O}$ of topology $\tau$ on $X$ is a base if every open neighborhood $O$ around $x$ contain an open set $U$ in $\mathcal{O}$ containing $U$. That is
\begin{equation}
\forall x\in X, \forall O\in\tau:x\in O,\exists U\in \mathcal{O}, x\in U\subseteq O
\end{equation}
We call open sets in a base basic open sets.
\end{definition}
\begin{theorem}
\label{0.3.2}
\textbf{(Equivalent Definition of Base)} A sub-collection of topology $\tau$ is a base if and only if every open set can be expressed as a union of a set of basic open sets. That is, the necessary and sufficient condition for $\mathcal{O}$ to be a base is 
\begin{equation}
\forall O\in \tau, \exists \mathcal{U}\subseteq \mathcal{O}, O=\bigcup \mathcal{U}
\end{equation}
\end{theorem}
\begin{proof}
  From left to right, for each point $x\in O$, we know there exists $U_x\in \mathcal{O}$ such that $x\in U_x\subseteq O$. Collect $U_x$ for each $x\in O$ as $\mathcal{U}$, and we are partially done.\\

  From right to left, let $O$ be an open neighborhood around $x$. If there exists no $U\in \mathcal{O}$ such that $x\in U\subseteq O$, then every union of sub-collection $\mathcal{U}\subseteq\mathcal{O}$ that contain $x$ contain some points not in  $O$, which is impossible.  
\end{proof}
\fbox{\begin{minipage}{39em}
Then, we will define separable, and give a sufficient condition of separable.
\end{minipage}}
\begin{definition}
\label{0.3.3}
\textbf{(Definition of Separable)} We say $X$ is separable if 
\begin{equation}
  X\text{ has a countable dense subset }
\end{equation}
\end{definition}
\begin{theorem}
\label{0.3.4}
\textbf{(Base and Dense Set)} 
\begin{equation}
\text{ A set intersecting with all basic open set is dense }
\end{equation}
\end{theorem}
\begin{proof}
For each point $p$ not in $A$ and for each open neighborhood $N_p$ around $p$, there exists an basic open set  $O_p$ contained by $N_p$. The fact  $O_p$ intersect $A$ implies  $N_p$ intersect with  $A$. We have proved every point  $p$ not in $A $ is a limit point of $A$.
\end{proof}
\begin{corollary}
\label{0.3.5}
\textbf{(Countable Base Implies Separable)} 
\begin{equation}
X\text{ has a countable base }\implies X\text{ is separable }
\end{equation}
\end{corollary}
\begin{proof}
Let $\mathcal{O}$ be a countable base for $X$. For each $O\in \mathcal{O}$, we can collect a point $x_O\in O$, and have $A:=\set{x_O:O\in \mathcal{O}}$. Because $\mathcal{O}$ is countable, we know $A$ is countable, and by  \myref{Theorem}{1.12.4}, we know $A$ is dense.
\end{proof}
\fbox{\begin{minipage}{39em}
The above let us draw a Venn diagram, where existence of countable base is a small circle in the big circle separable.\\

Now, we give definition of three different compactness.
\end{minipage}}
\begin{definition}
\label{0.3.6}
\textbf{(Definition of Open Cover)} We say a collection $\set{G_\alpha  }$ of open sets is an open cover of $E$ if 
\begin{equation}
E\subseteq \bigcup \set{G_\alpha }
\end{equation}
\end{definition}
\begin{definition}
\label{0.3.7}
\textbf{(Definition of Compact Space)} We say a topological space $X$ is compact if  
\begin{equation}
\text{every open cover for $X$ has a finite open sub-cover}
\end{equation}
\end{definition}
\begin{definition}
\label{0.3.8}
\textbf{(Definition of Countably Compact Space)} We say a topological space $X$ is countably compact if 
\begin{equation}
\text{every countable open cover for $X$ has a finite open sub-cover}
\end{equation}
\end{definition}
\begin{definition}
\label{0.3.9}
\textbf{(Definition of Limit Point Compact Space)} We say a topological space $X$ is limit point compact if 
\begin{equation}
\text{every infinite subset of $X$ has a limit point}
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
It is clear that compact implies countably compact, as every countable cover in compact space has a finite sub-cover. We now explore the relation of the three compactness.
\end{minipage}}
\begin{theorem}
\label{0.3.10}
\textbf{(Compact Implies Countably Compact)} 
\begin{equation}
 X\text{ is compact }\implies X\text{ is countably compact }
\end{equation}
\end{theorem}
\begin{theorem}
\label{0.3.11}
\textbf{(Countably Compact Implies Limit Point Compact)} 
\begin{equation}
X\text{ is countably compact }\implies X\text{ is limit point compact }
\end{equation}
\end{theorem}
\begin{proof}
Arbitrarily pick an infinite $A$. We know  $A$ is either countable or uncountable. We first prove  \vi{if $A$ is countably infinite, then $A$ has a limit point}.\\

\As{$A$ has no limit point}. For each $a\in A$, because $a$ is not a limit point of $A$, we know there exists an open neighborhood  $O_a$ around $a$ such that  $O_a\cap A=\set{a}$. Notice that $A$ has no limit point let us deduce
\begin{equation}
A'=\varnothing \implies \overline{A}=A\implies A^c\text{ is open }
\end{equation}
For each $a\in A$, collect one $O_a$ into the collection $\mathcal{O}=\set{O_a:a\inA}$.\\

Then, because $A$ is countable, we see $\mathcal{O}\cup \set{A^c}$ is an countable cover for $X$, and every finite open sub-cover contain only finite amount of point of $A$ when  $A$ is infinite. \CaC $\vdone$\\

If $A$ is uncountable, then  $A$ contain a countable set  $B$. We know  $B$ has a limit point  $p$, and we know  $p$ is also a limit point for $A$.
\end{proof}
\begin{corollary}
\label{0.3.12}
\textbf{(Compact Implies Limit Point Compact)} If $X$ is compact, then $X$ is limit point compact.
\end{corollary}
\fbox{\begin{minipage}{39em}
Lastly, we give a theorem involving countable base.
\end{minipage}}
\begin{theorem}
\label{0.3.13}
\textbf{(Existence of Countable Base Implies Existence of Countable Sub-Cover)} 
\begin{equation}
X\text{ has a countable base }\implies\text{every open cover for $X$ has a countable sub-cover}
\end{equation}
\end{theorem}
\begin{proof}
Let $\mathcal{O}$ be a countable base for $X$ and let $\mathcal{G}$ be an open cover of $X$. We wish to find an countable open sub-cover of $\mathcal{G}$.\\

Because $\mathcal{O}$ is a base, for each $G\in \mathcal{G}$, there exists basic open set $O\in \mathcal{O}$ contained by $G$. Then because  $\mathcal{G}$ is an open cover, for each $p\in X$, there exists $G_p,O_p$ such that
\begin{equation}
p\in O_p\subseteq G_p
\end{equation}
Collect all $G_p$ from above so we have a sub-cover $\mathcal{G}'$. Because $\mathcal{O}$ is countable, we know $\mathcal{G}'$ is also countable.
\end{proof}
\fbox{\begin{minipage}{39em}
Now, if we want to draw a conclusion for this section by drawing a Venn diagram, we should first draw compact inside countably compact inside limit point compact. 
\end{minipage}}
\chapter{Important Notions in Metric Space}
\section{Sequence}
\begin{definition}
\label{1.1.1}
\textbf{(Definition of Metric)} We say a real-valued function $d:X^2\rightarrow \R$ is a metric if
\begin{equation}
d(x,x)=0 
\end{equation}
\begin{equation}
x\neq y\longrightarrow d(x,y)>0\text{ (Positive Definitness) }
\end{equation}
\begin{equation}
d(x,y)=d(y,x)\text{ (Commutative) }
\end{equation}
\begin{equation}
d(x,z)\leq d(x,y)+d(y,z)\text{ (Triangle Inequality) }
\end{equation}
\end{definition}
\begin{definition}
\label{1.1.2}
\textbf{(Definition of Sequence)} In this chapter, by a sequence in $X$, we mean a function from  $\N$ to  $X$
\end{definition}
\fbox{\begin{minipage}{39em}
Above is specification.
\end{minipage}}
\begin{definition}
\label{1.1.3}
\textbf{(Definition of Convergence of Reals)} Let $\set{a_n}$ be a sequence of reals. By $\set{a_n}$ converges to $a$ 
\begin{equation}
\lim_{n\to\infty} a_n=a
\end{equation}
We mean for each $\epsilon \inr^+$, there exists great enough $N_\epsilon \inn$  such that for each $n\inn$ 
\begin{equation}
n>N_\epsilon \implies \abso{a_n-a}<\epsilon 
\end{equation}
\end{definition}
\begin{definition}
\label{1.1.4}
\textbf{(Definition of Convergence)} Let $\set{a_n}$ be a sequence in metric space $X$. By $\set{a_n}$ converge to $a$
\begin{equation}
\lim_{n\to\infty}a_n=a
\end{equation}
We mean for each $\epsilon \inr^+$, there exists great enough $N\epsilon \inn$ such that for each $n\inn$
 \begin{equation}
n>N_\epsilon \implies d(a_n,a)<\epsilon 
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
Above is definition.
\end{minipage}}
\begin{theorem}
\label{1.1.5}
\textbf{(Other Definition for Convergence)} Let $\set{a_n}$ be a sequence in metric space $X$. We have
 \begin{gather}
\lim_{n\to \infty}a_n=a\iff \lim_{n\to\infty}d(a_n,a)=0\\
\liff (\forall \epsilon ,\exists N_\epsilon, n\geq N_\epsilon \iff  d(a_n,a)<\epsilon) \\
\liff (\forall \epsilon, \exists N_\epsilon , a_n\in B_\epsilon (a)\iff  n\geq N_\epsilon )
\end{gather}
\end{theorem}
\begin{theorem}
\label{1.1.6}
\textbf{(Limit of Sequence is Unique)} Let $\set{a_n}$ be a sequence in metric space $X$. We have
 \begin{equation}
\lim_{n\to\infty}a_n=a\text{ and }\lim_{n\to\infty}a_n=a'\implies a'=a
\end{equation}
\end{theorem}
\begin{proof}
Assume not unique and use $\epsilon=\frac{d(a',a)}{2}$ to cause a contradiction.
\end{proof}
\fbox{\begin{minipage}{39em}
Below discuss sub-sequence.
\end{minipage}}
\begin{definition}
\label{1.1.7}
\textbf{(Definition of Sub-Sequence)} We use
\begin{equation}
\set{a_{n_k}}
\end{equation}
To denote sub-sequence of $\set{a_n}$, so $n_k\inn$ must satisfy
 \begin{equation}
n_k> \max \set{n_1,\dots, n_{k-1}}\text{ and }n_k\geq k 
\end{equation}
\end{definition}
\begin{theorem}
\label{1.1.8}
\textbf{(Sequence Converge if and only if All Sub-sequence Converge)} 
\begin{equation}
\text{ Sequence $\set{a_n}$ converge to $a$ $\iff $ all sub-sequence $\set{a_{n_k}}$ converge to $a$ }
\end{equation}
\end{theorem}
\begin{proof}
From right to left is trivial. From left to right, notice $k_n\geq n$. 
\end{proof}
\begin{theorem}
\label{1.1.9}
\textbf{(Existence of a Convenient sub-Sequence)} 
\begin{gather}
\set{a_n}\text{ converge to }a\\
\implies  \text{ there exists a sub-sequence }\set{a_{n_k}}  \text{ such that }\forall k\inn, d(a_{n_k},a)<\frac{1}{k}
\end{gather}
\end{theorem}
\begin{proof}
The construction is done by recursion of selecting a point in $B_{\frac{1}{k+1}}(a)\cap \set{a_n}$ after $a_{n_k}$. Such point must exists, otherwise all point after $a_{n_k}$ is of distance to $a$ greater than  $\frac{1}{k+1}$.
\end{proof}
\fbox{\begin{minipage}{39em}
Below introduce Cauchy.
\end{minipage}}
\begin{definition}
\label{1.1.10}
\textbf{(Definition of Cauchy Sequence)} We say 
 \begin{equation}
\set{a_n}\text{ is a Cauchy sequence }
\end{equation}
If for each $\epsilon \inr^+$, there exists great enough $N_\epsilon \inn$ such that for each $n,k\inn$
\begin{equation}
n,k>N_\epsilon \implies d(a_n,a_k)<\epsilon 
\end{equation}
\end{definition}
\begin{theorem}
\label{1.1.11}
\textbf{(Every Convergent Sequence is Cauchy)}
\begin{equation}
\set{a_n}\text{ converge }\implies \set{a_n}\text{ is Cauchy }
\end{equation}
\end{theorem}
\begin{proof}
Let $\set{a_n}$ converge to $a$. We know for each $\epsilon $ there exists $N_{\frac{\epsilon }{2} }$ such that $n>N_{\frac{\epsilon }{2}}\implies d(a_n,a)<\frac{\epsilon}{2}$. Observe $m,k>N_\frac{\epsilon }{2}\implies d(a_m,a_k)\leq d(a_m,a)+d(a,a_k)<\epsilon $
\end{proof}
\fbox{\begin{minipage}{39em}
Lastly, we close this section with example of uncompleted metric space.
\end{minipage}}
\begin{theorem}
\label{1.1.12}
\textbf{(Not Every Cauchy Sequence Converge)} 
\begin{equation}
\set{a_n}\text{ is Cauchy NOT}\implies \set{a_n}\text{ converge }
\end{equation}
\end{theorem}
\begin{proof}
Let $X=\R \setminus \set{p}$ be standard. Observe $\set{a_n=p+\frac{1}{n}}$ is in $X$ and for each $\epsilon \inr^+$, we have
\begin{equation}
m\geq k>\frac{1}{\epsilon } \implies d(a_m,a_k)= a_k-a_m<\frac{1}{k}-\frac{1}{m}<\frac{1}{k}<\epsilon 
\end{equation}
Let $q\in X$. We know $q\neq p$. Let $\epsilon =\frac{\abso{p-q}}{2}$. Let $k>\frac{1}{\epsilon }$. Observe
\begin{equation}
\frac{1}{k}<\frac{\abso{p-q}}{2}\implies \frac{q-p}{2}<\frac{1}{k}<\frac{p-q}{2}
\end{equation}
And observe
\begin{align}
  d(a_k,q)=\abso{p+\frac{1}{k}-q}&>p-q+\frac{1}{k}>\frac{p-q}{2}\\
  &>q-p-\frac{1}{k}>\frac{q-p}{2}
\end{align}
So we have
\begin{equation}
d(a_k,q)>\frac{\abso{p-q}}{2}=\epsilon 
\end{equation}
We have found an open ball around $q$ that contain only finite amount of  $\set{a_n}$, showing $\set{a_n}$ does not converge to $q$ when $q$ arbitrarily picked from  $X$.

\end{proof}
\section{Closed}
\begin{definition}
\label{1.2.1}
\textbf{(Definition of Closure and Closed in Metric Space)} Let $E$ be a subset of  $(X,d)$. By closure $\overline{E}$, we mean the set containing precisely all possible points to which the sequence in $E$ may converge. We say $E$ is closed if every convergent sequence in $E$ converge to some point in $E$, in other words:
 \begin{equation}
\overline{E}=E
\end{equation}
\end{definition}
\begin{theorem}
\label{1.2.2}
\textbf{(Another Definition of Closure)}
\begin{equation}
\overline{E}\text{ is the smallest closed set containing }E
\end{equation}
\end{theorem}
\begin{proof}
To see $E\subseteq \overline{E}$ is simple, for each $x\in E$, the trivial sequence $\set{x_n=x}$ is a sequence in $E$ that converge to $x$.\\

We first prove \vi{$\overline{E}$ is closed}. Let $\set{x_n}$ be a convergent sequence in $\overline{E}$, and let
\begin{equation}
\lim_{n\to\infty} x_n=x
\end{equation}
We wish to prove $x\in \overline{E}$. If $\set{x_n}$ contain infinite terms in $E$, then we know $\set{x_n}$ has a sub-sequence $\set{x_{n_k}}$ in $E$ which converge to $x$ by  \myref{Theorem}{1.1.8}. By definition of closure, we know $x\in \overline{E}$ and we are done.\\

Now, we only have to consider when $\set{x_n}$ contain finite terms in $E$, which tell us $\set{x_n}$ contain infinite terms (a sub-sequence that converge to $x$) $\set{x_{n_k}}$ in $\overline{E}\setminus E$.\\

We wish to find a sequence in $E$ that converge to  $x$, then we know  $x$ is in $\overline{E}$. By definition of closure, we know each term $x_{n_k}$ of the sub-sequence $\set{x_{n_k}}$ is a limit of a sequence $\set{x^k_m}$ in $E$. Then for each $x_{n_k}$, we can pick a point $x^k_{m_k}$ in $E$ being $d(x,x_{n_k})$ closed to $x_{n_k}$ 
\begin{equation}
x_{m_k}^k\in E\text{ and }d(x^k_{m_k},x_{n_k})<d(x,x_{n_k})
\end{equation}
This also give us
\begin{equation}
d(x_{m_k}^k,x)\leq d(x_{m_k}^k,x_{n_k})+d(x_{n_k},x)<2d(x,x_{n_k})
\end{equation}
Now, we wish to prove 
\begin{equation}
\lim_{k\to\infty}x^k_{m_k}=x
\end{equation}
Because
\begin{equation}
\lim_{k\to\infty}x_{n_k}=x
\end{equation}
For each small $\epsilon $, we know there exists $N$ such that
\begin{equation}
k>N_\epsilon \implies d(x,x_{n_k})<\frac{\epsilon}{2} 
\end{equation}
Then we have
\begin{equation}
k>N_\epsilon \implies d(x^k_{m_k},x)<2d(x,x_{n_k})<\epsilon \vdone
\end{equation}
We now prove \blue{$\overline{E}$ is the smallest closed set containing $E$}.\\ 

Let $K$ be a closed set containing  $E$. We wish to show all $x\in \overline{E}$ is also in $K$. By definition, we know  $x$ is a limit of a sequence  $\set{x_n}$ in $E\subseteq K$, then because $K$ is closed, we know $x$ is also in $K\bdone$  
\end{proof}
\begin{theorem}
\label{1.2.3}
\textbf{(Manipulation of Closure)} We have
\begin{gather}
\overline{X}=X\text{ and }\overline{\varnothing}=\varnothing\\
\bigcup_{n=1}^\infty \overline{A_n}\subseteq \overline{\bigcup_{n=1}^\infty A_n}\text{ and }\overline{\bigcap_{n=1}^\infty A_n}\subseteq \bigcap_{n=1}^\infty \overline{A_n} 
\end{gather}
where the $\subseteq$ may be proper. Notice that $\infty$ does not need to be countable. 
\end{theorem}
\begin{proof}
$\overline{X}=X\text{ and }\overline{\varnothing}=\varnothing$ are clear. We now prove  \vi{$\bigcup_{n=1}^\infty \overline{A_n}\subseteq \overline{\bigcup_{n=1}^\infty A_n}$}\\

Let $x\in \bigcup_{n=1}^\infty \overline{A_n}$. We know $x$ is a limit of some sequence $\set{x_k}$ in some $A_i$. Notice that the sequence $\set{x_k}$ is also in $\bigcup_{n=1}^\infty A_n$, so we also have $x\in \overline{\bigcup_{n=1}^\infty A_n}$. $\vdone$\\

For a case where $\subseteq$ is proper, well order $\Q$ into $\set{a_n}_{n\inn}$. We know $\overline{\set{a_n}}=\set{a_n}$, so we have
\begin{equation}
\bigcup _{n=1}^\infty \overline{A_n}=\Q 
\end{equation}
We also have
\begin{equation}
\overline{\bigcup_{n=1}^\infty A_n}=\overline{\Q}=\R
\end{equation}
For a rigorous proof of $\overline{\Q}=\R$, notice for each $x\inr$, the supremum of the set $\set{q\inq: q<x}$ is $x$.\\

We now prove \blue{$\overline{\bigcap_{n=1}^\infty A_n}\subseteq \bigcap _{n=1}^\infty \overline{A_n}$}\\

Let $x\in \overline{\bigcap _{n=1}^\infty A_n}$. We know there is a sequence $\set{x_n}$ in $\bigcap _{n=1}^\infty A_n$ that converge to $x$. Notice that $\set{x_n}$ is a sequence in $A_i$ for all  $i$, so by definition of closure, the limit  $x$ is in  $\overline{A_i}$ for all $i$. $\bdone$\\

For a case where $\subseteq$ is proper, see the below proof for \myref{Theorem}{1.2.4}.
\end{proof}
\fbox{\begin{minipage}{39em}
If the above are said to be a "general" statements of how closure act on infinite union and intersection. The below shows a stronger property of closure, where one and only one of the inclusion become equality.
\end{minipage}}
\begin{theorem}
\label{1.2.4}
\textbf{(Manipulation of Closure)} We have
\begin{equation}
\overline{E}\cup \overline{F}=\overline{E\cup F}\text{ and }\overline{E\cap F}\subseteq \overline{E}\cap \overline{F}
\end{equation}
\end{theorem}
\begin{proof}
We first prove \vi{$\overline{E}\cup \overline{F}=\overline{E\cup F}$}.\\

$\overline{E}\cup \overline{F}\subseteq \overline{E\cup F}$ is clear, since a convergent sequence in $E$ is a convergent sequence in $E\cup F$. To see $\overline{E\cup F}\subseteq \overline{E}\cup \overline{F}$, let $x$ be a limit of a sequence  $\set{x_n}$ in $E\cup F$. We know $\set{x_n}$ has infinite terms (a sub-sequence converging to $x$) $\set{x_{n_k}}$ either in $E$, in $F$ or in both. Then by definition of closure, we know $x$ is either in $\overline{E}$, $\overline{F}$ or both. $\vdone$\\


We now prove \blue{$\overline{E\cap F}\subseteq \overline{E}\cap \overline{F}$}.\\

Notice that if a sequence $\set{x_n}$ is in $E\cap F$, then the sequence $\set{x_n}$ is both in $E$ and in $F$. Then we know the limit is both in  $\overline{E}$ and $\overline{F}$. $\bdone$\\

For a case where $\subseteq $ is proper, observe
\begin{equation}
E=(0,1)\text{ and }F=(1,2)
\end{equation}
We have
\begin{equation}
\overline{E\cap F}=\overline{\varnothing}=\varnothing \subset \set{1}=[0,1]\cap [1,2]=\overline{E}\cap \overline{F}
\end{equation}
\end{proof}
\begin{theorem}
\label{1.2.5}
\textbf{(Manipulation of Closed Sets)} Let $\mathfrak{F}$ be the family of closed sets. We have
\begin{gather}
\varnothing\text{ and }X\text{ are closed. }\\
\text{ Intersection of closed sets are closed. }\\
\text{ Union of finite closed sets are closed, but union of infinite closed set may not be closed. }
\end{gather}
\end{theorem}
\begin{proof}
In \myref{Theorem}{1.2.3}, we have proved $\varnothing$ and $X$ are closed. Let $\set{A_\ld}$ be an infinite collection of closed sets. Because $A_\ld $ are closed, by \myref{Theorem}{1.2.3}, we have
\begin{equation}
\overline{\bigcap_{\ld  \in \Lambda }A_\ld }\subseteq \bigcap _{\ld \in\Lambda }\overline{A_\ld }=\bigcap _{\ld \in\Lambda }A_\ld 
\end{equation}
And notice the other side is trivial.\\

Finite union of closed sets is closed is an immediate consequence of \myref{Theorem}{1.2.4} by induction. To see $\bigcup_{\ld \in \Lambda }A_\ld $ need not always be closed. Notice that if $\bigcup _{\ld \in\Lambda }A_\ld$ are closed, then we have
 \begin{equation}
   \overline{\bigcup_{\ld \in \Lambda }A_\ld}=\bigcup_{\ld \in\Lambda }A_\ld=\bigcup_{\ld \in\Lambda }\overline{A_\ld }
\end{equation}
but \myref{Theorem}{1.2.3} and \myref{Theorem}{1.2.4} tell us the equality between $\overline{\bigcup_{\ld \in\Lambda }A_\ld }=\bigcup_{\ld \in \Lambda }\overline{A_\ld }$ need not hold true. For a constructive counter-example, let $A_n=[\frac{1}{n},1]$, and observe
\begin{equation}
  \bigcup_{n=1}^\infty A_n=(0,1]\not\in \mathfrak{F}
\end{equation}
Notice if we let $A_n=(\frac{1}{n},1]$, we have a counter-example for $\bigcup_{\ld \in \Lambda }\overline{A_\ld }=\overline{\bigcup _{\ld \in\Lambda }A_\ld }$
\begin{equation}
  \bigcup_{n=1}^\infty A_n=\bigcup_{n=1}^\infty [\frac{1}{n},1]=(0,1]\subset [0,1]=\overline{(0,1]}=\overline{\bigcup_{n=1}^\infty(\frac{1}{n},1]}=\overline{\bigcup _{n=1}^\infty A_n}
\end{equation}
\fbox{\begin{minipage}{39em}
We now introduce an important idea hidden behind our above proofs for each theorems. 
\end{minipage}}
\begin{definition}
\label{1.2.6}
\textbf{(Definition of Limit Point)} We say $x$ is a limit point of  $E$ if there is a sequence $\set{x_n}$ in $E$ such that
\begin{equation}
\lim_{n\to\infty} x_n=x\text{ and }\forall n, x_n\neq x
\end{equation}
We denote the set of limit points of $E$ by  $E'$. We say a point in $E$ that isn't a limit point is an isolated point. Also, we say a set is perfect if $E'=E$. 
\end{definition}
\begin{theorem}
\label{1.2.7}
\textbf{(Property of Limit Points)} We have
\begin{equation}
\overline{E}=E'\cup E
\end{equation}
\end{theorem}
\begin{proof}
The fact $E\cup E'\subseteq \overline{E}$ is clear, as we notice for each $x$ in $E$, the sequence $\set{x_n=x}$ is a sequence in $E$ that converges to $x$. Let $x\in \overline{E}\setminus E$. We wish to show $x\in E'$. Let $\set{x_n}$ be a sequence in $E$ that converge to  $x$. Because $\set{x_n}$ is a sequence in $E$ and $x$ is not in $E$, we know  $\set{x_n}$ must not contain $x$, and we are done.
\end{proof}
\begin{corollary}
\label{1.2.8}
\textbf{(Property of Limit Points)} We have
\begin{equation}
E\text{ is closed }\iff  E'\subseteq E
\end{equation}
\end{corollary}
\begin{proof}
If $E$ is closed, then  $E'\cup E=\overline{E}=E$ tell us $E'\subseteq E$. If $E'\subseteq E$, then $\overline{E}=E'\cup E=E$
\end{proof}
\begin{theorem}
\label{1.2.9}
\textbf{(Property of Limit Points)} 
\begin{equation}
p\in E'\iff \forall \epsilon, B_\epsilon (p)\cap E\text{ is infinite }
\end{equation}
\end{theorem}
\begin{proof}
  From left to right, let $\set{x_n}$ be a sequence in $E$ that converge to $p$ and does not contain  $p$. For all $\epsilon$, we know there exists $N_\epsilon $ such that $n>N_\epsilon \implies x_n\in B_\epsilon (p)$. \As{the terms after $N_\epsilon $ is finitely distinct}. We can let $\epsilon=\min \set{x_k:k>N_\epsilon }$ and $\tCaC$\\

From right to left, we wish to construct a sequence $\set{x_n}$ in $E$ that converge to $p$. For all $n$, by premise we know there exists a point in  $B_{\frac{1}{n}}(p)\cap E$ that isn't $p$  (because $B_{\epsilon }(p)\cap E$ is infinite). Select that point as $x_n$. Then the sequence $\set{x_n}$ does converge to $p$ and does not contain $p$.
\end{proof}
\begin{theorem}
\label{1.2.10}
\textbf{(Property of Limit Points)} We have
\begin{gather}
(E\cap F)'\subseteq E'\cap F'\\
E'\cup F'=(E\cup F)'
\end{gather}
Where the $\subseteq$ may be proper. We also have
\begin{equation}
E\subseteq F\implies E'\subseteq F'
\end{equation}
Where the converse may not hold true. We also have
\begin{equation}
E'\text{ is closed. }
\end{equation}
\end{theorem}
\begin{proof}
For the first two statements, use the fact that a sequence in $E\cap F$ is in $E$ and a sequence in  $E$ is in $E\cup F$, and that a sequence in $E\cup F$ must has a sub-sequence in $E$ or $F$.\\

For an example of $\subseteq$ being proper, let $E=(0,1)$ and $F=(1,2)$. We have 
\begin{equation}
  (E\cap F)'=\varnothing \subset \set{1}=E'\cap F'
\end{equation}
For the third statements, use the fact a sequence in $E$ is in $F$. To see the converse may not hold true, let $E=(0,1)\cup \set{2}$ and $F=(0,1)$\\

We now prove \vi{$E'$ is closed}. Let $\set{x_n}_{n\inn}$ be a convergent sequence in $E'$. Let $x=\lim_{n\to\infty} x_n$. We wish to prove $x\in E'$. Notice that we can construct a sub-sequence $\set{x_{n_m}}_{m \inn}$ such that for all $m$, we have 
 \begin{equation}
d(x_{n_m},x)<\frac{1}{m}
\end{equation}
Remember $\set{x_{n_m}}$ converge to $x$, and $\set{x_{n_m}}\subseteq \set{x_n}$ is in $E'$. From now, we use $\set{x_u}$ to denote $\set{x_{n_m}}$ where $u=m$.\\ 

Because $\set{x_u}$ is in $E'$, so if  $x\in \set{x_u}$, our proof is trivially done. We only have to consider when $x\not\in \set{x_u}$.\\

Because $\set{x_u}_{u\inn}$ is in $E'$, we know for each  $u\inn$, there exists a sequence  $\set{x^u_k}_{k\inn}$ in $E$ that converges to $x_u$. Using the infinite amount of sequence $\set{\set{x^u_k}_{k\inn}:u\inn}$ in $E$, we wish to construct a sequence in $E$ that converge to  $x$ and doesn't contain  $x$.\\

Fix $u$. Because 
\begin{equation}
\lim_{k\to\infty} x_k^u=x_u
\end{equation}
We know there exists $N_{\frac{1}{u}}$ such that
\begin{equation}
k>N_{\frac{1}{u}}\implies d(x_k^u,x_u)<\frac{1}{u}
\end{equation}
Notice that because the limit is unique and we are under the consideration $x\not\in \set{x_n}$, it is impossible to happen that 
\begin{equation}
\forall k>N_{\frac{1}{u}}, x_k^u=x
\end{equation}
Otherwise we can see $\set{x^n_k}$ converge to $x$, not  $x_n$.\\

Then, we know there exists some  $k_u$ such that  $d(x_{k_u}^u,x_u)<\frac{1}{u}$ and $x_{k_u}^u<\frac{1}{u}$. Collect all such $x^u_{k_u}$ for all $u$, and we have a sequence in  $E$ that doesn't contain $x$. We now prove $\set{x^u_{k_u}}_{u\inn}$ converge to $x$.\\

Fix $\epsilon $. Recall how we construct $\set{x_u}$. We have
\begin{equation}
\forall u\inn, d(x_u,x)<\frac{1}{u}
\end{equation}
Observe  
\begin{equation}
u>\frac{2}{\epsilon }\implies d(x^u_{k_u},x)\leq d(x^u_{k_u},x_u)+d(x_u,x)<\frac{1}{u}+\frac{1}{u}<\frac{2}{u}<\epsilon \vdone
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
Lastly, we verify the idea of subspace topology. (need to formulate for limit point and closure)
\end{minipage}}
\begin{theorem}
\label{1.2.11}
\textbf{(Subspace Topology)} Let $Y$ be a subspace of  $(X,d)$, let $E\subseteq X$, and let $p\in Y$. We have
\begin{gather}
p\text{ is a limit point of $E\cap Y$ in }Y\implies p\text{ is a limit point of $E$ in  $X$ }\\
\text{ The closure of $E\cap Y$  in $Y$ is a subset of the closure of $E$ in $X$ }\\
E\text{ is closed in $X$ }\implies  E\cap Y\text{ is closed in $Y$ }
\end{gather}
where the converse of the first and the third statement may not hold true, and the subset relation in the second statement may be proper. 
\end{theorem}
\begin{proof}
For the first statement, use the fact a sequence is in $E\cap Y$ is in $E$.\\

For a non-trivial example of of the converse in first statement mat not hold true, let $X=\R$, let $Y=\set{1}\cup [2,3]$ and let $E=(0,3)$. We see $1$ and $0$ are both limit points of $E$ in $X$, and neither of them is a limit point of  $E\cap Y$ in $Y$, as $1\in Y$ is an isolated point and $0$ is not even in $Y$.\\

We now prove the second statement. Let $p$ be in the closure of $E\cap Y$, and let $\set{x_n}$ be a sequence in $E\cap Y$ that converge to $p$. Notice that the sequence $\set{x_n}$ is in $E$ and we are done.\\

We now prove the last statement. From left to right, let $\set{x_n}$ be a sequence in $E\cap Y$ that converge to some $p$ in $Y$. We wish to prove  $p$ is in  $E\cap Y$. Notice that $\set{x_n}$ is also in $E$, so we know  $p$ is in $E$. Then because $p$ is in $Y$, we know  $p\in  E\cap Y$.\\

For an non-trivial example of the converse in last statement may not hold true. Let $X=\R$, let $Y=(0,2)$ and $E=[1,2)$. Clearly $E$ is not closed, but  $E\cap Y=[1,2)$ is closed in $Y$ (One can even observe that $E$ in  $Y$ is even "informally" unbounded).\\
\end{proof}
\section{Open}
\begin{definition}
\label{1.3.1}
\textbf{(Definition of Interior Points and Open)} Let $E$ be a subset of $(X,d)$. By an interior point $p$ of $E$, we mean a point such every sequence  $\set{x_n}$ converge to $p$ must eventually be in  $E$:
 \begin{equation}
\exists N, \forall n>N, x_n\in E
\end{equation}
We call the set of interior points of $E$  interior, and denote interior by  $E^\circ $. We say $E$ is open if every sequence that converge to a point in  $E$ must eventually be in  $E$, in other words, every point of $E$ is an interior point of $E$:
 \begin{equation}
E^\circ =E
\end{equation}
\end{definition}
\begin{theorem}
\label{1.3.2}
\textbf{(Another Definition of Interior)} 
\begin{equation}
E^\circ\text{ is the greatest open set in $E$ }
\end{equation}
\end{theorem}
\begin{proof}
We first prove \vi{$E^\circ \subseteq E$}.\\

Let $p$ be an interior point of $E$. Verify for the trivial sequence $\set{x_n=p}_{n\inn}$. $\vdone$\\

We now prove \blue{$E^\circ $ is open}.\\

Let $x$ be a point in $E^\circ $, and let $\set{x_n}$ be a sequence converge to $x$. We wish to show  $\set{x_n}$ must eventually be in $E^\circ $. \As{$\set{x_n}$ doesn't end in $E^\circ $}. That is, there exists a sub-sequence $\set{x_u}$ of $\set{x_n}$ in $E\setminus E^\circ $.\\

Because $\set{x_u}$ is a sub-sequence of $\set{x_n}$, we know $\set{x_u}$ converge to $x$. Because of such, by  \myref{Theorem}{1.1.9}, we know there exists a sub-sequence $\set{x_r}$ of $\set{x_u}$ such that
\begin{equation}
\forall r\inn, d(x_r,x)<\frac{1}{r}
\end{equation}
Fix $r$. Notice that $x_r\in \set{x_u}$, so we know $x_r$ is not in  $E^\circ $. Then we know there exists a sequence $\set{x^r_m}$ converge to $x_r$ that does not end in $E$.\\

Then by \myref{Theorem}{1.1.9}, we know there exists a sub-sequence $\set{x^r_k}\subseteq \set{x^r_m}$ such that
\begin{equation}
\forall k\inn, d(x^r_k,x_r)<\frac{1}{k}
\end{equation}
Now for each $r$, notice that  $k=r$ implies
\begin{equation}
d(x_k^r,x)<d(x^r_k,x_r)+d(x_r,x)<\frac{1}{k}+\frac{1}{r}=\frac{2}{r}
\end{equation}
Collect all such $x_r^r$ as a sequence  $\set{x_r^r}$. Notice that every term $x_r^r$ is in the sequence $\set{x_m^r}$ which are not in $E$, so we know the sequence is not in $E$. Observe
 \begin{equation}
\forall \epsilon, r>\frac{2}{\epsilon }\implies d(x_r^r,x)<\frac{2}{r}<\epsilon 
\end{equation}
We have constructed a sequence $\set{x_r^r}$ that converge to $x$ but completely not in  $E\tCaC$ to $x\in E^\circ $. $\bdone$\\

Lastly, we prove \vi{$E^\circ $ is the greatest open set contained by $E$}. \As{There exists an open set $O\subseteq E$ such that $O\not\subseteq E^\circ $}. Let $x\in O\setminus E^\circ $. Because $x\not\in E^\circ $, we know there exists a sequence $\set{x_n}$ converge to $x$ and have a sub-sequence  $\set{x_k}\subseteq \set{x_n}$ not in $E$. Then because $x\in O$, we know the sub-sequence $\set{x_k}$ must eventually end in $O\subseteq E\tCaC$. $\vdone$
\end{proof}
\begin{theorem}
\label{1.3.3}
\textbf{(Manipulation of Interior)} We have
\begin{gather}
X=X^\circ\text{ and }\varnothing^\circ =\varnothing\\
\bigcup_{n=1}^\infty A_n^\circ \subseteq (\bigcup_{n=1}^\infty A_n)^\circ\\
(\bigcap _{n=1}^\infty A_n)^\circ \subseteq \bigcap _{n=1}^\infty A_n^\circ 
\end{gather}
where the $\subseteq$ can be proper.
\end{theorem}
\begin{proof}
The first statement is trivial. For the second and the third, use the fact a sequence that ends in  some $A_n$ will end in  $\bigcup A_n$ and the fact a sequence that ends in $\bigcap A_n$ will end in each $A_n$.\\

For an example of the second statement may be proper, well order all numbers in $(0,1)$, and let $A_n$ contain exactly one number. Then
\begin{equation}
\bigcup_{n=1}^\infty A_n^\circ=\bigcup_{n=1}^\infty \varnothing=\varnothing \subset (0,1)=(\bigcup_{n=1}^\infty A_n)^\circ 
\end{equation}
For an example of the third statement may be proper, let $A_n:=(1-\frac{1}{n},1+\frac{1}{n})$. Then
\begin{equation}
  (\bigcap _{n=1}^\infty A_n)^\circ =\set{1}^\circ =\varnothing \subset \set{1}=\bigcap_{n=1}^\infty A_n^\circ 
\end{equation}
\end{proof}
\begin{theorem}
\label{1.3.4}
\textbf{(Manipulation of Interior)} We have
\begin{gather}
E^\circ \cup F^\circ\subseteq (E\cup F)^\circ\\
(E\cap F)^\circ = E^\circ \cap F^\circ 
\end{gather}
And if $E\subseteq F$, we have
\begin{equation}
E^\circ \subseteq F^\circ 
\end{equation}
\end{theorem}
\begin{proof}
For the first statement, use the fact a sequence that ends in $E$ is a sequence that ends in $E\cup F$. Notice that a sequence end in $E\cup F$ need not end in neither $E$ nor  $F$.\\

To see the $\subseteq$ may be proper, let $E=[0,1]$ and $F=[1,2]$. We have
\begin{equation}
E^\circ \cup F^\circ= (0,1)\cup (1,2)\neq (0,2)=[0,2]^\circ =(E\cup F)^\circ 
\end{equation}
For $(E\cap F)^\circ \subseteq E^\circ \cap F^\circ $, use the fact a sequence that ends in $E\cap F$ will end in both $E$ and  $F$.\\

For $E^\circ \cap F^\circ \subseteq (E\cap F)^\circ $, use the fact a sequence that end in both $E$ and  $F$ will end in  $E\cap F$. In more rigor, let $N_E$ satisfy
 \begin{equation}
n>N_E\implies x_n\in E
\end{equation}
and let $N_F$ satisfy
\begin{equation}
n>N_F\implies x_n\in F
\end{equation}
Then we see
\begin{equation}
n>\max \set{N_E,N_F}\implies x_n\in E\cap F
\end{equation}
For the last statement, use the fact a sequence that ends in $E$ is a sequence that ends in  $F$
\end{proof}
\begin{theorem}
\label{1.3.5}
\textbf{(Manipulation of Open Sets)} We have
\begin{gather}
\text{ $X$ and  $\varnothing$ are open. }\\
\text{ Union of open sets are open. }\\
\text{ Finite intersection of open sets are open}\\
\text{ Infinite intersection of open sets may not be open. }
\end{gather}
\end{theorem}
\begin{proof}
In \myref{Theorem}{1.3.3}, we have proved $X$ and $\varnothing$ are open. Let $\set{A_\ld :\ld \in\Lambda }$ be a collection of open sets. By \myref{Theorem}{1.3.3}, we know
\begin{equation}
\bigcup_{\ld \in \Lambda } A_\ld= \bigcup_{\ld  \in \Lambda }A_\ld ^\circ \subseteq (\bigcup_{\ld  \in \Lambda } A_\ld )^\circ 
\end{equation}
The other side follows from \myref{Theorem}{1.3.2}.\\

Finite intersection of open sets are open follows from \myref{Theorem}{1.3.4}:
\begin{equation}
  (E\cap F)^\circ =E^\circ \cap F^\circ =E\cap F
\end{equation}
For an example of infinite intersection of open sets may not be open, let $A_n=(1-\frac{1}{n},1+\frac{1}{n})$. We have $\bigcap_{n=1}^\infty A_n=\set{1}$
\end{proof}
\fbox{\begin{minipage}{39em}
We now introduce some interaction between interior and closure operator.
\end{minipage}}
\begin{theorem}
\label{1.3.6}
\textbf{(Interaction of Interior and Closure)} We have
\begin{equation}
  (E^\circ )^c=\overline{E^c}
\end{equation}
\end{theorem}
\begin{proof}
$x\in \overline{E^c}$ means there exists a sequence in $E^c$ converge to  $x$. That sequence has no term in $E$, so clearly does not end in  $E$. This show  $x\not \in E^\circ $, which means $x\in (E^\circ )^c$.\\

$x\not \in E^\circ $ means there exists a sequence $\set{x_n}$ that converges to $x$ and does not end in  $E$. We know $\set{x_n}$ has a sub-sequence $\set{x_k}$ not in $E$ that converges to $x$. The sequence $\set{x_k}$ is in $E^c$, and converge to $x$, so we know  $x\in \overline{E^c}$
\end{proof}
\begin{theorem}
\label{1.3.7}
\textbf{(Non-relation)}  
\begin{equation}
  \overline{E^\circ }\subseteq \overline{E}\text{ and }E^\circ \subseteq (\overline{E})^\circ 
\end{equation}
Are true, but the $\subseteq$ can be proper. Also, $\overline{E^\circ }$ and $(\overline{E})^\circ $ are incomparable.
\end{theorem}
\begin{proof}
For $\overline{E^\circ }\subset \overline{E}$ and $E^\circ \subset (\overline{E})^\circ $, let $E=\Q$. We have
 \begin{equation}
\overline{E^\circ }=\overline{\varnothing}=\varnothing \subset \R=\overline{\Q}=\overline{E}
\end{equation}
And we have
\begin{equation}
E^\circ = \varnothing \subset \R=(\R)^\circ  = (\overline{\Q})^\circ = (\overline{E})^\circ 
\end{equation}
\end{proof}
For $\overline{E^\circ }\not \subseteq (\overline{E})^\circ $, let $E=[0,1]$. We have
\begin{equation}
\overline{E^\circ }=[0,1]\not\subseteq (0,1)=(\overline{E})^\circ 
\end{equation}
For $(\overline{E})^\circ \not\subseteq \overline{E^\circ }$, let $E=\Q$ . We have
\begin{equation}
  (\overline{E})^\circ =\R \not\subseteq \varnothing= \overline{E^\circ }
\end{equation}
\fbox{\begin{minipage}{39em}
We now shed light on subspace topology of sequential space. 
\end{minipage}}
\begin{theorem}
\label{3.3.2}
\textbf{(Subspace Topology)} Let $Y$ be a subspace of $(X,d)$, let $E\subseteq X$, and let $p\in  Y$. We have
\begin{gather}
p\text{ is an interior point of $E$ in $X$ }\implies p\text{ is an interior point of $E\cap Y$ in $Y$ } \\
\text{ $Y\cap E^\circ $ in $X$ is a subset of the interior of $E\cap Y$ in $Y$ }\\
E\text{ is open in $X$ }\implies E\cap Y\text{ is open in $Y$ }
\end{gather}
where the converse may not hold true.
\end{theorem}
\begin{proof}
We first prove the first statement. Let $\set{x_n}$ be a sequence in $Y$ that converge to $p$. Because  $p$ is an interior point of  $E$ in  $X$, and  $\set{x_n}$ is in $X$, as  $Y\subseteq X$, we know there exists $N$ such that 
 \begin{equation}
n>N\implies x_n\in E
\end{equation}
Notice $x_n\in Y$, and we are done.\\

For a nontrivial example of the converse of the first statement may not hold true, let $E=(0,2)$, let $Y=\set{1}\cup (2,3)$. We see $1$ is an interior point of  $E$ in  $\R$, but  $1$ isn't an interior point of  $\set{1}=E\cap Y$ in $Y$.

The second and the third statement follows from the first statement. 
\end{proof}
\fbox{\begin{minipage}{39em}
We now show that metric space is sequential.
\end{minipage}}
\begin{theorem}
\label{1.3.9}
  \textbf{(Open Balls are Sequentially Open)} 
  \begin{equation}
  B_r(p)\text{ is open }
  \end{equation}
\end{theorem}
\begin{proof}
Let $x\in B_r(p)$. We wish to show every sequence $\set{x_n}$ that converge to $x$ ends in  $B_r(p)$. Let $u=r-d(p,x)$. Notice that $B_u(x)\subseteq B_r(p)$ and that $\set{x_n}$ ends in $B_u(x)$, and we are done.
\end{proof}
\begin{theorem}
\label{1.3.10}
\textbf{(Metric Spaces are Sequential)} 
\begin{gather}
\text{ $p$ is an interior point of $E$ }\\
\liff \text{ there exists an small enough open ball $B_r(p)$ contained by $E$}
\end{gather}
\end{theorem}
\begin{proof}
We first prove from left to right. \As{every open ball $B_r(p)$ is too big to be contained by $E$}. That is:
\begin{equation}
\forall \epsilon, B_\epsilon (p)\setminus E\neq \varnothing
\end{equation}
Then for each $n$, we let  $x_n\in B_{\frac{1}{n}}(p)\setminus E$. Then $\set{x_n}$ is a sequence outside of $E$ that converge to  $p\tCaC$ to $p\in E^\circ $.\\

We now prove from right to left. Let $\set{x_n}$ be a sequence converge to $p$. We know there exists $N$ such that
\begin{equation}
n>N\implies x_n\in B_r(p)\subseteq E
\end{equation}
This finish our proof.
\end{proof}
\begin{corollary}
\label{1.3.11}
\textbf{(Metric Spaces are Sequential)} 
\begin{gather}
\text{ $E$ is open  }\\
\liff \text{ for each point  $p$ in  $E$ there exists an small enough open ball $B_r(p)$ contained by $E$ }
\end{gather}
\end{corollary}
\fbox{\begin{minipage}{39em}
Lastly, the most important.
\end{minipage}}
\begin{theorem}
\label{1.3.12}
\textbf{(Topology Axiom)}
\begin{equation}
E\text{ is open  }\iff E^c\text{ is closed }
\end{equation}
\end{theorem}
\begin{proof}
We first prove from left to right. Let $\set{x_n}$ be a sequence in $E^c$ that converge to $x$. We wish to show  $x\in E^c$. \As{$x\in E$}. Because $E$ is open, we know $\set{x_n}$ eventually ends in $E\tCaC$.\\

We now prove from right to left. Let $x\in E$, and let $\set{x_n}$ be a sequence converge to $x$. We wish to show  $\set{x_n}$ eventually ends in $E$. Because  $x\not \in E^c$, and $E^c$ is closed, we know  $\set{x_n}$ has no sub-sequence in  $E^c$, otherwise we can see that sub-sequence in $E^c$ converge to  $x\not\in E^c$.\\

Then we know there exists only finite terms in $E^c$. Let $N$ be the maximal index of all finite terms in  $E^c$. We see
 \begin{equation}
n>N\implies x_n\not\in E^c\implies x_n\in E
\end{equation}
\end{proof}
\section{Connected}
\begin{definition}
\label{1.4.1}
\textbf{(Definition of Separated)} We say two sets $A,B$ are separated if 
 \begin{equation}
A\cap \overline{B}=\varnothing=\overline{A}\cap B
\end{equation}
\end{definition}
\begin{theorem}
\label{1.4.2}
\textbf{(Subsets of Separated Sets are Separated)} Let $A\subseteq N$ and $B\subseteq M$.  
\begin{equation}
N,M\text{ are separated }\implies A,B\text{ are separated }
\end{equation}
\end{theorem}
\begin{proof}
Notice
\begin{equation}
\overline{A}\subseteq \overline{N}\subseteq M^c\subseteq B^c
\end{equation}
And
\begin{equation}
\overline{B}\subseteq \overline{M} \subseteq N^c \subseteq A^c
\end{equation}
\end{proof}
\begin{theorem}
\label{1.4.3}
\textbf{(Subspace Topology)} Let $Y$ be a subspace of $(X,d)$.
\begin{equation}
A,B\text{ are separated }\implies A\cap Y\text{ and }B\cap Y\text{ are separated in $Y$ }
\end{equation}
The converse may not hold true.
\end{theorem}
\begin{proof}
In \myref{Theorem}{1.2.11}, we have proved the closure of $A\cap Y$ in $Y$ is a subset of the closure of  $A$ in $X$. Then because $A,B$ are separated, we know the closure of  $A\cap Y$ in $Y$ is disjoint to  $B$, thus disjoint to $B\cap Y$. The other side is similar.\\

To see the converse may not hold true, let $Y=(0,1)\cup (2,3)$, and let $A=(0,2)$ and $B=(1,3)$. 
\end{proof}
\begin{theorem}
\label{1.4.4}
\textbf{(Equivalent Definition of Connected)} The following are equivalent
\begin{gather}
E\text{ is not a union of two nonempty separated sets. }\\
\liff E\text{ has no proper nontrivial clopen subset in subspace topology for $E$. }
\end{gather}
\end{theorem}
\begin{proof}
We prove
\begin{gather}
E\text{ has a proper non-trivial clopen subset in subspace topology for $E$}\\
\liff E\text{ is a union of two non-empty separated sets }
\end{gather}
From \vi{left to right}, let $M\subseteq E$ be clopen in subspace topology of $E$ . We wish to show $M\text{ and }E\setminus M$ are separated, and we are done. \As{$M\text{ and }E\setminus M$ are not separated}. WOLG, let $x\in M'\cap (E\setminus M)$.\\

 Because  $x\in E\setminus M$ and $E\setminus M$ is open in subspace topology of $E$, we know there exists open ball $B_r(x)$ such that $B_r(x)\cap E\subseteq E\setminus M$. Because  $x\in M'$, we know $B_r(x)$ contain infinite points in $M\tCaC$ to $B_r(x)\cap E\subseteq E\setminus M$. $\vdone$\\


We now prove from \blue{right to left}. Let $A$ and  $B$ be separated and  $E=A\cup B$. We wish to show $A$ is clopen in subspace topology of  $E$. Notice we have 
\begin{equation}
A=\overline{A}\cup E
\end{equation}
so we know $A$ is closed in subspace topology of  $E$. Because we have
\begin{equation}
A\subseteq \overline{B}^c
\end{equation}
So we have
\begin{equation}
A=\overline{B}^c \cap E \bdone
\end{equation}
\end{proof}
\begin{theorem}
\label{3.3.3}
\textbf{(Union of Connected Sets that have Nonempty Intersection is Connected)} Let $\mathcal{F}$ be a class of connected sets. We have 
\begin{equation}
\bigcap \mathcal{F}\neq \varnothing \implies \bigcup \mathcal{F}\text{ is connected }
\end{equation}
\end{theorem}
\begin{proof}
\As{$\bigcup \mathcal{F}$ is not connected}. Let 
\begin{equation}
\bigcup  \mathcal{F}= A \disjointunion B\text{ and }A\neq \varnothing\neq B
\end{equation}
And let $A,B$ be relatively open to  $\bigcup \mathcal{F}$. We know $\bigcap \mathcal{F}$ must intersect with either $A$, or  $B$, or both.\\

WOLG, let
\begin{equation}
A\cap \bigcap \mathcal{F}\neq \varnothing
\end{equation}
Because $B$ is non-empty and $B\subseteq \bigcup \mathcal{F}$, we know $B$ must intersect with some $F_n\in \mathcal{F}$. Notice that because $A\cap \bigcap \mathcal{F}\neq \varnothing$, we have $A\cap F_n\neq \varnothing$. Then by \myref{Theorem}{1.3.1}, we see $A\cap F_n$ and $B\cap F_n$ are both relatively open to $F_n$, while $F_n= (A\cap F_n)\disjointunion (B\cap F_n)\tCaC$ 
\end{proof}

\section{Metric Space: Open}
\begin{definition}
\label{1.5.1}
\textbf{(Definition of Open Ball)} Let $(X,d)$ be a metric space, we say the set
\begin{equation}
B_r(x)=\set{y \in X: d(x,y)<r}
\end{equation}
is the open ball of radius $r$ around  $x$
\end{definition}
\begin{theorem}
\label{1.5.2}
\textbf{(Basic Property of Open Ball)} If $r\leq h$, then  $B_r(x)\subseteq B_h(x)$.
\end{theorem}
\fbox{\begin{minipage}{39em}
Give clear notice that although we use the word "open" ball, we have not proved "open" ball is open. In fact, we have not even defined what would be open.\\

Notice in $\R^1$, the open ball  $B_r(x)$ is just the interval $(x-r,x+r)$, and the interval $(a,b)$ is the open ball $B_{\frac{b-a}{2}}(\frac{a+b}{2})$. Also notice $B_0(x)\neq (x,x)=\varnothing$.\\

The following first define interior points, then define open set from definition of interior points.
\end{minipage}}
\begin{definition}
\label{1.5.3}
\textbf{(Definition of Interior Points and Open)} A point $p$ is an interior point of $E$ if 
\begin{equation}
\exists r\inr^+, B_r(x)\subseteq E
\end{equation}
The set  of interior points of  $E$ is called interior $E^{\circ }$ of $E$. Also, we say $E$ is open if 
\begin{equation}
E^\circ =E
\end{equation}
\end{definition}
\begin{theorem}
\label{1.5.4}
\textbf{(Basic Property of Interior)} For all set $E$, we have  $E^\circ \subseteq E$
\end{theorem}
\fbox{\begin{minipage}{39em}
Now, we prove an "open" ball is indeed open. The proof of such should of course be completely rigorous, but to come up with a proof rely more than rigor. One can and should try to use geometric intuition to form a proof, and try to rigorously formulate the proof to verify whether the idea also hold true in all metric spaces. \\

Notice \myref{Theorem}{1.7.6} will prove that our definition of open do satisfy the axioms of open sets. In other words, every metric induce a topology. 
\end{minipage}}
\begin{theorem}
\label{1.5.5}
\textbf{(Open Ball is Open)} Open ball is open.
\end{theorem}
\begin{proof}
  For each point $p\in B_r(x)$ with distance to the center $r'$, we can see the ball of radius  $r-r'$ centering $p$ is contained by $B_r(x)$.
\end{proof}
\begin{theorem}
\label{1.5.6}
\textbf{(Compatibility of Definitions of Open)} 
Let $\mathfrak{O}$ be the family of open set, by our definition of open in metric space $X$, we have
 \begin{equation}
\varnothing , X \in \mathfrak{O}
\end{equation}
\begin{equation}
A, B \in \mathfrak{O}\implies A\cap B\in \mathfrak{O}
\end{equation}
\begin{equation}
\mathfrak{A}\subseteq \mathfrak{O}\implies \bigcup \mathfrak{A}\in\mathfrak{O}
\end{equation}
\end{theorem}
\begin{proof}
Notice $\varnothing^\circ =\varnothing$. Every open ball centering any point is clearly contained by $X$.\\

For any point in the intersection of two open sets, we by definition have two open balls where each of them is in $A$ or $B$. Pick the smaller one and we are done.\\

For each point $p$ in an union of open sets, we know there exists an open set $O$ in the union containing $p$. By definition we have an open ball centering  $p$ contained by  $O$. This open ball is contained by the union.
\end{proof}
\fbox{\begin{minipage}{39em}
Now, we present some example of open sets in different metric spaces. Give clear notice that some open set in a sub-metric space may not be open in the larger metric space.
\end{minipage}}
\begin{theorem}
\label{1.5.7}
\textbf{(Examples of Open Sets in Euclidean Metric Space)} The followings are open if not specified to be not open
\begin{gather}
   (-\infty , a)\text{ in }\R\\
   (-\infty,a]\text{ is not open in }\R\\
   (a,b)\text{ in }\R\\
   [a,b)\text{ is not open in }\R\\
   (a,b)\times \set{c}\text{ is not open in  }\R^2\\
   (a,b)\times (c,d)\text{ in }\R^2\\
   \set{(x,y)\inr^2: x^2+y^2\neq 1}\text{ ($\R^2$ minus a sphere) }\\
      \R^2 \text{ in } \R^2\\ 
      \Q\text{ in }\Q\\
      \Q\text{ is not open in }\R\\
      (1,2)\cap \Q\text{ in }\Q\\
      [1,2]\cap \Q\text{ is not open in }\Q\\
      (1,2)\cap \Q\text{ is not open in }\R
\end{gather}
\end{theorem}
\begin{theorem}
\label{1.5.8}
\textbf{(Example: Discrete Metric)} Discrete metric is defined as
\begin{equation}
d(x,y)=\begin{cases}
  1& \text{ if  }x\neq y\\
  0& \text{ if  }x=y
\end{cases}
\end{equation}
every set in discrete metric space is open.
\end{theorem}
\begin{proof}
Every ball is either the whole space or the center, depending on if the radius is greater than $1$. Pick any ball of radius smaller than or equal to  $1$ and we are done.
\end{proof}
\begin{theorem}
\label{1.5.9}
\textbf{(Subspace Topology)} Let $(X,d)$ be a metric space and let $(Y,d_Y)\subseteq (X,d)$, where $d_Y$ is the restriction of $d$. Let $\tau$ be the standard topology for $X$. The standard topology $\tau_Y$ for $(Y,d_Y)$ is exactly
\begin{equation}
\tau_Y=\set{O\cap Y: O\in \tau}
\end{equation}
\end{theorem}
\begin{proof}
In this proof, in metric space $(Y,d^Y)$, we will denote the open ball centering $p$ of radius $r$ as $B^Y_r(p)$. In symbol
\begin{equation}
B_r^Y(p):=B_r(p)\cap Y
\end{equation}
Arbitrarily pick $O$ from $\tau$. We wish to prove \vi{$O\cap Y$ is open in $Y$}. Because $O$ is open, for each $p\in O\cap Y$, we know there exists an open ball  $B_r(p)$ contained by $O$. Then because $B_r^Y(p)\subseteq B_r(p)$ and $B_r^Y(p)\subseteq Y$, we have
\begin{equation}
B_r^Y(p)\subseteq B_r(p)\cap Y\subseteq O\cap Y\vdone
\end{equation}
Arbitrarily pick $O_Y$ from  $\tau_Y$. We wish to prove
\begin{equation}
\blue{\exists O\in \tau, O_Y=O\cap Y}
\end{equation}
For each point $p\in O_Y$, because  $O_Y$ is open in $Y$, we know there exists an radius $r_p$ small enough so that the open ball $B_{r_p}^Y(p)$ is contained by $O_Y$. Collect all such $r_p$, and let
\begin{equation}
O:=\bigcup_{p\in O_Y}B_{r_p}(p)
\end{equation}
We know $O$ is open in  $X$, we wish to prove
 \begin{equation}
\teal{O_Y=O\cap Y}
\end{equation}
Recall the definition of $O$. It is clear that $O_Y\subseteq O\cap Y$. Let $x\in O\cap Y$. Because $x\in O$, we know there exists $q\in O_Y$ such that
\begin{equation}
x\in B_{r_q}(q)
\end{equation}
then because $x\in Y$, we know
\begin{equation}
x\in B_{r_q}(q)\cap Y=B_{r_q}^Y(q)\subseteq O_Y\tdone \bdone
\end{equation}
\end{proof}
\begin{theorem}
\label{1.5.10}
\textbf{(General Sufficient Condition for Open)}
\begin{equation}
E\text{ is finite or }E^c\text{ is finite }\implies E\text{ is open }
\end{equation}
\end{theorem}
\begin{proof}
Verify for  $B_{\min \set{d(p,y):y\in E^c}}(p)$
\end{proof}
\section{Metric Space: Closed and Limit Point}
\begin{definition}
\label{1.6.1}
\textbf{(Definition of Limit Points and Closed)} A point $p$ is a limit point of $E$ if 
 \begin{equation}
\forall r\inr^+, \exists q\neq p, q\in B_r(p) \cap E
\end{equation}
or equivalently 
\begin{equation}
\forall r\inr^+, B_r(p)\cap E\setminus \set{p}\neq \varnothing
\end{equation}
The set of limit points of  $E$ is denoted $E'$. We say $E$ is closed if 
\begin{equation}
E'\subseteq E
\end{equation}
\end{definition}
\begin{theorem}
\label{1.6.2}
\textbf{(Property of Limit Points)} Let $E\subseteq F$. We have
\begin{equation}
E'\subseteq F'
\end{equation}
\end{theorem}
\begin{proof}
If $p$ is a limit point of $E$, then we know every open ball centering $p$ non-trivially intersect with  $E$, which implies non-trivially intersecting with $F$. 
\end{proof}
\begin{theorem}
\label{1.6.3}
\textbf{(Property of Limit Points)} If $p \in E'$, then every open neighborhood around $p$ non-trivially intersect with  $E$.
\end{theorem}
\begin{proof}
  Notice that an open neighborhood around $p$ must contain an open ball centering $p$.
\end{proof}
\fbox{\begin{minipage}{39em}
    Notice \myref{Theorem}{1.12.3} is written in language of general topology. Now, we prove that our definition of closed and limit point in metric space is compatible to those in general topology. Then we can apply the result we have in general topology into metric space.
\end{minipage}}
\begin{theorem}
\label{1.6.4}
\textbf{(Compatibility of Definition of Limit Point)} A point $p$ is a limit point of $E$ in metric space $(X,d)$ if and only if  $p$ is a limit point of $E$ in topology induced by $(X,d)$ 
\end{theorem}
\begin{proof}
From left to right, notice every open neighborhood around $p$ contain an open ball centering $p$. From right to left, notice every open ball is an open neighborhood.
\end{proof}
\begin{theorem}
\label{1.6.5}
\textbf{(Compatibility of Definition of Open and Closed)} 
Let $\mathfrak{O},\mathfrak{F}$ respectively be the family of open sets and family of closed set under our metric definition. We have
\begin{equation}
E\in \mathfrak{O}\iff E^c\in\mathfrak{F}
\end{equation}
\end{theorem}
\begin{proof}
From left to right, let $p$ be a limit point of $E^c$. If $p$ is not in $E^c$, we know there exists an open ball centering  $p$ contained in $E$. Meanwhile, because  $p$ is a limit point of $E^c$, we know every open ball centering $p$ contain a point $q\neq p$ in $E^c$. Then we can deduce $p$ must be in $E^c$.\\

From right to left, let $p\in E$. Because $p$ is not a limit point of $E^c$, we know there exists an open ball centering $p$ disjoint $E^c$, that is, contained by  $E$.
\end{proof}
\begin{corollary}
\label{1.6.6}
\textbf{(Axioms for Closed Sets)} Let $\mathfrak{F}$ be the family of closed sets under our metric definition. We have
\begin{gather}
X,\varnothing \in \mathfrak{F}\\
A,B\in\mathfrak{F}\implies A\cup  B\in\mathfrak{F}\\
\mathfrak{B}\subseteq \mathfrak{F}\implies \bigcap \mathfrak{B}\in \mathfrak{F}
\end{gather}
\end{corollary}
\fbox{\begin{minipage}{39em}
Notice \myref{Corollary}{1.7.6} is proved using language of general topology in the first section of this chapter. I personally haven't tried to prove \myref{Corollary}{1.7.6} using limit point definition, but I think this won't be difficult.\\

Again, we now give some examples of closed set. One can see that the proof for some sets are closed if following straight from the limit point definition is extremely long: One have to first find the set of limit points, by checking every points whether for all real number a property stand, and then check if the set of limit points is a subset of $E$. A possible optimal way is proving the complement is open, since proving something is open is more.
\end{minipage}}
\begin{theorem}
\label{1.6.7}
\textbf{(Example of Closed Sets in Euclidean Metric Space)} The followings are closed set if not specified.
\begin{gather}
[a,b]\text{ in }\R\\
[a,b)\text{ is not closed in }\R\\
  [a,\infty)\text{ in }\R\\
  (a,\infty)\text{ is not closed in}\R\\
  [a,b]\times [c,d]\text{ in }\R^2\\
  \set{c}\text{ in }\R\\
  [a,b]\times [c,c]\text{ in }\R^2\\
  [a,b)\times [c,d]\text{ is not closed in }\R^2\\
  [a,b)\times [c,c]\text{ is not closed in }\R^2\\
 \set{(x,y)\inr^2:x^2+y^2=1}\text{ A circle }\\
[0,1]\cap \Q \text{ is closed in $\Q$ but not in  $\R$ } \\
\text{ finite set in $\R^n$ } \\
\Z  \text{ in $\R$ }\\
\R^2 \text{ in  }\R^2
\end{gather}
\end{theorem}
\begin{theorem}
\label{1.6.8}
\textbf{(Example: Discrete Metric)} Every set in discrete metric space is closed.
\end{theorem}
\begin{theorem}
\label{1.6.9}
\textbf{(Subspace Topology)} Let $Y\subseteq X$. If $p$ is a limit point of $E\cap Y$ in $Y$, then $p$ is a limit point of  $E$ in $X$. 
\end{theorem}
\begin{corollary}
\label{1.6.10}
\textbf{(Subspace Topology)} Let $(X,d)$ be a metric space and let $(Y,d_Y)\subseteq (X,d)$, where $d_Y$ is the restriction of $d$. Let $\tau^c$ be the family of closed set with respect to $X$, and let $\tau^c_Y$ be the family of closed set with respect to $Y$. We have
\begin{equation}
\tau^c_Y=\set{F\cap Y:F\in \tau^c}
\end{equation}
\end{corollary}
\begin{proof}
If $p\in Y$ is a limit point of $F\cap Y$ in $Y$, then  $p$ is a limit point of $F$, which implies  $p\in F$. We have proved $\set{F\cap Y:F\in \tau^c}\subseteq \tau_Y^c$. We now prove
\begin{equation}
\vi{ \tau_Y^c\subseteq \set{F\cap Y:F\in \tau^c}}
\end{equation}
For each $F_Y\in \tau_Y^c$, we know $Y\setminus F_Y$ is open with respect to $Y$. Then we know there exists open $O\in\tau$ such that $O\cap Y=Y\setminus F_Y$. Then we have $O^c \cap Y=F_Y\vdone$
\end{proof}
\begin{theorem}
\label{1.6.11}
\textbf{(General Sufficient Condition for Closed)} If a set $E$ is finite, it is closed.
\end{theorem}
\section{Metric Space: Cauchy Sequence}
\fbox{\begin{minipage}{39em}
We first introduce sequence and convergence.
\end{minipage}}
\begin{definition}
\label{1.7.1}
\textbf{(Definition of Convergence in Metric Space)} Let $X$ be a metric space. We say $\set{a_n}$ converge to $a$
 \begin{equation}
\lim_{n\to\infty}a_n=a
\end{equation}
If 
\begin{equation}
\forall \epsilon \inr^+,\exists N_\epsilon\inn , n>N_\epsilon \implies  d(a_n,a)<\epsilon 
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
We now introduce two properties concerning limit and convergence.  
\end{minipage}}
\begin{theorem}
\label{1.7.2}
\textbf{(In Metric Space, Sequence Converge to At Most One Point)} Let $\set{a_n}$ be a sequence in $(X,d)$. We have
\begin{equation}
\lim_{n\to\infty} a_n=a\text{ and }\lim_{n\to\infty} a_n=a'\implies a'=a
\end{equation}
\end{theorem}
\begin{proof}
Consider when $\epsilon =\frac{d(a,a')}{2}$
\end{proof}
\begin{theorem}
\label{1.7.3}
\textbf{(Limit Point is Limit of Some Sequence)} Let $E\subseteq X$ and let $p$ be a limit point of $E$. There exists a sequence $\set{p_n}$ in $E$  such that
\begin{equation}
\lim_{n\to\infty}p_n=p
\end{equation}
\end{theorem}
\begin{proof}
For each $k\inn$, we know there exists point  $q\in E$ in open ball $B_{\frac{1}{k}}(p)$. For each $k\inn$, let such $q$ be  $p_k$. 
\end{proof}
\begin{theorem}
\label{1.7.4}
\textbf{(Basic Property for Convergence Sequence)} Let $X$ be a metric space. We have
\begin{equation}
\lim_{n\to\infty}a_n=a\iff  \text{ every open ball $B_r(a)$ contain all but finitely many term of $\set{a_n}$ }
\end{equation}
\end{theorem}
\begin{proof}
From left to right is trivial. From right to left, let $k$ be the greatest natural such that $a_k\in \set{a_n}\cap B_r(a)$. Use $N=k+1$ and we are done.
\end{proof}
\fbox{\begin{minipage}{39em}
We now introduce two equivalent definition of bounded.
\end{minipage}}
\begin{definition}
\label{1.7.5}
\textbf{(Definition of Bounded)} We say a set $E$ is bounded if there exists some open ball $B_r(p)$ that contain $E$.
\end{definition}
\begin{theorem}
\label{1.7.6}
\textbf{(Equivalent Definition of Bounded)} 
\begin{equation}
E\text{ is bounded }\iff \exists r\inr^+, \forall p,q\in E, d(p,q)<r 
\end{equation}
\end{theorem}
\begin{proof}
From left to right, notice that every two points in $B_r(p)$ is of distance smaller than $2r$. From right to left, verify $B_r(p)$. 
\end{proof}
\begin{theorem}
\label{1.7.7}
\textbf{(Converge Implies Bounded)}
\begin{equation}
\lim_{n\to\infty} a_n=a\implies \set{a_n}\text{ is bounded }
\end{equation}
\end{theorem}
\begin{proof}
Fix $r $. Because $\set{a_n}$ converge to $a$, there exists $N_\epsilon \inn$ such that $n> N_r \implies a_n\in B_r (a)$. We know the ball $B_r(a)$ contain all but finitely many points of $\set{a_n}$. Then we know there exists a point in $\set{a_n}$ that is most far from $a$. Denote the most far point from $a$ by $a_k$. Observe that  $B_{d(a,a_k)+1}(a)$ contain $\set{a_n}$. 
\end{proof}
\fbox{\begin{minipage}{39em}
We now introduce Cauchy Sequence
\end{minipage}}
\begin{definition}
\label{1.7.8}
\textbf{(Definition of Cauchy Sequence)} We say $\set{a_n}$ is a Cauchy sequence if 
\begin{equation}
\forall \epsilon \inr^+,\exists N_\epsilon\inn, m,k>N_\epsilon  \implies d(m,k)<\epsilon 
\end{equation}
\end{definition}
\begin{theorem}
\label{1.7.9}
\textbf{(Every Convergent Sequence is Cauchy)} We have
\begin{equation}
\set{a_n}\text{ is convergent }\implies \set{a_n}\text{ is Cauchy }
\end{equation}
\end{theorem}
\begin{proof}
Let $\set{a_n}$ converge to $a$.  Notice every two point is  $\epsilon$-close in $B_{\frac{\epsilon }{2}}(a)$. 
\end{proof}
\section{Metric Space: Continuous Function}
\begin{definition}
\label{1.8.1}
\textbf{(Limit of a Function)} Let $f:X\rightarrow Y$ 
\end{definition}
\begin{definition}
\label{1.8.2}
\textbf{(Definition of Continuous at a Point)} We say $f:X\rightarrow Y$ is continuous at $a$ if 
 \begin{equation}
f(a)\text{ is defined and }\forall \epsilon\inr^+,\exists \delta\inr^+, x\in B_\delta(a)\implies d(f(x),f(a))<\epsilon 
\end{equation}
\end{definition}





\section{Metric Space: Interior, Closure and Limit Points}
\begin{definition}
\label{1.9.1}
\textbf{(Definition of Closure)} We define the closure $\overline{E}$ of $E$ to be
\begin{equation}
\overline{E}=E'\cup E
\end{equation}
\end{definition}
\begin{theorem}
\label{1.9.2}
\textbf{(Property of Limit Points)} If $p$ is not in $\overline{E}$, then there exists $B_r(p)$ disjoint $E$.
\end{theorem} 
\begin{proof}
  Because $p$ is not in $E'$, we know  there exists an open ball $B(p)$ not intersecting with  $E$ at everywhere expect possibly  $p$. We know  $p$ is not in $E$, so we know  $B(p)$ is disjoint with $E$.
\end{proof}
\begin{theorem}
\label{1.9.3}
\textbf{(Property of Closure and Interior)} Let $E\subseteq F$. We have
\begin{equation}
E^\circ \subseteq F^\circ\text{ and }\overline{E}\subseteq \overline{F}
\end{equation}
\end{theorem}
\begin{proof}
For $E^\circ \subseteq F^\circ $, notice an open ball contained by $E$ is also contained by $F$. For  $\overline{E}\subseteq \overline{F}$, notice $E'\subseteq F'$, by \myref{Theorem}{1.10.2}
\end{proof}
\begin{theorem}
\label{1.9.4}
\textbf{(Property (definition) of Closure and Interior)} 
\begin{gather}
\text{ $\overline{E}$ is the smallest closed set containing $E$ }\\
\text{ $E^\circ $ is the largest open subset of $E$ }
\end{gather}
\end{theorem}
\begin{proof}
  We first prove \vi{$\overline{E}$ is closed}.\\

  Let $p$ be a limit point of  $\overline{E}$. We know every open ball $B_r(p)$ contain a limit point of $E$ or a point in $E$. If  $B_r(p)$ contain a limit point $q$ of $E$, we know the open ball $B_{r-d(q,p)}(q)\subseteq B_r(p)$ contain a point in $E$. $\vdone$.\\

Let $F$ be a closed set containing  $E$. We can deduce 
 \begin{equation}
E'\subseteq F'\subseteq F\implies \overline{E}\subseteq \overline{F}
\end{equation}

Let $p$ be an interior point of $E$. We know there exists an open ball  $B_r(p)$ contained in $E$. If $B_r(p)$ contain a point $q$ not in interior, then we see $B_{r-d(q,p)}(q)\subseteq B_r(p)$ contain point not in $E$, which is impossible.\\

Let $O$ be an open set contained by $E$, if  $O$ contain any point $q$ not in interior, then there exists an open ball $B_r(q)$ contained in $O$ and containing a point not in $E$, which is impossible.  
\end{proof}
\begin{corollary}
\label{1.9.5}
\textbf{(Property of Closure)}
\begin{equation}
\text{ $E$ is closed $\iff \overline{E}=E$ }
\end{equation}
\begin{equation}
\text{ $E$ is open $\iff E^\circ =E$ }
\end{equation}
\end{corollary}
\fbox{\begin{minipage}{39em}
Also, notice \myref{Theorem}{1.10.1} have been proved in language of general topology, and here we give a simple proof in language of metric.\\

Lastly, we show some result in metric topology.
\end{minipage}}
\begin{theorem}
\label{1.9.6}
\textbf{(A Point is Limit Point if and only if All Open Ball Contain Infinite Point of $E$)} 
\end{theorem}
\begin{proof}
  From right to left, notice all open $B_r(p)$ contain infinite points of $E$ implies each open ball $B_r(p)$ contain some point in $E$ that isn't  $p$.\\

  From left to right, let $p$ be a limit point of  $E$. If an open ball $B_r(p)$ contain only finite amount of point in $E$, we can let $r'=\min \set{d(p,q):q\in B_r(p)\cap E}$ and verify  $B_{r'}(p)$ contain no point in $E$, which is impossible. 
\end{proof}
\begin{corollary}
\label{1.9.7}
\textbf{(Finite Points Set In Metric Topology has no Limit Points)} 
\end{corollary}
\begin{corollary}
\label{1.9.8}
\textbf{(Finite Points Set In Metric Topology is Always Clopen)} \end{corollary}
\begin{proof}
For closed, we can prove the complement is open or use above corollary. For open, verify for $B_{\min \set{d(x,y):y \in O}}(x)$. 
\end{proof}
\begin{theorem}
\label{1.9.9}
\textbf{(Counter Example of Above Statement in General Topology)} Let $X=\set{a,b,c}$ and define $\mathfrak{O}:=\set{\varnothing,X}$. We have 
\begin{equation}
\set{a,b}'=X
\end{equation}
Not only does $\set{a,b}$ has limit point, also the neighborhood $X$ around limit point contain only finite points. Notice $\set{a,b}$ is neither open nor closed.
\end{theorem}
\section{Metric Space: Compact, Countably Compact and Limit Point Compact}
\fbox{\begin{minipage}{39em}
There are three tools we need to prove the MEGA TFAE. 
\end{minipage}}
\begin{theorem}
\label{1.10.1}
\textbf{(In Metric Space, Existence of Countable Base is Equivalent to Separable)} Let $(X,d)$ be a metric space. 
\begin{equation}
X\text{ has a countable base }\iff  X\text{ is separable }
\end{equation}
\end{theorem}
\begin{proof}
Because by \myref{Corollary}{1.12.5}, $X$ is separable if  $X$ has a countable base, we only have to prove separable implies existence of countable base. Let $X$ be separable. Then we have a countable dense subset $E$ of $X$. We now prove
\vi{
 \begin{equation}
\mathcal{O}:=\set{B_r(p):p\in E\text{ and }r\inq} 
\end{equation}
is a countable base}.\\

Notice $\mathcal{O}=\bigcup \set{\set{B_r(p):r\inq}:p\in E}$ is a countable union of countable sets, so $\mathcal{O}$ is countable. We only have to prove $\mathcal{O}$ is a base.\\

For each open neighborhood $O$ around  $x\in X$, by definition of open in metric space, we know there exists an open ball $B_r(x)$ contained by $O$. Because $E$ is dense, we know  $x$ either in $E$ or in  $E'$. If $x$ is in  $E$, we can pick a positive rational  $n$ smaller than  $r$, so we have  
\begin{equation}
x\in B_n(x)\subseteq B_r(x)\subseteq O\text{ and }B_n(x)\in \mathcal{O} 
\end{equation}
and we are done. If $x\in E'$, we know there exists a point $q$ in  $E\cap B_{\frac{r}{2}}(x)$. Then we can pick a rational $n$ between $d(q,x)$ and $\frac{r}{2}$. Now, observe
\begin{equation}
x\in B_n(q)\subseteq B_r(x)\subseteq O\text{ and }B_n(q)\in \mathcal{O}
\end{equation}
and we are done. $\vdone$
\end{proof}
\begin{lemma}
\label{1.10.2}
\textbf{(Existence of Intuitively Small Enough Open Ball)} Let $p\in  B_r(q)$. There exists an open ball $B_{r'}(p)$ small enough to be contained by $B_r(q)$ and not containing $q$ 
\end{lemma}
\begin{proof}
If $d(p,q)\leq \frac{r}{2}$, we can let $r'=d(p,q)$. Clearly $B_{r'}(p)$ doesn't contain $q$, and for each  $x\in B_{r'}(p)$ we have
\begin{equation}
d(x,q)\leq d(x,p)+d(p,q)\leq r'+\frac{r}{2}\leq r
\end{equation}
If $d(p,q)\geq \frac{r}{2}$, we can let $r'=r-d(p,q)$. Clearly $B_{r'}(p)\subseteq B_r(q)$, and we can deduce
\begin{equation}
2d(p,q)\geq r\implies d(p,q)\leq r-d(p,q)=r'
\end{equation}
so we have $q\in B_{r'}(p)$. In short, we use the open ball  $B_{\min \set{d(p,q),r-d(p,q)}}(p)$
\end{proof}
\begin{theorem}
\label{1.10.3}
\textbf{(In Metric Space, Limit Point Compact Implies Separable)} Let $K$ be a metric space.
\begin{equation}
K\text{ is limit point compact }\implies K\text{ is separable }
\end{equation}
\end{theorem}
\begin{proof}
Let $\delta>0$ and let $a_{\delta, 1}\in K$. We now prove \vi{there exists a finite set  $A_\delta=\set{a_{\delta ,1},a_{\delta ,2}, \dots , a_{\delta, n}}$ such that $K\subseteq \bigcup \set{B_\delta (a_{\delta ,i}):a_{\delta ,i}\in A_{\delta}}$}.\\

To prove such, we construct $A_\delta$ by adding element $a_{\delta,i}$ such that $\forall j<i, d(a_{\delta, j},a_{\delta ,i})\geq \delta$ to $\set{a_{\delta ,1}}$ until impossible. \As{such finite set $A_\delta$ can not be constructed using this method}. In other words, we assume our method of adding points can go on infinitely. Then we have set $A^\N=\set{a_{\delta,i}:i\inn}$ such that
\begin{equation}
\forall a_{\delta,i},a_{\delta,j}\in A^\N, d(a_{\delta, i},a_{\delta , j})\geq \delta
\end{equation}
Arbitrarily pick $p\in  K$, we wish to find an open ball $B_r(p)$ small enough so that
\begin{equation}
B_r(p)\cap A^\N\subseteq \set{p}
\end{equation}
Let
\begin{equation}
E=\bigcup \set{B_\delta(a_{\delta,i}):a_{\delta,i}\in A^\N}
\end{equation}
Notice that each ball $B_{\delta}(a_{\delta,i})$ must not contain any other $a_{\delta,j}$.\\

If $p$ is in $E$, we know $p$ is contained by some ball  $B_{\delta}(a_{\delta,i})$. If $p=a_{\delta,i}$  then $B_{\delta}(p)$ is small enough. If $p\neq a_{\delta,i}$, we wish to find an open ball $B_r(p)$ small enough so that it neither contain $a_{\delta,i}$ nor any other $a_{\delta,j}$. Notice that if the ball $B_r(p)$ is contained by $B_\delta(a_{\delta,i})$, then $B_r(p)$ contain no $a_{\delta,j}$. By \myref{Lemma}{1.12.2}, we have found an open ball small enough to satisfy our need.\\

If $p$ is not in $E$, clearly $B_{\delta}(p)$ is small enough.\\

We have proved $A^\N$ has no limit point \CaC to $K$ is limit point compact. $\vdone$\\

Let $A_\delta$ be the finite set from $\violet{\text{violet part}}$. Consider the collection 
\begin{equation}
A=\bigcup \set{A_1,A_{\frac{1}{2}},A_{\frac{1}{3}},\dots}
\end{equation}
Because $A$ is a countable union of finite sets, we know $A$ is countable. We now prove \blue{$A$ is dense}.\\


Arbitrarily pick $p\in K\setminus A$. For each open ball $B_r(p)$, there exists $\frac{1}{n}$ small enough to be smaller than $r$ to give us $p\in B_{\frac{1}{n}}(a)$ for some $a\in A_{\frac{1}{n}}$, and give us $a\in B_{\frac{1}{n}}(p)\subseteq B_r(p)\bdone$
\end{proof}
\begin{theorem}
\label{1.10.4}
\textbf{(In Metric Space, Limit Point Compact Implies Compact)} 
\end{theorem}
\begin{proof}
  Let $\mathcal{G}$ be an open cover for $K$. By \myref{Theorem}{1.12.3}, we know $K$ is separable. Then by  \myref{Theorem}{1.12.1}, we know $K$ has a countable base. Then by \myref{Theorem}{0.3.13}, we know $\mathcal{G}$ contain a countable sub-cover
  \begin{equation}
  \set{G_i}_{i\inn}
  \end{equation}
We now prove \vi{there exists $m\inn$ such that $\set{G_i}_{i=1}^m$ cover $K$}.\\

For each $n\inn$, denote
\begin{equation}
E_n=\bigcup \set{G_i}_{i=1}^n\
\end{equation}
Obviously we have 
\begin{equation}
E_1\subseteq E_2\subseteq E_3\subseteq \cdots 
\end{equation}
We know $E_n$ converge to  $K$, that is
 \begin{equation}
\bigcup \set{E_i}_{i=1}^\infty=K
\end{equation}
\As{$\forall m \inn, E_m\neq K$}. Then we can construct an infinite sequence
\begin{equation}
\set{x_i:x_i\in E_i^c}_{i=1}^\infty
\end{equation}
Because $K$ is limit point compact, we know $\set{x_i}_{i=1}^\infty$ has a limit point $p$.\\

Because $\set{G_i}_{i=1}^\infty$ is an open cover, we know $p\in G_n$ for some $n$. Then we know there exist open ball $B_r(p)$ small enough to be contained by $G_n$. Notice  $B_r(p)$ is contained by $G_n$ implies $B_r(p)$ is contained by $E_n$, so we know  $B_r(p)$ at best contain all $x_j$ where  $j\leq n\tCaC$ to \myref{Theorem}{1.7.4} $\vdone$
\end{proof}
\fbox{\begin{minipage}{39em}
We now prove the MEGA TFAE.
\end{minipage}}
\begin{theorem}
\label{1.10.5}
\textbf{(In Metric Space, Limit Point Compact is Equivalent to Compact)} For metric space $K$, the followings three are equivalent
\begin{enumerate}[label=(\alph*)]
  \item $K$ is a limit point compact space
  \item $K$ is a compact space
  \item $K$ is a countably compact space
\end{enumerate}
Above three implies the following two equivalent statement ($\R$ is an example the above statements are stronger)
\begin{enumerate}[label=(\arabic*)]
  \item $K$ is separable
  \item $K$ has a countable base
\end{enumerate}
and all above implies
\begin{enumerate}[label=(\roman*)]
  \item every open cover for $K$ has a countable sub-cover.
\end{enumerate}
\end{theorem}
\begin{proof}
In \myref{Theorem}{1.12.5}, we prove that if $K$ has a count base then $K$ is separable by collecting one point from each basic open set, and in \myref{Theorem}{1.12.1}, we construct a countable base by collecting all open balls of rational radius around each point in the countable dense subset.\\

In \myref{Theorem}{1.12.3}, we prove if $K$ is limit point compact then  $K$ is separable. We proved such by covering $K$ with open ball of radius $\frac{1}{n}$ for each $n\inn$, and argue the set of centers $A$ is countable by proving to cover $K$ always require only finite amount of point (which is easy to see if one know $K$ is bounded, but our method here is to show if require infinite centers, then the set of infinite centers has no limit point, which is also easy to see if one use geometric intuition), and argue that each point $p$ that isn't in $A$ is a limit point of $A$ by arguing for each distance $r$, there exists an  $a\in A$ closed enough to be closer to $p$ than $r$.\\

One may observe, at the end of the proof for \myref{Theorem}{1.12.3}, we also construct a countable base for $K$.\\

In  \myref{Theorem}{0.3.13}, we prove if  $K$ has a countable base then every open cover for  $K$ has a countable sub-cover by filtering the open cover with countable base.\\

Notice that we have proved that if $K$ is limit point compact, then  $K$ is separable, has a countable base and every open cover for  $K$ has a countable sub-cover.\\

Then, in \myref{Theorem}{1.12.4}, we proved that if $K$ is limit point compact, the countable sub-cover $\set{G_i}_{i\inn}$ for $K$ must has a finite sub-cover $\set{G_i}_{i=1}^m$, otherwise we can construct an infinite set $\set{x_i}_{i=1}^\infty$ by picking a point from area that isn't covered by $\set{G_i}_{i=1}^n$ for each natural $n$, and show that the limit point of $\set{x_i}_{i=1}^\infty$, being in some $G_n$, must contain at most of  $n$ amount of points of  $\set{x_i}_{i=1}^\infty$, which is impossible.\\

It is clear that $K$ is compact implies $K$ is countably compact. In  \myref{Theorem}{1.6.11}, we proved if $K$ is countably compact, then $K$ is limit point compact by showing if no point is a limit point of a countably infinite set $A$, then for each point $a\in A$, we can find an open neighborhood around $a$ small enough to contain only one point in $A$, i.e.  $a$ itself, and the collection of such small enough open neighborhood and  $A^c$ form an open cover that has no finite sub-cover, as any finite sub-cover contain only finite amount of point in  $A$, and observe every uncountable set must contain some countable set thus also have a limit point.\\

In summary 
\begin{gather}
\text{(2)$\implies $(1) by \myref{Corollary}{1.12.5}}\\
\text{(1)$\implies $(2) by \myref{Theorem}{1.12.1}}\\
\text{(a)$\implies $(1) and (2) by \myref{Theorem}{1.12.3}}\\
\text{(2)$\implies $(i) by \myref{Theorem}{0.3.13}}\\
\text{(a)$\implies $(b) by \myref{Theorem}{1.12.4}, which use  (i)}\\
\text{(b)$\implies$(c) by \myref{Theorem}{1.6.10}, which is trivial}\\
\text{(c)$\implies $(a) by \myref{Theorem}{1.6.11}}
\end{gather}
\end{proof}
\fbox{\begin{minipage}{39em}
Above is a very important result. One must know how to prove such.
\end{minipage}}
\section{Metric Space: Some Properties Implied by Compact}
\fbox{\begin{minipage}{39em}
Notice there is a difference between compact space and compact set
\end{minipage}}
\begin{definition}
\label{1.11.1}
\textbf{(Definition of Compact Subset)} Let $X$ be a metric space, we say  $K\subseteq X$ is a compact subset if
\begin{equation}
\text{ every open cover for $K$ has a finite sub-cover}
\end{equation}
\end{definition}
\begin{theorem}
\label{1.11.2}
\textbf{(Compact Subset is itself a Compact Space)} 
\begin{equation}
\text{ A compact subset regarded as a metric space is compact }
\end{equation}
\end{theorem}
\begin{proof}
Let $K$ be a compact subset, and regard  $K$ as a metric space. Let $\set{G_\ld :\ld \in \Lambda }$ be an open cover for $K$ with respect to $K$. We know there exists a collection of open set $\set{G_i:i\in I}$ such that 
\begin{equation}
\set{G_\ld: \ld  \in \Lambda}=\set{G_i\cap K: i\in I}
\end{equation}
Because $\set{G_\ld }$ is an open cover for $K$ with respect to  $K$, we know  $\set{G_i}$ is an open cover for $K$.  Then because $K$ is compact, there exists a finite sub-cover  $\set{G_j}$. Notice $\set{G_j\cap K}$ is a finite sub-cover for $K$ with respect to  $K$.
\end{proof}
\begin{theorem}
\label{1.11.3}
\textbf{(Compact Sets Are Closed)} Let $X$ be a metric space, and let $K\subseteq X$
\begin{equation}
K\text{ is compact }\implies K\text{ is closed }
\end{equation}
\end{theorem}
\begin{proof}
We prove  \vi{$K^c$ is open}. Let $p\in K^c$. For each $k\in K$, collect the open balls $B_{\frac{d(k,p)}{2}}(k)$ as $\mathcal{O}$, so we have an open cover $\mathcal{O}$ for $K$. Because  $K$ is a compact subset, we know $\mathcal{O}$ has a finite sub-cover
\begin{equation}
\mathcal{O}':=\set{B_{\frac{d(k_i,p)}{2}}(k_i)}_{i=1}^m
\end{equation}
Let $r=\min \set{\frac{d(k_i,p)}{2}:1\leq i\leq m}$. We only have to prove 
\begin{equation}
  \text{ the open neighborhood $B_r(p)$ is disjoint to $\bigcup \mathcal{O}'$.}
\end{equation}
This isn't difficult to prove if one have geometric intuition.  \As{$q\in  B_r(p)\cap \bigcup \mathcal{O'}$}. Because $q\in \bigcup \mathcal{O}'$, we know there exists $B_{\frac{d(k_i,p)}{2}}(k_i)$ that contain $q$, so we have
 \begin{equation}
d(k_i,q)\leq \frac{d(k_i,p)}{2}
\end{equation}
Then we have
\begin{equation}
d(p,q)+d(q,k_i)< r+\frac{d(k_i,p)}{2}\leq d(k_i,p)\tCaC\vdone
\end{equation}
\begin{definition}
\label{1.11.4}
\textbf{(Definition of Bounded)} Let $X$ be a metric space, we say $E\subseteq X$ is bounded if there exists an open ball $B_r(p)$ centering some $p$ in $E$, that contained $E$
\end{definition}
\begin{theorem}
\label{1.11.5}
\textbf{(Compact Sets are Bounded)} Let $X$ be a metric space and $K\subseteq X$. We have
\begin{equation}
K\text{ is compact }\implies K\text{ is bounded }
\end{equation}
\end{theorem}
\begin{proof}
\As{$K$ is unbounded}. Arbitrarily pick $q$ from  $K$. We know for each $n\inn$, the open ball $B_n(q)$ doesn't cover $K$  
\begin{equation}
K\setminus B_n(q)\neq \varnothing
\end{equation}
Then we can construct a sequence $\set{x_n}_{n\inn}$ by arbitrarily picking $x_n$ from $K\setminus B_n(q)$ for each $n\inn$. Because  $K$ is compact implies $K$ is limit point compact, we know $\set{x_n}_{n\inn}$ has a limit point  $p$ in  $K$. Let $r=d(p,q)$, and let $m$ be the smallest natural greater than  $r$. Because $B_{m-r}(p)$ is contained by $B_m(q)$, we know $B_{m-r}(p)$ contain at most first $m$ points in  $\set{x_n}_{n=1}^\infty\tCaC$ to every open ball centering limit point contain infinite point.
\end{proof}
\begin{corollary}
\label{1.11.6}
\textbf{(Compact Sets are Closed and Bounded)}
\begin{equation}
K\text{ is compact }\implies K\text{ is closed and bounded }
\end{equation}
\end{corollary}
\fbox{\begin{minipage}{39em}
We close this section with a method to generate new compact sets.
\end{minipage}}
\end{proof}
\begin{theorem}
\label{1.11.7}
\textbf{(Closed Subsets of Compact Sets Are Compact)} 
\begin{equation}
\text{$K$ is compact and  $F\subseteq K$ is closed}\implies E\text{ is compact }
\end{equation}
\end{theorem}
\begin{proof}
Arbitrarily pick an open cover $\mathcal{G}$ for $F$. We wish to prove there is a finite sub-cover for $F$. Because $F$ is closed, we know $F^c$ is open, so we know  $\mathcal{G}\cup \set{F^c}$ is also an open cover, and moreover, open cover for $X$ and $K$. Then because $K$ is compact, we know $\mathcal{G}\cup \set{F^c}$ has a finite sub-cover $\mathcal{G}'$ for $K$, and apparently, for $F$. If  $\mathcal{G}'\subseteq \mathcal{G}$, then we are done. If $F^c\subseteq \mathcal{G}'$, then we can see $\mathcal{G}'\setminus \set{F^c}$ is a finite sub-cover of $\mathcal{G}$ for $F$.
\end{proof}
\begin{corollary}
\label{1.11.8}
Let $F$ be closed and  $K$ be compact. We have $F\cap K$ is compact.
\end{corollary}
\begin{proof} 
The fact that  $K$ is compact tell us $K$ is closed. Then we know $F\cap K$ is closed and is a subset to $K$
\end{proof}
\section{Euclidean Metric}
\begin{definition}
\label{1.12.1}
\textbf{(Definition of k-cell)} In $(\R^k,d(\vecta{x},\vecta{y})=\abso{\vecta{x}-\vecta{y}})$,  we say $I$ is a $k$-cell, when there exists  $k$ intervals  $\set{[a_1,b_1],\dots , [a_k,b_k]}$ such that
 \begin{equation}
   I=\prod_{n=1}^k [a_n,b_n]
\end{equation}
\end{definition}
\begin{lemma}
\label{1.12.2}
\textbf{(Shrinking k-cell Sequence Convergence)} Let $\set{I_n}_{n=1}^\infty$ be a sequence of  k-cell such that 
\begin{equation}
\forall n\inn, I_{n+1}\subseteq I_n
\end{equation}
Then we have
\begin{equation}
\bigcap \set{I_n}_{n=1}^\infty\neq \varnothing
\end{equation}
\end{lemma}
\begin{proof}
For each $n\inn$, denote the first component of $I_n$ by $[a_n,b_n]$. We know $\set{a_n}_{n=1}^\infty$ is an monotonically increasing sequence  and bounded above by every $b_n$. Notice that the supremum of a set $A$ is exactly the infimum of the set of upper bounds of $A$. Applying this fact into our situation, we know for each $n$, $\sup \set{a_n}_{n=1}^\infty$ is greater than or equal to $a_n$ and smaller than or equal to  $b_n$. Them we know $\sup \set{a_n}_{n=1}^\infty$ must be contained by every $[a_n,b_n]$. In other words,
\begin{equation}
\sup \set{a_k}_{k=1}^\infty\in \bigcap_{n=1}^\infty [a_n,b_n]
\end{equation}
Use the same argument in every other component to get a point in $\bigcap \set{I_n}_{n=1}^\infty$. 
\end{proof}
\begin{lemma}
\label{1.12.3}
\textbf{(Maximum Distance of Two Points In k-cell is the length of Diagonal Line)} Let $I=[a_1,b_1]\times\cdots\times[a_k,b_k]$. Let $\vecta{a}=(a_1,\dots, a_k)\text{ and }\vecta{b}=(b_1,\dots, b_k)$. The maximum distance of two points in k-cell are 
\begin{equation}
 \abso{\vecta{b}-\vecta{a}}= (\sum_{i=1}^k (b_i-a_i)^2)^\frac{1}{2}
\end{equation}
\end{lemma}
\begin{proof}
Let $\vecta{x},\vecta{y}\in I$. For each $n\inn$ smaller then or equal to $k$,  because $x_n,y_n\in [a_n,b_n]$, we have $\abso{x_n-y_n}\leq b_n-a_n$. Then we can deduce
\begin{equation}
\abso{\vecta{x}-\vecta{y}}=(\sum_{i=1}^k \abso{x_i-y_i}^2)^{\frac{1}{2}}\leq (\sum_{i=1} (b_i-a_i)^2)^{\frac{1}{2}}=\abso{\vecta{b}-\vecta{a}}
\end{equation}
\end{proof}
\begin{theorem}
\label{1.12.4}
\textbf{(k-Cell is Compact)} 
\begin{equation}
\text{ Every k-cell $I$ is compact. }
\end{equation}
\end{theorem}
\begin{proof}
Let $I_0$ be $[a_1,b_1]\times \cdots \times [a_k,b_k]$. \As{$\set{G_\ld:\ld \in\Lambda }$ is an open cover for $I_0$ that has no finite sub-cover}. For each $n\inn: 1\leq n\leq k$, let 
\begin{equation}
c_n=\frac{a_n+b_n}{2}
\end{equation}
Now, we can break $I_0$ into  $2^k$ amount of  $k$-cell of same size, where the $n$-th component of each of them is either  $[a_n,c_n]$ or $[c_n,b_n]$. Notice that at least one of them can not be covered by finite amount of $G_\ld$, since if all of them can be covered by a finite subset of $\set{G_\ld}$ the union of finite sub-covers for each small k-cell is a finite sub-cover for $I_0$, where we have assumed such finite sub-cover does not exist.\\

Denote the smaller k-cell that can not be covered by finite amount of $G_\ld$ by $I_1$. Notice that $\set{G_\ld:\ld\in\Lambda  }$ is an open cover for $I_1$, and there exists no finite sub-cover of $\set{G_\ld :\ld\in \Lambda }$ for $I_1$, just like  $I_0$.\\

Let $I_1=[x_1,y_1]\times\cdots\times[x_k,y_k]$. For each $n\inn:1\leq n\leq k$, let
\begin{equation}
z_n=\frac{x_n+y_n}{2}
\end{equation}
Again, break  $I_1$ into  $2^k$ amount of k-cell of even smaller size using $z_n$. And, again, argue that one of the even smaller k-cell has can not be covered by a finite subset of $\set{G_\ld }$.\\

Let $I_2$ be one of the even smaller k-cell that can not be covered by finite amount of  $G_\ld $, and use the same technique to construct a even even smaller k-cell $I_3$, which can not be covered by finite amount of $G_\ld $. This procedure can go on infinitely, so we have a sequence
\begin{equation}
\cdots \subseteq I_3 \subseteq I_2\subseteq I_1\subseteq I_0
\end{equation}
Denote this sequence $\set{I_n}_{n=1}^\infty$. By \myref{Lemma}{1.12.4}, we know 
\begin{equation}
\bigcap \set{I_n}_{n=0}^\infty \neq \varnothing
\end{equation}
Then, we can let
\begin{equation}
\vecta{x}\in \bigcap \set{I_n}_{n=0}^\infty
\end{equation}
Because for each non-negative integer $n$, 
\begin{equation}
\vecta{x}\in I_n\text{ and }\set{G_\ld :\ld \in\Lambda }\text{ is an open cover for $I_n$ }
\end{equation}
We know there exists $G_\ld $ that contain $\vecta{x}$. By definition of open, we know there exists an open ball $B_r(\vecta{x})$ small enough to be contained by $G_\ld $
\begin{equation}
\vecta{x}\in B_r(\vecta{x})\subseteq G_\ld 
\end{equation}
Now, we wish to pick a even smaller $I_m \in \set{I_n}_{n=0}^\infty$ contained by $B_r(\vecta{x})$, so we have
\begin{equation}
\vecta{x}\in I_m \subseteq B_r(\vecta{x})\subseteq G_\ld 
\end{equation}
to show $\set{G_\ld }$ is a cardinality-one sub-cover for $I_m$, which is impossible as we construct $\set{I_n}_{n=0}^\infty$ to satisfy that each of them can not be covered by finite subset of $\set{G_\ld :\ld \in \Lambda }$.\\

Because of the way we break each k-cell to smaller k-cell is to cut the k-cell right in half, it is simple to use geometric intuition to see such small enough $I_m$ should exist.\\

Let
\begin{equation}
\delta=(\sum_{j=1}^k (b_j-a_j)^2)^{\frac{1}{2}}=\abso{\vecta{b}-\vecta{a}}
\end{equation}
We can use mathematical induction to rigorously prove that the length of diagonal line for each $I_n$ is exactly $2^{-n}\delta$.\\

Now, using \myref{Lemma}{1.12.3}, it is easy to verify when  $m>\log_2 \frac{\delta}{r}$, the k-cell $I_m$ is small enough to be contained by $B_r(\vecta{x})\tCaC$.
\end{proof}
\begin{corollary}
\label{1.12.5}
\textbf{(Heine-Borel Theorem)} In $(\R^k, d(\vecta{x},\vecta{y})=\abso{\vecta{x}-\vecta{y}})$, we have
\begin{equation}
K\text{ is closed and bounded}\iff K\text{ is compact }
\end{equation}
\end{corollary}
\begin{proof}
  We have proved from right to left in \myref{Theorem}{1.12.3} and  \myref{Theorem}{1.12.5}. To prove from left to right, just observe $K$ is bounded implies that $K$ is contained by some k-cell. Then because closed subset of compact set is compact, we can deduce $K$ is compact.
\end{proof}
\begin{definition}
\label{1.12.6}
\textbf{(Definition of Sequentially Compact)} Let $E\subseteq X$ be a topological space. We say $E$ is sequentially compact if 
 \begin{equation}
\text{ for each sequence $\set{a_n}$ there exists a converging sub-sequence $\set{a'_n}$  }
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
Notice that in general topology, a sequence can converge to multiple point, the trivial topology of multiple points is an example.
\end{minipage}}
\fbox{\begin{minipage}{39em}
Notice that in the proof above, we actually show that it is possible that it is impossible for $N_U$ and  $N_\epsilon $ to be equal.
\end{minipage}}
\begin{theorem}
\label{1.12.7}
\textbf{(In Metric Space, Limit Point Compact Implies Sequentially Compact)} 
\begin{equation}
K\text{ is limit point compact }\implies K\text{ is sequentially compact }
\end{equation}
\end{theorem}
\begin{proof}
Let $\set{p_n}$ be a sequence in $K$. If the range of $\set{p_n}$ is finite, then there exists a point $p_m$ appears infinitely many time in the sequence, otherwise the sequence end at a finite term. Then, we can pick the sub-sequence that contain only $p_m$ and we are done. \\

If the range of $\set{p_n}$ is infinite, then because $K$ is limit point compact, we know  the range of  $\set{p_n:n\inn}$ has a limit point in $K$. Denote this point  by $p'$, and pick the first term $p'_1=p_{k_1}$ of our sub-sequence by arbitrarily picking  $p_{k_1}$ in  $B_1(p)$. Now, we wish to find points in $B_{\frac{1}{2}}(p)\cap \set{p_n:k_1<n\inn}$. Notice the set
\begin{equation}
B_{\frac{1}{2}}(p)\cap \set{p_n:n\inn}
\end{equation}
is infinite, so  it is impossible
\begin{equation}
B_{\frac{1}{2}}(p)\cap \set{p_n:n\inn}\subseteq \set{p_n:p\leq k_1\inn}
\end{equation}
then we know 
\begin{equation}
\text{ $B_{\frac{1}{2}}(p)\cap \set{p_n:n>k_1\inn}\neq \varnothing$  }
\end{equation}
So we can let $p'_2=p_{k_2}\in B_{\frac{1}{2}}(p)$. By axiom of choice, we can do this infinite amount of time and have a sub-sequence $\set{p'_n}$ that converge to $p$.
\end{proof}
\begin{theorem}
\label{1.12.8}
\textbf{(In Euclidean Space, Bounded Implies Existence of Convergent Sub-sequence)} In $\R^n$, we have
 \begin{equation}
\set{p_n}\text{ is bounded }\implies \set{p_n}\text{ has a convergent sub-sequence }
\end{equation}
\end{theorem}
\begin{proof}
In Euclidean space, if $\set{p_n}$ is bounded, we can find a k-cell $I$ that contain  $\set{p_n}$. We know k-cell $I$ is compact, so we know it is sequentially compact. Then we know  $\set{p_n}$ has a convergent sub-sequence in $I$. 
\end{proof}
\section{Cauchy Sequence}
\begin{definition}
\label{1.13.1}
\textbf{(Definition of Cauchy Sequence)} Let $X$ be a metric space. We say $\set{p_n}$ is a Cauchy sequence if 
\begin{equation}
\forall \epsilon\inr^+,\exists N\inn, \forall k,m>N, d(p_m,p_k)<\epsilon 
\end{equation}
\end{definition}
\begin{definition}
\label{1.13.2}
\textbf{(Definition of Diameter)} Let $E\subseteq X$. We say the diameter of $E$ is
 \begin{equation}
\diam{E}=\sup \set{d(p,q):p,q\in E}
\end{equation}
\end{definition}
\begin{theorem}
\label{1.13.3}
\textbf{(Convergent Implies Cauchy)} 
\begin{equation}
\set{p_n}\text{ converge }\implies \set{p_n}\text{ is a Cauchy sequence }
\end{equation}
\end{theorem}
\begin{proof}
Let $\set{p_n}$ converge to $p$. Fix $\epsilon $, we know there exists $N_{\frac{\epsilon }{2}}$ such that
\begin{equation}
k,m>N_{\frac{\epsilon}{2}}\implies d(p_k,p),d(p_m,p)<\frac{\epsilon}{2}\implies d(p_k,p_m)<d(p_k,p)+d(p_m,p)=\epsilon 
\end{equation}
\end{proof}
\begin{theorem}
\label{1.13.4}
\textbf{(Diameter of Closure Equals to Original Diameter)} Let $E\subseteq X$. We have
\begin{equation}
\diam{\overline{E}}=\diam{E}
\end{equation}
\end{theorem}
\begin{proof}
We wish to prove
\begin{equation}
  \vi{\sup \set{d(p,q):p,q\in \overline{E}}=\sup \set{d(p,q):p,q\in E}}
\end{equation}
Because $E\subseteq \overline{E}$, we have
\begin{equation}
\sup \set{d(p,q):p,q\in \overline{E}}\geq \sup \set{d(p,q):p,q\in E}
\end{equation}
\As{$\sup \set{d(p,q):p,q\in \overline{E}}>\sup \set{d(p,q):p,q\in E}$}. We know there exists $p',q'\in \overline{E}$ such that
\begin{equation}
d(p',q')>\diam{E}
\end{equation}
Clearly, $p',q'$ can not both be in  $E$. Let $p'\in \overline{E}\setminus E$. We know 
\begin{equation}
p'\in E'
\end{equation}
If $q'\in E$, denote $q'$ by  $q$. We see
\begin{equation}
\forall p\in  E,d(p',q)\leq d(p,p')+d(p,q)
\end{equation}
where $d(p,p')>0$ can be arbitrarily small. So if 
\begin{equation}
d(p,q)<\diam{E}
\end{equation}
We have
\begin{equation}
d(p',q)\leq d(p,p')+d(p,q)<\diam{E}
\end{equation}
Then we have
\begin{equation}
\forall p\in E, d(p,q)=\diam{E}
\end{equation}
Which give us 
\begin{equation}
E=\set{q}\tCaC
\end{equation}
Let $q'\not\in E$. We know
\begin{equation}
q'\in E'
\end{equation}
We see 
\begin{equation}
\forall p,q\in E, d(p',q')\leq d(p',p)+d(p,q)+d(q,q')
\end{equation}
where $d(p',p)$ and $d(q,q')$ can be arbitrarily small.\\

Let $d(p,q)$ satisfy 
\begin{equation}
d(p,q)<\diam{E}
\end{equation}
Let $d(p',p)$ and $d(q,q')$ small enough to have 
\begin{equation}
d(p',q')\leq d(p',p)+d(p,q)+d(q,q')<\diam{E}
\end{equation}
\end{proof}
\begin{theorem}
\label{1.13.5}
\textbf{(Sufficient Condition for Infinite Intersection of Compact Sets being Non-empty)} Let $\set{K_\ld :\ld \in \Lambda }$ be an infinite collection of compact sets.
\begin{equation}
\text{ every finite sub-collection of $\set{K_\ld:\ld \in\Lambda }$ is non-empty }\implies \text{ $\bigcap_{\ld\in \Lambda }  K_\ld $ is non-empty }
\end{equation}
\end{theorem}
\begin{proof}
\As{$\bigcap_{\ld \in \Lambda }K_\ld =\varnothing$}. Fix $K_{\alpha }$. Because 
\begin{equation}
K_{\alpha }\cap (\bigcap_{\ld \in \Lambda ,\ld \neq \alpha }K_{\ld  })=\varnothing
\end{equation}
We know no point of $K_{\alpha }$ belong to every $K_\ld $, otherwise that point is in $K_{\alpha }\cap (\bigcap_{\ld \in \Lambda ,\ld \neq \alpha }K_\ld )$.\\

Then we see
\begin{equation}
\set{K_{\ld}^c: \ld  \in\Lambda }
\end{equation}
Is an open cover for $K_\alpha $.\\

Because $K_\alpha $ is compact, there exists a finite sub-cover
\begin{equation}
\set{K^c_1,\dots, K^c_m}
\end{equation}
Notice that for all $x\in K_\alpha $, we have
\begin{equation}
\exists n:1\leq n\leq m, x\in K^c_n 
\end{equation}
Where $x\in K_n^c\implies x\not\in K_n$. This tell us 
\begin{equation}
\text{ no points in $K_\alpha $ belong to all }K_1,\dots ,K_m
\end{equation}
Meaning
\begin{equation}
  K_{\alpha }\cap \bigcap \set{K_1,\dots, K_m}=\varnothing\tCaC
\end{equation}
\end{proof}
\begin{corollary}
\label{1.13.6}
\textbf{(Single Point)} Let $\set{K_n}$ be a sequence of compact sets such that 
 \begin{equation}
   \forall n,K_{n+1}\subseteq K_n\text{ and }\lim_{n\to\infty}\diam{K_n}=0
\end{equation}
We have
\begin{equation}
\bigcap_{n=1}^\infty K_n\text{ consists of exact one point }
\end{equation}
\end{corollary}
\begin{proof}
Notice if $\bigcap_{n=1}^\infty K_n$ has more than one point, we can pick two different points in $\bigcap_{n=1}^\infty K_n$ to show
\begin{equation}
  \diam{\bigcap_{n=1}^\infty K_n}>0
\end{equation}
However, because for all $m$, we have
 \begin{equation}
\bigcap_{n=1}^\infty K_n\subseteq K_m
\end{equation}
We know
\begin{equation}
\forall m, 0<\diam{\bigcap_{n=1}^\infty K_n}\leq \diam{K_m}
\end{equation}
\CaC to
\begin{equation}
\lim_{n\to\infty}\diam{K_n}=0
\end{equation}
\end{proof}
\begin{definition}
\label{1.13.7}
\textbf{(Definition of Completed)} We say a subset $X$ of a metric space is complete if 
\begin{equation}
\text{ every Cauchy sequence in $X$ converge to some point in $X$}
\end{equation}
\end{definition}
\begin{theorem}
\label{1.13.8}
\textbf{(Compact Implies Complete)} 
\begin{equation}
K\text{ is compact }\implies K\text{ is complete }
\end{equation}
\end{theorem}
\begin{proof}
Let $\set{p_n}$ be a Cauchy sequence in $K$. For each $n$ let
 \begin{equation}
E_n:=\set{p_k:k> n}
\end{equation}
We first prove 
\begin{equation}
  \vi{\lim_{n\to\infty}\diam \overline{E_n}=0}
\end{equation}
Fix $\epsilon $. We know there exists $N$ such that
 \begin{equation}
m,k>N\implies d(p_m,p_k)<\epsilon 
\end{equation}
This implies
\begin{equation}
\epsilon \geq \diam{E_N}=\diam \overline{E_N}\vdone
\end{equation}
Notice that
\begin{equation}
\overline{E_n}\subseteq K\text{ and }\overline{E_n}\text{ is closed }\implies \overline{E_n}\text{ is compact }
\end{equation}
Then by \myref{Corollary}{1.13.6}, we know there exists a unique $p$ such that
 \begin{equation}
\forall n, p\in  \overline{E_n}
\end{equation}
Now, we wish to prove
\begin{equation}
  \blue{\lim_{n\to\infty}p_n=p}
\end{equation}
Fix $\epsilon $. Because
\begin{equation} \lim_{n\to\infty}\diam{\overline{E_n}=0}
\end{equation}
We know there exists $N$ such that
 \begin{equation}
\forall n>N, \diam{\overline{E_n}}<\epsilon 
\end{equation}
Let $N_1>N$. We have
 \begin{equation}
\diam{\overline{E_{N_1}}}<\epsilon 
\end{equation}
Notice
\begin{equation}
E_{N_1}=\set{p_{N_1+1},p_{N_1+2},\dots }\subseteq \overline{E_{N_1}}
\end{equation}
This implies 
\begin{equation}
\forall n>N_1, d(p_n,p)\leq \diam{\overline{E_n}}<\epsilon \bdone
\end{equation}
\end{proof}
\begin{corollary}
\label{1.13.9}
\textbf{($\R^n$ is complete)}
\begin{equation}
\R^n\text{ is complete }
\end{equation}
\end{corollary}
\begin{proof}
Let $\set{p_n}$ be a Cauchy sequence in $\R^n$. We first prove \vi{$\set{p_n}$ is bounded}.\\

Again, let
\begin{equation}
E_n:=\set{p_k:k>n}
\end{equation}
Because 
\begin{equation}
\lim_{n\to\infty}\diam{\overline{E_n}}=0
\end{equation}
We know there exists $n$ such that
 \begin{equation}
\diam{E_n}=\diam{\overline{E_n}}\inr^+
\end{equation}
This implies $\set{p_n}$ is bounded. $\vdone$\\

Pick a k-cell that contain $\set{p_n}$. We know k-cell is compact. By \myref{Theorem}{1.13.8}, we see $\set{p_n}$ must converge to some point in that k-cell.
\end{proof}
\begin{corollary}
\label{1.13.10}
\textbf{(Cauchy Criterion for Series)}  
\begin{equation}
\sum a_n\text{ converge }\iff \forall \epsilon ,\exists N, \forall m>u>N, \abso{\sum_{n=u}^m a_n}\leq \epsilon 
\end{equation}
\end{corollary}
\begin{proof}
Let 
 \begin{equation}
s_n=\sum_{k=1}^n a_k
\end{equation}
We see 
\begin{equation}
  \abso{s_m-s_u}=\abso{\sum_{n=u}^m a_n}
\end{equation}
Because $\R$ is complete, we know 
 \begin{equation}
s_n\text{ converge }\iff  s_n\text{ is Cauchy }
\end{equation}
Notice $s_n$ is Cauchy means 
 \begin{equation}
\forall \epsilon, \exists N, \forall m,u>N, \abso{s_m-s_u}<\epsilon 
\end{equation}
\end{proof}
\section{Cantor Set}
\begin{definition}
\textbf{(Construction of Cantor Set)} Define 
\begin{equation}
C_0:=[0,1]\text{ and }C_{n+1}:=\frac{1}{3}C_n\cup (\frac{2}{3}+\frac{1}{3}C_n)
\end{equation}
Define
\begin{equation}
\mathcal{C}:=\bigcap_{n\inn}C_n
\end{equation}
\end{definition}
\begin{theorem}
\textbf{(Measure)} We have
\begin{equation}
\abso{C_0}=1,\abso{C_1}=\frac{2}{3},\abso{C_2}=(\frac{2}{3})^2, \abso{C_n}=(\frac{2}{3})^n
\end{equation}
and 
\begin{equation}
\abso{\mathcal{C}}=\lim_{n\to\infty}(\frac{2}{3})^n=0
\end{equation}
\end{theorem}
\begin{theorem}
\textbf{(Composition of Cantor Set)}
\begin{equation}
\mathcal{C}=\set{\sum_{n=1}^\infty   \frac{a_n}{3^n}: \set{a_n:n\inn}\subseteq \set{0,2}}
\end{equation}
\end{theorem}

\chapter{Numerical Sequence and Series}
\section{Special Real Sequence and Series}
\begin{definition}
\label{2.1.1}
\textbf{(Definition of Extended Real Numbers)} We define
\begin{gather}
\forall x\inr, -\infty <x<\infty\\
\forall x\inr, x+\infty=\infty \text{ and }x-\infty=-\infty\\
\infty+\infty=\infty \text{ and }-\infty-\infty=-\infty\\
\forall x\inr^+, x(\infty)=\infty \text{ and }x(-\infty)=-\infty\\
0(\infty)=0=0(-\infty)\\
\forall x\inr^-, x(\infty)=-\infty\text{ and }x(-\infty)=\infty\\
\forall x\inr, \frac{x}{\infty}=0=\frac{x}{-\infty}\\
  (\infty)(\infty)=\infty=(-\infty)(-\infty)\text{ and }(\infty)(-\infty)=-\infty\\
  \forall r>0, \sqrt[r]{\infty}=\infty=\abso{-\infty}= \abso{\infty}
\end{gather}
Notice that we don't define  $\frac{\infty}{\infty}$ and $\infty-\infty$ and $\sqrt[r]{-\infty} $
\end{definition}
\begin{definition}
\label{2.1.2}
\textbf{(Definition of Converge to Infinity)} We say a sequence $\set{x_n}$ converge to positive infinity $\infty$:
\begin{equation}
\lim_{n\to\infty} x_n=\infty
\end{equation}
If the sequence $\set{x_n}$ get sufficiently big after some point:
 \begin{equation}
\forall M, \exists N, \forall n>N, x_n>M
\end{equation}
Similarly, we define
\begin{equation}
\lim_{n\to\infty}x_n=-\infty\iff \forall M, \exists N, \forall n>N, x_n<M
\end{equation}
\end{definition}
\begin{theorem}
\label{2.1.3}
\textbf{(Convergent Implies Bounded)} 
\begin{equation}
\set{x_n}\text{ converge to a real number $x$}\implies \set{x_n}\text{ is bounded }
\end{equation}
\end{theorem}
\begin{proof}
\As{$\set{x_n}$ is unbounded}. WOLG, let $\sup \set{x_n}=\infty$. Observe for all $R$, there exists infinite $n$ such that  $x_n>R$. Then for each $\epsilon $, it is impossible $x_n<x+\epsilon $ after some finite $N$.  \CaC
\end{proof}
\begin{corollary}
\label{2.1.4}
\textbf{(Unbounded Implies Existence of a sub-sequence Converge to Infinity)}
\begin{equation}
\set{x_n}\text{ is unbounded above }\implies \exists \set{x_{f(n)}}, \lim_{n\to\infty}x_{f(n)}=\infty
\end{equation}
\end{corollary}
\fbox{\begin{minipage}{39em}
Notice that divergent doesn't imply unbounded.\\

Notice that $\lim_{n\to\infty}x_n=\infty\implies \set{x_n}$ is unbounded above, 

An example for sequence converge to infinity is $x_n=n-\frac{1}{n}$. A non-example is 
\begin{equation}
x_n=\begin{cases}
  n& \text{ if $n$ is odd }\\
  0& \text{ if $n$ is even }
\end{cases}
\end{equation}
Notice that we seldom say a series converge to infinity.\\


Now we introduce some special sequence. 
\end{minipage}}
\begin{definition}
\label{2.1.5}
\textbf{(Definition of Little-o and Equivalent)} We say $b_n=o(a_n)$ if
\begin{equation}
\lim_{n\to\infty}\frac{b_n}{a_n}=0
\end{equation}
And say $a_n\sim b_n$ if
\begin{equation}
\lim_{n\to\infty} \frac{b_n}{a_n}=1
\end{equation}
\end{definition}
\begin{theorem}
\label{2.1.6}
\textbf{(Sequence Arithmetic)} Let $\set{x_n},\set{y_n}$ be two real sequences that respectively converge to $x\inr\cup \set{\infty,-\infty}$ and  $y\inr$. We have
\begin{gather}
\lim_{n\to\infty} -x_n=-x\\
\lim_{n\to\infty} x_n+y_n= x+y\\
\lim_{n\to\infty} cx_n=cx\text{ and }\lim_{n\to\infty}c+x_n=c+x\\
\lim_{n\to\infty} x_ny_n=xy\\
\lim_{n\to\infty} x_n^{-1}=x^{-1}
\end{gather}
If the arithmetic on right hand side is possible. 
\end{theorem}
\begin{proof}
Fix $\epsilon $. Notice that the foundation of the proof is below is that we can let $\abso{x-x_n}$ and $\abso{y_n-y}$ be arbitrarily small.\\

For $\lim_{n\to\infty}-x_n=-x$, notice
\begin{equation}
  \abso{-x_n-(-x)}=\abso{x-x_n}
\end{equation}
For $\lim_{n\to\infty}x_n+y_n$, notice
\begin{equation}
\abso{(x_n+y_n)-(x+y)}\leq \abso{x_n-x}+\abso{y_n-y}
\end{equation}
For $\lim_{n\to\infty} cx_n=cx$, notice
\begin{equation}
\abso{cx_n-cx}=\abso{c}\times\abso{x_n-x}
\end{equation}
For $\lim_{n\to\infty} c+x_n=c+x$, notice
\begin{equation}
\abso{c+x_n-(c+x)}=\abso{x_n-x}
\end{equation}
For $\lim_{n\to\infty} x_ny_n=xy$, notice
\begin{align}
  \abso{x_ny_n-xy}&=\abso{(x_n-x)(y_n-y)+x(y_n-y)+y(x_n-x)}\\
  &\leq \abso{x_n-x}\times\abso{y_n-y}+\abso{x}\times\abso{y_n-y}+\abso{y}\times\abso{x_n-x}
\end{align}
For $\lim_{n\to\infty}x_n^{-1}=x^{-1}$, notice 
\begin{equation}
\abso{x-x_n}<\frac{\abso{x}}{2}\implies \abso{x}\leq \abso{x_n}+\abso{x-x_n}<\abso{x_n}+\frac{\abso{x}}{2}\implies \frac{\abso{x}}{2}<\abso{x_n}\implies \frac{1}{\abso{x_n}}<\frac{2}{\abso{x}}
\end{equation}
Then notice
\begin{equation}
\abso{\frac{1}{x_n}-\frac{1}{x}}=\abso{\frac{x-x_n}{x\times x_n}}=\abso{\frac{1}{x}}\times \abso{\frac{1}{x_n}}\times \abso{x-x_n}\leq \frac{1}{\abso{x}}\times \frac{2}{\abso{x}}\times \abso{x-x_n}
\end{equation}
\end{proof}
\begin{corollary}
\label{2.1.7}
\textbf{(Equivalent)} 
\begin{equation}
\sim\text{ is an equivalent relation. }
\end{equation}
\end{corollary}
\begin{corollary}
\label{2.1.8}
\textbf{(Sequence Arithmetic)} Let $p\inz,q\inn$
\begin{gather}
\lim_{n\to\infty} x_n=x\implies \lim_{n\to\infty} x_n^p=x^p\\
\lim_{n\to\infty} x_n=x\text{ and }x_n\text{ is positive }\implies \lim_{n\to\infty} x_n^{\frac{p}{q}}=x^{\frac{p}{q}}
\end{gather}
\end{corollary}
\begin{proof}
The first statement follows from \myref{Theorem}{2.1.6}.\\

To prove the second statement, we only have to prove
\begin{equation}
\lim_{n\to\infty} \sqrt[q]{x_n} =\sqrt[q]{x} 
\end{equation}
Notice that we have
\begin{equation}
\abso{\sqrt[q]{x_n}-\sqrt[q]{x}}=\frac{\abso{x_n-x}}{\sum_{i=0}^{q-1}x_n^{\frac{q-1-i}{q}}\times x^{\frac{i}{q}}}=\frac{\abso{x_n-x}}{\sum_{i=0}^{q-1}(x_n^{q-1-i}\times x^i)^{\frac{1}{q}}}
\end{equation}
We wish to find a lower bound for 
\begin{equation}
\sum_{i=0}^{q-1}(x_n^{q-1-i}\times x^i)^{\frac{1}{q}}
\end{equation}
Notice that for sufficiently large $n$, we have $x_n>\frac{x}{2}$. Then we know
 \begin{equation}
\sum_{i=0}^{q-1}(x_n^{q-1-i}\times x^i)^{\frac{1}{q}}>\sum_{i=0}^{q-1}((\frac{1}{2})^{q-1-i}\times x^{q-1} )^{\frac{1}{q}}
\end{equation}
Then we know for sufficiently large $n$, we have
 \begin{equation}
\abso{\sqrt[q]{x_n}-\sqrt[q]{x} }=\frac{\abso{x_n-x}}{\sum_{i=0}^{q-1}(x_n^{q-1-i}\times x^i)^{\frac{1}{q}}}<\frac{\abso{x_n-x}}{\sum_{i=0}^{q-1}((\frac{1}{2})^{q-1-i}\times x^{q-1})^{\frac{1}{q}}}
\end{equation}
\end{proof}
\begin{theorem}
\label{2.1.9}
\textbf{(Special Sequence)} Let $p>0$ and $q>1$ and $\alpha \inr$. We have
\begin{gather}
\lim_{n\to\infty}\frac{1}{n^p}=0\\
\lim_{n\to\infty}\sqrt[n]{p}=1\\
\lim_{n\to\infty}\sqrt[n]{n}=1\\
\lim_{n\to\infty}\frac{1}{q^n}=0\\
\lim_{n\to\infty}\frac{n^{\alpha }}{q^n}=0
\end{gather}
\end{theorem}
\begin{proof}
For $\lim_{n\to\infty}\frac{1}{n^p}=0$, observe
\begin{equation}
\frac{1}{n^p}<\epsilon \iff n>\sqrt[p]{\frac{1}{\epsilon }}  
\end{equation}
For $\lim_{n\to\infty}\sqrt[n]{p}=1$, observe
\begin{equation}
\sqrt[n]{p}-1<\epsilon  \iff p<(1+\epsilon )^n\text{ and }1-\sqrt[n]{p}<\epsilon \iff (1-\epsilon )^n<p  
\end{equation}
For $\lim_{n\to\infty}\sqrt[n]{n} =1$, observe
\begin{equation}
 (\sqrt[n]{n}-1+1)^n=n\implies \binom{n}{2} (\sqrt[n]{n}-1)^2<n\implies \sqrt[n]{n}-1<\sqrt{\frac{2}{n-1}}  
\end{equation}
And observe
\begin{equation}
\sqrt{\frac{2}{n-1}}<\epsilon  \iff n>\frac{2}{\epsilon^2}+1  
\end{equation}
For $\lim_{n\to\infty}\frac{1}{q^n}=0$, observe
\begin{equation}
\frac{1}{q^n}<\epsilon  \iff  q^n>\frac{1}{\epsilon }
\end{equation}
For $\lim_{n\to\infty}\frac{n^\alpha }{q^n}=0$. Let $q=1+p$. We have
 \begin{equation}
\forall k\leq n\inn, q^n>\binom{n}{k}p^k=n(n-1)\cdots (n-k+1) \frac{p^k}{k!}
\end{equation}
Notice that if $k<\frac{n}{2}$, we have
 \begin{equation}
n-k+1>\frac{n}{2}\text{ and }n(n-1)\cdots (n-k+1) \frac{p^k}{k!}>(\frac{n}{2})^k \frac{p^k}{k!}
\end{equation}
Then if we pick $k>\alpha $, for large  $n$  ($n>2k$), we have 
\begin{equation}
\frac{n^{\alpha }}{q^n}<\frac{n^{\alpha }}{(\frac{n}{2})^k \frac{p^k}{k!}}=n^{\alpha -k}\frac{2^kk!}{p^k}
\end{equation}
We see the right hand side approach to $0$.
\end{proof}
\fbox{\begin{minipage}{39em}
Remark: to prove $\lim_{n\to\infty} (f(n))^{g(n)}$ converge to sth. One trick is to use binomial theorem so that $\binom{\alpha }{k}(f(n))<h(n) $, then we get an upper bound $h(n)$ that may be easier to handle.
\end{minipage}}
\section{Comparison Test, Geometric Series and p-Series}
\fbox{\begin{minipage}{39em}
We first give an easier way to determine if a series converge
\end{minipage}}
\begin{theorem}
\label{2.2.1}
\textbf{(Cauchy Criterion For Series)} 
\begin{equation}
  \sum_{k=1}^\infty a_k\text{ converge }\iff \forall \epsilon , \exists N, \forall n>m>N, \abso{\sum_{k=m}^n a_k}<\epsilon   
\end{equation}
\end{theorem}
\begin{proof}
Notice 
\begin{equation}
\sum_{k=1}^\infty a_k=\lim_{n\to\infty} (\sum_{k=1}^n a_k)
\end{equation}
Because $\R$ is complete, we know  
 \begin{gather}
\lim_{n\to\infty}\sum_{k=1}^n a_k\inr\\
\liff \set{\sum_{k=1}^n a_k}_{n\inn}\text{ is Cauchy }\\
\liff \forall \epsilon ,\exists N,\forall n>m>N, \abso{\sum_{k=m}^n a_k}=\abso{\sum_{k=1}^n a_k- \sum_{k=1}^m a_k}<\epsilon 
\end{gather}
\end{proof}
\begin{corollary}
\label{2.2.2}
\textbf{(Cauchy Criterion For Series)} 
\begin{equation}
  \sum_{k=1}^\infty a_k\text{ diverge }\iff \exists \epsilon, \forall N, \exists  n>m \inn, \abso{\sum_{k=m}^n a_k}>\epsilon 
\end{equation}
\end{corollary}
\fbox{\begin{minipage}{39em}
We now introduce absolutely converge.
\end{minipage}}
\begin{definition}
\label{2.2.3}
\textbf{(Definition of Absolutely Convergent)} We say $\sum_{k=1}^\infty a_k$ absolutely converge if 
\begin{equation}
 \sum_{k=1}^\infty \abso{a_k} \text{ converge to a real number }
\end{equation}
\end{definition}
\begin{theorem}
\label{2.2.4}
\textbf{(Non-negative Series Converge Implies Absolutely Converge)} Let $\set{a_n}$ be a sequence that eventually become non-negative. We have
\begin{equation}
\sum_{k=1}^\infty a_k\text{ converge }\implies \sum_{k=1}^\infty a_k\text{ absolutely converge }
\end{equation}
\end{theorem}
\begin{theorem}
\label{2.2.5}
\textbf{(Absolutely Convergent Implies Convergent)} 
\begin{equation}
\sum_{k=1}^\infty a_k\text{ absolutely converge }\implies \sum_{k=1}^\infty a_k\text{ converge }
\end{equation}
\end{theorem}
\begin{proof}
Notice 
\begin{equation}
\forall n>m \inn, \abso{\sum_{k=m}^n a_k}\leq \sum_{k=m}^n \abso{a_k}=\abso{\sum_{k=m}^n \abso{a_k}}
\end{equation}
Then from $\sum_{k=1}^\infty \abso{a_k}$ satisfy Cauchy criterion, we can deduce $\sum_{k=1}^\infyt a_k$ satisfy Cauchy Criterion. 
\end{proof}
\fbox{\begin{minipage}{39em}
    We now introduce comparison test.Notice that in comparison test, the $\set{b_n},\set{c_n}$ must eventually be non-negative.
\end{minipage}}
\begin{theorem}
\label{2.2.6}
\textbf{(Squeeze Theorem)} If for large $n$, we have  $x_n<y_n<z_n$, then we have
 \begin{equation}
\lim_{n\to\infty}x_n=\alpha =\lim_{n\to\infty}z_n\implies \lim_{n\to\infty}y_n=\alpha 
\end{equation}
\end{theorem}
\begin{proof}
For large $n$, 
 \begin{equation}
\alpha -\epsilon <x_n<y_n<z_n<\alpha +\epsilon 
\end{equation}
\end{proof}
\begin{theorem}
\label{2.2.7}
\textbf{(Comparison Test)} Let $\set{c_n}$ be eventually non-negative. We have
\begin{gather}
  \sum_{k=1}^\infty c_k\text{ converge and for large }n, \abso{b_n}\leq c_n\implies \sum_{k=1}^\infty b_k\text{ absolutely converge }\\
  \sum_{k=1}^\infty a_k\text{ diverge and for large $n$}, b_n>\abso{a_n}\implies \sum_{k=1}^\infty b_k\text{ diverge }
\end{gather}
\end{theorem}
\begin{proof}
Observe for all large $n$ and $m$,
\begin{equation}
\abso{\sum_{k=m}^n \abso{b_k}}=\sum_{k=m}^n \abso{b_k}\leq \sum_{k=m}^n c_k\leq \abso{\sum_{k=m}^n c_k}
\end{equation}
Observe for all $n,m$
\begin{equation}
\abso{\sum_{k=m}^n a_k}<\sum_{k=m}^n \abso{a_k}<\sum_{k=m}^n b_k=\abso{\sum_{k=m}^n b_k}
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
We now introduce geometric series.
\end{minipage}}
\begin{theorem}
\label{2.2.8}
\textbf{(Geometric Series)} 
\begin{align}
x\in (-1,1)\implies \sum_{n=0}^\infty x^n=\frac{1}{1-x}\\
x\not\in (-1,1)\implies \sum_{n=0}^\infty x^n\text{ diverge }
\end{align}
\end{theorem}
\begin{proof}
Let 
\begin{equation}
s_n:=\sum_{k=1}^n x^k
\end{equation}
Notice
\begin{equation}
  (1-x)s_n=\sum_{k=0}^n x^k-\sum_{k=0}^n x^{k+1}=1-x^{n+1}
\end{equation}
This give us
\begin{equation}
s_n=\frac{1-x^{n+1}}{1-x}
\end{equation}
Then we have
\begin{equation}
x\in (-1,1)\implies \lim_{n\to\infty}x^{n+1}=0\implies \lim_{n\to\infty}s_n=\frac{1}{1-x}
\end{equation}
And have
\begin{equation}
x\not\in (-1,1)\implies \lim_{n\to\infty}x^{n+1}=\infty\text{ or }-\infty\implies \lim_{n\to\infty}s_n= \frac{-\infty}{1-x}\text{ or }\frac{\infty}{1-x}
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
We now introduce monotonic series and important \myref{Theorem}{2.2.10}
\end{minipage}}
\begin{definition}
\label{2.2.9}
\textbf{(Monotonic)} We say a real sequence $\set{x_n}$ is monotonic if $\set{x_n}$ monotonically increase or monotonically decrease.
\begin{equation}
\set{x_n}\text{ monotonically increase if }\forall n, x_{n+1}\geq x_n
\end{equation}
\begin{equation}
\set{x_n}\text{ monotonically decrease if }\forall n, x_{n+1}\leq x_n
\end{equation}
\end{definition}
\begin{theorem}
\label{2.2.10}
\textbf{(Monotonic Sequence Converge if and only if Bounded)} Let $\set{x_n}$ be a monotonic sequence. We have
\begin{equation}
\set{x_n}\text{ converge }\iff \set{x_n}\text{ is bounded }
\end{equation}
\end{theorem}
\begin{proof}
Let $\set{x_n}$ monotonically increase. We know $\set{x_n}$ is bounded below by $x_1$. We first prove
\begin{equation}
  \vi{\set{x_n}\text{ is bounded above }\implies \set{x_n}\text{ converge }}
\end{equation}
Notice that
\begin{equation}
\set{x_n}\text{ is bounded above }\implies \sup \set{x_n}\inr
\end{equation}
Let $x:=\sup \set{x_n}$. We wish to prove
\begin{equation}
\lim_{n\to\infty}x_n=x
\end{equation}
Fix $\epsilon $. We know there exists some $N$ such that
 \begin{equation}
x_N>x-\epsilon 
\end{equation}
Notice that
\begin{equation}
\forall m>u>N, x_m,x_u\in (x-\epsilon ,x)\text{ and }\abso{x_m-x_u}<\epsilon 
\end{equation}
We have proved $\set{x_n}$ is Cauchy. $\vdone$\\


For $\set{x_n}\text{ converge }\implies \set{x_n}\text{ is bounded}$, look at \myref{Theorem}{2.1.5}.\\

Let $\set{x_n}$ monotonically decrease. We know $\set{-x_n}$ monotonically increase. If $\set{x_n}$ is bounded, then $\set{-x_n}$ is bounded, which implies $\set{-x_n}$ converges and $\set{x_n}$ converges.\\

If $\set{x_n}$ converge, then $\set{-x_n}$ converge, which implies $\set{-x_n}$ is bounded and $\set{x_n}$ is bounded.
\end{proof}
\fbox{\begin{minipage}{39em}
Lastly, we introduce p-series.
\end{minipage}}
\begin{lemma}
\label{2.2.11}
Let $\set{a_n}$ be a positive monotonically decreasing sequence. We have
 \begin{equation}
\sum_{n=1}^\infty a_n\text{ converge }\iff \sum_{n=0}^\infty 2^na_{2^n}\text{ converge }
\end{equation}
\end{lemma}
\begin{proof}
Notice that $\sum_{n=1}^\infty a_n$ and $\sum_{n=0}^\infty 2^n a_{2^n}$ both monotonically increase. We have introduce the question into proving 
\begin{equation}
\sum_{n=1}^\infty a_n\text{ is bounded above }\iff \sum_{n=0}^\infty 2^na_{2^n}\text{ is bounded above }
\end{equation}
We first prove
\begin{equation}
\vi{\forall n,\sum_{k=0}^n 2^ka_{2^k}\leq M\implies \forall n,\sum_{k=1}^n a_k\leq M}
\end{equation}
Fix $n$. Let  $u$ be the smallest natural such that  $2^{u+1}-1\geq n$.\\

Observe
\begin{equation}
M\geq \sum_{k=0}^u 2^k a_{2^k}\geq \sum_{k=0}^u \sum_{r=1}^{2^k} a_{2^{k}+r-1}=\sum_{k=1}^{2^{u+1}-1} a_k\geq \sum_{k=1}^n a_k\vdone
\end{equation}
We now prove
\begin{equation}
  \blue{\forall n,\sum_{k=1}^n a_k<M\implies \forall n, \sum_{k=0}^n 2^ka_{2^k}<2M}
\end{equation}
Fix $n$. Observe
\begin{align}
  2M\geq 2\sum_{k=1}^{2^{n+2}-1} a_k=2\sum_{k=0}^{n+1}\sum_{r=1}^{2^k}a_{2^k+r-1}&\geq 2\sum_{k=0}^{n+1} \sum_{r=1}^{2^k}a_{2^{k+1}}\\
  &=2\sum_{k=0}^{n+1} 2^ka_{2^{k+1}}\\
  &=\sum_{k=0}^{n+1} 2^{k+1}a_{2^{k+1}}\\
  &\geq \sum_{k=0}^n 2^{k}a_{2^k}\bdone
\end{align}
\end{proof}
\begin{corollary}
\label{2.2.12}
\textbf{(p-series)}
\begin{equation}
\sum_{n=1}^\infty \frac{1}{n^p}\text{ converge }\iff  p>1
\end{equation}
\end{corollary}
\begin{proof}
If $p\leq 0$, observe
\begin{equation}
\lim_{n\to\infty}\frac{1}{n^p}=\infty\text{ or }1\implies \sum_{n=1}^\infty \frac{1}{n^p}=\infty
\end{equation}
If $p>0$, observe
 \begin{equation}
\sum_{n=0}^\infty 2^n \frac{1}{(2^n)^p}=\sum_{n=0}^\infty 2^{n(1-p)}=\sum_{n=0}^\infty (2^{1-p})^n\text{ converge }\iff 2^{1-p}<1\iff p>1
\end{equation}
\end{proof}

\section{sub-Sequential Limit}
\begin{definition}
\label{2.3.1}
\textbf{(Definition of Limit Superior)} For real sequence $\set{x_n}$, we define
\begin{align}
  \limsup_{n\to\infty} x_n&:=\lim_{n\to\infty} \sup \set{x_k:k>n}=\inf \set{\sup \set{x_k:k>n}:n\inn}\\
  \liminf_{n\to\infty} x_n&:=\lim_{n\to\infty}\inf \set{x_k:k>n}=\sup \set{\inf \set{x_k:k>n}:n\inn}
\end{align}
\end{definition}
\fbox{\begin{minipage}{39em}
We now give the most important theorem in this section.
\end{minipage}}
\begin{theorem}
\label{2.3.2}
\textbf{(Main Property of Limit Superior and Inferior)} 
Given $\liminf_{n\to\infty} x_n\inr$ and $\limsup_{n\to\infty} x_n\inr$, we have
\begin{gather}
\forall \epsilon ,\set{x_n}\text{ ends in }(\liminf_{n\to\infty} x_n-\epsilon ,\limsup_{n\to\infty} x_n+\epsilon )
\end{gather}
\end{theorem}
\begin{proof}
Because 
\begin{equation}
\lim_{n\to\infty}\sup  \set{x_k:k>n}<\limsup_{n\to\infty} x_n+\epsilon \text{ and }\lim_{n\to\infty}\inf \set{x_k:k>n}>\liminf_{n\to\infty} x_n-\epsilon 
\end{equation}
We know there exists $N$ such that 
 \begin{equation}
\sup \set{x_k:k>N}<\limsup_{n\to\infty} x_n+\epsilon \text{ and }\inf \set{x_k:k>N}>\liminf_{n\to\infty} x_n-\epsilon 
\end{equation}
This tell us
\begin{equation}
\forall n>N, x_n\in (\liminf_{n\to\infty} x_n-\epsilon ,\limsup_{n\to\infty} x_n+\epsilon )
\end{equation}
\end{proof}
\begin{theorem}
\label{2.3.3}
\textbf{(Main Property of Limit Superior and Inferior)} 
Given $\liminf_{n\to\infty} x_n\inr\text{ and }\limsup_{n\to\infty} x_n\inr$, we have
\begin{equation}
\forall \epsilon , \set{x_n}\text{ does not end in }(\liminf_{n\to\infty} x_n+\epsilon ,\limsup_{n\to\infty} x_n-\epsilon )
\end{equation}
\end{theorem}
\begin{proof}
Notice that $\set{\inf \set{x_k:k>n}}_{n\inn}$ is an increasing sequence, so
\begin{equation}
\forall n, \inf \set{x_k:k>n}\leq \liminf_{n\to\infty} x_n<\liminf_{n\to\infty} x_n+\epsilon 
\end{equation}
Let $n=1$. We have
 \begin{equation}
\inf \set{x_k:k>1}<\liminf_{n\to\infty}  x_n+\epsilon 
\end{equation}
Then by definition of infimum, we know there exists $n_1$ greater than  $1$ such that
 \begin{equation}
x_{n_1}<\liminf_{n\to\infty} x_n+\epsilon 
\end{equation}
Again, we have
\begin{equation}
\inf \set{x_{k}:k>n_1}<\liminf_{n\to\infty} x_n+\epsilon 
\end{equation}
Then we know there exists $n_2$ greater than  $n_1$ such that
 \begin{equation}
x_{n_2}<\liminf_{n\to\infty} x_n+\epsilon 
\end{equation}
Proceeding the procedure above, we have an sub-sequence $\set{x_{n_k}}_{k\inn}$ such that
\begin{equation}
\forall k, x_{n_k}<\liminf_{n\to\infty} x_n+\epsilon 
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
Give clear notice that \myref{Theorem}{2.3.2} and \myref{Theorem}{2.3.3} is mainly for when $\liminf_{n\to\infty} x_n$ and $\limsup_{n\to\infty} x_n$ are reals.\\


\end{minipage}}
\begin{corollary}
\label{2.3.4}
\textbf{(Useful Property of Limit Superior)} 
\begin{equation}
x_n\leq  y_n\text{ for large $n$ }\implies \limsup_{n\to\infty} x_n\leq \limsup_{n\to\infty} y_n\text{ and }\liminf_{n\to\infty}  x_n\leq \liminf_{n\to\infty} y_n
\end{equation}
\end{corollary}
\begin{proof}

\end{proof}
\begin{theorem}
\label{2.3.5}
\textbf{(Main Property of Limit Superior and Inferior)} 
\begin{equation}
\set{a_n}\text{ converge }\implies \liminf_{n\to\infty} a_n=\lim_{n\to\infty}a_n=\limsup_{n\to\infty} a_n
\end{equation}
\end{theorem}
\begin{proof}
This is a direct consequence of \myref{Theorem}{2.2.6} (Squeeze Theorem). 
\end{proof}
\fbox{\begin{minipage}{39em}

\end{minipage}}
\begin{theorem}
\label{2.3.6}
\textbf{(Limit Points Set of Range Are Exactly Set of sub-Sequential Limits)} Let $E$ be the set of sub-sequence limits of  $\set{x_n}$. We have
\begin{equation}
\set{x_n:n\inn}'\subseteq E
\end{equation}
\end{theorem}
\begin{proof}
Let $y\in \set{x_n:n\inn}'$. We know there exists a sequence $\set{x_{f(n)}}_{n\inn}$ converge to $y$, where we are not guarantee $a<b\implies f(a)<f(b)$.\\

We wish to construct a sub-sequence of $\set{x_{f(n)}}$ that is also a sub-sequence of $\set{x_n}$.\\

Notice  $\forall n, \exists m>n, f(m)>f(n)$ and we are done.
\end{proof}
\begin{theorem}
\label{2.3.7}
\textbf{(Topological Properties of sub-Sequential Limits)} Let $E$ be the set of sub-sequential limits of $\set{x_n}$, and let $Y$ be the set of points that appears infinite times in  $\set{x_n}$, i.e.
\begin{equation}
  Y=\set{y:\exists \set{x_{n_k}},\forall k, y=x_{n_k}}
\end{equation}
We have
\begin{equation}
E=\set{x_n:n\inn}' \cup Y
\end{equation}
\end{theorem}
\begin{proof}
By \myref{Theorem}{2.3.6}, it is clear 
\begin{equation}
\set{x_n:n\inn}' \cup Y\subseteq E
\end{equation}
Arbitrarily pick $z\in E$. We wish to prove
\begin{equation}
z\in \set{x_n:n\inn}'\cup Y
\end{equation}
In other words, we wish to prove
\begin{equation}
  \vi{z\not\in Y\implies z\in \set{x_n:n\inn}'}
\end{equation}
We know there exist a sub-sequence $\set{x_{f(n)}}$ such that 
\begin{equation}
\lim_{n\to\infty}x_{f(n)}=z
\end{equation}
Because $z\not\in Y$. We know there a sub-sequence $\set{x_{f(g(n))}}$ such that
\begin{equation}
\forall n,x_{f(g(n))}\neq z
\end{equation}
Notice that
 \begin{equation}
z=\lim_{n\to\infty}x_{f(n)}=\lim_{n\to\infty}x_{f(g(n))} 
\end{equation}
And we are done.
\end{proof}
\fbox{\begin{minipage}{39em}

\end{minipage}}

\begin{theorem}
\label{2.3.8}
\textbf{(Equivalent Definition of Limit Inferior)} Let $E$ be the set of sub-sequential limit of $\set{x_n}$. We have
\begin{equation}
\liminf_{n\to\infty} x_n=\inf E
\end{equation}
even in the context of extended real numbers. 
\end{theorem}
\begin{proof}
Notice that the sequence 
\begin{equation}
\set{\inf \set{x_k:k>n}}_{n\inn}
\end{equation}
monotonically increase.\\

We first prove
\begin{equation}
\vi{\liminf_{n\to\infty} x_n=-\infty\implies \inf E=-\infty}
\end{equation}
Because $\set{\inf \set{x_k:k>n}}_{n\inn}$ monotonically increase, we know
\begin{equation}
\inf \set{x_n}=-\infty
\end{equation}
For each $n$,  let 
\begin{equation}
R_n=-n
\end{equation}
Fix $n$. We know 
\begin{equation}
\forall N, \exists u_n>N,x_{u_n}<R_n
\end{equation}
Otherwise, say $\exists N,\forall u>N, x_u\geq -R$, we will have $\inf \set{x_k}_{k\inn}\geq \min \set{R_n,x_1,\dots ,x_N}\inr$.\\

Then for each $n$, we know there exists $u_n$ greater than  $\max \set{u_1,\dots , u_{n-1}}$, such that 
\begin{equation}
x_{u_n}<R_n=-n
\end{equation}
Let $f(n)=u_n$. We see
\begin{equation}
\lim_{n\to\infty}x_{f(n)}=-\infty 
\end{equation}
which implies $\inf E=-\infty\vdone$\\

We now prove 
\begin{equation}
\blue{\liminf_{n\to\infty} x_n=L \implies \inf E=L}
\end{equation}
Because $\set{\inf \set{x_k:k>n}}$ is a monotonically increasing sequence. For each $n$, we know
\begin{equation}
\inf \set{x_k:k>n}\leq L
\end{equation}
Then for each $n$, we can let  $f(n)$ be a number greater than $\max \set{f(1),\dots ,f(n-1),n}$ such that $x_{f(n)}\leq L$. Then by squeeze Theorem, we know 
\begin{equation}
\lim_{n\to\infty}x_{f(n)}=L
\end{equation}
We have proved $\inf E\leq L$. \As{$\inf E<L$}. Let $M=\frac{\inf E+L}{2}$. We have
\begin{equation}
\inf E<M<L
\end{equation}
Then there exists a sub-sequence $\set{x_{f(n)}}$ such that
\begin{equation}
\lim_{n\to\infty}x_{f(n)}=M
\end{equation}
Then we know there exists $N$ such that
 \begin{equation}
n>N\implies x_{f(n)}<\frac{L+M}{2}<L
\end{equation}
Then we see for all $n$
\begin{equation}
\inf \set{x_k:k>n}<\frac{L+M}{2}<L\tCaC\bdone
\end{equation}
Lastly we prove 
\begin{equation}
  \vi{\liminf_{n\to\infty} x_n=\infty\implies \inf E=\infty}
\end{equation}
Let $\set{x_{f(n)}}$ be a sub-sequence. We wish to prove
\begin{equation}
\lim_{n\to\infty} x_{f(n)}=\infty
\end{equation}
Notice that we have
\begin{gather}
\liminf_{n\to\infty} x_n=\infty\\
\liff \forall R\inr^+ ,\exists N, n>N\implies \inf \set{x_k:k>n}>R\\
\liff  \forall R\inr^+,\exists N, \inf \set{x_k:k>N}>R\\
\implies  \forall R\inr^+,\exists N, k>N\implies x_k>R
\end{gather}
Then for all $R$, we know there must exists  $N_n$ such that  $f(N_n)>N$, then we see 
\begin{equation}
n>N_n\implies f(n)>f(N_n)>N\implies x_{f(n)}>R \vdone
\end{equation}
\end{proof}
\begin{corollary}
\label{2.3.9}
\textbf{(Equivalent Definition of Limit Superior)} Let $E$ be the set of sub-sequential limit of  $\set{x_n}$. We have
\begin{equation}
\limsup_{n\to\infty} x_n=\sup E
\end{equation}
\end{corollary}
\begin{theorem}
\label{2.3.10}
\textbf{(Sub-sequential Limit of a Sequence in Metric Space form a Closed Set)} Let $E$ be the set of all sub-sequential limit of $\set{x_n}$. We have
\begin{equation}
E\text{ is closed }
\end{equation}
\end{theorem}
\begin{proof}
Let $q\in E'$. We wish to prove \vi{$q\in E$}. In other words, we wish to find a sub-sequence $\set{x_{f(n)}}$ of $\set{x_n}$ that converge to $q$.\\

Because $q\in E'$, we know $q$ is a limit of some sequence  $\set{p_n}$ in $E$ such that $q\not\in \set{p_n}$.\\

Let the sequence $\set{p_n}$ satisfy 
\begin{equation}
d(q,p_n)<\frac{1}{n}
\end{equation}
Because for each $k$, the point $p_k$ is a sub-sequential limit of $\set{x_n}$. We know for each $k$, there exists a sub-sequence $\set{x_{f_k(n)}}\subseteq \set{x_n}$ such that for each $k$, we have
\begin{equation}
\lim_{n\to\infty}x_{f_k(n)}= p_k
\end{equation}
We now construct a sub-sequence $\set{x_{f(n)}}$ that converge to $q$.\\

We wish that for each $n$, we have
\begin{equation}
d(x_{f(n)},q)<\frac{2}{n}
\end{equation}
Notice that because 
\begin{equation}
  \lim_{n\to\infty}x_{f_k(n)}=p_k
\end{equation}
For all $n$, there exists  $N_n$ such that
 \begin{equation}
u>N_n\implies d(x_{f_n(u)},p_n)<\frac{1}{n}\implies d(x_{f_n(u)},q)\leq d(x_{f_n(u)},p_n)+d(p_n,q)<\frac{2}{n}
\end{equation}
Then we can let $f(n)>\max \set{N_n, f(1),\dots ,f(n-1)}$ and we are done. $\vdone$ 
\end{proof}
\begin{theorem}
\label{2.3.11}
\textbf{(Properties of Limit Inferior and Superior)} Let $\set{x_n}$ be a real sequence. We have 
\begin{equation}
\liminf_{n\to\infty} x_n=\inf E\in E\text{ and }\limsup_{n\to\infty} x_n=\sup E\in E
\end{equation}
And have
\begin{equation}
L<\liminf_{n\to\infty}  x_n\implies (\exists N, n>N\implies x_n>L)
\end{equation}
\end{theorem}
\begin{proof}
The first statement hold true because  $E$ is closed. Let $L<\liminf_{n\to\infty}  x_n$. We know there exists $N$ such that
 \begin{equation}
L<\inf \set{x_k:k>N}
\end{equation}
This tell us 
\begin{equation}
\forall k>N, x_k>L
\end{equation}
This finish the proof.
\end{proof}
\begin{theorem}
\label{2.3.12}
\textbf{(Useful Theorem)} If there exists $N$ such that
 \begin{equation}
\forall n>N, x_n\leq y_n
\end{equation}
Then
\begin{equation}
\limsup_{n\to\infty} x_n\leq \limsup_{n\to\infty} y_n
\end{equation}
And
\begin{equation}
\liminf_{n\to\infty} x_n\leq \liminf_{n\to\infty} y_n
\end{equation}
\end{theorem}
\begin{proof}
\As{ $\limsup_{n\to\infty} x_n>\limsup_{n\to\infty} y_n$}. Let $\beta $ satisfy
\begin{equation}
\limsup_{n\to\infty} x_n>\beta >\limsup_{n\to\infty} y_n
\end{equation}
We know there exists $N_1$ such that
 \begin{equation}
\forall n>N_1, y_n<\beta 
\end{equation}
Let $\set{x_{f(n)}}$ be a sub-sequence converge to $\limsup_{n\to\infty} x_n$. Then we know there exists $N_2$ such that
 \begin{equation}
\forall n>N_2, x_{f(n)}>\beta 
\end{equation}
Then we can select $n>\max \set{N_1,N_2}$, and because $f(n)>f(N_1)\geq N_1$, we have
\begin{equation}
y_{f(n)}<\beta <x_{f(n)}\tCaC
\end{equation}
The other side is similar.
\end{proof}
\section{Euler Number}
\begin{lemma}
\label{2.4.1}
\textbf{(Bernoulli's Inequality)} 
Let $x\geq -1$ and $r\inn$. We have
\begin{equation}
  (1+x)^r\geq 1+rx
\end{equation}
\end{lemma}
\begin{proof}
We prove by induction. Notice that when $r=1$, the proof is trivial. We wish to prove
\begin{equation}
  (1+x)^k \geq 1+kx\implies (1+x)^{k+1}\geq 1+(k+1)x
\end{equation}
Notice
\begin{equation}
  (1+x)^{k+1}=(1+x)^k +x(1+x)^k\text{ and }1+(k+1)x=1+kx+x
\end{equation}
This reduce to proving 
\begin{equation}
x(1+x)^k \geq x
\end{equation}
When $x=0$. The proof is trivial. When  $x>0$, the above statement is equivalent to 
 \begin{equation}
   (1+x)^k\geq 1
\end{equation}
Which is clear. When $x<0$, the above statement is equivalent to 
 \begin{equation}
   (1+x)^k\leq 1
\end{equation}
which is also clear.
\end{proof}
\begin{theorem}
\label{2.4.2}
\textbf{(Existence of Euler Number)} 
\begin{equation}
\sum_{n=0}^\infty \frac{1}{n!}\text{ converge }
\end{equation}
\end{theorem}
\begin{proof}
Notice 
\begin{equation}
\forall n, n!\geq 2^{n-1}\implies \forall n,\frac{1}{n!}\leq \frac{1}{2^{n-1}}
\end{equation}
Observe 
\begin{equation}
\sum_{n=0}^\infty  \frac{1}{2^{n-1}}=\frac{2}{\frac{1}{2}}=4
\end{equation}
Then by comparison test, we are done. 
\end{proof}
\begin{definition}
\label{2.4.3}
\textbf{(Definition of Euler Number)}
\begin{equation}
e:=\sum_{n=0}^\infty \frac{1}{n!}
\end{equation}
\end{definition}
\begin{theorem}
\label{2.4.4}
\textbf{(Existence of Euler Number)}
\begin{equation}
\lim_{n\to\infty} (1+\frac{1}{n})^n\text{ converge }
\end{equation}
\end{theorem}
\begin{proof}
We first prove
\begin{equation}
\vi{(1+\frac{1}{n})^n\text{ monotonically increase }}
\end{equation}
We wish to prove
\begin{equation}
\frac{(1+\frac{1}{n+1})^{n+1}}{(1+\frac{1}{n})^n}\geq 1
\end{equation}
Observe
\begin{align}
\frac{(1+\frac{1}{n+1})^{n+1}}{(1+\frac{1}{n})^n}&=\frac{(\frac{n+2}{n+1})^{n+1}}{(\frac{n+1}{n})^n}\\
&=(\frac{n(n+2)}{(n+1)^2})^n(1+\frac{1}{n+1})\\
&=(1-\frac{1}{(n+1)^2})^n (1+\frac{1}{n+1})\\
&\geq (1-\frac{n}{(n+1)^2})(1+\frac{1}{n+1})\\
&=\frac{(n^2+n+1)(n+2)}{(n+1)^3}\\
&=\frac{n^3+3n^2+3n+3}{n^3+3n^2+3n+1}> 1\vdone
\end{align}
We now prove
\begin{equation}
  \blue{\forall n,(1+\frac{1}{n})^n<e}
\end{equation}
Observe
\begin{align}
  (1+\frac{1}{n})^n&= \sum_{k=0}^n \binom{n}{k}\frac{1}{n^k}\\
  &=\sum_{k=0}^n \frac{n(n-1)\cdots (n-k+1)}{n^kk!}\\
  &=\sum_{k=0}^n \frac{1}{k!}(\frac{n}{n})(\frac{n-1}{n})(\frac{n-2}{n})\cdots (\frac{n-k+1}{n})\leq \sum_{k=0}^n \frac{1}{k!}<\sum_{n=0}^\infty \frac{1}{n!}=e\bdone
\end{align}
\end{proof}
\begin{theorem}
\label{2.4.5}
\textbf{(Existence of Euler Number)} 
\begin{equation}
e=\lim_{n\to\infty}(1+\frac{1}{n})^n
\end{equation}
\end{theorem}
\begin{proof}
Define
\begin{equation}
s_n:=\sum_{k=0}^n \frac{1}{k!}
\end{equation}
We have
\begin{equation}
\lim_{n\to\infty}s_n=e
\end{equation}
Define 
\begin{equation}
t_n=(1+\frac{1}{n})^n
\end{equation}
In \myref{Theorem}{2.4.4}, we have proved
\begin{equation}
\forall n, t_n\leq s_n<e
\end{equation}
Which give us
\begin{equation}
\limsup_{n\to\infty} t_n\leq e
\end{equation}
Let $n\geq m$. We have
\begin{align}
  (1+\frac{1}{n})^n&= \sum_{k=0}^n \binom{n}{k}\frac{1}{n^k}\\
  &\geq \sum_{k=0}^m \binom{n}{k}\frac{1}{n^k}\\
  &=\sum_{k=0}^m \frac{n(n-1)\cdots (n-k+1)}{n^k k!}\\
  &=\sum_{k=0}^m \frac{1}{k!}(\frac{n}{n})(\frac{n-1}{n})(\frac{n-2}{n})\cdots (\frac{n-k+1}{n})
\end{align}
Define 
\begin{equation}
v_{n,m}:=\sum_{k=0}^m \frac{1}{k!}(\frac{n}{n})(\frac{n-1}{n})\cdots (\frac{n-k+1}{n})
\end{equation}
We now have
\begin{equation}
  n>m\implies t_n\geq v_{n,m}
\end{equation}
Which in turn means
\begin{equation}
\forall m, \liminf_{n\to\infty} t_n\geq \liminf_{n\to\infty} v_{n,m}=\lim_{n\to\infty} v_{n,m}
\end{equation}
Notice 
\begin{align}
\forall m,\lim_{n\to\infty} v_{n,m}&=\lim_{n\to\infty}\sum_{k=0}^m \frac{1}{k!}(\frac{n}{n})(\frac{n-1}{n})\cdots (\frac{n-k+1}{n})\\
&=\sum_{k=0}^m \frac{1}{k!}\lim_{n\to\infty}(\frac{n}{n})(\frac{n-1}{n})\cdots (\frac{n-k+1}{n})\\
&=\sum_{k=0}^m \frac{1}{k!}
\end{align}
Then
\begin{equation}
\lim_{m\to\infty}\lim_{n\to\infty}v_{n,m}=e
\end{equation}
Then we have
\begin{align}
  \forall \epsilon , \exists N, \lim_{n\to\infty}v_{n,N}>e-\epsilon 
\end{align}
Notice 
\begin{equation}
\liminf_{n\to\infty} t_n\geq \lim_{n\to\infty}v_{n,N}>e-\epsilon 
\end{equation}
Then because $\epsilon $ can be arbitrary small, we know 
\begin{equation}
\liminf_{n\to\infty} t_n\geq e
\end{equation}
Then because 
\begin{equation}
\limsup_{n\to\infty} t_n\leq e
\end{equation}
We now have
\begin{equation}
\lim_{n\to\infty} t_n=e
\end{equation}

\end{proof}



\section{Tests for Convergence of Series}
\begin{theorem}
\label{2.5.1}
\textbf{(Root Test)} Given $\sum a_n$. Let
\begin{equation}
\alpha:= \limsup_{n\to\infty} \sqrt[n]{\abso{a_n}} 
\end{equation}
Then 
\begin{enumerate}[label=(\alph*)]
  \item $\alpha <1\implies \sum a_n$ absolutely converge\\
  \item $\alpha >1\implies \sum a_n$ diverge
\end{enumerate}
\end{theorem}
\begin{proof}
Let 
\begin{equation}
\limsup_{n\to\infty} \sqrt[n]{\abso{a_n}} =\alpha <1
\end{equation}
We know there exists $N$ such that
 \begin{equation}
\forall n>N, \sqrt[n]{\abso{a_n}}\leq \alpha  <1 
\end{equation}
Then we have
\begin{equation}
\forall n>N, a_n\leq \abso{a_n}<\alpha  ^n
\end{equation}
Because $\alpha <1$, we know 
\begin{equation}
\sum_{n=1}^\infty \alpha ^n=\frac{\alpha }{1-\alpha  }
\end{equation}
Then by Comparison Test, we know $\sum a_n$ converge. If
\begin{equation}
\alpha =\limsup_{n\to\infty} \sqrt[n]{\abso{a_n}}>1
\end{equation}
Let $\set{a_{f(n)}}$ be a sub-sequence such that
\begin{equation}
  \forall n,\sqrt[f(n)]{\abso{a_{f(n)}}}>1 
\end{equation}
Which means
\begin{equation}
\forall n, \abso{a_{f(n)}}>1^{f(n)}=1
\end{equation}
Then it is impossible $\lim_{n\to\infty}a_n=0$, let alone $\sum_{n=1}^\infty a_n$ converge.
\end{proof}
\begin{theorem}
\label{2.5.2}
\textbf{(Ratio Test)} Given series $\sum a_n$. We have
\begin{enumerate}[label=(\alph*)]
  \item  $\limsup_{n\to\infty} \abso{\frac{a_{n+1}}{a_n}}<1\implies \sum a_n$ converge\\
  \item $\liminf_{n\to\infty} \abso{\frac{a_{n+1}}{a_n}}> 1\implies \sum a_n$ diverge
\end{enumerate}
\end{theorem}
\begin{proof}
We first prove 
\vi{
\begin{equation}
\limsup_{n\to\infty} \abso{\frac{a_{n+1}}{a_n}}<1\implies \sum a_n\text{ converge }
\end{equation}}
Let 
\begin{equation}
\limsup_{n\to\infty} \abso{\frac{a_{n+1}}{a_n}}=\alpha <1
\end{equation}
We know there exists $N$ that satisfy
 \begin{equation}
\forall n\geq N, \abso{\frac{a_{n+1}}{a_n}}\leq \alpha <1
\end{equation}
This give us
\begin{equation}
\forall n>N, \abso{a_n}\leq \alpha ^{n-N}\abso{a_N}
\end{equation}
In other words,
\begin{equation}
\forall k, \abso{a_{N+k}}\leq \alpha ^{k}\abso{a_N}
\end{equation}
Then because
\begin{equation}
\alpha <1\implies \sum_{k=1}^\infty \beta^{k} \abso{a_{N+k}}=\frac{\abso{a_N}\alpha  }{1-\alpha  }
\end{equation}
By comparison test we know the series
\begin{equation}
\sum_{k=1}^\infty a_{N+k}\text{ converges }
\end{equation}
This tell us
\begin{equation}
\sum a_n=\sum_{k=1}^N a_k+ \sum_{k=1}^\infty a_{N+k}\text{ converge }\vdone
\end{equation}
We now prove 
\blue{
\begin{equation}
\liminf_{n\to\infty} \abso{\frac{a_{n+1}}{a_n}}>1\implies \sum a_n\text{ diverge }
\end{equation}}
Let 
\begin{equation}
\liminf_{n\to\infty} \abso{\frac{a_{n+1}}{a_n}}=\beta >1
\end{equation}
Then we know there exists $N$ that satisfy
 \begin{equation}
\forall n\geq N, \abso{\frac{a_{n+1}}{a_n}}\geq \beta >1
\end{equation}
This give us
\begin{equation}
\forall k, \abso{a_{N+k}}\geq \beta^k \abso{a_N}
\end{equation}
Then as 
\begin{equation}
\beta >1\implies \lim_{k\to\infty}\beta ^k\abso{a_N}=\infty
\end{equation}
We can see it is impossible $\lim_{n\to\infty}a_n=0$, let alone $\sum a_n$ converge. $\bdone$
\begin{theorem}
\label{2.5.3}
\textbf{(Root Test is Stronger than Ratio Test)} For positive sequence $\set{a_n}$, we have
\begin{equation}
\liminf_{n\to\infty}\frac{a_{n+1}}{a_n}\leq \liminf_{n\to\infty} \sqrt[n]{a_n} \leq \limsup_{n\to\infty} \sqrt[n]{a_n} \leq \limsup_{n\to\infty} \frac{a_{n+1}}{a_n}
\end{equation}
\end{theorem}
\begin{proof}
Clearly, 
\begin{equation}
\liminf_{n\to\infty} \sqrt[n]{a_n}\leq \limsup_{n\to\infty} \sqrt[n]{a_n}  
\end{equation}
We first prove
\begin{equation}
  \vi{\liminf_{n\to\infty} \frac{a_{n+1}}{a_n}\leq \liminf_{n\to\infty} \sqrt[n]{a_n}}
\end{equation}
Let 
\begin{equation}
\alpha =\liminf_{n\to\infty} \frac{a_{n+1}}{a_n}
\end{equation}
If $\alpha =-\infty$, the theorem hold true trivially. We only have to consider when $\alpha >-\infty$. Arbitrarily pick positive $\beta $ smaller than $\alpha $:
\begin{equation}
\beta <\alpha=\liminf_{n\to\infty} \frac{a_{n+1}}{a_n}
\end{equation}
Then we know there exists $N$ such that
 \begin{equation}
\forall n\geq N, \frac{a_{n+1}}{a_n}>\beta 
\end{equation}
This implies 
\begin{equation}
\forall k, a_{N+k}>\beta^k a_N
\end{equation}
Then for all $n>N$, we have
 \begin{equation}
   \sqrt[n]{a_n}>\sqrt[n]{ \beta^{n-N}a_{N}}=\beta \sqrt[n]{\beta^{-N}a_N} 
\end{equation}
Because 
\begin{equation}
\lim_{n\to\infty}\beta \sqrt[n]{\beta^{-N}a_N}=\beta 
\end{equation}
We see
\begin{equation}
\liminf_{n\to\infty} \sqrt[n]{a_n} \geq \beta 
\end{equation}
Then because $\beta<\alpha $ can be arbitrarily close to $\alpha $, we see
\begin{equation}
\liminf_{n\to\infty} \sqrt[n]{a_n}  \geq \alpha \vdone
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
We now introduce Dirichlet's Test
\end{minipage}}
\begin{lemma}
\label{2.5.4}
\textbf{(Abel's Formula)} Let
\begin{equation}
A_n=\sum_{k=0}^n a_k\text{ and }q\geq p \geq 0
\end{equation}
We have
\begin{equation}
\sum_{n=p}^q a_nb_n=\sum_{n=p}^{q-1}A_n(b_n-b_{n+1})+A_qb_q-A_{p-1}b_p
\end{equation}
\end{lemma}
\begin{proof}
\begin{align}
  \sum_{n=p}^q a_nb_n&=\sum_{n=p}^q (A_{n}-A_{n-1})b_n\\
  &=\sum_{n=p}^q A_nb_n-\sum_{n=p-1}^{q-1}A_nb_{n+1}\\
  &=\sum_{n=p}^{q-1}A_n(b_n-b_{n+1})+A_qb_q-A_{p-1}b_p
\end{align}
\end{proof}
\begin{theorem}
\label{2.5.5}
\textbf{(Dirichlet's Test)} 
Let $A_n=\sum_{k=0}^n a_k$. Given
\begin{gather}
b_1\geq b_2\geq b_3\cdots\\
\forall n, b_n\geq 0\\
\set{A_n}\text{ is bounded  }
\end{gather}
We have
\begin{gather}
\sum_{n=0}^\infty a_nb_n\text{ converge }
\end{gather}
\end{theorem}
\begin{proof}
Given $\epsilon $, there exists $N$ such that for all $n>N$, we have  $b_n<\frac{\epsilon }{2M}$. Let 
\begin{equation}
q\geq p\geq N
\end{equation}
We have
\begin{align}
\abso{\sum_{n=p}^q a_nb_n}&=\abso{\sum_{n=p}^{q-1}A_n(b_n-b_{n+1})+A_qb_q-A_{p-1}b_p}\\
&\leq \sum_{n=p}^{q-1}\abso{A_n(b_n-b_{n+1})}+\abso{A_qb_q}+\abso{A_{p-1}b_p}\\
&=\sum_{n=p}^{q-1} \abso{A_n}\abso{b_n-b_{n+1}}+\abso{A_qb_q}+\abso{A_{p-1}b_p}\\
&=\sum_{n=p}^{q-1}\abso{A_n}(b_n-b_{n+1})+\abso{A_q}\abso{b_q}+\abso{A_{p-1}}\abso{b_p}\\
&\leq M(\sum_{n=p}^{q-1}(b_n-b_{n+1})+b_q+b_p)\\
&=M(b_p-b_q+b_q+b_p)=2Mb_p<2M \frac{\epsilon }{2M}=\epsilon 
\end{align}
\end{proof}
\begin{theorem}
\label{2.5.6}
\textbf{(Abel's Test)}
Given 
\begin{gather}
\sum_{n=1}^\infty a_n\text{ converges }\\
\set{b_n}\text{ is monotone and bounded }
\end{gather}
We have
\begin{equation}
\sum_{k=1}^\infty a_kb_k\text{ converges }
\end{equation}
\end{theorem}
\begin{proof}
Define $b'_n:=b_n-b$. We have
 \begin{align}
\sum_{k=1}^\infty &=\sum_{k=1}^\infty a_k(b+b'_k)\\
&=b\sum_{k=1}^\infty a_k+\sum_{k=1}^\infty a_kb'_k
\end{align}
Where by  \myref{Theorem}{2.5.5} (Dirichlet's test), the series converge.
\end{proof}

\chapter{Advanced Calculus HW}
\section{HW1}
\begin{question}{}{}
\begin{enumerate}
    \item Prove that the following statements are equivalent: for a given sequence $\{x_n\}$,
    \begin{enumerate}
        \item for every $0 < \epsilon \in \mathbb{Q}$, there exists $N \in \mathbb{N}$ such that $|x_n - x| < \epsilon$ whenever $n \geq N$.
        \item for every $0 < \epsilon \in \mathbb{R}$, there exists $N \in \mathbb{N}$ such that $|x_n - x| < \epsilon$ whenever $n \geq N$.
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}
From $(b)$ to $(a)$, just observe  $\Q \subseteq \R$ and we are done.Now we prove from $(a)$ to $(b)$.\\

Because $\Q$ is dense in  $\R$,  for all $\epsilon \in \R^+$, we can pick $\epsilon' \in \Q$ such that $0<\epsilon '< \epsilon $. By $(a)$,  we know there exists $N\in \N$ such that $\abso{x_n-x}<\epsilon ' <\epsilon $ whenever $n\geq N$. This finish the proof.
\end{proof}
\begin{question}{}{}
2. Let $\{x_n\}_{n=1}^{\infty}$ be a monotone increasing sequence such that 
\[x_{n+1} - x_n \leq \frac{1}{n}.\]
Determine whether the sequence converges. (If yes, prove it; if not, disprove it or give a counterexample.)
\end{question}
\begin{proof}
No, consider $p$-series. The sequence $\set{x_n}_{n=1}^{\infty}$ defined by $x_i:=\sum_{j=1}^i \frac{1}{j}$ is monotone increasing, satisfying the desired property, and from our knowledge, diverge. 
\end{proof}
\begin{question}{}{}
Let $M_{n \times m}$ be the collection of all $n \times m$ matrices with real entries. Define a function $\| \cdot \|: M_{n \times m} \to \mathbb{R}$ by
\[
\| A \| = \sup \left\{ \frac{\|Ax\|_2}{\|x\|_2} : x \in \mathbb{R}^m, x \neq 0 \right\},
\]
where we recall that $\| \cdot \|_2$ is the 2-norm on Euclidean space given by
\[
\| Ax \|_2 = \left( \sum_{i=1}^{k} x_i^2 \right)^{1/2} \quad \text{if } x \in \mathbb{R}^k.
\]
Show that:
\begin{enumerate}
    \item $\| A \| = \sup \left\{ \|Ax\|_2 : x \in \mathbb{R}^m, \norm{x}_2 =1 \right\} = \inf \left\{ M \in \mathbb{R} : \|Ax\|_2 \leq M \|x\|_2 \, \forall x \in \mathbb{R}^m \right\}$.
    \item $\| Ax \|_2 \leq \| A \| \| x \|_2$ for all $x \in \mathbb{R}^m$.
    \item $\| \cdot \|$ defines a norm on $M_{n \times m}$.
\end{enumerate}
\end{question}
\begin{proof}
In this proof, we use $\abso{\cdot}$ to denote $\norm{\cdot}_2$, and if we write $x$ without specification, it belong to  $\R^m$\\

We first show \vi{$\norm{A}= \sup \set{ \abso{Ax}: \abso{x}=1}$}\\

\As{$\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}=\norm{A}>  \sup \set{\abso{Ax} : \abso{x}=1} $}.Then we know $ \sup \set{\abso{Ax}:\abso{x}=1} $ is not an upper bound of $ \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0} $, so we know there exists $x\in \R^m$ such that $\frac{\abso{Ax}}{\abso{x}}>\sup \set{\abso{Ay}:\abso{y}=1}$.\\

Define $\hat{x}:=\frac{x}{\abso{x}}$. We have $\frac{\abso{Ax}}{\abso{x}}=\abso{\frac{Ax}{\abso{x}}}=\abso{A \hat{x}}\leq \sup \set{\abso{Ay}:\abso{y}=1}
$, since $\abso{\hat{x}}=\abso{\frac{x}{\abso{x}}}=\frac{\abso{x}}{\abso{x}}=1\implies \abso{A \hat{x}}\in \set{\abso{Ay}:\abso{y}=1}$. This \CaC.\\

\As{$\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}=\norm{A}<\sup \set{\abso{Ax} : \abso{x}=1} $}. Then we know $\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}$ is not an upper bound of $\sup \set{\abso{Ax}:\abso{x}=1}$, so we know there exists $\hat{x} \in \R^m:\abso{\hat{x}}=1$ such that $\abso{A \hat{x}}>\sup \set{\frac{\abso{Ay}}{\abso{y}}:y\neq 0}$.\\

We see $\abso{A \hat{x}}>\sup \set{\frac{\abso{Ay}}{\abso{y}}:y\neq 0}\geq \frac{\abso{A \hat{x}}}{\abso{\hat{x}}}=\frac{\abso{A \hat{x}}}{1}=\abso{A \hat{x}}\tCaC \vdone$\\

Observe $  \inf \left\{ M \in \mathbb{R} : \|Ax\|_2 \leq M \|x\|_2 \, \forall x \in \mathbb{R}^m \right\}= \inf \set{c \in \R: \forall x\neq 0, c\geq \frac{\abso{Ax}}{\abso{x}}}$, since $\forall M, \abso{A\vecta{0}}\leq M\abso{\vecta{0}}$.\\

Observe that $   \set{c \in \R: \forall x\neq 0, c\geq \frac{\abso{Ax}}{\abso{x}}}$ is the set of upper bound of $\set{\frac{\abso{Ax}}{\abso{x}}:\abso{x}\neq 0}$, so $\inf   \set{c \in \R: \forall x, c\geq \frac{\abso{Ax}}{\abso{x}}}=\norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:\abso{x}\neq 0}$.\\
\end{proof}
\begin{proof}
In this proof, we use $\abso{\cdot}$ to denote $\norm{\cdot}_2$, and if we write $x$ without specification, it belong to  $\R^m$\\

If $x=0$, then we trivially have  $\abso{Ax}=\abso{0}=0\leq \norm{A}\abso{x}=0$, so from now, we only have to consider $x\neq 0$.\\

If $x\neq 0$, we have $\abso{Ax}\leq \norm{A}\abso{x}\iff \frac{\abso{Ax}}{\abso{x}}\leq \norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}$, trivially true.
\end{proof}
\begin{proof}
In this proof, we use $\abso{\cdot}$ to denote $\norm{\cdot}_2$, and if we write $x$ without specification, it belong to  $\R^m$\\

For non-negativity, observe $\forall x\neq 0,\frac{\abso{Ax}}{\abso{x}}\geq 0 \implies \norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:x \in \R^m, x\neq 0}\geq 0$.\\

For definite-positive, observe $A=0\implies \forall x\neq 0, \frac{\abso{Ax}}{\abso{x}}=\frac{\abso{0}}{\abso{x}}=0\implies \norm{A}=0$. Also, if $A\neq 0$, we can pick a column, say $p$-th column, that contain non-zero entry. We see the vector $e\in \R^m$ where the only non-zero entry is the  $p$-th entry being $1$ satisfy $\abso{Ae}>0$, thus $\frac{\abso{Ae}}{\abso{e}}>0$. Because $e\neq 0$, we see $\norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\in\R^m,x\neq 0}\geq \frac{\abso{Ae}}{\abso{e}}>0$.\\

For absolute-homogenity, let $c \in \R\text{ and }A\in M_{n\times m}$. We wish to prove \vi{$\norm{cA}=\sup \set{\frac{\abso{cAx}}{\abso{x}}:x\neq 0}=\abso{c}\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}=\abso{c}\norm{A}$}. Notice that $\frac{\abso{cAx}}{\abso{x}}=\frac{\abso{c}\abso{Ax}}{\abso{x}}$, so we only have to prove the more general statement : $c>0 \implies c \sup X= \sup \set{cx:x\in X}$. Notice that $\forall x \in X, c \sup X\geq cx$, so we have $c\sup X\geq \sup \set{cx:x\in X}$. If $c\sup X$ is not the smallest upper bound, we see there exists $cx$ such that $c\sup X<cx$, and we see $\sup X<x$, causing a contradiction, so we do have $c\sup X=\sup \set{cx:x\in X}\vdone$   \\

For triangle-inequality, first observe $\frac{\abso{(A+B)x}}{\abso{x}}=\frac{\abso{Ax+Bx}}{\abso{x}}\leq \frac{\abso{Ax}+\abso{Bx}}{\abso{x}}=\frac{\abso{Ax}}{\abso{x}}+\frac{\abso{Bx}}{\abso{x}}$. \As{$\norm{A+B}>\norm{A}+\norm{B}$}.\\

Because $\norm{A}+\norm{B}$ is not an upper bound of $\set{\frac{\abso{(A+B)x}}{\abso{x}}:x\neq 0}$, we know there exists $x'$ such that  $\frac{\abso{(A+B)x'}}{\abso{x'}}>\norm{A}+\norm{B}$. Further, by definition of $\norm{A},\norm{B}$, we have
\begin{equation}
\frac{\abso{(A+B)x'}}{\abso{x'}}>\frac{\abso{Ax'}}{\abso{x'}}+\frac{\abso{Bx'}}{\abso{x'}}\tCaC
\end{equation}
\end{proof}

\begin{question}{}{}
Suppose that \(S_1, S_2, \ldots, S_n\) are sets in \(\mathbb{R}\) and 
\[ S = \bigcup_{i=1}^{n} S_i. \]
Define \(B_i = \sup S_i\) for \(i = 1, \ldots, n\).

\begin{enumerate}
    \item Show that \(\sup S = \max\{B_1, B_2, \ldots, B_n\} \).
    \item If \(S\) is the union of an infinite collection of \(S_i\), find the relation between \(\sup S\) and \(B_i\).
\end{enumerate}
\end{question}
\begin{proof}
Let $\sup S_j=B_j=\max \set{B_1,\dots, B_n}$. We first show \vi{$\sup S_j$ is an upper bound of $S$}.\\

By definition, we have $\forall x\in S_j,x\leq \sup S_j$ and have $\forall i \neq j, \forall x \in S_i, x\leq \sup S_i\leq \sup S_j $, so we have $\forall x\in S, \exists k \in \set{1,\dots, n}, x \in S_k \implies x\leq \sup S_k\leq \sup S_j\vdone$\\

We now show  \blue{$\sup S_j$ is the least upper bound of $S$}.\\

\As{there exists an upper bound of $S$ smaller than $\sup S_j$}. Denote that upper bound $y$. Because $y$ is smaller than $\sup S_j$, we know $y$ is not an upper bound of $S_j$, so we know there is a number  $z \in S_j$ greater than $y$. Observe that the fact $y$ is an upper bound of $S$ implies  $y$ is greater than or equal to $z \in S_j\subseteq S\tCaC\bdone$
\end{proof}
\begin{proof}
  We prove \vi{$\sup S=\sup \set{B_i}$}.\\

  Notice $\sup S$ is an upper bound of $S_i$, so we have $\forall i, \sup S>\sup S_i=B_i$. This means $\sup S$ is an upper bound of $\set{B_i}$. We have proved $\sup S\geq \sup \set{B_i}$. \As{$\sup S>\sup \set{B_i}$}. Then because $\sup \set{B_i}$ is not an upper bound of $S$, we know there exists  $s \in S$ such that $s>\sup \set{B_i}$. But because $S=\bigcup \set{S_i}$, we know $\exists S_j,s \in S_j$, which give us $s\leq \sup S_j=B_j\leq \sup \set{B_i}\tCaC\vdone$
\end{proof}
\begin{question}{}{}
Let \( A \) be a non-empty set of \( \mathbb{R} \) which is bounded below. Define the set \( -A \) by 
\[ -A \equiv \{-x \in \mathbb{R} : x \in A\}. \]
Prove that
\[ \inf(A) = -\sup(-A). \]
\end{question}
\begin{proof}
Observe $\forall x\in -A, \sup (-A)\geq  x\implies \forall a \in A, -\sup (-A)\leq  a$. So $-\sup (-A)$ is an lower bound of $A$. \As{$-\sup (-A)$ is not the greatest lower bound of $A$} (greatest lower bound exists because bounded below and completeness). Let $b>-\sup (-A)$ be another lower bound of $A$. We have $-b<\sup (-A)$, so we know $-b$ is not an upper bound of $-A$, then we know  $\exists x \in -A, -b<x$. Then we know $\exists a \in A, -b<-a$, which implies $\exists a \in A, b>a$, but $b$ is an lower bound of $A\tCaC$
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \item Let \( A, B \) be non-empty subsets of \( \mathbb{R} \). Define \( A+B \) as 
    \[ A+B = \{ x+y : x \in A, y \in B \}. \]
    Justify if the following statements are true or false by providing a proof for the true statements and giving a counter-example for the false ones.
    \begin{enumerate}
        \item \( \sup(A+B) = \sup A + \sup B \).
        \item \( \inf(A+B) = \inf A + \inf B \).
        \item \( \sup(A \cap B) \leq \min\{\sup A, \sup B\} \).
        \item \( \sup(A \cap B) = \min\{\sup A, \sup B\} \).
        \item \( \sup(A \cup B) \geq \max\{\sup A, \sup B\} \).
        \item \( \sup(A \cup B) = \max\{\sup A, \sup B\} \).
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}
We prove $\sup (A+B)=\sup A+\sup B$. For all $a+b \in A+B$, we by definition have $a\leq \sup A, b\leq \sup B$, so we have $a+b\leq \sup A+\sup B$. This prove $\sup A+\sup B$ is an upper bound of $A+B$. \As{there exists an upper bound $x$ of $A+B$ smaller than $\sup A+\sup B$}. We have $x-\sup B<\sup A$, so we know $x-\sup B$ is not an upper bound of $A$. Then we know  $\exists a'\in A, x-\sup B<a'$. This implies $x-a'< \sup B$, so we know $x-a'$ is not an upper bound of  $B$. Then we know there exists  $b' \in B$ such that $x-a'< b'$. This implies $x<a'+b' \in A+B\tCaC$ to $x$ is an upper bound of  $A+B$
\end{proof}
\begin{proof}
We prove $\inf (A+B)= \inf A +\inf B$. For all $a+b \in A+B$, we by definition have $\inf A\leq a,\inf B\leq b$, so we have $\inf A+\inf B\leq a+b$. This prove $\inf A+ \inf B$ is an lower bound of $A+B$.  \As{there exists an lower bound $x$ of $A+B$ greater than $\inf A+\inf B$}. We have $x- \inf A > \inf B$, so we know $x - \inf A$ is not an lower bound of $B$. Then we know  $\exists b' \in B, x- \inf A > b'$. This implies $x-b'>\inf A$, so we know $x- b'$ is not an lower bound of $A$. Then we know  $\exists a' \in A, x-b'>a'$. So we know $x<a'+b' \in A+B\tCaC$ to $x$ is an lower bound of $A+B$ 
\end{proof}
\begin{proof}
We prove $\sup (A\cap B)\leq \min \set{\sup A,\sup  B}$.\\

WOLG, let $\sup A\leq \sup B$. By definition $x \in A\cap B \implies  x \in A \implies x\leq \sup A$, so we know $\sup A$ is an upper bound of $A\cap B$. This implies $\sup A\cap B\leq \sup (A\cap B)$ 
\end{proof}
\begin{proof}
We show $\sup (A\cap B)= \min \set{\sup A,\sup B}$ is not always correct. Let $A=[0,2]$ and $B=[0,1]\cup [3,4]$. We have $\sup (A\cap B= [0,1])=1\neq \min{\set{\sup A=2,\sup B=4}}$
\end{proof}
\begin{proof}
$\sup A\cup B$ is an upper bound of both $A$ and  $B$, so  $\sup A\cup B>\sup A\text{ and }\sup A\cup B>\sup B$

\end{proof}
\begin{proof}
We prove $\sup (A\cup B)=\max \set{\sup A,\sup B}$. WOLG, let $\sup A\geq \sup B$. \As{$\sup B\leq \sup A<\sup (A\cup B)$}. Let $x$ be a number between  $\sup A\text{ and }\sup A\cup B(x\text{ exists since it can be $\frac{\sup A+\sup (A\cup B)}{2}$ })$. Because $x<\sup (A\cup B)$, we know $x$ is not an upper bound of  $A\cup B$. By definition, we know there exists $z\in A\cup B$ such that $x<z$. We know either $z \in A$ or $z \in B$, but we see $z \in A\implies z\leq \sup A<x$ and we see $z \in B\implies z\leq \sup B\leq \sup A<x\tCaC$
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{6}
    \item Let \( S \subseteq \mathbb{R} \) be bounded below and non-empty. Show that
    \[ \inf S = \sup\{ x \in \mathbb{R} : x \text{ is a lower bound for } S \}. \]
\end{enumerate}
\end{question}
\begin{proof}
Denote $B=\set{x\in R: x\text{ is a lower bound for $S$ }}$. \As{$\inf S> \sup B$}. Let $\inf S>x>\sup B$. Notice $\inf S>x$ implies there is a lower bound  $b$ of  $S$ greater than  $x$. Observe $b>x\text{ and }b \in B\implies x$ is not an upper bound of $B\tCaC x>\sup B$.\\

\As{$\inf S<\sup B$}. Let $\inf S<x<\sup B$. Notice $\inf S<x$ implies there exists $s' \in S$ such that $s'<x$, and notice $x> \sup B$ implies there exists $b'\in B$ such that $b'>x$. We see  $b'>x>s'$ while  $b'$ is an lower bound of  $S\tCaC$
\end{proof}
\begin{question}{}{}
8. Let \( f \) be a continuous function on \( \mathbb{R} \) and \( D \) is a dense subset in \( \mathbb{R} \). Prove that:
\begin{enumerate}
    \item \( \sup_{x \in D} f(x) = \sup_{x \in \mathbb{R}} f(x) \).
    \item There exists a sequence \( \{x_n\}_{n=1}^{\infty} \) in \( D \) such that 
    \[
    \lim_{n \to \infty} f(x_n) = \sup_{x \in \mathbb{R}} f(x).
    \]
\end{enumerate}
\end{question}
\begin{proof}
Because $D\subseteq \R$, we must have $\sup \set{f(x): x\in D}\leq \sup \set{f(x): x\in \R}$, since any upper bound of the latter will be one of the former.\\

\As{$\sup \set{f(x):x \in D}<\sup \set{f(x):x\in \R}$}. Because $\sup \set{f(x):x\in D}$ is not an upper bound of $\set{f(x):x\in \R}$, we know there exists $x'\in \R$ such that 
\begin{equation}
f(x')>\sup \set{f(x):x\in D}
\end{equation}
We first \vi{construct a sequence $\set{x_i}_{i=1}^\infty$ in $D$ such that} 
\begin{equation}
  \vi{\lim_{i\to \infty}x_i=x'\text{ which reads } \forall \epsilon, \exists N, n>N \longrightarrow \abso{x_n - x'}<\epsilon}
\end{equation}
By Axiom of Choice and the fact that $D$ is dense in  $\R$, we can pick $x_i \in (x'- \frac{1}{i},x' +\frac{1}{i})$, so we have
\begin{equation}
\forall i, \abso{x_i-x'}<\frac{1}{i}
\end{equation}
For all $\epsilon $, we can pick a natural $N>\epsilon $, so we have 
\begin{equation}
n>N\implies \abso{x_n-x'}<\frac{1}{n}<\frac{1}{N}<\frac{1}{\epsilon }\vdone
\end{equation}
We now prove 
\begin{equation}
\blue{\lim_{i\to\infty}f(x_i)=f(x')\text{ which reads }\forall \epsilon , \exists N, n>N\longrightarrow  \abso{f(x_n)-f(x')}<\epsilon }
\end{equation}
Because $f$ is continuous, we have 
\begin{equation}
  \forall \epsilon ,\exists \delta, \forall u\in \R, \abso{u-x'}<\delta\implies \abso{f(u)-f(x')}<\epsilon  
\end{equation}
Then for all $\epsilon $, we can first let $\delta$ satisfy $\abso{u-x}<\delta \implies \abso{f(u)-f(x')}<\epsilon $. Then by the \vi{violet fact} we can pick $N$ such that 
\begin{equation}
n>N\implies \abso{x_n - x'}< \delta \implies \abso{f(x_n)-f(x')}<\epsilon \bdone 
\end{equation}
Let $H=\sup \set{f(x): x\in D}$. Now we prove  
\begin{equation}
  \vi{\lim_{i \to \infty}f(x_i)\leq H}
\end{equation}
\As{$f(x')=\lim_{i \to \infty} f(x_i) >H $}. We know there exists $N$ such that 
\begin{equation}
n>N\longrightarrow \abso{f(x_n)-f(x')}<\abso{H - f(x') }=f(x')-H
\end{equation}
The last equality hold true due to the premise equation (5.2). Notice 
\begin{equation}
\abso{f(x_n)-f(x')}<f(x')-H\implies H-f(x')< f(x_n)-f(x')\implies f(x_n)>H
\end{equation}
so in fact we know there exists $N$ such that 
\begin{equation}
n>N \longrightarrow f(x_n)>H= \sup \set{f(x): x \in D}\tCaC\vdone
\end{equation}
Now, using all our proven facts, we have
\begin{equation}
\sup \set{f(x): x\in D}<f(x')=\lim_{i\to \infty }f(x_i)\leq H=\sup \set{f(x): x \in D}\tCaC
\end{equation}
where the first inequality follows from premise equation (5.2) 
\end{proof}
\begin{proof}
Let $H=\sup \set{f(x): x \in D}$. We first prove
\begin{equation}
\vi{\forall i \in \N, \set{f(x): x \in D\text{ and }H-f(x)<\frac{1}{i}}\neq \varnothing}
\end{equation}
\As{there exists some $n\inn$ such that the set is empty}. We then have
\begin{equation}
\forall x\in D, H\geq f(x)+\frac{1}{n}
\end{equation}
So we have
\begin{equation}
\forall x\in D, H-\frac{1}{2n}\geq f(x)+\frac{1}{2n}>f(x)
\end{equation}
Then we see $H-\frac{1}{2n}$ is an upper bound of $\set{f(x): x \in D}$ smaller than $H\tCaC\vdone$\\

By Axiom of Choice, we can construct a sequence $\set{x_i}_{i=1}^\infty$ by picking $x_i: f(x_i)\in \set{f(x):x \in D\text{ and }H-f(x)<\frac{1}{i}}$. Then we have
\begin{equation}
\forall \epsilon, n> [\frac{1}{\epsilon }]+1\implies n>\frac{1}{\epsilon }\implies \abso{f(x_n)-H}<\frac{1}{n}<\epsilon 
\end{equation}
This written in limit sign is 
\begin{equation}
\lim_{i\to \infty}f(x_i)=H=\sup \set{f(x): x\in D}=\sup \set{f(x):x \inr}
\end{equation}
\end{proof}
\section{HW2}
\begin{question}{}{}

Let \(A \subseteq \mathbb{R}^n\) be an open set and \(B \subset \mathbb{R}^n\) be any set. Then the set 
\[ A + B \equiv \{a + b : a \in A \text{ and } b \in B\} \]
is open.
\end{question}
\begin{proof}
Notice 
\begin{equation}
A+B= \bigcup \set{\set{a+b:a\in A}:b\in B}
\end{equation}
We only have to prove  \vi{for all $b\in B$, the set $A+b:=\set{a+b:a\in A}$ is open}.\\

Fix $b$. Arbitrarily pick $a+b\in A+b$. Because $A$ is open, we know there exists $r\inr^+$ such that
\begin{equation}
B_r(a)\subseteq A
\end{equation}
Let
\begin{equation}
B_r(a)+b:=\set{x+b:x\in B_r(a)}
\end{equation}
We now prove 
\begin{equation}
\teal{B_r(a)+b=B_r(a+b)}
\end{equation}
Arbitrarily pick $x+b\in B_r(a)+b$. We have
\begin{equation}
\abso{(x+b)-(a+b)}=\abso{x-a}<r
\end{equation}
We have proved $B_r(a)+b\subseteq B_r(a+b)$. Arbitrarily pick $y\in B_r(a+b)$. Let $z=y-b$. We have
\begin{equation}
y=z+b\text{ and }\abso{z-a}=\abso{y-(a+b)}<r
\end{equation}
The latter tell us $z \in B_r(a)$, so we have
\begin{equation}
y=z+b \in B_r(a)+b
\end{equation}
Because $y$ is arbitrarily picked from $B_r(a+b)$, we have proved $B_r(a+b)\subseteq B_r(a)+b\tdone$\\

Notice that  $r$ is selected to satisfy
\begin{equation}
B_r(a)\subseteq A
\end{equation}
and it is clear that
\begin{equation}
B_r(a)+b\subseteq A+b
\end{equation}
So we have
\begin{equation}
B_r(a+b)=B_r(a)+b\subseteq A+b
\end{equation}
Notice $a+b$ is arbitrarily picked from $A+b$. Our proof is done  $\vdone$
\end{proof}

\begin{question}{}{}
Show that every open set in \( \mathbb{R} \) is the union of at most countable collection of disjoint open intervals.
\end{question}
\begin{proof}
Because $\Q$ is countable and dense in  $\R$, so in \myref{Theorem}{1.10.1}, we have proved the set
\begin{equation}
\mathcal{O}:=\set{B_r(p):p\inq\text{ and }r\inq^+}
\end{equation}
is a countable base. Notice that every open ball $B_r(p)$ can be expressed as $(p-r,p+r)$, so we know $\mathcal{O}$ is a countable collection of open interval.\\

Let $A$ be an open set. We wish to prove \vi{$A$ can be expressed as union of a countable collection of disjoint open interval}.\\


Because $\mathcal{O}$ is a base, for each $a\in A$, we can find $B_{r_a}(p_a)$, such that
\begin{equation}
a\in B_{r_a}(p_a)\subseteq A
\end{equation}
Collect all such open ball for each points in $A$ and call this collection  $\mathcal{O}'$.\\

Define a relation $\sim$ on $\mathcal{O}'$ by 
\begin{gather}
  (a,b)\sim (c,d) \text{ if }\exists S\in \power{\mathcal{O}'}\text{ such that }\\
  \bigcup S\text{ is an open interval and }(a,b)\subseteq\bigcup S\text{ and }(c,d)\subseteq \bigcup S
\end{gather}
We wish to prove \teal{$\sim$ is an equivalence relation}.\\

To show $(a_1,b_1)\sim (a_1,b_1)$, use $S=\set{(a_1,b_1)}$. To show $(a_1,b_1)\sim (a_2,b_2)\implies (a_2,b_2)\sim (a_1,b_1)$, use the same $S$. It is left to prove
\begin{equation}
  (a_1,b_1)\sim (a_2,b_2)\text{ and }(a_2,b_2)\sim (a_3,b_3)\implies (a_1,b_1)\sim (a_3,b_3)
\end{equation}

Let $S_1\in \power{\mathcal{O}'}$ be from $(a_1,b_1)\sim (a_2,b_2)$, and let $S_2\in \power{\mathcal{O}'}$ be from $(a_2,b_2)\sim (a_3,b_3)$.\\

Define 
\begin{equation}
S_3:=S_1\cup S_2 
\end{equation}
Because $(a_2,b_2)\subseteq \bigcup S_1\cap \bigcup S_2$, we know $\bigcup S_1\cap \bigcup S_2$ are not disjoint. Then because union of two intersecting open interval is again an open interval, we know $\bigcup S_3$ is an open interval.\\

Deduce
\begin{equation}
  (a_1,b_1)\subseteq \bigcup S_1\subseteq \bigcup S_3
\end{equation}
and deduce
\begin{equation}
  (a_3,b_3)\subseteq \bigcup S_2\subseteq \bigcup S_3\tdone
\end{equation}
Let $E$ be the collection of union of each equivalent class of $\sim$ on $\mathcal{O}'$. Because $\mathcal{O}'$ is countable, we know $E$ is countable. Every element of $\mathcal{O}'$ is a subset of $A$ by definition, so we know  $\bigcup E=\bigcup \mathcal{O}'\subseteq A$. Every element of $A$ is in some  $O\in \mathcal{O}'$ by definition, so we have $A\subseteq \bigcup \mathcal{O}'=\bigcup E$. It is only left to prove \olive{each member in  $E$ is an open interval} and \brown{each two members of $E$ are disjoint}.\\

We first prove \brown{disjoint}.\\

Let $B,C\in E$ and let $B',C'$ be equivalent class that satisfy
\begin{equation}
B=\bigcup B'\text{ and }C=\bigcup C'
\end{equation}
\As{$B,C$ is not disjoint, say, $x\in B\cap C$}, we have
\begin{equation}
\exists (a,b)\in B', x\in (a,b)\subseteq B
\end{equation}
and have
\begin{equation}
\exists (c,d)\in C',x \in (c,d)\subseteq C
\end{equation}
We then can see $(a,b)$ and $(c,d)$ intersect, then we can use $S=\set{(a,b),(c,d)}$ to show $(a,b)\sim (c,d)\tCaC\bodone$.\\

We now prove  \olive{open interval}.\\
 
Let $B\in E$, and let $B'$ be equivalent class that satisfy  $B=\bigcup B'$. We wish to prove $B=(\inf B,\sup B)$ where negative and positive infinity is taken into account.\\

Because $B'$ contain only open sets, we know  $B$ is open. Then we know $\sup  B$ and $\inf B$ if exists, is not in $B$. To see such, just observe every open ball centering $\sup B$ has a number greater than all numbers in $B$, and similarly for $\inf B$ vice versa.\\

We have proved $B\subseteq (\inf B,\sup B)$.\\

We only have to prove every point in $(\inf B,\sup  B)$ is in $B$, where infimum and supremum can be negative or positive infinity.\\

\As{$\exists x\in (\inf B,\sup B), x\not\in B$}. We have
\begin{equation}
\exists (y_1,z_1)\in B', (y_1,z_1)\subseteq (\inf B,x)\text{ and }\exists (y_2,z_2)\in B', (y_2,z_2)\subseteq (x,\sup B)
\end{equation}
Because $(y_1,z_1)\sim (y_2,z_2)$ there exists $S\in \mathcal{O}'$ such that $(y_1,z_2)\subseteq \bigcup S\text{ and }\bigcup S$ is an open interval.\\

If $S$ contain any element  $(v,w)$ not in $B'$, we can use  $S$ to show  $(v,w)\sim (y_2,z_2)$, causing a contradiction. We have proved $S$ is a subset of  $B'$.\\

Now, Because $x\in \bigcup S$, we know there must exists some interval in $S\subseteq B'$ containing  $x$  \CaC to $x\not\in B\odone\vdone$
\end{proof}
\begin{question}{}{}
Let \( A \subseteq B \subseteq \mathbb{R} \). Suppose that \( A \) is a dense subset of \( B \).

1. Prove that \( B \subseteq \overline{A} \).

2. If \( B \) is closed, determine whether \( B = \overline{A} \).
\end{question}
\begin{proof}
$A$ is a dense subset of $B$ means that every point $b\in B\setminus A$ is a limit point of $A$ in the scope of $B$. Notice that $b$ is a limit point of  $A$ in the scope of $B$ also means $b$ is a limit point in the scope of $\R$. Then we have proved $B\setminus A\subseteq A'$. It follows
\begin{equation}
B=A \cup (B\setminus A)\subseteq A\cup A'=\overline{A}
\end{equation}
If $B$ is closed, we have
 \begin{equation}
\overline{A}\subseteq \overline{B}=B
\end{equation}
Then because $B\subseteq \overline{A}$, we have $B=\overline{A}$



\end{proof}
\textbf{Definition 0.1.} A metric space \( X \) is \textit{sequentially compact} if every sequence of points in \( X \) has a convergent sub-sequence converging to a point in \( X \).
\begin{question}{}{}

Let \( A \) and \( B \) be subsets of a metric space \( (M, d) \) and denote \( \text{cl}(A) = \overline{A} \). Show that

1. \( \text{cl}(\text{cl}(A)) = \text{cl}(A) \).

2. \( \text{cl}(A \cup B) = \text{cl}(A) \cup \text{cl}(B) \).

3. \( \text{cl}(A \cap B) \subseteq \text{cl}(A) \cap \text{cl}(B) \). Find an example such that \( \text{cl}(A \cap B) \subsetneq \text{cl}(A) \cap \text{cl}(B) \).
\end{question}
\begin{proof}
Notice that closure is the smallest closed set containing the set.\\

Because $\overline{A}$ is a closed set, we know the smallest closed set containing $\overline{A}$ is $\overline{A}$ itself.\\

Deduce
\begin{equation}
A\subseteq A\cup B\implies \overline{A}\subseteq \overline{A\cup B}
\end{equation}
and deduce
\begin{equation}
B\subseteq A\cup B\implies \overline{B}\subseteq \overline{A\cup B}
\end{equation}
so deduce
\begin{equation}
\overline{A}\cup \overline{B}\subseteq \overline{A\cup B}
\end{equation}
Notice that $\overline{A}\cup \overline{B}$ is a closed set containing both $A$ and  $B$, thus containing $A\cup B$, so because $\overline{A\cup B}$ by definition is the smallest closed set containing $A\cup B$, we have
\begin{equation}
\overline{A\cup B}\subseteq \overline{A}\cup \overline{B}
\end{equation}
Notice that $\overline{A}$ and $\overline{B}$ are both closed set containing $A\cap B$. Then because $\overline{A\cap B}$ is the smallest closed set containing  $A\cap B$. We have
\begin{equation}
\overline{A\cap B}\subseteq \overline{A}\text{ and }\overline{A\cap B}\subseteq \overline{B}
\end{equation}
Then have
\begin{equation}
\overline{A\cap B}\subseteq \overline{A}\cap \overline{B}
\end{equation}
Let $A=(0,1)$ and $B=(1,2)$. We have
\begin{equation}
\overline{A\cap B}=\overline{\varnothing}=\varnothing\text{ and }\overline{A}\cap \overline{B}=[0,1]\cap [1,2]=\set{1}
\end{equation}
\end{proof}
\begin{question}{}{}

Let \( K \) be a sequentially compact set in a metric space \( (M, d) \) and let \( F \subseteq K \) be closed. Prove that \( F \) is sequentially compact.
\end{question}
\begin{proof}
Let $\set{x_i}_{i=1}^\infty$ be a sequence in $F$
\begin{equation}
  \set{x_i}_{i=1}^\infty \subseteq F\subseteq K
\end{equation}
Because $K$ is sequentially compact, we know there exists a sub-sequence $\set{x_{n_i}}_{i=1}^\infty$ converge to some point $a$
 \begin{equation}
\lim_{i\to\infty}\set{x_{n_i}}=a
\end{equation}
We only have to prove  $a$ is in  $F$.\\

\As{$a\not\in F$}. Because $F$ is closed, we know  $F^c$ is open. Then  $a\in F^c$ tell us there exists an open ball $B_r(a)$ contain no point in $F$, thus disjoint to  $\set{x_{n_i}}\tCaC$

\end{proof}
\textbf{Definition 0.2.} The discrete metric \( d \) on a set \( X \) is defined by
\[
d(x,y) = 
\begin{cases} 
1 & \text{if } x \neq y, \\
0 & \text{if } x = y,
\end{cases}
\]
for any \( x, y \in X \). In this case \( (X,d) \) is called a discrete metric space.
\begin{question}{}{}

Let \( (M, d) \) be a metric space with discrete metric \( d \). Prove that every compact set in \( M \) is finite.
\end{question}
\begin{proof}
Notice we have
\begin{equation}
\forall p\in M, B_1(p)=\set{p}
\end{equation}
So we know no set in $M$ has a limit point. Let $K\subseteq M$ be compact. By \myref{Theorem}{1.7.4}, we know $K$ is limit point compact. \As{$K$ is infinite}. Then $K$ has a limit point  $\tCaC$.
\end{proof}
\begin{question}{}{}

Let \( \{ x_n \}_{n=1}^{\infty} \subseteq \mathbb{R} \) be a convergent sequence with the limit \( x \). Prove that the set \( \{ x_n : n \in \mathbb{N} \} \cup \{ x \} \) is compact.
\end{question}
\begin{proof}
Let 
\begin{equation}
E\subseteq \set{x_n:n\inn}\cup \set{x}
\end{equation}
If $E$ is infinite, we can regard  $E\setminus \set{x}$ as a sub-sequence of $\set{x_n}$. Then because $\set{x_n}_{n=1}^\infty$ converge to $x$, we know  $E\setminus \set{x}$ converge to $x$. Then we know $x$ is a limit point of $E\setminus \set{x}$ thus a limit point of $E$. We have proved every infinite subset of $\set{x_n:n\inn}\cup \set{x}$ has a limit point $x$ in $\set{x_n:n\inn}\cup \set{x}$. By \myref{Theorem}{1.7.4}, $\set{x_n:n\inn}\cup \set{x}$ is compact.
\end{proof}
\begin{question}{}{}

\begin{enumerate}
    \item Let \( A \) and \( B \) be two subsets of a metric space \( (M,d) \). The distance between \( A \) and \( B \) is defined by
    \[
    d(A,B) \equiv \inf\{d(x,y) : x \in A, y \in B\}.
    \]
    \begin{enumerate}
        \item Give an example of two disjoint, nonempty, closed sets \( A \) and \( B \) in \( \mathbb{R}^n \) for which \( d(A, B) = 0 \).
        \item Let \( A, B \) be nonempty sets in \( \mathbb{R}^n \) with \( A \) closed and \( B \) compact. Show that there are points \( a \in A \) and \( b \in B \) such that \( d(a, b) = |a-b| \). Deduce that \( d(A, B) \) is positive if such \( A, B \) are disjoint.
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}
Let $n=1$. Let 
\begin{equation}
A=\set{a_k=k-1+\sum_{i=1}^{k-1}2^{-i-1}:k\inn}
\end{equation}
Let
\begin{equation}
B=\set{b_k=k-\sum_{i=1}^{k-1}2^{-i-1}:u\inn}
\end{equation}
Notice the pattern
\begin{align}
  a_1&=0<\frac{1}{2}< 1=b_1\\
  a_2&=1+\frac{1}{4}< 1+\frac{1}{2}< 2-\frac{1}{4}=b_2\\
  a_3&=2+\frac{1}{4}+\frac{1}{8}< 2+\frac{1}{2}< 3-\frac{1}{4}-\frac{1}{8}=b_3\\
  \vdots
\end{align}
and compute
\begin{equation}
b_k-a_k=2^{1-k}
\end{equation}
First observe for each non-negative integer $m$m the interval  $[m,m+1]$ contain exactly one point from $A$ and contain exactly one point from  $B$. To see  $A$ and  $B$ are disjoint, observe that because  $A,B$ contain only non-negative numbers, so every point is in $[m,m+1]$ for some non-negative integer $m$, and we know each interval only contain $a_{m+1}$ from $A$ and $b_{m+1}$ from $B$ where  $b_{m+1}-a_{m+1}=2^{-m}$.\\

We now show $A,B$ are both closed. For negative  $-x\inr$, observe $B_{x}(-x)$ intersect with neither $A$ nor  $B$. We know $B_1(0)$ does not intersect with $B$ and  $0\in A$. For positive $x$ not in $A$, let $m=\lfloor x \rfloor$. We know point closest to $x$ is either $a_{m},a_{m+1}\text{ or }a_{m+2}$. Then we can let $r=\min \set{\abso{x-a_m},\abso{x-a_{m+1}},\abso{x-a_{m+2}}}$, and see $B_r(x)$ does not intersect with $A$.For positive $x$ not in $B$, let $m=\lfloor x \rfloor$. We know point closest to $x$ is either $b_{m},b_{m+1}\text{ or }b_{m+2}$. Then we can let $r=\min \set{\abso{x-b_m},\abso{x-b_{m+1}},\abso{x-b_{m+2}}}$, and see $B_r(x)$ does not intersect with $B$.\\

Lastly, to prove $d(A,B)=0$ is to prove for each positive real $r$, there exists a pair of $a,b$ such that  $\abso{a-b}<r$. Observe
 \begin{equation}
b_k-a_k=2^{1-k}<r\iff 1-k<\log_2 r\iff k>1-\log_2 r
\end{equation}
And we are done, by picking great enough $k$.\\



Now we do (b).\\

Because 
\begin{equation}
\set{d(a,b):a\in A,b\in B}=\bigcup \set{\set{d(a,b):a\in A}:b \in B}
\end{equation}
so we have 
\begin{align}
d(A,B)&=\inf \set{d(a,b):a\inA,b\inB}\\
&=\inf \bigcup \set{\set{d(a,b):a\in A}:b\in B}\\
&=\inf \set{\inf \set{d(a,b):a\in A}:b\in B}\\
&=\inf \set{d(A,\set{b}):b \in B}
\end{align}
where the third equality hold true by the fourth question of HW1.\\


We first prove \vi{if $d(A,B)=0$, then $A$ and  $B$ intersect.}\\

If $B$ is finite, then  $0=d(A,B)=\min \set{d(A,\set{b}:b\in B)}$, so we know there exists $b\in B$ such that $0=d(A,\set{b})=\inf \set{d(a,b):a\in A}$. Then we can deduce every open ball $B_r(b)$ contain a point $a\in A$, since there exists $a$ such that  $d(a,b)<r$. We have proved $b$ is a limit point of $A$, then because  $A$ is closed, we know  $b\in A$.\\

If $B$ is infinite, then  $0=\inf \set{d(A,\set{b}):b\in B}$. For each $n$, we then know there exists  $b_n$ such that  $d(A,\set{b_n})<\frac{1}{n}$.\\


Construct an infinite sequence $\set{b_n}_{n\inn}$ by picking $b_n$ such that $d(A,\set{b_n})<\frac{1}{n}$. We can see our method for picking $b_n$ will give us an infinite sequence as every $b$  satisfy  $d(A,\set{b})>0$. By \myref{Theorem}{1.7.4}, we know $B$ is limit point compact, so we know $\set{b_n}_{n\inn}$ has a limit point in $B$.\\

Denote the limit point for $\set{b_n}_{n\inn}$ as $p$. We now show $p\in A$. \As{$p\in A^c$}. Because $A$ is closed, we know there exists an open ball  $B_r(p)$ disjoint with $A$. Then we know $d(A,\set{p})\geq r$. \\

Notice that if we fix $b'\in B$. We have triangle inequality
\begin{equation}
d(A,\set{p})\leq d(A,\set{b'})+d(b',p)*
\end{equation}
Because 
\begin{equation}
d(A,\set{b'})+d(b',p)=\inf \set{d(a,b'):a \in A}+d(b',p)=\inf \set{d(a,b')+d(b',p):a \in A}
\end{equation}
where for each $a$, we have
 \begin{equation}
d(A,\set{p})\leq d(a,p)\leq d(a,b')+d(b',p)
\end{equation}



Then from
\begin{equation}
  \forall b\in B, r\leq d(A,\set{p})\leq d(A,\set{b})+d(\set{b},\set{p})
\end{equation}
we have
\begin{equation}
  \forall b\in B [d(A,\set{b})< \frac{r}{2}\implies d(\set{b},\set{p})>\frac{r}{2}]
\end{equation}
Then we see if $n>\frac{2}{r}$, then $b_n$ is not contained by the open ball  $B_{\frac{r}{2}}(p)$. In other words, the open ball $B_{\frac{r}{2}}(p)$ that center a limit point $p$ contain at most $\lfloor \frac{2}{r}\rfloor$ amount of point in $\set{b_n}_{n\inn}$ \CaC$\vdone$\\

Lastly, we prove there exists $a\in A,b\in B$ such that $d(A,B)=d(a,b)$. If  $A$ and  $B$ are not disjoint, the fact $\exists a\in A,\exists b\in B, d(A,B)=\abso{a-b}$ is clear by picking $a=b$. We only have to consider when $A$ and $B$ are disjoint.\\

Let $d(A,B)=u$. We know $u>0$, because of the result we have proved.\\

We have 
\begin{equation}
  \inf \set{d(A,\set{b}):b\in B}=d(A,B)=u
\end{equation}
At this stage, we wish to prove \blue{$\exists b\in B$ such that $d(A,\set{b})=u$}. \As{there does not exist such $b$}\\

We know, for each $n\inn$, there exists a point $b_n$ such that
 \begin{equation}
d(A,\set{b_n})<u+\frac{1}{n}
\end{equation}
Because $\forall b\in B, d(A,\set{b})>u$, we know if we collect one $b_n$ that satisfy $d(A,\set{b_n})<u+\frac{1}{n}$ for each $n\inn$, the sequence $\set{b_n}_{n\inn}$ is infinite.\\

Then by \myref{Theorem}{1.7.4}, we know there exists a limit point $p\in B$ for $\set{b_n}_n\inn$.\\

We know $d(A,\set{p})>u$ by our assumption.\\

Let $m=d(A,\set{p})>u$. Then from
\begin{equation}
\forall b\in B,m=d(A,\set{p})<d(A,\set{b})+d(b,p)\text{ This was proved at * }
\end{equation}
we have
\begin{equation}
\forall b\inB, d(A,\set{b})<u+\frac{1}{n}\implies d(b,p)>m-u-\frac{1}{n}
\end{equation}
Let $k$ be a natural such that  $u+\frac{1}{k}<m$. For each natural $t$ greater than  $k$, we have 
\begin{equation}
d(b_t,p)>m-u-\frac{1}{t}>m-u-\frac{1}{k}
\end{equation}
In other words, the open ball $B_{m-u-\frac{1}{k}}(p)$ centering a limit point contain at most $k$ amount of point in  $\set{b_n}_{n\inn}\tCaC\bdone$\\

Let $b\in B$ satisfy $d(A,\set{b})=u$. At the final stage, we wish to prove \vi{$\exists a\in A, d(a,b)=u$}.\\

\As{$\forall a\in A, d(a,b)>u$}. We know, for each $n\inn$, there exists a point $a_n$ such that 
\begin{equation}
d(a_n,b)<u+\frac{1}{n}
\end{equation}
Because $\forall a\in A, d(a,b)>u$, we know if we we collect one $a_n$ that satisfy  $d(a_n,b)<u+\frac{1}{n}$ for each $n\inn$, the sequence $\set{a_n}_{n\inn}$ is infinite.\\

Notice that the sequence $\set{a_n}_{n\inn}$ is also bounded as one can check $B_{2(u+1)}(a_1)$ contain all $\set{a_n}_{n\inn}$, using $b$ as a "pivot".\\

Then because we are in $\R^n$ and $\set{a_n}_{n\inn}$ is closed and bounded, we know $\set{a_n}_{n\inn}$ is compact, then by \myref{Theorem}{1.7.4}, we know $\set{a_n}_{n\inn}$ has a limit point in itself.\\

Let $a_k$ be a limit point of $\set{a_n}_{n\inn}$.\\

Let $m=d(a_k,b)>u$. Observe that 
\begin{equation}
\forall a_n,m=d(a_k,b)<d(b,a_n)+d(a_n,a_k)
\end{equation}
give us
\begin{equation}
\forall a_n, d(a_n,b)<u+\frac{1}{n}\implies d(a_n,a_k)>m-u-\frac{1}{n}
\end{equation}
Let $s\inn$ be great enough so that  $m-u-\frac{1}{s}>0$. Then we see for each natural $w$ greater than  $s$, we have
 \begin{equation}
d(a_w,b)<u+\frac{1}{w}<u+\frac{1}{s}
\end{equation}
so we have
\begin{equation}
d(a_w,a_k)>m-u-\frac{1}{s}
\end{equation}
Then we see the open ball $B_{m-u-\frac{1}{s}}(a_k)$ contain at most $s$ amount of point in  $\set{a_n}_{n\inn}\tCaC\vdone$
















\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{8}
    \item Let \( (M, d) \) be a metric space.
    \begin{enumerate}
        \item Show that the union of a finite number of compact subsets of \( M \) is compact.
        \item Show that the intersection of an arbitrary collection of compact subsets of \( M \) is compact.
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}
  Let $\mathcal{K}=\set{K_1,\dots , K_n}$ be a finite collection of compact subset of $M$. We wish to show $\bigcup  \mathcal{K}$ is compact. Let $\mathcal{G}$ be an open cover for $\mathcal{K}$. For each $m \inn:1\leq m\leq n$, because $K_m\subseteq \bigcup \mathcal{K}$, we know $\mathcal{G}$ is also an open cover for $K_m$. Then, we can pick a finite sub-cover  $\mathcal{G}_m\subseteq \mathcal{G}$ for $K_m$. Collect all such finite sub-cover  $\mathcal{G}_1,\dots, \mathcal{G}_m$. The union $\bigcup \set{\mathcal{G}_1,\dots ,\mathcal{G}_m}$ is a finite open cover for $\bigcup \mathcal{K} $.\\

Notice that a compact set must be closed, and arbitrary collection of closed sets are closed. Then, we know the intersection of an arbitrary collection of compact set must be a closed set and a subset of every compact set in the collection. Then because closed subset of compact set is compact, we know the intersection is compact.
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{9}
    \item A metric space \( (M,d) \) is said to be \textit{separable} if there is a countable subset \( A \) which is dense in \( M \). Show that every compact set is separable.
\end{enumerate}
\end{question}
\begin{proof}
See the proof in \myref{Theorem}{1.7.4}, there is a summary where you can find the numbering of rigorous proof for each step. Some proof for corollary is omitted because they are immediate consequences of theorem before.\\

Because I use a program written by artificial intelligence to update my reference in latex code whenever I edit my latex code, some reference may be directed to a wrong theorem, but all the tools are there in Chapter 2. 
\end{proof}
\section{HW3}
\begin{question}{}{}
1. Let $S_1$ and $S_2$ be two nonempty subsets in a metric space with $S_1 \cap \overline{S_2} = \overline{S_1}\cap S_2 = \emptyset$. If $A \subseteq S_1 \cup S_2$ is a connected set, then either $A \subseteq S_1$ or $A \subseteq S_2$.
\end{question}
\begin{proof}
\As{we have $A\not\subseteq S_1\text{ and }A\not\subseteq S_2$}. Then we know $A\cap S_1\text{ and }A\cap S_2$ are both non-empty. We know
\begin{equation}
A=(A\cap S_1)\cup (A\cap S_2)
\end{equation}
We wish to show
 \begin{equation}
A\cap S_1\text{ and }A\cap S_2\text{ are separated. }
\end{equation}
Notice 
\begin{equation}
\overline{A\cap S_1}\subseteq \overline{S_1}
\end{equation}
Then because $\overline{S_1}$ and $S_2$ are disjoint, we know $\overline{A\cap S_1}$ and $S_2$ are disjoint. Then because $A\cap S_2\subseteq S_2$, we know $\overline{A\cap S_1}$ and $A\cap S_2$ are disjoint. Similarly, notice
\begin{equation}
\overline{A\cap S_2}\subseteq \overline{S_2}
\end{equation}
Then because $\overline{S_2}$ and $S_1$ are disjoint, we know $\overline{A\cap S_2}$ and $S_1$ are disjoint. Then because $A\cap S_1\subseteq S_1$, we know $\overline{A\cap S_2}$ and $A\cap S_1$ are disjoint.    \\

We have proved $A\cap S_1$ and $A\cap S_2$ are separated, which $\tCaC$ to $A$ is connected.
\end{proof}
\begin{question}{}{}
2. If $A_1$ and $A_2$ are two nonempty and connected sets with $A_1\cap A_2\neq \varnothing$. Prove or disprove that
\begin{enumerate}[label=(\alph*)]
  \item $A_1\cap A_2$ is connected
  \item $A_1\cup A_2$ is connected
\end{enumerate}
\end{question}
\begin{proof}
Let $A_1=\set{(x,y)\inr^2:x^2+y^2=1}$ and let  $A_2=\set{(0,y)\inr^2:y\inr}$.\\

To show $A_1,A_2$ are both connected, we can show they are both path connected.\\

Let $(\cos \alpha ,\sin \alpha  )\in A_1$ and $(\cos \beta ,\sin \beta )\in A_1$. Define $f:[0,1]\rightarrow A_1$ by
\begin{equation}
 f(x)=(\cos (\alpha +x(\beta -\alpha )), \sin (\alpha +x(\beta -\alpha )))
\end{equation}
Clearly $f$ is continuous, and  $f(0)=(\cos \alpha ,\sin \alpha ),f(1)=(\cos \beta ,\sin \beta )$.\\

Let $(0,z)\in A_2$ and $(0,y)\in A_2$. Define $g:[0,1]\rightarrow A_2$ by
\begin{equation}
g(x)=(0,z+x(y-z))
\end{equation}
Clearly $g$ is continuous and  $g(0)=(0,z),g(1)=(0,y)$.\\


We see $A_1\cap A_2=\set{(0,1),(0,-1)}$. We see $\set{(0,1)}$ and $\set{(0,-1)}$ are separated, because they are close.\\

For (b), see next three Theorems.
\end{proof}
\begin{theorem}
\label{3.3.1}
\textbf{(Connected)} If $A$ is disconnected, then $A$ can be partitioned into two non-empty disjoint relatively open subsets. 
\end{theorem}
\begin{proof}
Because $A$ is disconnected, we know  $A=E\cup F$ for some pair $E,F$ of separated sets. We wish to prove $E,F$ are both relatively open to $A$.\\

Because $\overline{E}\cap F=\varnothing$, we know the closure of $E$ in subspace topology of $A$ is disjoint to $F$. Then with respect to $A$, we can see $\overline{E}\subseteq F^c=E$, so we know $E$ is relatively closed to  $A$.\\


Similarly, because $\overline{F}\cap E=\varnothing$, we know the closure of $F$ in subspace topology of $A$ is disjoint to $E$. Then with respect to $A$, we can see $\overline{F}\subseteq E^c=F$, so we know $F$ is relatively closed to  $A$.\\

Then because $E$ and  $F$ are both relatively closed to  $A$ and  $A=E\cup F$ where $E,F$ are disjoint, we know  $E$ and  $F$ are both relatively open to  $A$.
\end{proof}
\begin{theorem}
\label{3.3.2}
\textbf{(Subspace Topology)} Let $Y$ be a subspace of $(X,d)$, let $E\subseteq X$, and let $p\in  Y$. We have
\begin{gather}
p\text{ is an interior point of $E$ in $X$ }\implies p\text{ is an interior point of $E\cap Y$ in $Y$ } \\
\text{ $Y\cap E^\circ $ in $X$ is a subset of the interior of $E\cap Y$ in $Y$ }\\
E\text{ is open in $X$ }\implies E\cap Y\text{ is open in $Y$ }
\end{gather}
where the converse may not hold true.
\end{theorem}
\begin{proof}
We first prove the first statement. Let $\set{x_n}$ be a sequence in $Y$ that converge to $p$. Because  $p$ is an interior point of  $E$ in  $X$, and  $\set{x_n}$ is in $X$, as  $Y\subseteq X$, we know there exists $N$ such that 
 \begin{equation}
n>N\implies x_n\in E
\end{equation}
Notice $x_n\in Y$, and we are done.\\

For a nontrivial example of the converse of the first statement may not hold true, let $E=(0,2)$, let $Y=\set{1}\cup (2,3)$. We see $1$ is an interior point of  $E$ in  $\R$, but  $1$ isn't an interior point of  $\set{1}=E\cap Y$ in $Y$.

The second and the third statement follows from the first statement. 
\end{proof}
\begin{theorem}
\label{3.3.3}
\textbf{(Union of Connected Sets that have Nonempty Intersection is Connected)} Let $\mathcal{F}$ be a class of connected sets. We have 
\begin{equation}
\bigcap \mathcal{F}\neq \varnothing \implies \bigcup \mathcal{F}\text{ is connected }
\end{equation}
\end{theorem}
\begin{proof}
\As{$\bigcup \mathcal{F}$ is not connected}. Let 
\begin{equation}
\bigcup  \mathcal{F}= A \disjointunion B\text{ and }A\neq \varnothing\neq B
\end{equation}
And let $A,B$ be relatively open to  $\bigcup \mathcal{F}$. We know $\bigcap \mathcal{F}$ must intersect with either $A$, or  $B$, or both.\\

WOLG, let
\begin{equation}
A\cap \bigcap \mathcal{F}\neq \varnothing
\end{equation}
Because $B$ is non-empty and $B\subseteq \bigcup \mathcal{F}$, we know $B$ must intersect with some $F_n\in \mathcal{F}$. Notice that because $A\cap \bigcap \mathcal{F}\neq \varnothing$, we have $A\cap F_n\neq \varnothing$. Then by \myref{Theorem}{3.3.2}, we see $A\cap F_n$ and $B\cap F_n$ are both relatively open to $F_n$, while $F_n= (A\cap F_n)\disjointunion (B\cap F_n)\tCaC$ 
\end{proof}
\begin{question}{}{}
3. Let $\{A_k\}_{k=1}^{\infty}$ be a family of connected subsets of $M$, and suppose that $A$ is a connected subset of $M$ such that $A_k \cap A \neq \emptyset$ for all $k \in \mathbb{N}$. Show that the union $\left(\bigcup_{k \in \mathbb{N}} A_k\right) \cup A$ is also connected.
\end{question}
\begin{proof}
\As{$\bigcup_{k\inn}A_k\cup A$ is not connected}. Let $\bigcup_{k\inn}A_k\cup A$ be partitioned into two non-empty  $E,F$ relatively open to  $\bigcup_{k\inn}A_k\cup A$.\\

If $E,F$ both intersect with  $A$, observe that $A$ can be partitioned into two non-empty $E\cap A$ and $F\cap A$, which are relatively open to $A$, causing a contradiction to  $A$ is connected.\\

Then, we only have to consider when only one of  $E,F$ intersect with  $A$. WOLG, let  $E$ intersect with $A$.\\

We know $F$ must intersect with some  $A_n$. From last question, we know $A_n\cup A$ is connected. Notice that $A_n\cup A$ can be partitioned into two non-empty $E\cap (A\cup A_n)$ and $F\cap (A\cup A_n)$, and they are relatively open to $A\cup A_n\tCaC$ to $A_n\cup A$ is connected.
\end{proof}
\begin{question}{}{}
4. Let $\{a_k\}_{k=1}^{\infty}$ be a sequence, and define $s_n = \frac{1}{n} \sum_{k=1}^{n} a_k$. Prove or disprove that
\begin{enumerate}[label=(\alph*)]
  \item If ${a_k}$ converges, then $s_n$ converges.\\
  \item If $s_n$ converges, then $a_k$ converges.\\
  \item Let $t = \frac{(2n-1)a_1 + (2n-3)a_2 + \ldots + 3a_{n-1} + a_n}{n^2}$. Assume ${a_k}$ converges to $a$. Does $t_n$ also converge to $a$?
\end{enumerate}
\end{question}
\begin{proof}
First notice
\begin{align}
  \abso{s_n-L}=\abso{\frac{\sum_{k=1}^n a_k}{n}-L}&=\abso{\frac{(\sum_{k=1}^na_k)-nL}{n}}\\
  &=\abso{\frac{\sum _{k=1}^n a_k-L}{n}}\\
  &=\frac{1}{n}\abso{\sum_{k=1}^n a_k-L}\\
  &\leq \frac{1}{n} \sum_{k=1}^n \abso{a_k-L}
\end{align}
We prove \vi{$\lim_{k\to \infty}a_k=L\implies \lim_{k\to\infty }s_k=L$}.\\

Arbitrarily pick $R\inr^+$. We wish to find $N$ such that 
 \begin{equation}
k>N\implies \abso{s_k-L}<R
\end{equation}
Because $\lim_{n\to\infty}a_n=L$, we know there exists $N_0$ such that 
 \begin{equation}
n>N_0\iff \abso{a_n-L}<\frac{R}{2}
\end{equation}
Let
\begin{equation}
H=\sum_{k=1}^{N_0} \abso{a_k-L}\text{ and }m=\frac{2}{R}(H-N_0R)
\end{equation}
We wish to prove
\begin{equation}
n>N_0+m \implies \abso{s_n-L}<R
\end{equation}
Let $n=N_0+u$ where $u>m$. Observe
\begin{align}
  \abso{s_n-L}\leq \frac{1}{n}\sum_{k=1}^n \abso{a_k-L}&=\frac{\sum_{k=1}^n \abso{a_k-L}}{N_0+u}\\
  &= \frac{\sum_{k=1}^{N_0} \abso{a_k-L}+\sum_{k=N_0+1}^{N_0+u} \abso{a_k-L}}{N_0+u}\\
  &\leq \frac{H+u \frac{R}{2}}{N_0+u}
\end{align}
and Observe 
\begin{align}
  u>m=\frac{2}{R}(H-N_0R)&\implies \frac{Ru}{2}>H-N_0R\\
                         &\implies N_0R+ Ru>H+ \frac{Ru}{2}\\
&\implies R>\frac{H+\frac{Ru}{2}}{N_0+u}
\end{align}
In other words, we have
\begin{equation}
n>N_0+m \implies u>m\implies \abso{s_n-L}\leq \frac{H+\frac{Ru}{2}}{N_0+u}<R\vdone
\end{equation}
For (b), we raise an counter-example. Let
\begin{equation}
a_n=\begin{cases}
  1& \text{ if $n$ is odd }\\
  0& \text{ if $n$ is even }
\end{cases}
\end{equation}
To see $\set{a_n}$ does not converge to any number, consider the sub-sequences
\begin{equation}
\set{a_{n_k}}\text{ where }n_k=2k-1\text{ and }\set{a_{n_u}}\text{ where }n_u=2u
\end{equation}
We have
\begin{equation}
\forall k,a_{n_k}=1\text{ and }\forall u,a_{n_u}=0
\end{equation}
Then we see 
\begin{equation}
\lim_{k\to\infty}a_{n_k}=1\text{ and }\lim_{u\to\infty}a_{n_u}=0
\end{equation}
If $\set{a_n}$ converge, then these two sub-sequence should converge to the same number.\\

We wish to show 
\begin{equation}
\lim_{n\to\infty}s_n=\frac{1}{2}
\end{equation}
With simple logical computation, we have
\begin{equation}
s_n=\begin{cases}
  \frac{n-1}{2n}& \text{ if $n$ is odd }\\
  \frac{1}{2}& \text{ if $n$ is even }
\end{cases}
\end{equation}
Notice 
\begin{equation}
\frac{n-1}{2n}=\frac{1}{2}-\frac{1}{2n}
\end{equation}
Fix $\epsilon \inr^+$. We see that 
\begin{equation}
n>\frac{1}{2\epsilon }\implies \abso{s_n-\frac{1}{2}}=\begin{cases}
\frac{1}{2n}& \text{ if $n$ is odd }\\
 0& \text{ if $n$ is even } 
\end{cases}<\epsilon 
\end{equation}
Lastly, we prove 
\begin{equation}
\blue{\lim_{n\to\infty}a_n=a\implies \lim_{n\to\infty}t_n=a}
\end{equation}
First notice
\begin{align}
  \abso{t_n-a}&=\abso{\frac{(2n-1)a_1+(2n-3)a_2+\cdots + a_n}{n^2}-a}\\
&=\abso{\frac{1}{n^2}[(2n-1)(a_1-a)+(2n-3)(a_2-a)+\cdots +(a_n-a)]}\\
&=\frac{1}{n^2}\abso{\sum_{k=1}^n (2n-2k+1)(a_k -a)}\\
&\leq \frac{1}{n^2}\sum_{k=1}^n \abso{(2n-2k+1)(a_k-a)}\\
&= \frac{1}{n^2}\sum_{k=1}^n (2n-2k+1)\abso{a_k-a}\\
&\leq \frac{1}{n^2}\sum_{k=1}^n (2n-1)\abso{a_k-a}=\frac{2n-1}{n^2}\sum_{k=1}^n \abso{a_k-a}
\end{align}
Arbitrarily pick $\epsilon \inr^+$. Because $\lim_{n\to\infty}a_n=a$. We know there exists $N_0$ such that
 \begin{equation}
n>N_0\implies \abso{a_n-a}<\frac{\epsilon }{4}\implies (\frac{2n-1}{n})\abso{a_n-a}=(2-\frac{1}{n})\abso{a_n-a}<2\abso{a_n-a}<\frac{\epsilon}{2} 
\end{equation}
Let
\begin{equation}
H=\sum_{k=1}^{N_0} \abso{a_k-a}
\end{equation}
We have
\begin{align}
  \abso{t_n-a}\leq \frac{2n-1}{n^2}\sum_{k=1}^n \abso{a_k-a}&=\frac{2n-1}{n^2}\sum_{k=1}^{N_0}\abso{a_k-a}+\frac{2n-1}{n^2}\sum_{k=N_0+1}^n \abso{a_k-a}\\
&=\frac{2n-1}{n^2}H+\frac{2n-1}{n^2}\sum_{k=N_0+1}^n \abso{a_k-a}\\
&= \frac{2n-1}{n^2}H+\frac{1}{n}\sum_{k=N_0+1}^n \frac{2n-1}{n}\abso{a_k-a}\\
&\leq  \frac{2n-1}{n^2}H+ \frac{1}{n}(n-N_0) \frac{\epsilon }{2} 
\end{align}
Then if we let 
\begin{equation}
X_n:=\frac{2n-1}{n^2}H+\frac{(n-N_0)\epsilon }{2n}
\end{equation}
For all $n>N_0$, we have
 \begin{equation}
\abso{t_n-a}<X_n
\end{equation}
Notice 
\begin{equation}
X_n=\frac{2H}{n}-\frac{H}{n^2}+\frac{\epsilon}{2}-\frac{N_0\epsilon }{2n}
\end{equation}
So we have
\begin{equation}
\lim_{n\to\infty}X_n=\frac{\epsilon}{2}
\end{equation}
Then we know there exists some $N_1$ such that 
 \begin{equation}
   n>N_1\implies \abso{X_n-\frac{\epsilon}{2}}<\frac{\epsilon}{2}\implies \abso{t_n-a}\leq X_n<\epsilon \bdone
\end{equation}


\end{proof}
\begin{question}{}{}
5. If $a_k > 0$ for all $k \in \mathbb{N}$, prove that
\[
  \liminf_{k\to\infty} \frac{a_{k+1}}{a_k} \leq \liminf_{k\to\infty} \sqrt[k]{a_k} \leq \limsup_{k\to\infty} \sqrt[k]{a_k} \leq \limsup_{k\to\infty} \frac{a_{k+1}}{a_k}
\]
Moreover, find a sequence $\{a_k\}_{k=1}^{\infty}$ such that 
\[
  \limsup_{k\to\infty} \sqrt[k]{a_k} < \limsup_{k\to\infty} \frac{a_{k+1}}{a_k}
\]
\end{question}

\begin{proof}
The fact 
\begin{equation}
\liminf_{n\to\infty} \sqrt[n]{a_n}\leq \limsup_{n\to\infty} \sqrt[n]{a_n}  
\end{equation}
follows from definition.\\

We first prove
\begin{equation}
  \vi{\liminf_{n\to\infty} \frac{a_{n+1}}{a_n}\leq \liminf_{n\to\infty} \sqrt[n]{a_n}}
\end{equation}
Let 
\begin{equation}
\alpha =\liminf_{n\to\infty} \frac{a_{n+1}}{a_n}
\end{equation}
Notice that $\set{a_k}$ being positive give us $\alpha \geq 0$ and $0\leq \liminf_{n\to\infty} \sqrt[n]{a_n} $. If $\alpha =0$, the proof is done trivially. We only have to consider when $\alpha $ is positive.\\

Arbitrarily pick positive $\beta $ smaller than $\alpha $:
\begin{equation}
\beta <\alpha=\liminf_{n\to\infty} \frac{a_{n+1}}{a_n}
\end{equation}
Then we know there exists $N$ such that
 \begin{equation}
\forall n\geq N, \frac{a_{n+1}}{a_n}>\beta 
\end{equation}
This implies 
\begin{equation}
\forall k, a_{N+k}>\beta^k a_N
\end{equation}
Then for all $n>N$, we have
 \begin{equation}
   \sqrt[n]{a_n}>\sqrt[n]{ \beta^{n-N}a_{N}}=\beta \sqrt[n]{\beta^{-N}a_N} 
\end{equation}
Because 
\begin{equation}
\lim_{n\to\infty}\beta \sqrt[n]{\beta^{-N}a_N}=\beta 
\end{equation}
We see
\begin{equation}
\liminf_{n\to\infty} \sqrt[n]{a_n} \geq \beta 
\end{equation} 
Notice that $\beta $ is arbitrarily pick from $\set{x\inr: 0\leq x<\alpha }$, so we have in fact proved
\begin{equation}
0\leq x<\alpha \implies x\leq \liminf_{n\to\infty} \sqrt[n]{a_n} 
\end{equation}
If $\liminf_{n\to\infty} \sqrt[n]{a_n} <\alpha $, there should exists $x<\alpha $ such that $\liminf_{n\to\infty} \sqrt[n]{a_n} <x$, which we have prove is impossible. $\vdone$\\

We now prove 
\begin{equation}
\blue{\limsup_{n\to\infty} \sqrt[n]{a_n}\leq \limsup_{n\to\infty} \frac{a_{n+1}}{a_n}}
\end{equation}
Let $\gamma =\limsup_{n\to\infty} \frac{a_{n+1}}{a_n}$.  If $\gamma =\infty$, the proof is done trivially. We only have to consider when $\gamma<\infty$.\\

Notice that $\set{a_k}$ being positive give us $\gamma \geq 0$. Arbitrarily pick positive $\delta$ greater than $\gamma $:
\begin{equation}
\delta>\gamma =\limsup_{n\to\infty} \frac{a_{n+1}}{a_n}
\end{equation}
Then we know there exists $N$ such that
 \begin{equation}
\forall n\geq N, \frac{a_{n+1}}{a_n}<\delta 
\end{equation}
This implies
\begin{equation}
\forall k,a_{N+k}<\delta^k a_N
\end{equation}
Then for all $n>N$, we have
 \begin{equation}
\sqrt[n]{a_n}<\sqrt[n]{\delta^{n-N}a_N}=\delta \sqrt[n]{\delta^{-N}a_N} 
\end{equation}
Because
\begin{equation}
\lim_{n\to\infty}\delta \sqrt[n]{\delta ^{-N}a_N} =\delta 
\end{equation}
We see
\begin{equation}
\limsup_{n\to\infty} \sqrt[n]{a_n}\leq \delta 
\end{equation}
Notice that $\delta $ is arbitrarily picked from $\set{x\inr:x>\gamma }$, so we have in fact proved
\begin{equation}
x>\gamma \implies x\geq \limsup_{n\to\infty} \sqrt[n]{a_n} 
\end{equation}
If $\limsup_{n\to\infty} \sqrt[n]{a_n} >\gamma $, there should exists some $x>\gamma $ such that $\limsup_{n\to\infty} \sqrt[n]{a_n}>x$, which we have proved is impossible. $\bdone$\\

Let
\begin{equation}
a_k=\begin{cases}
  2& \text{ if  }k\text{ is odd }\\
  1& \text{ if $k$ is even }
\end{cases}
\end{equation}
We see 
\begin{equation}
\limsup_{n\to\infty} \sqrt[n]{a_n}=1 <2\limsup_{n\to\infty} \frac{a_{n+1}}{a_n}
\end{equation}
\end{proof}
\begin{question}{}{}
6. If $s_1 = \sqrt{2}$, and
\begin{equation}
s_{n+1} =  \sqrt{2+\sqrt{s_n}}, \quad n = 1, 2, 3, \ldot
\end{equation}
prove that $s_n$ converge and bounded above by $2$
\end{question}
\begin{proof}
We first prove \vi{$\set{s_n}$ increase monotonically} by induction.\\

Base case:
\begin{equation}
s_1^2=2<2+\sqrt{2+\sqrt{\sqrt{2} } }=s_2^2 \implies s_1<s_2
\end{equation}
Induction case: Let $s_k<s_{k+1}$. We wish to prove $s_{k+1}<s_{k+2}$. Because $s_{k+1}=\sqrt{2+\sqrt{s_k} } $, we have
\begin{equation}
s_k\leq s_{k+1}=\sqrt{2+\sqrt{s_k} } 
\end{equation}
Then we can deduce
\begin{gather}
s_k\leq \sqrt{2+\sqrt{s_k} } \\
\implies \sqrt{s_k}\leq \sqrt{\sqrt{2+\sqrt{s_k} } }\\
\implies 2+\sqrt{s_k}\leq 2+\sqrt{\sqrt{2+\sqrt{s_k} } }\\
\implies \sqrt{2+\sqrt{s_k} }\leq \sqrt{2+\sqrt{\sqrt{2+\sqrt{s_k} } } }\\
\implies s_{k+1}=\sqrt{2+\sqrt{s_k} }\leq \sqrt{2+\sqrt{s_{k+1}} }=s_{k+2}\vdone
\end{gather}
We now prove \blue{$\set{s_n}$ is bounded above by 2} by induction.\\

Base case: $s_1=\sqrt{2}<2$.\\

Induction case: Let $s_k\leq 2$. We wish to prove  $s_{k+1}\leq 2$. Observe
\begin{align}
  s_k\leq 2&\implies s_k\leq 4\\
  &\implies \sqrt{s_k}\leq \sqrt{4} =2\\
  &\implies 2+\sqrt{s_k} \leq 4\\
  &\implies s_{k+1}=\sqrt{2+\sqrt{s_k} }\leq \sqrt{4}=2 \bdone
\end{align}
The fact that $\set{s_n}$ monotonically increase and bounded above tell us $\set{s_n}$ converge.
\end{proof}
\begin{question}{}{}
7. Suppose $a_n > 0$ and $s_n = \sum _{k=1}^{n} a_k$. If $s_n$ diverges, prove or disprove that $t_n=\sum_{k=1}^{n} \frac{a_k}{1+a_k}$ diverges. What can be said about
\begin{equation}
S_n=\sum_{k=1}^n \frac{a_k}{1+ka_k}
\end{equation}
\begin{equation}
T_n=\sum_{k=1}^n \frac{a_k}{1+k^2a_k}
\end{equation}
\begin{equation}
\text{If } s_n=\sum_{k=1}^n a_k\text{ converge, does }J_n=\sum_{k=1}^n ka_k\text{ converge }
\end{equation}
\end{question}
\begin{proof}
  We prove 
 \vi{
  \begin{equation}
  t_n\text{ converge }\implies s_n\text{ converge }
\end{equation}}
Notice that
\begin{equation}
a_n=\frac{a_n+a_n^2}{1+a_n}=\frac{a_n}{1+a_n}+\frac{a_n^2}{1+a_n}
\end{equation}
So we have
\begin{equation}
s_n=t_n+\sum_{k=1}^n \frac{a_n^2}{1+a_n}
\end{equation}
Because $t_n$ converge, above tell us we only have to prove  $\sum_{k=1}^n \frac{a_n^2}{1+a_n}$ converge.\\

Because $t_n$ converge, we know 
 \begin{equation}
\lim_{n\to\infty}\frac{a_n}{1+a_n}=0
\end{equation}
\As{$\lim_{n\to\infty}a_n\neq 0$}. Then there exists $\epsilon $ such that
\begin{equation}
\forall N\inn, \exists n>N, a_n>\epsilon 
\end{equation}
Notice
\begin{equation}
a_n>\epsilon \implies \frac{a_n}{1+a_n}=1-\frac{1}{1+a_n}>1-\frac{1}{1+\epsilon }\implies \abso{\frac{a_n}{1+a_n}-0}>1-\frac{1}{1+\epsilon }
\end{equation}
In other words, there exists a sub-sequence $\set{a_{f(n)}}$ such that
\begin{equation}
\lim_{n\to\infty}\frac{a_{f(n)}}{1+a_{f(n)}}\neq 0\tCaC
\end{equation}
We have proved $\lim_{n\to\infty}a_n=0$. Then we know there exists $N_1$ such that
 \begin{equation}
\forall n>N_1, a_n<1
\end{equation}
In other words,
\begin{equation}
\forall n>N_1, \frac{a_n^2}{1+a_n}<\frac{a_n}{1+a_n}
\end{equation}
By comparison test, our proof is done $\vdone$.\\

We show
\begin{equation}
\blue{\text{ It is possible $s_n$ diverge and $S_n$ converge.}}
\end{equation}
Let 
\begin{equation}
a_k=\begin{cases}
  1& \text{ if $\exists u\inn, k=u^2$ }\\
  \frac{1}{k^2}& \text{ otherwise }
\end{cases}
\end{equation}
Clearly,  $\lim_{n\to\infty}s_n=\infty$. Yet, we have
\begin{align}
  \lim_{n\to\infty}S_n=\sum_{k=1}^\infty \frac{a_k}{1+ka_k}&=\sum_{u=1}\frac{a_{u^2}}{1+u^2a_{u^2}}+\sum_{k\inn\setminus \set{r^2:r\inn}}\frac{a_k}{1+ka_k}\\
&=\sum_{u=1}\frac{1}{1+u^2}+\sum_{k\inn\setminus \set{r^2:r\inn}}\frac{\frac{1}{k^2}}{1+\frac{1}{k}}\\
&=\sum_{u=1}\frac{1}{1+u^2}+\sum_{k\inn\setminus \set{r^2:r\inn}} \frac{1}{k(k+1)}
\end{align}
Notice that 
\begin{equation}
\frac{1}{1+u^2}<\frac{1}{u^2}\text{ and }\frac{1}{k(k+1)}<\frac{1}{k^2}
\end{equation}
Then by comparison test, we know 
\begin{equation}
\text{ both }\sum_{u=1}\frac{1}{1+u^2}\text{ and }\sum_{k\inn\setminus \set{r^2:r\inn}} \frac{1}{k(k+1)}\text{ converge }
\end{equation}
Then we know
\begin{equation}
S_n\text{ also converge }\bdone
\end{equation}
Notice that for all $n$
\begin{equation}
k\geq 1\implies 1+k^2a_k>1+ka_k\implies \frac{a_k}{1+k^2a_k}<\frac{a_k}{1+ka_k}\implies T_n<S_n
\end{equation}
Then because the term is non-negative, by comparison test, we know the example above also satisfy $T_n$ converge while $s_n$ diverge.

Notice that if we let $a_k=\frac{1}{k^2}$, then $s_n$ converge and $J_n=\sum_{k=1}^n \frac{1}{k}$ diverge. 

\end{proof}
\begin{question}{}{}
8. Assume \( A \subset \mathbb{R} \) is compact and let \( a \in A \). Suppose \( \{ a_n \} \) is a sequence in \( A \) such that every convergent sub-sequence of \( \{ a_n \} \) converges to \( a \). 
    \begin{enumerate}
        \item Does the sequence \( \{ a_n \} \) also converge to \( a \)?
        \item Without the assumption that \( A \) is compact, does the sequence \( \{ a_n \} \) converge to \( a \)?
    \end{enumerate}
\end{question}
\begin{proof}
\As{$a_n$ does not converge to $a$}. We know there exists $\epsilon $ such that there exists a sub-sequence $\set{a_{n_k}}_{k\inn}$
\begin{equation}
\forall k\inn, a_{n_k}\not\in B_{\epsilon }(a)
\end{equation}
Because  $A$ is (sequentially ) compact,  we know there must exist a sub-sequence $\set{a_{n_{k_u}}}_u\inn$ such that
\begin{equation}
\set{a_{n_{k_u}}}\text{ converge }
\end{equation}
Notice that
\begin{equation}
\set{a_{n_{k_u}}}\text{ is a sub-sequence of $\set{a_n}$ }
\end{equation}
So we know 
 \begin{equation}
\lim_{u\to\infty}a_{n_{k_u}}=a\tCaC\text{ to }\forall n\inn, a_{n_{k}}=\not\in B_\epsilon (a)
\end{equation}
Let $A=\Q$, and let
 \begin{equation}
a_n=\begin{cases}
  0& \text{ if $n$ is odd }\\
  n& \text{ if $n$ is even }
\end{cases}
\end{equation}
and we see every convergent sub-sequence converge to $0$ but  $a_n$ itself does not converge to  $0$
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{8}
    \item Suppose that \( a_k \neq 0 \) for large \( k \) and that
    \[
    p = \lim_{{k \to \infty}} \frac{\ln\left(\frac{1}{|a_k|}\right)}{\ln(k)}
    \]
    exists as an extended real number.
    \begin{enumerate}
        \item If \( p > 1 \), then \(\sum_{k=1}^{\infty} a_k\) converges absolutely.
        \item If \( p < 1 \), then $\sum _{k=1}^\infty a_k$ diverge
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}
Let $p>\alpha >1$.  Then we know there exists $N$ such that
 \begin{equation}
\forall n>N, \frac{\ln (\frac{1}{\abso{a_n}})}{\ln n}>\alpha >1
\end{equation}
This give us
\begin{equation}
\forall n>N, \ln(\frac{1}{\abso{a_n}})>\alpha \ln n 
\end{equation}
This give us
\begin{equation}
\forall n>N, \frac{\ln (\frac{1}{\abso{a_n}})}{\alpha }>\ln n
\end{equation}
This give us
\begin{equation}
\forall n>N, \ln (\abso{a_n}^{-\frac{1}{\alpha }})>\ln n
\end{equation}
This give us
\begin{equation}
\forall n>N, \abso{a_n}^{\frac{-1}{\alpha }}>n
\end{equation}
This give us
\begin{equation}
\forall n>N, \abso{a_n}<n^{-\alpha }<n^{-1}
\end{equation}
By comparison test, we are done.\\

Let $p<\beta <1$. Then we know there exists $N$ such that
\begin{equation}
\forall n>N, \frac{\ln (\frac{1}{\abso{a_n}})}{\ln n}<\beta <1
\end{equation}
This give us
\begin{equation}
  \forall n>N, \frac{\ln(\abso{a_n}^{-1})}{\beta }<\ln n
\end{equation}
This give us
\begin{equation}
\forall n>N, \ln(\abso{a_n}^{\frac{-1}{\beta }})<\ln n 
\end{equation}
This give us
\begin{equation}
\forall n>N, \abso{a_n}^{\frac{-1}{\beta }}<n
\end{equation}
This give us
\begin{equation}
\forall n>N, \abso{a_n}>n^{-\beta }>n^{-1}
\end{equation}
By comparison test, we are done.
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{9}
    \item Suppose that \( f : \mathbb{R} \to (0,\infty) \) is differentiable, that \( f(x) \to 0 \) as \( x \to \infty \), and that
    \[
    \alpha = \lim_{{x \to \infty}} \frac{xf'(x)}{f(x)}
    \]
    exists. If \( \alpha < -1 \), prove that
    \[
    \sum_{k=1}^{\infty} f(k)
    \]
    converges.
\end{enumerate}
\end{question}
\begin{proof}
Let $\beta $ satisfy
\begin{equation}
\alpha<\beta <-1 
\end{equation}
Because
\begin{equation}
\lim_{x\to\infty}\frac{xf'(x)}{f(x)}=\alpha 
\end{equation}
We know there exists $R$ such that
\begin{equation}
\forall x>R, \frac{xf'(x)}{f(x)}\leq \beta 
\end{equation}
Then we have
\begin{equation}
\forall x>R, \frac{d}{dx}\ln f(x)=\frac{f'(x)}{f(x)}\leq \frac{\beta }{x}
\end{equation}
This tell us 
\begin{equation}
  \forall y>R, \int^y_R \frac{d}{dx}\ln f(x)dx\leq \int^y_R \frac{\beta}{x}dx
\end{equation}
Which means
\begin{equation}
\forall y>R,\ln ( \frac{f(y)}{f(R)})=\ln f(y)-\ln f(R)\leq \beta (\ln(y)-\ln(R))= \ln(\frac{y}{R})^\beta 
\end{equation}
This shows
\begin{equation}
\forall y>R, \frac{f(y)}{f(R)}\leq (\frac{y}{R})^{\beta }
\end{equation}
It means
\begin{equation}
\forall y>R, f(y)\leq \frac{f(R)}{R^{\beta }}y^{\beta }
\end{equation}
Notice $\beta <-1$, we know the series 
\begin{equation}
\sum_{n>R} \frac{f(R)}{R^{\beta }}n^{\beta }=\frac{f(R)}{R^{\beta }}\sum_{n>R}n^{\beta }\text{ converge }
\end{equation}
Then because $f(y)$ is always positive (given by the question), we know $\sum_{n=1}^\infty f(n)$ converge by comparison test.
\end{proof}
\begin{lemma}
\label{3.3.4}
\textbf{(Bernoulli Inequality)} Let  $r\geq 1$ and $x\geq -1$. We have
\begin{equation}
  (1+x)^r\geq 1+rx
\end{equation}
\end{lemma}
\begin{proof}
Let $r\geq 1$, and let
\begin{equation}
f(x)=(1+x)^r-1-rx
\end{equation}
We wish to prove 
\begin{equation}
\forall x\geq -1, f(x)\geq 0
\end{equation}
We now split the proof into two parts
\begin{gather}
  \vi{\forall x\geq 0, f(x)\geq 0}\\
  \blue{\forall x\in [-1,0), f(x)\geq 0}
\end{gather}
First notice by computation
\begin{equation}
f'(x)=r(1+x)^{r-1}-r=r((1+x)^{r-1}-1)
\end{equation}
And notice by some algebra
\begin{equation}
f'(x)\geq 0\iff  (1+x)^{r-1}\geq 1\iff  x\geq 0
\end{equation}
We first prove 
\begin{equation}
\vi{\forall x\geq 0, f(x)\geq 0}
\end{equation}
By computation,
\begin{equation}
f(0)=0
\end{equation}
This give us 
\begin{equation}
\forall x\geq 0, f(x)=f(x)-0=f(x)-f(0)=\int_{0}^x f'(t)dt\geq 0\vdone
\end{equation}
We now prove
\begin{equation}
\blue{\forall x\in [-1,0), f(x)\geq 0}
\end{equation}
Notice that above have shown
\begin{equation}
f'(x)\geq 0\iff  x\geq 0
\end{equation}
So we know
\begin{equation}
\forall x\in [-1,0), f'(x)<0
\end{equation}
Observe that $f(x)$ is an polynomial, so we know  $f(x)$ is continuous. Then if for some $y\in [-1,0)$, we have $f(y)<0=f(0)$, there must exists $u\in (y,0)\subseteq [-1,0)$ such that $f'(u)>0$, which is impossible.
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{10}
    \item Suppose that \( \{ a_n \} \) is a sequence of nonzero real numbers and that
    \[
    p = \lim_{{k \to \infty}} k(1-\abso{\frac{a_{k+1}}{a_k}})
    \]
    exists as an extended real number. Prove that
    \[
    \sum_{k=1}^{\infty} |a_k|
    \]
    converges absolutely when \( p > 1 \).
\end{enumerate}
\end{question}
\begin{proof}
Pick $\alpha $ that satisfy
\begin{equation}
\lim_{k\to\infty}k(1-\abso{\frac{a_{k+1}}{a_k}})>\alpha >1
\end{equation}
We know there exist $N$ such that
 \begin{equation}
\forall n>N, n(1-\abso{\frac{a_{n+1}}{a_n}})>\alpha 
\end{equation}
With a little algebra,
\begin{equation}
\forall n>N, 1-\frac{\alpha }{n}>\abso{\frac{a_{n+1}}{a_n}}
\end{equation}
Plugin \myref{Lemma}{1.3.4} (Bernoulli Inequality) with $r=\alpha >1$ and $x=\frac{-1}{n}\geq -1$. We have
\begin{equation}
\forall n>N,\abso{\frac{a_{n+1}}{a_n}}<1+\frac{-\alpha }{n}\leq (1-\frac{1}{n})^\alpha= (\frac{n-1}{n})^{\alpha }
\end{equation}
Then we have
\begin{equation}
  (*)\forall n>N, \abso{a_{n+1}}n^\alpha < \abso{a_n} (n-1)^{\alpha }
\end{equation}
For each $n>N$, define
 \begin{equation}
b_n=\abso{a_{n+1}}n^{\alpha }
\end{equation}
Then we have
\begin{equation}
\abso{a_n}(n-1)^{\alpha }=b_{n-1}
\end{equation}
So by $(*)$ we have
\begin{equation}
\forall n>N+1, b_n<b_{n-1}
\end{equation}
This tell us $\set{b_n}_{n>N+1}$ is a decreasing sequence. Then we know $\set{b_n:n>N+1}$ is bounded above. More precisely, let
\begin{equation}
M=b_{N+1}
\end{equation}
We have
\begin{equation}
\forall n>N+1, b_n< M
\end{equation}
Recall the definition of $b_n$, we have
 \begin{equation}
\forall n>N+1, \abso{a_{n+1}}n^{\alpha }<M
\end{equation}
In other words
\begin{equation}
\forall n>N+2, \abso{a_n}<Mn^{-\alpha }
\end{equation}
Notice that because $\alpha>1 $. We know 
\begin{equation}
\sum_{n\inn} Mn^{-\alpha }\text{ converge }
\end{equation}
Then by comparison test, we know
\begin{equation}
\sum_{n\inn} \abso{a_n}\text{ converge }
\end{equation}

\end{proof}

\section{HW4}

\begin{question}{}{}
Suppose that $\sum_{k=1}^{\infty} a_k$ 
converges and that 
$b_k \searrow b \text{ as } k \to \infty$. Prove that 
\begin{equation}
  \sum_{k=1}^{\infty} a_k b_k \text{ converges.}
\end{equation}
\end{question}
\begin{proof}
Define
\begin{equation}
b'_n:=b_n-b
\end{equation}
Deduce
\begin{align}
  \sum_{k=1}^\infty a_kb_k&=\sum_{k=1}^\infty a_k(b+b'_k)\\
  &=b\sum_{k=1}^\infty a_k+\sum_{k=1}^\infty a_kb'_k
\end{align}
Notice
\begin{equation}
b_k\searrow b\implies b_k'\searrow 0
\end{equation}
Then by Dirichlet's test, we know
\begin{equation}
\sum_{k=1}^\infty a_kb'_k\text{ converge }
\end{equation}
Because by premise $\sum_{k=1}^\infty a_k$ converge, we know $\sum_{k=1}^\infty a_kb_k=b\sum_{k=1}^\infty a_k+\sum_{k=1}^\infty a_kb'_k\text{ converge. }$


\end{proof}

\begin{question}{}{}
Show that under the hypotheses of Dirichletâ€™s test,
\[
\sum_{k=1}^{\infty} a_k b_k = \sum_{k=1}^{\infty} s_k (b_k - b_{k+1}),
\]
where 
\[
s_k = \sum_{j=1}^{k} a_j.
\]
\end{question}
\begin{proof}
Abel's formula give us
\begin{align}
\sum_{k=1}^na_kb_k&=\sum_{k=1}^n (s_{k}-s_{k-1})b_k\\
&=\sum_{k=1}^n s_kb_k-\sum_{k=1}^{n-1} s_kb_{k+1}\\
&=\sum_{k=1}^{n-1}s_k(b_k-b_{k+1})+s_nb_n
\end{align}
Define 
\begin{equation}
X_n:=\sum_{k=1}^n a_kb_k\text{ and }Y_n:=\sum_{k=1}^{n}s_k(b_k-b_{k+1})+s_nb_n
\end{equation}
We have deduced
\begin{equation}
\forall n,Y_n=X_{n+1}-s_nb_n
\end{equation}
Define
\begin{equation}
\alpha :=\lim_{n\to\infty}X_n 
\end{equation}
The question ask us to prove
\begin{equation}
\lim_{n\to\infty}Y_n=\alpha 
\end{equation}
The hypothesis of Dirichlet's test are 
\begin{equation}
 \lim_{n\to\infty}s_n=\sum_{k=1}^\infty a_n\text{ converge and }b_n\searrow 0
\end{equation}
Define 
\begin{equation}
\beta :=\lim_{n\to\infty}s_n
\end{equation}
Fix $\epsilon $. We know there exists $N$ such that 
 \begin{equation}
\forall n>N, s_n\in (\beta - \epsilon ,\beta +\epsilon )
\end{equation}
Which implies 
\begin{equation}
\forall n>N, \abso{s_n}<\max \set{\abso{\beta -\epsilon ,\beta +\epsilon }}
\end{equation}
Let $K=\max \set{\abso{\beta -\epsilon },\abso{\beta +\epsilon }}$. Because $b_n\searrow 0$, we also know there exists $N_1$ such that
 \begin{equation}
   \forall n>N_1, 0\leq b_n<\frac{\epsilon }{2K}
\end{equation}
Lastly, because $\lim_{n\to\infty}X_n=\alpha $ by definition, we know there exists $N_2$ such that 
\begin{equation}
\forall n>N_2, \abso{X_n-\alpha }<\frac{\epsilon }{2}
\end{equation}
Then we see
\begin{align}
  n>\max \set{N,N_1,N_2}\implies \abso{Y_n-\alpha }&=\abso{X_{n+1}-s_nb_n-\alpha }\\
&\leq \abso{X_{n+1}-\alpha }+\abso{s_nb_n}\\
&\leq \frac{\epsilon}{2}+\abso{s_n}\times \abso{b_n}\\
&\leq \frac{\epsilon}{2}+K\times \frac{\epsilon }{2K}=\epsilon 
\end{align}





\end{proof}
\begin{lemma}
\label{3.4.1}
Given $n$
\begin{equation}
  \sum_{k=1}^\infty x_k\text{ converge }\implies \sum_{k=n}^\infty x_k=\sum_{k=1}^\infty x_k-\sum_{k=1}^{n-1}x_k
\end{equation}
\end{lemma}
\begin{proof}
For all $u\inn$, define 
\begin{equation}
s_u:=\sum_{k=n}^{n+u}x_k\text{ and }v_u:=\sum_{k=1}^{u}x_k
\end{equation}
From definition, we have
\begin{equation}
  \forall u\inn,s_u=v_{n+u}-\sum_{k=1}^{n-1}x_k\text{ and }\lim_{u\to\infty}v_u\text{ converge }
\end{equation}
Notice 
\begin{equation}
\lim_{u\to\infty}v_{n+u}=\lim_{u\to\infty}v_u
\end{equation}
Then we have
\begin{equation}
\lim_{u\to\infty}s_u=\lim_{u\to\infty} (v_{n+u}-\sum_{k=1}^{n-1}x_k)=(\lim_{u\to\infty}v_{n+u})-\sum_{k=1}^{n-1}x_k=\lim_{u\to\infty}v_u-\sum_{k=1}^{n-1}x_k
\end{equation}
Which written in series is
\begin{equation}
\sum_{k=n}^{\infty} x_k=\sum_{k=1}^\infty x_k-\sum_{k=1}^{n-1}x_k
\end{equation}
\end{proof}
\begin{lemma}
\label{3.4.2}
\begin{equation}
\sum_{k=1}^\infty x_k\text{ converge }\implies \lim_{n\to\infty}\sum_{k=n}^\infty x_k=0
\end{equation}
\end{lemma}
\begin{proof} 
By \myref{Lemma}{1.4.1}, we have
\begin{align}
  \lim_{n\to\infty}\sum_{k=n}^\infty x_k&=\lim_{n\to\infty}\sum_{k=1}^\infty a_k-\sum_{k=1}^{n-1}a_k\\
  &=\sum_{k=1}^\infty a_k-\lim_{n\to\infty}\sum_{k=1}^{n-1}a_k\\
  &=\sum_{k=1}^\infty a_k-\sum_{k=1}^\infty a_k=0
\end{align}
\end{proof}
\begin{question}{}{}
Suppose that $\sum_{k=1}^{\infty} a_k $ converges, that $b_k \nearrow \infty \text{ and that }\sum_{k=1}^{\infty} a_k b_k $
converge. Prove
\begin{equation}
\lim_{m\to\infty}b_m\sum_{k=m}^\infty a_k=0
\end{equation}
\end{question}
\begin{proof}
Two strategies: 

Main: Prove
\begin{equation}
\lim_{m\to\infty}(b_k-b_m)\sum_{k=m}^\infty a_k=0
\end{equation}

Secondary: From
\begin{equation}
\lim_{n\to\infty}a_nb_n=0
\end{equation}

\end{proof}
\begin{question}{}{}
Suppose that \( a_k > 0 \) and 
\[
\sum_{k=1}^{\infty} a_k
\]
converges. Prove that there exist \( b_k \) such that 
\[
\lim_{k \to \infty} \frac{b_k}{a_k} = \infty
\]
and 
\[
\sum_{k=1}^{\infty} b_k
\]
converges.
\end{question}
\begin{proof}
Define
\begin{equation}
r_n:=\sum_{k=n}^\infty a_k
\end{equation}
Notice that if $r_n=0$ for some $n$, then we would have $\sum_{k=n}^\infty a_k=0$, which is impossible, because the sequence $\set{a_n}$ is positive.\\

Because $\set{a_k}$ is positive and \myref{Lemma}{3.4.2}, we know $r_n\searrow 0$.\\

Observe
\begin{equation}
\sqrt{r_n} -\sqrt{r_{n+1}}=\frac{r_n-r_{n+1}}{\sqrt{r_n} +\sqrt{r_{n+1}} }=\frac{a_n}{\sqrt{r_n} +\sqrt{r_{n+1}} }
\end{equation}
Define $\set{b_n}$ by
\begin{equation}
b_n:=\frac{a_n}{\sqrt{r_n} +\sqrt{r_{n+1}} }=\sqrt{r_n} -\sqrt{r_{n+1}} 
\end{equation}
Observe
\begin{equation}
\sum_{k=1}^\infty b_k=\sum_{k=1}^\infty \sqrt{r_k} -\sqrt{r_{k+1}}=\sqrt{r_1}  
\end{equation}
Notice 
\begin{equation}
\frac{b_n}{a_n}=\frac{1}{\sqrt{r_n} +\sqrt{r_{n+1}} }
\end{equation}
And deduce
\begin{equation}
r_n\searrow 0\implies \sqrt{r_n} \searrow 0\implies \frac{b_n}{a_n}=\frac{1}{\sqrt{r_n} +\sqrt{r_{n+1}} }\nearrow \infty
\end{equation}
\end{proof}
\begin{question}{}{}
Suppose that \( a_k > 0 \) and 
\[
\sum_{k=1}^{\infty} a_k
\]
diverges. Prove that there exist \( b_k \) such that 
\[
\lim_{k \to \infty} \frac{b_k}{a_k} = 0
\]
and 
\[
\sum_{k=1}^{\infty} b_k
\]
diverges.
\end{question}
\begin{proof}
Define
\begin{equation}
A_n:= \sum_{k=1}^n a_k
\end{equation}
And define
\begin{equation}
b_n:=\frac{a_n}{A_n}
\end{equation}
Notice that $\set{a_n}$ are positive and $\sum_{k=1}^\infty a_k$ diverges implies 
\begin{equation}
\lim_{n\to\infty}A_n=\sum_{k=1}^\infty a_k=\infty
\end{equation}
So we have
\begin{equation}
\lim_{n\to\infty}\frac{b_n}{a_n}=\lim_{n\to\infty}\frac{1}{A_n}=0
\end{equation}
We now show the following, which will be essential for proving $\sum_{k=1}^\infty b_k$ diverges.\\

Define
\begin{equation}
X^q_p:=\sum_{n=p}^q b_n
\end{equation}
Let $q>p$. Because  $\set{a_n}$ are positive, we have 
\begin{equation}
A_p<A_q
\end{equation}
This give us
\begin{equation}
X_p^q=\sum_{n=p}^q \frac{a_n}{A_n}\geq \sum_{n=p}^q \frac{a_n}{A_q}=\frac{A_q-A_{p-1}}{A_q}=1-\frac{A_{p-1}}{A_q}
\end{equation}
Then because $\lim_{n\to\infty}A_n=\infty$, we have
\begin{equation}
\forall p,\lim_{q\to\infty}X_p^q=\lim_{q\to\infty}1-\frac{A_{p-1}}{A_q}=1
\end{equation}
Let $\epsilon =\frac{1}{2}$, and define $p_1=1$. We now know there exists $p_2>p_1$ such that
\begin{equation}
\sum_{n=p_1}^{p_2-1} b_n= X_{p_1}^{p_2-1}>1-\epsilon =\frac{1}{2}
\end{equation}
Again, because $\forall p,\lim_{q\to\infty}X_p^q=1$, we know there exists $p_3>p_2$ such that
 \begin{equation}
\sum_{n=p_2}^{p_3-1} b_n=X_{p_2}^{p_3-1} >\frac{1}{2}
\end{equation}
Proceeding the argument above, we know there exists an increasing index sequence $\set{p_k}_{k\inn}$ such that 
\begin{equation}
\forall k,\sum_{n=p_k}^{p_{k+1}-1} b_k>\frac{1}{2}
\end{equation}
Then we have
\begin{equation}
\sum_{k=1}^\infty b_k=  \sum_{k=1}^\infty \sum_{n=p_k}^{p_{k+1}-1} b_k\geq \sum_{k=1}^\infty \frac{1}{2}=\infty
\end{equation}

\end{proof}

\begin{question}{}{}
Prove that 
\[
\sum_{k=1}^{\infty} a_k \cos(kx)
\]
converges for every \( x \in (0, 2\pi) \) and every \( a_k \searrow 0 \). What happens when \( x = 0 \)?
\end{question}
\begin{proof}
Let $x\in (0,2\pi)$, and let 
\begin{equation}
B_n=\sum_{k=1}^n \cos(kx)
\end{equation}
We wish to prove
\begin{equation}
\vi{\set{B_n}\text{ is bounded }}
\end{equation}
Deduce
\begin{align}
  \abso{B_n}=\abso{\sum_{k=1}^n \cos (kx)}&= \abso{\sum_{k=1}^n \text{ Re }e^{i(kx)}}\\
  &=\abso{\sum_{k=1}^n \text{ Re }(e^{ix})^k}\\
  &=\abso{\text{ Re }\sum_{k=1}^n (e^{ix})^k}\\
  &=\abso{\text{ Re }\frac{e^{ix}(1-e^{nix})}{1-e^{ix}}}\\
  &=\abso{\frac{e^{ix}(1-e^{nix})}{1-e^{ix}}}\\
  &\leq \frac{\abso{e^{ix}-e^{(n+1)ix}}}{\abso{1-e^{ix}}}\\
  &\leq \frac{\abso{e^{ix}}+\abso{e^{(n+1)ix}}}{\abso{1-e^{ix}}}\\
  &\leq \frac{2}{\abso{1-e^{ix}}}
\end{align}
Notice that because $x\in (0,2\pi)$, we know 
\begin{equation}
\abso{1-e^{ix}}>0
\end{equation}
so, informally speaking, $\set{\abso{B_n}}$ is bounded above by a real number $\frac{2}{\abso{1-e^{ix}}}$ instead of infinity. $\vdone$\\

Because $\set{B_n}$ is bounded, by Dirichlet's Test, we are done.\\

If $x=0$, it is possible that  $a_k=\frac{1}{k}$, and we will have
\begin{equation}
\sum_{k=1}^\infty a_k\cos(kx)=\sum_{k=1}^\infty a_k\text{ diverge when $a_k\searrow 0$ }
\end{equation}
\end{proof}

\begin{question}{}{}
Prove that 
\[
\sum_{k=1}^{\infty} a_k \sin((2k + 1)x)
\]
converges for every \( x \in \mathbb{R} \) and every \( a_k \searrow 0 \).
\end{question}
\begin{proof}
Notice that if 
\begin{equation}
x\equiv 0\text{ mod $\pi$}
\end{equation}
Then, we have 
\begin{equation}
\forall k,\sin(2k+1)x=0
\end{equation}
Then our proof is trivial. We only have to consider when 
\begin{equation}
x\not\equiv 0\text{ mod }\pi
\end{equation}
Observe
\begin{align}
  \abso{\sum_{k=1}^n \sin((2k+1)x)}&= \abso{\sum_{k=1}^n \text{ Im }e^{i(2k+1)x}}\\
  &=\abso{\text{ Im }\sum_{k=1}^n e^{i(2k+1)x}}\\
  &=\abso{\sum_{k=1}^n e^{i(2k+1)x}}\\
  &=\abso{\frac{e^{i3x}(1-e^{i2nx})}{1-e^{i2x}}}\\
  &\leq \frac{\abso{e^{i3x}}+\abso{e^{i(3x+2nx)}}}{\abso{1-e^{i2x}}}\\
  &\leq \frac{2}{\abso{1-e^{i 2x}}}
\end{align}
Because $x\not\equiv 0\text{ mod $\pi$}$, we know $\frac{2}{\abso{1-e^{i2x}}}$ exists.\\

We have proved the partial sums $\sum_{k=1}^n \sin((2k+1)x)$

\end{proof}

\begin{question}{}{}
Suppose that 
\[
\sum_{k=1}^{\infty} a_k^2
\]
and 
\[
\sum_{k=1}^{\infty} b_k^2
\]
converges. Prove that the following series
\begin{enumerate}
    \item \[
    \sum_{k=1}^{\infty} |a_kb_k|
    \]
    \item \[
    \sum_{k=1}^{\infty} (a_k + b_k)^2
    \]
    \item \[
    \sum_{k=1}^{\infty} \frac{|a_k|}{k}
    \]
\end{enumerate}
converge.
\end{question}
\begin{proof}
Notice 
\begin{equation}
0\leq (a_k-b_k)^{2}\implies a_kb_k\leq \frac{a_k^2+b_k^2}{2}
\end{equation}
and notice
\begin{equation}
0\leq (a_k-b_k)^2\implies -a_kb_k\leq \frac{a_k^2+b_k^2}{2}
\end{equation}
Above give us
\begin{equation}
\abso{a_kb_k}\leq \frac{a_k^2+b_k^2}{2}
\end{equation}
Clearly
\begin{equation}
\sum_{k=1}^\infty \frac{a_k^2+b_k^2}{2}\text{ converges }
\end{equation}
Then by comparison test, we know $\sum_{k=1}^\infty \abso{a_kb_k}$ converges.\\

Notice that
\begin{equation}
  0\leq (a_k+b_k)^2=a_k^2 +2a_kb_k+b_k^2 \leq a_k^2+2\abso{a_kb_k}+b_k^2 
\end{equation}
Because 
\begin{equation}
\sum_{k=1}^\infty a_k^2 +2\abso{a_kb_k}+b_k^2\text{ converges }
\end{equation}
By comparison test, we know 
\begin{equation}
\sum_{k=1}^\infty (a_k+b_k)^2 \text{ converges }
\end{equation}
\end{proof}

\begin{question}{}{}
Does the series
\[
\sum_{k=1}^{\infty} \frac{(-1)^k \ln(k + 1)}{k}
\]
converge? Does it converge absolutely? Justify your answer.
\end{question}
\begin{proof}
First notice
\begin{equation}
\frac{d}{dt}\frac{\ln (t+1)}{t} =\frac{\frac{t}{t+1}-t \ln (t+1)}{t^2}=\frac{1}{t}(\frac{1}{t+1}-\ln (t+1))
\end{equation}
Because 
\begin{equation}
\frac{1}{t+1}\searrow 0\text{ and }\ln (t+1)\nearrow \infty
\end{equation}
We know for large $k$, 
\begin{equation}
\frac{d}{dt}\frac{\ln (t+1)}{t} \bigg|_{t=k} =\frac{1}{k}(\frac{1}{k+1}-\ln (k+1))<0
\end{equation}
By fundamental theorem of calculus, 
\begin{equation}
\frac{\ln (k+2)}{k+1}-\frac{\ln (k+1)}{k}=\int_{k}^{k+1} \frac{d}{dt} \frac{\ln (t+1)}{t}dt>0\text{ for large $k$ }
\end{equation}
We now know 
\begin{equation}
\frac{\ln (k+1)}{k}\text{ monotonically decrease for large $k$}
\end{equation}
Notice that 
\begin{equation}
\lim_{k\to\infty} \frac{\ln (k+1)}{k}\stackrel{\mathrm{H}}{=}\lim_{k\to\infty} \frac{\frac{1}{k+1}}{1}=0
\end{equation}
We have proved $\frac{\ln (k+1)}{k}\searrow 0$ as $k\to\infty$. Then by Alternating Series Test, we know 
\begin{equation}
\sum_{k=1}^\infty (-1)^k \frac{\ln (k+1)}{k}\text{ converges }
\end{equation}
Notice 
\begin{equation}
\int \frac{\ln k}{k}dk=\frac{(\ln k)^2}{2}
\end{equation}
Then we have
\begin{equation}
\int_{1}^\infty \frac{\ln k}{k}dk= \frac{(\ln k)^2}{2}\bigg|_{k=1}^\infty =\infty 
\end{equation}
Notice that 
\begin{equation}
\frac{\ln k}{k}\leq \frac{\ln (k+1)}{k}\text{ for large $k$ }
\end{equation}
Then we know
\begin{equation}
\int_1^\infty \frac{\ln (k+1)}{k}dk =\infty
\end{equation}
By integral test, we now know 
\begin{equation}
\sum_{k=1}^\infty \abso{(-1)^k \frac{\ln (k+1)}{k}}=\ln 2+\sum_{k=2}^\infty \frac{\ln (k+1)}{k}\text{ diverges }
\end{equation}


\end{proof}

\begin{question}{}{}
Find all values of \( p \in \mathbb{R} \) that make the following series converge absolutely:
\[
\sum_{k=1}^{\infty} (-1)^k \frac{\ln(p^k)}{k}
\]
\end{question}
\begin{proof}
Notice 
\begin{equation}
  \sum_{k=1}^\infty \abso{(-1)^k \frac{\ln (p^k)}{k}}=\sum_{k=1}^\infty \ln p
\end{equation}
Then the series $\sum_{k=1}^\infty (-1)^k \frac{\ln (p^k)}{k}$ converge only when $\ln p=0$, which only happen when $p=e$. 
\end{proof}

\begin{question}{}{}
Let \( a_k \) and \( b_k \) be real sequences. Decide which of the following statements are true and which are false. Prove the true ones and give counterexamples to the false ones.

\begin{enumerate}
    \item If \( a_k \searrow 0 \) as \( k \to \infty \), and  $\sum_{k=1}^{\infty} b_k$ converges conditionally, then 
    \[
    \sum_{k=1}^{\infty} a_kb_k
    \]
    converges.
    
    \item If \( a_k \to 0 \) as \( k \to \infty \), then 
    \[
    \sum_{k=1}^{\infty} (-1)^k a_k
    \]
    converges.
    
    \item If \( a_k \to 0 \) as \( k \to \infty \), and \( a_k \geq 0 \) for all \( k \in \mathbb{N} \), then 
    \[
    \sum_{k=1}^{\infty} (-1)^k a_k
    \]
    converges.
    
    \item If \( a_k \to 0 \) as \( k \to \infty \), and 
    \[
    \sum_{k=1}^{\infty} (-1)^k a_k
    \]
    converges, then \( a_k \searrow 0 \) as \( k \to \infty \).
\end{enumerate}
\end{question}
\begin{proof}
From now, we let 
\begin{equation}
A_n=\sum_{k=1}^n a_n\text{ and }B_n=\sum_{k=1}^n b_n
\end{equation}
We claim
\begin{equation}
  \vi{a_k\searrow 0\text{ and }\sum_{k=1}^\infty b_k\text{ converges }\implies \sum_{k=1}^\infty a_kb_k\text{ converges }}
\end{equation}
Notice 
\begin{equation}
\sum_{k=1}^\infty b_k\text{ converges }\implies \exists L\inr, \lim_{n\to\infty}B_n=L
\end{equation}
Let $\epsilon =1$, we know there exists $N$ such that  
\begin{equation}
\forall n>N, B_n<L+1
\end{equation}
Then we see 
\begin{equation}
\forall k, B_k<\max \set{B_1+1,B_2+1,\dots ,B_{N}+1,L+1}
\end{equation}
Then by Dirichlet's Test, we are done. $\vdone$\\

Define
\begin{equation}
a_k=(-1)^k \frac{1}{k}
\end{equation}
We have
\begin{equation}
\lim_{k\to\infty}a_k=0\text{ and }\sum_{k=1}^\infty (-1)^k a_k=\sum_{k=1}^\infty (-1)^{2k}\frac{1}{k}=\sum_{k=1}^\infty \frac{1}{k}\text{ diverges }
\end{equation}
Define
\begin{equation}
a_k=\begin{cases}
\frac{1}{\sqrt{\lceil \frac{k}{2} \rceil }+1}& \text{ if $k$ is odd }\\
\frac{1}{\sqrt{\lceil \frac{k}{2} \rceil }-1 }& \text{ if $k$ is even }
\end{cases}
\end{equation}
The sequence we have is
\begin{equation}
a_1=\frac{1}{\sqrt{2} -1},a_2=\frac{1}{\sqrt{2} +1},a_3=\frac{1}{\sqrt{3} -1},a_4=\frac{1}{\sqrt{3} +1},a_5=\frac{1}{\sqrt{4} -1},\dots
\end{equation}
Because 
\begin{equation}
\lim_{k\to\infty} \lceil \frac{k}{2}\rceil =\infty
\end{equation}
We have
\begin{equation}
\lim_{k\to\infty} a_k=0
\end{equation}
Clearly, $\forall k,a_k\geq 0$. Define
\begin{equation}
B_n:=\sum_{k=1}^n (-1)^k a_k
\end{equation}
Notice
\begin{equation}
B_{2n}=\sum_{k=1}^n \frac{1}{\sqrt{k+1}+1}+\frac{1}{\sqrt{k+1} -1}=\sum_{k=1}^n \frac{2}{k}
\end{equation}
Then we have
\begin{equation}
\lim_{n\to\infty}B_{2n}=\sum_{k=1}^n \frac{2}{k}\text{ diverge }
\end{equation}
This tell us
\begin{equation}
\sum_{n=1}^\infty (-1)^n a_n=\lim_{n\to\infty}B_{2n}\text{ diverge }
\end{equation}
otherwise the sub-sequence $\lim_{n\to\infty}B_{2n}$ would have converge.




\end{proof}

\end{document}

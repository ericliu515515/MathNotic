
\documentclass{report}
\input{preamble}
\input{macros}
\input{letterfonts}
\usepackage{mathtools}

% Suppress tags for all equations
\mathtoolsset{showonlyrefs}

\title{\Huge{NCKU 112.1}\\Probability}
\author{\huge{Eric Liu}}
\date{}
\begin{document}
\maketitle
\newpage 
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak
\setcounter{chapter}{-1}
\chapter{Probability Space}
\section{Basic Definition for Background Space}
\begin{definition}
\label{0.1.1}
\textbf{(Definition of $\sigma$-Algebra)} We say  $(\Omega,\mathcal{G}\subseteq\power{\Omega})$ is a $\sigma$-algebra if 
\begin{equation}
\Omega \in\mathcal{G}
\end{equation}
\begin{equation}
X \in \mathcal{G}\implies \Omega \setminus X\in \mathcal{G} \text{ (Closed under complement) }
\end{equation}
\begin{equation}
\mathcal{A} \subseteq  \mathcal{G}\text{ and }\abso{\mathcal{A}}\leq \abso{\N}\implies \bigcup \mathcal{A}\in \mathcal{G}\text{ (Closed under countable union) }
\end{equation}
From now, we denote $\Omega\setminus X$ by $X^c$. We say $\mathcal{G}=\set{\varnothing,\Omega}$ is the trivial $\sigma$-algebra on $\Omega$. 
\end{definition}
\begin{theorem}
\label{0.1.2}
\textbf{(Basic Property of $\sigma$-Algebra)} Let $(\Omega,\mathcal{G})$ be a $\sigma$-algebra. Then we have
\begin{equation}
\varnothing \in \mathcal{G}
\end{equation}
\begin{equation}
\mathcal{A}\subseteq \mathcal{G}\implies \bigcap \mathcal{A} \in \mathcal{G}
\end{equation}
\begin{equation}
A,B\in \mathcal{G}\implies A\setminus B \in \mathcal{G}
\end{equation}
\end{theorem}
\begin{proof}
Observe $\varnothing=\Omega^c$, and observe $\bigcap \mathcal{A}=(\bigcup_{X \in \mathcal{A}}X^c)^c$, and observe $A\setminus B=A\cup B^c$
\end{proof}
\begin{lemma}
\label{0.1.3}
\textbf{(Intersection of $\sigma$-Algebras is a $\sigma$-Algebra)} Let $S$ be a set of $\sigma$-algebra over $\Omega$, then $\bigcap S$ is a $\sigma$-algebra. 
\end{lemma}
\begin{proof}
  $\Omega\in \bigcap S$ is trivial. Observe $A\in \bigcap S\implies  \forall \mathcal{G}\in S, A\in \mathcal{G}\implies \forall \mathcal{G}\in S, A^c\in \mathcal{G}\implies A^c \in\bigcap S$. Observe $\mathcal{A}\subseteq \bigcap S\text{ and }\abso{\mathcal{A}}\leq \abso{\N}\implies \forall\mathcal{G}\in S, \mathcal{A}\subseteq \mathcal{G}\implies \forall \mathcal{G}\in S, \bigcup \mathcal{A} \in\mathcal{G}\implies \bigcup A\in \bigcap S$.
\end{proof}
\begin{definition}
\label{0.1.4}
\textbf{(Definition of Generating $\sigma$-Algebra)} Let $\mathcal{F}\subseteq \power{\Omega}$. The $\sigma$-algebra generated by $\mathcal{F}$ is defined to be the smallest  $\sigma$-algebra that contain $\mathcal{F}$
\end{definition}
\fbox{\begin{minipage}{39em}
We have now gave enough tools to generate $\sigma$-algebra. 
\end{minipage}}
\fbox{\begin{minipage}{39em}
The following concern a class of measure space, called probability space.
\end{minipage}}
\begin{definition}
\label{0.1.5}
  \textbf{(Definition of Measure)} Let $\mathcal{G}$ be a $\sigma$-algebra over $\Omega$. Function $\mu:\mathcal{G}\rightarrow \R$ is called a measure if
\begin{equation}
\forall E\in \mathcal{G}, \mu(E)\geq 0\text{ (Nonnegative) }
\end{equation}  
\begin{equation}
\mu(\varnothing)=0
\end{equation}
\begin{equation}
\mathcal{F}\subseteq \mathcal{G}\text{ and }\abso{\mathcal{F}}\leq \abso{\N}\text{ and }\mathcal{F}\text{ is disjoint }\implies \mu(\bigcup  \mathcal{F})=\sum_{X\in \mathcal{F}} \mu(X)\text{ ($\sigma$ additivity) }
\end{equation}
\end{definition}
\begin{theorem}
\label{0.1.6}
\textbf{(Intended Property of Measure)} We have
\begin{equation}
A\subseteq B\in \mathcal{F}\implies \mu(A)\leq  \mu(B)
\end{equation}
\end{theorem}
\begin{proof}
Observe $\mu(B)=\mu(A\cup (B\setminus A))=\mu(A)+\mu (B\setminus A)\implies \mu(B)-\mu(A)=\mu(B\setminus A)\geq 0$
\end{proof}
\begin{definition}
\label{0.1.7}
\textbf{(Definition of Probability Measure)} A probability measure $P$ is a measure that satisfy $P(\Omega)=1$ 
\end{definition}
\begin{definition}
\label{0.1.8}
\textbf{(Definition of Probability Space)} A probability space is a triple $(\Omega,\mathcal{\mathcal{G}},P)$ where 
\begin{equation}
\Omega \text{ is a set called \textit{sample space} }
\end{equation}
\begin{equation}
\mathcal{G} \text{ is a $\sigma$-algebra over $\Omega$ called event space}
\end{equation}
\begin{equation}
P:\mathcal{G}\rightarrow [0,1]\text{ is a measure called probability measure }
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
Basically, probability measure "measure" the probability an event will happen. Normally we don't measure the probability a sample will happen, since it is undoable in some cases, for instance, shooting a dart to an infinite set. We only measure the probability that the outcome sample is in a set of certain samples, where the assignment of measure is outside of the system.   
\end{minipage}}


\fbox{\begin{minipage}{39em}
A simple example of a $\sigma$-algebra is
\begin{equation}
\Omega_2=\set{HH,HT,TH,TT},\mathcal{G}=\set{\varnothing,X,\set{HT,HH},\set{TH,TT}}
\end{equation}

Notice in this example, $\Omega$ is ought to be interpreted as tossing two coins and $\mathcal{G}$ is to observe the first coin is head or tail.\\

To expand the first example, we have another simple example:
\begin{equation}
\Omega_3=\set{HHH,HHT,HTH,HTT,THH,THT,TTH,TTT}
\end{equation}
Define
\begin{equation}
A_H:=\set{HHH,HHT,HTH,HTT}\text{ and }A_T:=\set{THH,THT,TTH,TTT}
\end{equation}
which is the information of tossing head or tail on first try.\\

Notice $A_T=A_H^c$. Define
\begin{equation}
A_{HH}:=\set{HHH,HHT}\text{ and }A_{HT}:=\set{HTH,HTT}
\end{equation}
\begin{equation}
A_{TH}:=\set{THH,THT}\text{ and }A_{TT}:=\set{TTH,TTT}
\end{equation}
so we have
\begin{equation}
A_H=A_{HH}\cup A_{HT}\text{ and }A_T=A_{TH}\cup A_{TT}
\end{equation}
Then we can define 
\begin{equation}
\mathcal{G}:= \set{\bigcup N: N\in \power{M}}
\end{equation}
where  $M=\set{A_{HH},A_{HT},A_{TH},A_{TT}}$\\

Notice we can define four $\sigma$-algebras by
\begin{equation}
\mathcal{F}_0=\set{\varnothing,\Omega},\mathcal{F}_1=\set{\varnothing,\Omega,A_T,A_H},\mathcal{F}_2=\mathcal{G},\mathcal{F}_3=\power{\Omega}
\end{equation}
then we have
\begin{equation}
\mathcal{F}_0\subset \mathcal{F}_1\subset \mathcal{F}_2 \subset \mathcal{F}_3
\end{equation}

The following concern Borel $\sigma$-algebra
\end{minipage}}
\begin{definition}
\label{0.1.9}
\textbf{(Definition of a Random Variable)} We say the function from $\Omega$ to $\R$ is a random variable, and often a random variable is defined on a fixed probability space, since the usage of random variable are mostly associated with a probability measure. 
\end{definition}
\fbox{\begin{minipage}{39em}
We now define 3 random variable for example from the last example of $\sigma$-algebra.\\

Let $S_0,u,d\inr^+$ and let $d<1<u$. We define three random variables $S_1,S_2,S_3$ on $\Omega_3$
 \begin{equation}
S_1(\omega)= \begin{cases}
  uS_0& \text{ if $\omega \in A_H$ }\\
  dS_0& \text{ if $\omega\inA_T$ }
\end{cases}S_2(\omega)=\begin{cases}
  u^2S_0& \text{ if $\omega\in A_{HH}$ }\\
  udS_0& \text{ if $\omega\in A_{HT}\cup A_{TH}$ }\\
  d^2S_0& \text{ if $\omega\in A_{TT}$ }
\end{cases}
\end{equation}
\begin{equation}
S_3(\omega)=\begin{cases}
  u^3S_0& \text{ if $\omega\in \set{HHH}$ }\\
  u^2dS_0& \text{ if $\omega\in \set{HHT,HTH,THH}$ }\\
  ud^2S_0& \text{ if $\omega\in \set{HTT,THT,TTH}$ }\\
  d^3S_0& \text{ if $\omega\in \set{TTT}$ }
\end{cases}
\end{equation}
Often, we just use $S$ to denote  $S(\omega)$. 
\end{minipage}}
\begin{definition}
\label{0.1.10}
\textbf{(Definition of Borel-Algebra)} The Borel-Algebra on $\R$, which we denote  $\mathcal{B}(\R)$ is the $\sigma$-algebra generated by all open interval of $\R$.\\

Some members of $\mathcal{B}(\R):$ 
 \begin{equation}
   (b,a),(a,\infty),\R
\end{equation}
\begin{equation}
  (b,a]=(b,\infty)\setminus (a,\infty)
\end{equation}
\begin{equation}
[a,\infty)=\R\setminus (-\infty, a) 
\end{equation}
\begin{equation}
[a,b]=[a,\infty)\setminus (b,\infty) 
\end{equation}
\begin{equation}
\set{a}=\R \setminus (-\infty, a)\cup (a,\infty)
\end{equation}
\end{definition}
\begin{theorem}
\label{0.1.11}
\textbf{(Construct  $\sigma$-Algebra with Random Variable)} Let $X$ be a random variable on  $\Omega$. We define
\begin{equation}
X^{-1}[B]=\set{\omega \in \Omega : X(\omega)\in B}
\end{equation}
and define the $\sigma$-algebra $\sigma(X)$ by
\begin{equation}
\sigma(X)=\set{X^{-1}[B]:B\in\mathcal{B}(\R)}
\end{equation}
We can verify $\sigma(X)$ is a $\sigma$-algebra.
\end{theorem}
\begin{proof}
Notice $\Omega= X^{-1}[\R]\in \sigma(X)$. Observe $(X^{-1}[B])^c=X^{-1}[B^c]\in \sigma (X)$. Let $C=\set{X^{-1}[B]:B\in \cc}\subseteq \sigma$ be countable. Observe  $\bigcup_{B\in C}X^{-1}[B]=X^{-1}[\bigcup_{B\in\cc }B]\in \sigma(X)$ 
\end{proof}
\fbox{\begin{minipage}{39em}
Notice $\sigma(S_1)=\mathcal{F}_1,\sigma(S_2)\neq \mathcal{F}_2,\sigma(S_3)\neq \mathcal{F}_3$.\\

Normally, we write $P(X=x_i)$ to denote $P(X^{-1}[x_i])$
\end{minipage}}
\begin{theorem}
\label{0.1.12}
\textbf{(Induce Measure on Borel Algebra by a Random Variable and a Probability Space)} Let $(\Omega,\mathcal{F},P:\mathcal{F}\rightarrow \R)$ be a probability space and $X:\Omega\rightarrow \R$ be a random variable. We can induce a measure on  $\mathcal{B}(\R)$ (we say this measure is induced by $X$ and  $P$)
\begin{equation}
  \mathcal{L}_X:\mathcal{B}(\R)\rightarrow \R, B\mapsto P(X^{-1}[B])
\end{equation}
\end{theorem}
\begin{proof}
Because $P$ is nonnegative, we know  $\mathcal{L}_X$ is nonnegative. Notice that $X^{-1}[\varnothing]=\varnothing$, so we know $\mathcal{L}_X(\varnothing)=P(\varnothing)=0$. Let $\mathcal{A}\subseteq \mathcal{B}(\R)$ and $\mathcal{A}$ be countable and disjoint. We have
\begin{align}
\mathcal{L}_X(\bigcup \mathcal{A})&=P(X^{-1}[\bigcup \mathcal{A}])\\
&=P(\bigcup \mathcal{C})\text{ where $\cc=\set{X^{-1}[a]:a \in \mathcal{A}}$ }\\
&=\sum_{c \in \cc} P(c)\\
&=\sum_{a \in \mathcal{A}}P(X^{-1}[a])=\sum_{a\in\mathcal{A}}\mathcal{L}_X(a)
\end{align} 
Notice that $\cc$ is countable because $\mathcal{A}$ is countable, and $\cc$ is disjoint because $x\in X^{-1}[a]\cap X^{-1}[b]\implies X(x)\in a\cap b$.
\end{proof}
\begin{definition}
\label{0.1.13}
\textbf{(Definition of Cumulative Distribution Function)} We say $F_X:\R\rightarrow \R$ is the cumulative distribution function of  $X$ if
 \begin{equation}
   F_X(x)=\mathcal{L}_X((-\infty, x])=P(X^{-1}[(-\infty,x]])
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}

Distribution function is a function on the image of a random variable $X$, that map a real number to the probability the random variable $X$ is the real number $x_1$. How? Probability is the measure of the set that can be mapped to $x_1$. \\

In a more formal language, the random variable doesn't specify the probability of each event, but the one does, probability measure is often implicitly given by the random variable.
\end{minipage}}
\\
\fbox{\begin{minipage}{39em}
We now use the random variable $S_3:\Omega \rightarrow \R $ on $(\Omega,\mathcal{F},P:\power{\Omega}\rightarrow \R)$ to serve as an example of induced measure and cumulative distribution function.\\

Notice that the range of $S_3$ is $\set{d^3S_0<d^2uS_0<du^2S_0<u^3S_0}$. We have 
\begin{equation} F_{S_3}(d^3S_0)=\mathcal{L}_{S_3}((-\infty,d^3S_0])=P(S_3^{-1}[(-\infty,d^3S_0]])=P(\set{TTT})
\end{equation}
\begin{equation} F_{S_3}(d^2uS_0)=\mathcal{L}_{S_3}((-\infty,d^2uS_0])=P(S_3^{-1}[(-\infty,d^2uS_0]])=P(\set{TTT,TTH,THT,HTT})
\end{equation}
\begin{equation} F_{S_3}(du^2S_0)=\mathcal{L}_{S_3}((-\infty,du^2S_0])=P(S_3^{-1}[(-\infty,du^2S_0]])=P(\Omega \setminus \set{HHH} )
\end{equation}
\begin{equation} F_{S_3}(u^3S_0)=\mathcal{L}_{S_3}((-\infty, u^3S_0])=P(S_3^{-1}[(-\infty,u^3S_0]])=P(\Omega)
\end{equation}
With above deduction, we can precisely deduce
\begin{equation}
F_{S_3}(x)=\begin{cases}
  0& \text{ if  }x<d^3S_0\\
  P(\set{TTT})& \text{ if  }d^3S_0\leq x<d^2uS_0\\
  P(\set{TTT,TTH,THT,HTT})& \text{ if  }d^2uS_0\leq x<du^2S_0\\
  P(\Omega \setminus \set{HHH})& \text{ if  }du^2S_0\leq x<u^3S_0\\
  P(\Omega)& \text{ if  }u^3S_0\leq x
\end{cases}
\end{equation}
Notice that we can define measure $P$ in multiple ways, and then we will have different induced measures $\mathcal{L}_{S_3}$ and different cumulative distribution function $F_{S_3}(x)$. For instance, one can check that $P:\power{\Omega}=\mathcal{F}_3\rightarrow \R,X\mapsto \frac{\abso{X}}{8}$ is a measure, and $P:\mathcal{F}_3\rightarrow \R,X\mapsto \sum_{x\in X}f(x)$ where $f$ is defined by $\omega_1\omega_2\omega_3\mapsto \frac{2^i}{3^3}: i=\abso{\set{\omega_j:\omega_j=T,j=1,2,3}}$ are all measures, but the former is 
\begin{equation}
F_{S_3}(x)=\begin{cases}
  0& \text{ if  }x<d^3S_0\\
  \frac{1}{8}& \text{ if  }d^3S_0\leq x<d^2uS_0\\
  \frac{1}{2}& \text{ if  }d^2uS_0\leq x<du^2S_0\\
  \frac{7}{8}& \text{ if  }du^2S_0\leq x<u^3S_0\\
  1& \text{ if  }u^3S_0\leq x
\end{cases}
\end{equation}
and the latter is
\begin{equation}
F_{S_3}(x)=\begin{cases}
  0& \text{ if  }x<d^3S_0\\
  \frac{8}{27}& \text{ if  }d^3S_0\leq x<d^2uS_0\\
  \frac{8}{27}+\binom{3}{1}\frac{4}{27}& \text{ if  }d^2uS_0\leq x<du^2S_0\\
  \frac{8}{27}+\binom{3}{1}\frac{4}{27}+\binom{3}{2}\frac{2}{27}& \text{ if  }du^2S_0\leq x<u^3S_0\\
  1& \text{ if  }u^3S_0\leq x
\end{cases}
\end{equation}
\end{minipage}}
\section{Binomial Asset Pricing Model}
\begin{definition}
\label{0.2.1}
\textbf{(Definition of Stochastic Process)} Given a common probability space $(\Omega,\mathcal{F},P:\mathcal{F}\rightarrow \R)$, we say an indexed family of random variables defined on our given probability space is a stochastic process, denoted
\begin{equation}
\set{X_t:t\in \Lambda,\omega \in \Omega}
\end{equation}
where the index set $\Lambda$ is called time horizon. So, if someone say $X$ is a stochastic process, we can say $X_t$ is a random variable, and we can say  $X(t,\omega)=X_t(\omega)\in \R$.\\

Additionally, we say $\Omega$ is "background space" and $\Lambda \times \R$, where we can draw a trajectory to record the sequence of outcome, is "foreground space" or "configuration space", and we say $\Theta=\set{X(t,\omega):t \in \Lambda, \omega \in \Omega}$ is the "state space" that contains "state of process"\\

The "frequency" of a state of the process $X(t,\omega)$ is ?
\end{definition}
\fbox{\begin{minipage}{39em}
We now give an example of stochastic process. Let $\Omega=\set{H,T}$ and $\Lambda = [0,2]$. The stochastic process if the indexed set $\set{X_t:t\in \Lambda}$ of random variables specified by
\begin{equation}
X_t(H)=\sin(2\pi t)\text{ and }X_t(T)=\sin(4\pi t)
\end{equation}
Then 
\begin{equation}
\Theta=[-1,1]
\end{equation}
Another example is: Let $\Lambda=\set{1,2,3,4,5}$ and let $\Omega=\set{(\omega_1,\omega_2,\omega_3,\omega_4,\omega_5):\forall i\in \Lambda, \omega_i\in \set{H,T}}$. The configuration space is then $\set{1,2,3,4,5}\times \R$, and we can specify the stochastic process $\set{S_t:t \in \Lambda}$ by
\begin{equation}
S_t((\omega_1,\omega_2,\omega_3,\omega_4,\omega_5))=u^id^{t-i}S_0: i=\abso{\set{\omega_j: 1\leq j\leq t,\omega_j= H}}
\end{equation}
Then 
\begin{equation}
\Theta= \set{u^id^jS_0:i,j\in \N\cup \set{0},1\leq i+j\leq 5} 
\end{equation}
\end{minipage}}
\\
\fbox{\begin{minipage}{39em}
To buy an option from someone means acquiring the right, but not the obligation, to purchase a stock at a predetermined price, $K$. This comes with an associated cost called the ``risk premium'' or $V_0$, which is paid at the time of the transaction.\\

Notice when we say net earn or profit, we are comparing his money with and without making the deal.\\

If the stock ends up at price $S_1(\omega)$  lower than $K$, the buyer won't buy the stock at the price $K$, so for seller, he profit $V_0$.\\

If the stock ends up at price $S_1(\omega)$ higher than  $K$, then the seller net earn:  $-(S_1(\omega)-K)+V_0$\\

Now, we consider the profit we can make for depositing money into bank and get interest. The interest rate is $r$.\\


If the stock ends up at price $S_1(\omega)$ lower than $K$, the buyer won't buy the stock at the price $K$, so for seller, he profit $(1+r)V_0$.\\

If the stock ends up at price $S_1(\omega)$ higher than  $K$, then the seller net earn:  $-(S_1(\omega)-K)+(1+r)V_0$\\

Now, we wish to lower the risk so we buy $\Delta_0$ share of the stock we short at price $S_0$ to form a portfolio.\\

If the stock ends up at price $S_1(\omega)$ lower than $K$, the buyer won't buy the stock at the price $K$, so for seller, he profit $(1+r)V_0+\Delta_0(S_1(\omega)-(1+r)S_0)$.\\

If the stock ends up at price $S_1(\omega)$ higher than  $K$, then the seller net earn:  $-(S_1(\omega)-K)+(1+r)V_0+\Delta_0(S_1(\omega)-(1+r)S_0)$\\

\end{minipage}}

\fbox{\begin{minipage}{39em}
From now, we denote the value of the option at time $t$
\begin{equation}
V_t(\omega):=\max \set{S_t(\omega)-K,0}
\end{equation}
So we can say the value of our portfolio $X_t(\omega)$, our action of selling the option and buy the stock, at time $1$ is 
\begin{equation}
X_1(\omega)=-V_1(\omega)+(1+r)V_0+\Delta_0(S_1(\omega)-(1+r)S_0)
\end{equation}
Now we wish, for all $\omega$, we have $X_1(\omega)\geq 0$, by negotiating with the buyer on $V_0$ and deciding how many share  $\Delta_0$ we want to buy.\\

Notice that if we negotiate $V_0$ at
 \begin{equation}
V_0:=\frac{1}{1+r}[\frac{1+r-d}{u-d}V_1(H)+\frac{u-(1+r)}{u-d}V_1(T)]
\end{equation}
and buy share $\Delta_0$
\begin{equation}
\Delta_0:= \frac{V_1(H)-V_1(T)}{S_1(H)-S_1(T)}
\end{equation}
We see 
\begin{multline}
X_1(H)=-V_1(H)+(1+r)\frac{1}{1+r}[\frac{1+r-d}{u-d}V_1(H)+\frac{u-(1+r)}{u-d}V_1(T)]\\ 
+\frac{V_1(H)-V_1(T)}{S_1(H)-S_1(T)}(S_1(H)-(1+r)S_0)
\end{multline}
equals $0$ by substituting  $S_1(H)\text{ and }S_1(T)$ with $S_0u\text{ and }S_0d$
\end{minipage}}
\chapter{Discrete Random Variable}
\section{Basic Discrete Random Variable and Their Expected Values and Variance}
\begin{definition}
\label{1.1.1}
\textbf{(Definition of Discrete Random Variable and Probability Mass Function)} Let $(\Omega,\mathcal{F},P:\mathcal{F}\rightarrow \R)$ be a probability space. We say a random variable $X:\Omega\rightarrow \R $ is a discrete random variable, if 
\begin{equation}
  X[\Omega]\text{ if countable }
\end{equation}
and we define the probability mass function $p_X$ as
\begin{equation}
p_X(r)=P(X=r)
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
In this section, $X$ is always a discrete random variable.
\end{minipage}}
\begin{theorem}
\label{1.1.2}
\textbf{(Property of Probability Mass Function)} Let $X[\Omega]=\set{x_1, \dots }$. We have
\begin{equation}
P(a\leq X\leq b)=\sum_{x_i\in [a,b]}p_X(x_i)
\end{equation}
This reads: The probability $X$ is in  $[a,b]$ equals the sum of the probability $X$ is a number in  $[a,b]$
\end{theorem}
\begin{theorem}
\label{1.1.3}
\textbf{(Property of Probability Mass Function)} We have
\begin{equation}
\sum_{x_i \in \R} p_X(x_i)=1
\end{equation}
\end{theorem}
\fbox{\begin{minipage}{39em}
Now we introduce expected value. 
\end{minipage}}
\begin{definition}
\label{1.1.4}
\textbf{(Definition of Expected Value)} We say the expected value of $X$ is 
 \begin{equation}
E(X)=\sum x_ip(x_i)
\end{equation}
If possible, normally we write
\begin{equation}
\mu = E(X)
\end{equation}
\end{definition}
\begin{theorem}
\label{1.1.5}
\textbf{(Expected Value)} For function $g:\R\rightarrow \R$, we have
\begin{equation}
E(g\circ X)=\sum g(x_i)p(x_i)
\end{equation}
\end{theorem}
\begin{theorem}
\label{1.1.6}
\textbf{(Linearity of Expected Value of Discrete Random Variable)} We have
\begin{equation}
E(\alpha _1 X_1 +\alpha_2 X_2)=\alpha_1 E(X_1)+\alpha _2 E(X_2)
\end{equation}
\end{theorem}
\fbox{\begin{minipage}{39em}
We now introduce variance.
\end{minipage}}
\begin{definition}
\label{1.1.7}
\textbf{(Definition of Variance)} We define variance of $X$ to be
\begin{equation}
\var (X):=E((X-\mu)^2)
\end{equation}
If possible, normally we write
\begin{equation}
  \sigma(X):=\sqrt{\var (X)}
\end{equation}
\end{definition}
\begin{theorem}
\label{1.1.8}
\textbf{(Calculation of Variance)} We have
\begin{equation}
\var (X)=E(X^2)-\mu^2
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
\var (X)&=E[(X-\mu^2)]\\
&=E[X^2-2\mu X +\mu^2]\\
&=E[X^2]-2\mu E[X]+\mu^2\\
&=E[X^2]-\mu^2
\end{align}
\end{proof}
\begin{theorem}
\label{1.1.9}
\textbf{(Variance)} We have
\begin{equation}
\var [\alpha_1 X_1]=\alpha _1^2\var [X_1]
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
\var [\alpha _1 X_1]&=E[(\alpha _1X_1)^2]-E[\alpha _1X_1]^2\\
&=\alpha _1^2E[X_1^2]-\alpha _1^2E[X_1]^2\\
&=\alpha _1^2 (E[X_1^2]-E[X_1]^2)=\alpha _1^2 \var [X_1]
\end{align}
\end{proof}
\fbox{\begin{minipage}{39em}
We now introduce Bernoulli random variable.
\end{minipage}}
\begin{definition}
\label{1.1.10}
\textbf{(Definition of Bernoulli Random Variable)} Let $A$ be an event and $P(A)=p$. We define
\begin{equation}
I_A(\omega)=\begin{cases}
  1& \text{ if  }\omega \in A\\
  0& \text{ if  }\omega\not\in A
\end{cases}
\end{equation}
\end{definition}
\begin{theorem}
\label{1.1.11}
\textbf{(Properties of Bernoulli Random Variable)} We have
\begin{gather}
P(I_A=1)=p \text{ and }P(I_A=0)=1-p\\ 
E[I_A]=p\\
\var [I_A]=p(1-p)
\end{gather}
\end{theorem}
\begin{proof}
\begin{equation}
\var [I_A]=E[I_A^2]-E[I_A]^2=1^2p-p^2=p-p^2=p(1-p)
\end{equation}
\end{proof}
\begin{definition}
\label{1.1.12}
\textbf{(Definition of Binomial Random Variable)} We say the binomial random variable $B_{n,p}$ is the number of success in $n$ independent trials, each of which is a success with probability $p$. We have
\begin{equation}
P(B_{n,p}=x)=\binom{n}{x}p^x (1-p)^{n-x}
\end{equation}
\end{definition}
\begin{theorem}
\label{1.1.13}
\textbf{(Properties of Binomial Random Variable)} We have
\begin{equation}
E[B_{n,p}]=np \text{ and }\var [B_{n,p}]= np(1-p)
\end{equation}
\end{theorem}
\begin{proof} 
\begin{equation}
E[B_{n,p}]=E[\sum I_A]=\sum E[I_A]=np
\end{equation}
That of variance is left unproved. 
\end{proof}
\fbox{\begin{minipage}{39em}
Now we introduce the notion of Poisson random variable.
\end{minipage}}
\begin{definition}
\label{1.1.14}
  \textbf{(Definition of Poisson Random Variable)} For $\ld >0$, we define Poisson random variable $X_{\ld }$ by
  \begin{equation}
  P(X_\ld =i)=\frac{\ld ^i}{i!}e^{-\ld }
  \end{equation}
\end{definition}
\begin{theorem}
\label{1.1.15}
\textbf{(Verification of Poisson Random Variable)} Let $X$ be a Poisson random variable with parameter $\ld $. We verify
\begin{equation}
\sum_{k=0}^\infty P(X=k)=1
\end{equation}
\end{theorem}
\begin{proof}
\begin{equation}
\sum _{k=0}^{\infty}P(X=k)= \sum_{k=0}^{\infty}\frac{\ld ^k}{k!}e^{-\ld }=e^{-\ld }\sum _{k=0}^{\infty}\frac{\ld ^k}{k!}=e^{-\ld }e^{\ld }=1
\end{equation}
\end{proof}
\begin{theorem}
\label{1.1.16}
\textbf{(Expectation Value of Poisson Random Variable)} Let $X$ be a Poisson random variable with parameter $\ld $. We have
\begin{equation}
E[X]=\ld 
\end{equation}
\end{theorem}
\begin{proof}
Compute
\begin{align}
E[X]&=\sum_{k=0}^\infty kP(x=k)\\
&=\sum_{k=0}^\infty ke^{-\ld }\frac{\ld ^k}{k!}\\
&=e^{-\ld }\sum_{k=0}^\infty k \frac{\ld ^k}{k!}\\
&=e^{-\ld}\sum_{k=1}^\infty k\frac{\ld ^k}{k!}\\
&=e^{\ld }\sum_{k=1}^\infty \ld  \frac{\ld ^{k-1}}{(k-1)!}\\
&=e^{\ld }\ld\sum_{u=0}^\infty \frac{\ld ^u}{u! }\\
&=\ld e^{\ld }e^{-\ld }=\ld 
\end{align}
\end{proof}
\begin{theorem}
\label{1.1.17}
\textbf{(Variance of Poisson Random Variable)} Let $X$ be a Poisson random variable with parameter $\ld $. We have
\begin{equation}
\var [X]=\ld 
\end{equation}
\end{theorem}
\begin{proof}
Compute 
\begin{align}
E[X^2]&=\sum_{k=0}^\infty k^2P(x=k)\\
&=\sum_{k=0}^\infty k^2e^{-\ld }\frac{\ld^k}{k!}\\
&=e^{-\ld } \sum_{k=1}^\infty k^2 \frac{\ld ^k}{k!}\\
&=\ld e^{-\ld }\sum_{k=1}^\infty k \frac{\ld^{k-1}}{(k-1)!}\\
&=\ld e^{-\ld }[\sum_{k=1}^\infty (k-1)\frac{\ld ^{k-1}}{(k-1)!}+\sum_{k=1}^\infty \frac{\ld ^{k-1}}{(k-1)!}]\\
&=\ld  e^{-\ld}[\sum_{k=2}^\infty (k-1) \frac{\ld ^{k-1}}{(k-1)!}+\sum_{k'=0}^\infty \frac{\ld ^{k'}}{k'!}]\\
&=\ld e^{-\ld }[\sum_{k=2}^\infty \ld \frac{\ld ^{k-2}}{(k-2)!}+e^{\ld }]\\
&=\ld e^{-\ld }[\ld \sum_{k=0}^\infty \frac{\ld ^k}{k!}+e^\ld ]\\
&=\ld e^{-\ld }[\ld e^{\ld }+e^{\ld }]\\
&=\ld (\ld +1)
\end{align}
So we have
\begin{equation}
\var [X]=E[X^2]-E[X]^2=\ld ^2+\ld -\ld ^2=\ld 
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
Now we introduce Poisson Approximation of Binomial Random Variable
\end{minipage}}
\begin{theorem}
\label{1.1.18}
\textbf{(Poisson Approximation of Binomial Random Variable)} Let $X$ be a binomial $B_{n,p}$ and let $\ld =np$. We have
\begin{equation}
  \lim_{n\to\infty}P(X=k)=e^{-\ld }\frac{\ld ^k}{k!}
\end{equation}
\end{theorem}
\begin{proof}
Compute
\begin{align}
P(X=k)&=\binom{n}{k}p^k (1-p)^{n-k}\\
&=\binom{n}{k}(\frac{\ld }{n})^k(1-\frac{\ld }{n})^{n-k}\\
&=\frac{n(n-1)\cdots (n-k+1)}{k!}(\frac{\ld ^k}{n^k})(1-\frac{\ld }{n})^n(1-\frac{\ld }{n})^{-k}\\
&=\frac{\ld ^k}{k!}(1-\frac{\ld }{n})^n(\frac{n(n-1)\cdots (n-k+1)}{n^k})(1-\frac{\ld }{n})^{-k}
\end{align}
So we have
\begin{align}
  \lim_{n\to\infty}P(X=k)&=\frac{\ld ^k}{k!}\lim_{n\to\infty}(1-\frac{\ld}{n})^n\lim_{n\to\infty}\frac{n(n-1)\cdots (n-k+1)}{n^k}\lim_{n\to\infty}(1-\frac{\ld}{n})^{-k}\\
&=\frac{\ld ^k}{k!}e^{-\ld }(1)(1)=e^{-\ld }\frac{\ld ^k}{k!}
\end{align}
\end{proof}
\fbox{\begin{minipage}{39em}
Now we introduce the geometric random variable. 
\end{minipage}}
\begin{definition}
\label{1.1.19}
\textbf{(Definition of Geometric Random Variable)} A geometric random variable counts the number of trials required for the first success in independent trials with success probability $p$. Let  $X$ be a geometric random variable. We have
\begin{equation}
P(X=k)=(1-p)^{k-1}p
\end{equation}
\end{definition}
\begin{theorem}
\label{1.1.20}
\textbf{(Verification of Geometric Random Variable)} Let $X$ be a geometric random variable with parameter $p$. We have
\begin{equation}
\sum_{k=1}^\infty P(X=k)=1
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
\sum_{k=1}^\infty P(X=k)&=\sum_{k=1}^\infty (1-p)^{k-1}p\\
&=p\sum_{k=1}^\infty (1-p)^{k-1}\\
&=p\sum_{k=0}^\infty (1-p)^k\\
&=p(\frac{1}{p})=1
\end{align}
\end{proof}
\begin{theorem}
\label{1.1.21}
\textbf{(Expected Value of Geometric Random Variable)} Let $X$ be a geometric random variable with parameter $p$. We have
 \begin{equation}
E[X]=\frac{1}{p}
\end{equation}
\end{theorem}
\begin{proof}
  Notice that the trials are independent. We have
  \begin{equation}
  E[X]=(p)(1)+(1-p)(E[X]+1)
  \end{equation}
  So we have
  \begin{gather}
 p(E[X])=p+1-p\\
 \implies E[X]=\frac{1}{p} 
  \end{gather}
\end{proof}
\begin{theorem}
\label{1.1.22}
\textbf{(Variance of Geometric Random Variable)} Let $X$ be a geometric random variable with parameter $p$. We have
\begin{equation}
\var [X]=\frac{1-p}{p^2}
\end{equation}
\end{theorem}
\begin{proof}
  Denote $1-p$ by $q$. First notice
\begin{equation}
\sum_{k=1}^\infty kq^{k-1}p=E[X]=\frac{1}{p}
\end{equation}
Then deduce
\begin{align}
E[X^2]&=\sum_{k=1}^\infty k^2q^{k-1}p\\
&=\sum_{k=1}^\infty (k-1+1)^2q^{k-1}p\\
&=\sum_{k=1}^\infty (k-1)^2q^{k-1}p+\sum_{k=1}^\infty 2(k-1)q^{k-1}p+\sum_{k=1}^\infty q^{k-1}p\\
&=q\sum_{k=1}^\infty (k-1)^2q^{k-2}p+2\sum kq^{k-1}p-\sum_{k=1}^\infty q^{k-1}p\\
&=q\sum_{u=1}^\infty u^2q^{u-1}p+2E[X]-p\sum_{k=1}^\infty q^{k-1}\\
&=qE[X^2]+2E[X]-\frac{p}{1-q}
\end{align}
Then we can deduce
\begin{equation}
 p(E[X^2])= (1-q)E[X^2]=2E[X]-\frac{p}{1-q}=\frac{2}{p}-\frac{p}{p}=\frac{2-p}{p}
\end{equation}
So in summary we have
\begin{equation}
\var [X]=E[X^2]-E[X]^2=\frac{2-p}{p^2}-(\frac{1}{p})^2=\frac{1-p}{p^2}
\end{equation}
\end{proof}
\begin{theorem}
\label{1.1.23}
\textbf{(Geometric Random Variable)} Let $X$ be a geometric random variable with parameter $p$. We have
\begin{equation}
P(X>n)=(1-p)^n
\end{equation}
\end{theorem}
\begin{proof}
Let $q=1-p$
\begin{align}
P(X>n)&=1-\sum_{k=1}^n P(X=k)\\
&=1-\sum_{k=1}^n q^{k-1}p\\
&=1-(1-q)\sum_{k=1}^n q^{k-1}\\
&=1-\sum_{k=1}^n q^{k-1}+\sum_{k=1}^n q^{k}\\
&=1-\sum_{k=0}^{n-1} q^k+\sum_{k=1}^n q^k\\
&=1+(q^n-1)=q^n
\end{align}
\end{proof}
\begin{corollary}
\label{1.1.24}
We have
\begin{equation}
  P(X>n+k\text{ while }X>n)=\frac{q^{n+k}}{q^{n}}=q^k
\end{equation}
\end{corollary}
\begin{theorem}
\label{1.1.25}
\textbf{(Summary)} We have
\begin{gather}
\text{ A Bernoulli random variable $I$ is a building block}\\
\text{ Parameter $p$ is the probability it happens }\\
E[I]=p \text{ and }\var [X]=p-p^2
\end{gather}\\

\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
         A Binomial random variable $B_{n,p}$ counts the success of multiple independent Bernoulli random variable (trials) of parameter $p$. \\
         Parameter $n$ is the number of trials and parameter $p$ is the success probability.\\
         $E[B_{n,p}]=np \text{ and }\var [B_{n,p}]=np(1-p)$
    \end{minipage}
\end{center}\\
\begin{gather}

\end{gather}
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
        A Poisson random variable  $X_{\ld }$ is a random variable that counts the number of success in a given time unit when it is expected $\ld $ amount of success would occur.\\

        Parameter $\ld $ is the expected amount of success in the given time unit.\\

        $E[X_\ld ]=\ld \text{ and }\var [X_\ld ]=\ld $
    \end{minipage}
\end{center}\\
\begin{gather}

\end{gather}
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
        A geometric random variable $X_p$ is a random variable that counts the counts the number of trials required for the first success.\\
        
        Parameter  $p$ is the success rate of each independent trials.\\

        $E[X_p]=\frac{1}{p}\text{ and }\var [X_p]=\frac{1-p}{p^2}$
    \end{minipage}
\end{center}
\end{theorem}
\fbox{\begin{minipage}{39em}
$P$ measure is specified by the natural condition of experiment (if the coin is fair). $X$ is specified by what do you want to observe in the experiment.
\end{minipage}}
\chapter{Continuous Random Variable}
\begin{definition}
\label{2.0.1}
\textbf{(Definition of Continuous Random Variable)} A continuous random variable $X:(\Omega,\mathcal{F},P)\rightarrow (\R,\mathcal{B}(\R))$ is a random variable such that 
\begin{equation}
X[\Omega]\text{ is uncountable }
\end{equation}
\end{definition}
\begin{definition}
\label{2.0.2}
\textbf{(Definition of Cumulative Distribution Function)} The cumulative distribution function $F_X$ is 
 \begin{equation}
F_X(x)=P(X\leq x)
\end{equation}
\end{definition}
\begin{definition}
\label{2.0.3}
\textbf{(Definition of Absolutely Continuous Random Variable)} By an absolutely continuous random variable, we mean a continuous random variable $X:(\Omega,\mathcal{F},P)\rightarrow (\R,\mathcal{B}(\R))$ such that
\begin{equation}
F_X\text{ is differentiable everywhere }
\end{equation}
\end{definition}
\begin{definition}
\label{2.0.4}
\textbf{(Definition of Probability Density Function)} Let $X$ be an absolutely continuous random variable. The probability density function $f_X$ for $X$ is defined to be
\begin{equation}
f_X(x)=F'_X(x)
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
Above is how we begin in our argument, we now develop some simple yet crucial tool. These tool enable us too calculate the probability of $X$ taking value in some Borel set $B$ by taking 
 \begin{equation}
P(X\in B)=\int_B f_X(s)ds
\end{equation}
\end{minipage}}
\begin{theorem}
\label{2.0.5}
\textbf{(Fundamental Theorem of Calculus)} We have
\begin{equation}
P(a\leq X\leq b)=\int_a^b f_X(s)ds
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
  P(a\leq X\leq b)&=P(X\leq b)-P(X<a)\\
&=P(X\leq b)-P(X\leq a)\\
&=F_X(b)-F_X(a)\\
&=\int_a^b F_X'(s)ds\\
&=\int_a^b f_X(x)ds
\end{align}
\end{proof}
\begin{corollary}
\label{2.0.6}
\textbf{(Fundamental Theorem of Calculus)} We have
\begin{equation}
P(a\leq X)=\int_a^\infty f_X(s)ds
\end{equation}
\end{corollary}
\begin{proof}
Because measure is countable additive, we have
\begin{align}
P(a\leq X)&=\lim_{n\to\infty}\sum_{k=0}^n P(a+k\leq X<a+k+1)?\\
&=\lim_{n\to\infty}\sum_{k=0}^n \int_{a+k}^{a+k+1}f_X(s)ds\\
&=\lim_{n\to\infty}\int_a^{a+n+1} f_X(s)ds\\
&=\int_a^\infty f_X(s)ds
\end{align}
\end{proof}
\begin{corollary}
\label{2.0.7}
\textbf{(Fundamental Theorem of Calculus)} We have
\begin{equation}
P(X\leq a)=\int_{-\infty}^a f_X(s)ds
\end{equation}
\end{corollary}
\begin{proof}
Because measure is countable additive, we have
\begin{align}
  P(X\leq a)&=\lim_{n\to\infty}\sum_{k=0}^n P(a-k-1<X\leq a-k)\\
&=\lim_{n\to\infty} \sum_{k=0}^n \int_{a-k-1}^{a-k} f_X(s)ds\\
&=\lim_{n\to\infty} \int^a_{a-n-1}f_X(s)ds\\
&=\int^a_{-\infty}f_X(s)ds
\end{align}
\end{proof}
\fbox{\begin{minipage}{39em}
The definition of expected value and variance of continuous random variable present.
\end{minipage}}
\begin{definition}
\label{2.0.8}
\textbf{(Definition of Expected Value)} Let $X$ be an absolutely continuous random variable. We define
 \begin{equation}
E[X]:=\int_{-\infty}^\infty s\times f_X(s)ds
\end{equation}
\end{definition}
\begin{definition}
\label{2.0.9}
\textbf{(Definition of Variance)} Let $X$ be an absolutely continuous random variable. We define
\begin{equation}
\var [X]=\int^\infty_{-\infty} (s-E[X])^2\times f_X(s)ds
\end{equation}
\end{definition}
\begin{theorem}
\label{2.0.10}
\textbf{(Formula for Variance)}
\begin{equation}
\var [X]=E[X^2]-E^2[X]
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
\var [X]&= \int^\infty_{-\infty}(s-E[X])^2 \times f_X(s)ds\\
&=\int^\infty_{-\infty} s^2 \times f_X(s) ds-2E[X]\int^\infty_{-\infty} s\times f_X(s)ds+\int_{-\infty}^\infty E^2[X]\times f_X(s)ds\\
&=E[X^2]-2E^2[X]+E^2[X]\\
&=E[X^2]-E^2[X]
\end{align}
\end{proof}
\fbox{\begin{minipage}{39em}
The below show case when a variable $Y$ depend on a random variable $X$ (thus $Y$ is a random variable): what is the correct way to compute $f_Y$ from $f_X$. Notice that \myref{Theorem}{2.0.11} is inspired by \myref{Theorem}{2.0.12}
\end{minipage}}
\begin{theorem}
\label{2.0.11}
\textbf{(Example)} Define
\begin{equation}
f_X(x):=\begin{cases}
  3x^2& \text{ if $x\in [0,1]$ }\\
  0& \text{ if otherwise }
\end{cases}\text{ and }g(x):=1-x^4\text{ and }Y=g\circ X
\end{equation}
We don't have
\begin{equation}
f_Y(y)=g^{-1}(f_X(g^{-1}(y)))
\end{equation}
\end{theorem}
\begin{proof}
We have
\begin{align}
F_Y(y)&=P(Y\leq y)\\
&=P(1-X^4\leq y)\\
&=P(1-y\leq X^4)\\
&=P(X\geq (1-y)^{\frac{1}{4}})\\
&=\int_{(1-y)^{\frac{1}{4}}}^\infty f_X(s)ds\\
&=\int_{(1-y)^{\frac{1}{4}}}^1 3s^2ds\\
&= \put{s^3}_{s=(1-y)^{\frac{1}{4}}}^1\\
&=1-(1-y)^{\frac{3}{4}}
\end{align}
This give us
\begin{align}
f_Y(y)&=\frac{d}{dy}F_Y(y)\\
&=\frac{d}{dy}1-(1-y)^{\frac{3}{4}}\\
&=\frac{3}{4}(1-y)^{\frac{-1}{4}}
\end{align}
While 
\begin{align}
g^{-1}(f_X(g^{-1}(y)))&= g^{-1}(f_X((1-y)^{\frac{1}{4}}))\\
&=g^{-1}(3(1-y)^{\frac{1}{2}})\\
&=(1-3(1-y)^{\frac{1}{2}})^{\frac{1}{4}}
\end{align}

\end{proof}
\begin{theorem}
\label{2.0.12}
\textbf{(Example)} Define 
\begin{equation}
f_X(x):=\begin{cases}
  1& \text{ if $x\in [0,1]$ }\\
  0& \text{ if elsewhere }
\end{cases}\text{ and }g(x):=3x\text{ and }Y=g\circ X
\end{equation}
\end{theorem}
\begin{proof}
We see 
\begin{align}
F_Y(y)&=P(Y\leq y)\\
&=P(3X\leq y)\\
&=P(X\leq \frac{y}{3})\\
&=F_X(\frac{y}{3})\\
&=\frac{y}{3}\text{ for $y\in [0,3]$ }
\end{align}
Then 
\begin{equation}
f_Y(y)=\begin{cases}
  \frac{1}{3}& \text{ if $y\in [0,3]$ }\\
  0& \text{ if otherwise }
\end{cases}
\end{equation}
And
\begin{equation}
g^{-1}(f_X(g^{-1}(y)))=g^{-1}f_X(\frac{y}{3}))=g^{-1}(1)=\frac{1}{3}
\end{equation}
\end{proof}
\section{Law of Unconscious Statistician}
\section{Uniform, Exponential and Normal}
\fbox{\begin{minipage}{39em}
We now go into each continuous random variable. Start with the easiest, uniform random variable.
\end{minipage}}
\begin{definition}
\label{2.1.1}
\textbf{(Definition of Uniform Random Variable)} We say an absolutely continuous random variable $X$ is uniform if there exists $\alpha <\beta \inr$ such that
\begin{equation}
f_X(x)=\begin{cases}
\frac{1}{\beta -\alpha }& \text{ if $x\in [\alpha ,\beta ]$ }\\
0& \text{ if elsewhere }
\end{cases}
\end{equation}
\end{definition}
\begin{theorem}
\label{2.1.2}
\textbf{(Expected Value and Variance of Uniform Random Variable)} Define $X$ as above. We have
\begin{equation}
E[X]=\frac{\alpha +\beta }{2}\text{ and }\var [X]=\frac{(\beta -\alpha )^2}{12}
\end{equation}
\end{theorem}
\begin{proof}
First verify for
\begin{equation}
\int_{-\infty}^\infty f_X(x)dx=\int_{\alpha }^\beta \frac{1}{\beta -\alpha }dx=\frac{\beta -\alpha }{\beta -\alpha }=1
\end{equation}
Then 
\begin{align}
E[X]&=\int_{\alpha }^\beta \frac{x}{\beta -\alpha }dx\\
&=\frac{1}{\beta -\alpha }\times \frac{x^2}{2} \Big|_{x=\alpha }^\beta \\
&=\frac{\beta ^2-\alpha ^2}{2(\beta -\alpha )}\\
&=\frac{\beta +\alpha }{2}
\end{align}
Then 
\begin{align}
E[X^2]&=\int_{\alpha }^\beta \frac{x^2}{\beta -\alpha }dx\\
      &=\frac{1}{\beta -\alpha }\times \frac{x^3}{3} \put_{x=\alpha }^\beta\\
      &=\frac{\beta ^3-\alpha ^3}{3(\beta -\alpha )}\\
      &=\frac{(\beta -\alpha )(\beta ^2+\beta \alpha +\alpha ^2)}{3(\beta -\alpha )}\\
      &=\frac{\beta ^2+\beta \alpha +\alpha ^2}{3}
\end{align}
Then
\begin{align}
\var [X]&=E[X^2]-E^2[X]\\
&=\frac{\beta ^2+\beta \alpha +\alpha ^2}{3}-\frac{\beta ^2+2\beta \alpha +\alpha ^2}{4}\\
&=\frac{\beta^2-2\beta \alpha +\alpha ^2}{12}\\
&=\frac{(\beta -\alpha )^2}{12}
\end{align}
\end{proof}
\fbox{\begin{minipage}{39em}
Second, exponential.
\end{minipage}}
\begin{definition}
\label{2.1.3}
\textbf{(Definition of Exponential Random Variable)} We say an absolute continuous random variable $X$ is exponential if there exists $\ld\inr^+$ such that
\begin{equation}
f_X(x)=\begin{cases}
  \ld e^{-\ld x}& \text{ if $x\geq 0$ }\\
  0& \text{ if elsewhere }
\end{cases}
\end{equation}
\end{definition}
\begin{theorem}
\label{2.1.4}
\textbf{(Expected Value and Variance of Exponential Random Variable)} Define $X$ as above, we have 
\end{theorem}
\begin{proof}
Fist, verify for
\begin{align}
\int_{-\infty}^\infty f_X(x)dx&=\int_{0}^\infty \ld e^{-\ld x}dx\\
                              &=-e^{-\ld x}\put_{x=0}^\infty\\
                              &=-0-(-1)\\
                              &=1
\end{align}
We have
\begin{align}
E[X]&=\int_0^\infty x\ld e^{-\ld x}dx\\
&=-xe^{-\ld x}\put_{x=0}^\infty -\int_0^\infty -e^{-\ld x}dx\\
&=\int_0^\infty e^{-\ld x}dx\\
&=\frac{e^{-\ld x}}{-\ld } \put_{x=0}^\infty\\
&=0-(\frac{1}{-\ld })\\
&=\frac{1}{\ld }
\end{align}
And have
\begin{align}
E[X^2]&=\int_0^\infty x^2\ld e^{-\ld x}dx\\
&=-x^2e^{-\ld x}\put_{x=0}^\infty-\int_0^\infty -2xe^{-\ld x}dx\\
&=2\int_0^\infty xe^{-\ld x}dx\\
&=2(\frac{-1}{\ld })xe^{-\ld x}\put_{x=0}^\infty -2\int_0^\infty (\frac{-1}{\ld })e^{-\ld x}dx\\
&=\frac{2}{\ld }\int_{0}^\infty e^{-\ld x}dx\\
&=\frac{2}{\ld }(\frac{-1}{\ld })e^{-\ld x}\put_{x=0}^\infty\\
&=(\frac{-2}{\ld ^2})(0-1)=\frac{2}{\ld ^2}
\end{align}
Then we have
\begin{equation}
\var [X]=E[X^2]-E^2[X]=\frac{2}{\ld^2}-(\frac{1}{\ld })^2=\frac{1}{\ld ^2}
\end{equation}
\end{proof}
\begin{theorem}
\label{2.1.5}
\textbf{(Property of Exponential Random Variable)} Let $X$ be exponential with parameter  $\ld $. We see 
\begin{equation}
P(X\geq a )=e^{-a\ld }
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
P(X\geq a)&=\int_a^\infty \ld e^{-\ld x}dx\\
&=-e^{-\ld x}\put_{x=a}^\infty\\
&=e^{-a\ld }
\end{align}
\end{proof}
\begin{theorem}
\label{2.1.6}
\textbf{(Memory-less Property of Exponential Random Variable)}  Let $X$ be exponential with parameter $\ld $. We see
\begin{equation}
P(X\geq  a+b\put X\geq  b)=\frac{e^{-(a+b)\ld }}{e^{-b\ld }}=e^{-a\ld }
\end{equation}
\end{theorem}




\end{document}

\documentclass{report}
\input{preamble}
\input{macros}
\input{letterfonts}

\title{Notes on Commutative Algebra}
\author{Eric Liu}
\date{}
\begin{document}
\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}

\tableofcontents
\pagebreak
\chapter{Rings Theory} 
\section{Definitions}
The precise meaning of the term \textbf{ring} varies across different books, depending on the context and purpose. In this note, the multiplication of a ring is always associative and commutative, and have an identity. The additive identity is denoted by $0$. From the axioms, we can straightforwardly show that $x\cdot 0 = 0$ for all $x$. Consequently, the multiplicative and additive identities are always distinct unless the ring contained only one element, called  \textbf{zero} in this case.\\

An \textbf{ideal} of a ring $R$ is an additive subgroup $I$ such that $ar \in I$ for all $a \in I,  r \in R$, or equivalently, the kernel of some \textbf{ring homomorphism}\footnote{Ring homomorphisms are mapping between two rings that respects addition, multiplication and  multiplicative identity.}. To see the equivalency, one simply construct the \textbf{quotient ring}\footnote{Consider the equivalence relation on $R$ defined by  $x\sim  y\overset{\triangle}{\iff } x-y \in I$} $R\quotient I$, under which the quotient map $\pi: R \rightarrow R \quotient  I$ is a surjective ring homomorphism whose kernel is the ideal $I$. Remarkably, the mapping defined by 
 \begin{align*}
\operatorname{Ideal }J\text{ of $R$ that contains }I \mapsto \set{[x]\in R\quotient I: x\in J}
\end{align*}
forms a bijection between the collection of the ideals of $R$ containing  $I$ and the collection of the ideals of $R\quotient I$. This fact is commonly referred to as the \textbf{correspondence theorem} for rings. \\

A \textbf{unit} is an element that has a multiplicative inverse. Under our initial requirement that rings are commutative, for a non-zero ring $R$ to be a \textbf{field}, we only need all non-zero elements of $R$ to be units, or equivalently, the only ideals of $R$ to be $\set{0}$ or $R$ itself.\\

We use the term \textbf{proper} to describe strict set inclusion. By a \textbf{maximal ideal}, we mean a proper ideal $I$ contained by no other proper ideals, or equivalently\footnote{By the Correspondence Theorem for Rings.}, a proper ideal $I$ such that $R\quotient I$ is a field.\\

A \textbf{zero-divisor} is an element $x$ that has some non-zero element $y$ such that  $xy=0$. Again, under our initial requirement that rings are commutative, for a non-zero ring $R$ to be an  \textbf{integral domain}, we only need all non-zero elements to be zero-divisors. By a \textbf{prime ideal}, we mean a proper ideal $I$ such that the product of two elements belongs to $I$ only if one of them belong to $I$, or equivalently, a proper ideal $I$ such that $R\quotient I$ is an integral domain.  \\


There are many binary operations defined for ideals.  Given two ideals $I$ and $S$, we define their \textbf{sum} $I+S$ to be the set of all  $x+y$ where  $x\in I$ and $y \in S$, and define their \textbf{product} $IS$ to be the set of all finite sums $\sum x_iy_i$ where  $x_i \in I$ and $y_i\in S$. Note that the ideal multiplications are indeed distributive over addition, and they are both associative, so it make sense to write something like $I_1+I_2+I_3$ or $I_1I_2I_3$. Obviously, the intersection of ideals is still ideal, while the union of ideals generally are not. Moreover, we define their \textbf{quotient} $(I:S)$ to be the set of elements $x$ of $R$ such that $xy \in I$ for all $y \in S$. To simplify matters, we write $(I:x)$ instead of $(I:\langle x\rangle )$. \\ 

For all subsets $S$ of some ring $R$, we may \textbf{generate} an ideal by setting it to be the set of all finite sum  $\sum rs$ such that $r\in R$ and $s \in S$, or equivalently, the smallest ideal of $R$ containing $S$. An ideal is called \textbf{principal} and denoted by $\langle x\rangle $ if it can be generated by a single element $x$. \\

An element $x$ is called \textbf{nilpotent} if $x^n=0$ for some  $n\inn$. The set of all nilpotent elements obviously form an ideal, which we call \textbf{nilradical} and denote by $\operatorname{Nil}(R)$. Here, we give a nice description of the nilradical. 
\begin{theorem}
\textbf{(Equivalent Definition for Nilradical)} We use the term \textbf{spectrum} of $R$ and the notation  $\operatorname{spec}(R)$ to denote the set of prime ideals of $R$. We have 
 \begin{align*}
\operatorname{Nil}(R)=\bigcap \operatorname{spec}(R)
\end{align*}
\end{theorem}
\begin{proof}
$\operatorname{Nil}(R)\subseteq \bigcap \operatorname{spec}(R)$ is obvious. Suppose $x \not\in \operatorname{Nil}(R)$. Let $\Sigma$ be the set of ideals $I$ such that $x^n\not\in I$ for all $n>0$. Because unions of chains in $\Sigma$ belong to $\Sigma$, by Zorn's Lemma, there exists some maximal element $I \in \Sigma$. Because $x\not \in I$, to close out the proof, we only have to show $I$ is prime.\\

Let $yz \in I$. Assume for a contradiction that $y\not\in I$ and $z\not\in I$. By maximality of $I$, both ideal $I+ \langle y\rangle$ and ideal $I+\langle z\rangle$ do not belong to $\Sigma$. This implies $x^n \in I+ \langle y\rangle$ and $x^m \in I + \langle z\rangle $ for some $n,m>0$, which cause a contradiction to $I \in \Sigma$, since $x^{n+m} \in I + \langle yz\rangle =I$. 
\end{proof}
Let $I$ be an ideal of the ring $R$. By the term \textbf{radical} of $I$, we mean $\sqrt{I}\triangleq \set{ x \in R : x^n \in I \text{ for some } n > 0 }$, which is equivalent to  the preimage of $\operatorname{Nil}(R \quotient  I)$ under the quotient map and equivalent\footnote{This follows from the fact that the correspondence between the ideals of $R$ and the ideals of $R \quotient  I$ can be restricted to a bijection between $\operatorname{Spec}(R)$ and $\operatorname{Spec}(R \quotient  I)$.} to the intersection of all prime ideals of $R$ that contain $I$. \\

It should be noted that there is a "less is more" philosophy in our wording and notations for product, quotient and radical of ideals. For any ideal $I,Q$, we have 
 \begin{align*}
IQ \subseteq I \subseteq \sqrt{I}  \text{ and }I \subseteq (I:Q)
\end{align*}


\section{Rings of Fraction}
Let $A$ be a ring. We say  $S\subseteq A$ is a \textbf{multiplicatively closed subset} of $A$ if  $S$ contains $1$ and is closed under multiplication. Given some multiplicatively closed subset $S$ of $A$, we may define an equivalence relation on  $A \times S$ by 
\begin{align*}
  (a,s)\sim  (b,t) \overset{\triangle}{\iff } (at-bs)u=0\text{ for some }u \in S
\end{align*}
Denoting the set of equivalence classes by $S^{-1}A$ and denote the equivalence class of $(a,s)$ by $\frac{a}{s}$, we have a ring structure on $S^{-1}A$ by defining 
\begin{align*}
 \frac{a}{s}+ \frac{b}{t}\triangleq \frac{at+bs}{st} \text{ and } \frac{a}{s}\cdot \frac{b}{t}\triangleq \frac{ab}{st}
\end{align*}
The ring $S^{-1}A$ is called the \textbf{ring of fraction}, or the \textbf{localization of $A$ by  $S$}. 
\section{Primary Decomposition}
Let $A$ be a ring. We say a proper ideal $Q$ is \textbf{primary} if for each $xy \in Q$, either $x \in Q$ or $y^n \in Q$ for some $n>0$. Equivalently, a proper ideal $I$ is primary if and only if every zero-divisors in $R \quotient  Q$ is nilpotent. Clearly, the radical $P=\sqrt{Q} $ of a primary ideal $Q$ is prime. In such case, we say $Q$ is $P$\textbf{-primary}. A \textbf{primary decomposition} of an ideal $I$ is an expression of $I$ as a finite intersection of primary ideals
 \begin{align*}
I= \bigcap_{i=1}^n Q_i
\end{align*}
Such primary decomposition is said to be \textbf{irredundant} if $\sqrt{Q_i}$ are all distinct and no $Q_i$ is unnecessary in the sense that 
\begin{align*}
\bigcap_{j\neq i}Q_j \not \subseteq Q_i\text{ for all }i. 
\end{align*}
An ideal $I$ is said to be  \textbf{decomposable} if there exists some primary decomposition of $I$. Because finite intersection of $P$-primary ideals is again  $P$-primary, every decomposable ideal has an irredundant primary decomposition.  
\begin{theorem}
\label{Fut}
\textbf{(First uniqueness theorem for irredundant primary decomposition)} Given some irredundant primary decomposition $I= \bigcap_{i=1}^n Q_i$, we have 
\begin{align}
\label{QiR}
\bset{\sqrt{Q_i}:1\leq i\leq n}= \operatorname{Spec}(R) \cap \bset{\sqrt{(I:x)} \subseteq R: x \in R } 
\end{align}
\end{theorem}
\begin{proof}
Before showing that both sides of \myref{Equation}{QiR} are subsets of each other, we first make the following observation. For all $x \in R$, clearly 
\begin{align*}
  (I:x)= \Big(\bigcap Q_i :x\Big) = \bigcap (Q_i : x)
\end{align*}
Therefore, 
\begin{align}
\label{sIx}
\sqrt{(I:x)}= \bigcap \sqrt{(Q_i:x)}= \bigcap_{k:x \not\in Q_k} \sqrt{Q_k}  
\end{align}
where the last equality is justified by 
\begin{align*}
x \in Q_i \implies (Q_i:x)=R,\quad\text{ and } x \not\in Q_i \implies  \sqrt{(Q_i:x)} = \sqrt{Q_i} 
\end{align*}
We now prove that the left hand side of \myref{Equation}{QiR} is a subset of the right hand side. Fix $i$. By irredundancy of the decomposition, there exists some  $x\in R$ such that $x$ belongs to all $Q_j$ except  $Q_i$. This $x$ by \myref{Equation}{sIx} must satisfies
\begin{align*}
\sqrt{Q_i}  =  \sqrt{(I:x)} 
\end{align*}
Noting that $\sqrt{Q_i}$ must be prime due to $Q_i$ being primary, we have shown the left hand side of \myref{Equation}{QiR} is a indeed a subset of the right hand side. \\

Now, suppose for some $x\in R$ that $\sqrt{(I:x)}$ is prime. Because prime ideal must be proper, we know there must exists some $k$ such that $x\not \in Q_k$. By \myref{Equation}{sIx}, to finish the proof, we only need to show $\sqrt{Q_k}\subseteq \sqrt{(I:x)}$ for some $k$ such that $x \not \in Q_k$. Assume not for a contradiction. Then for all $k$ such that $x \not \in Q_k$, there exists $y_k \in \sqrt{Q_k}$ such that $y_k \not \in \sqrt{(I:x)}$. The product of these $y_k$ is an element of  $\bigcap \sqrt{Q_k}$, thus an element of $\sqrt{(I:x)}$. This with $\sqrt{(I:x)}$ being prime shows that $y_k \in \sqrt{(I:x)}$ for some $k$, a contradiction. 
\end{proof}
Because of \myref{Theorem}{Fut}, we may well define the following notions. Given some decomposable ideal $I$, we say the prime ideals $\set{\sqrt{Q_1},\dots ,\sqrt{Q_n} }$ \textbf{belong} to $I$, and if $\sqrt{Q_i}$ is a minimal element of $\set{\sqrt{Q_1},\dots ,\sqrt{Q_n}}$, then we say $\sqrt{Q_i}$ is a \textbf{minimal} prime ideal belonging to $I$.  
\chapter{Modules}
\section{Modules}
Let $R$ be some ring. By a $R$-\textbf{module}, we mean an abelian group $M$ together with a $R$-scalar multiplication. We use the notation $\operatorname{Hom}(M,N)$ to denote the space of \textbf{$R$-module homomorphism} from  $M$ to $N$. It is clear that the obvious assignment of $R$-scalar multiplication and addition makes $\operatorname{Hom}(M,N)$ a $R$-module.\\

Let $M$ be a  $R$-module, and let $N$ be a subset of  $M$. We say $N$ is a $R$-\textbf{submodule} if $N$ is closed under both addition and $R$-scalar multiplication, or equivalently, if $N$ is the kernel of some  $R$-module homomorphism. Just like how ideal is proved to be kernel of some ring homomorphism, to see submodule is the kernel of some $R$-module homomorphism, we simply construct the \textbf{quotient module} $M\quotient N$, and get the quotient map $\pi :M\rightarrow M\quotient N$ that is a $R$-module homomorphism with kernel $N$, and get also the bijection
\begin{align*}
R\text{-submodule $S$ of  $M$ that contains  $N$}\mapsto \set{[x]\in M \quotient N: x \in S}
\end{align*}
 between the collection of the $R$-submodules of $M$ that contains  $N$ and the collection of the $R$-submodule of  $M\setminus N$, the  \textbf{correspondence theorem} for modules.\\


Again similar to the other algebraic structure, we have the \textbf{third isomorphism theorem} for modules. Let $N \subseteq M \subseteq L$ be three $R$-modules. It is obvious that $M\quotient N$ is a subset of $L\quotient N$, and moreover, $M\quotient  N$ forms a submodule of  $L\quotient N$. We have an isomorphism $\pfi:(L\quotient N)\quotient (M\quotient N)\to L\quotient M$ defined by $(l+N)+ (M\quotient N)\mapsto l+M$. To simplify matters, from now on all modules and submodules are over $R$ in this section. \\

Given a subset $E$ of  $M$, clearly its \textbf{span}, the set of finite sum $\sum rx$ where $x \in E$, forms a submodule. We say  $M$ is \textbf{finitely generated} if $M$ can be spanned by a finite set.\\




Let $\set{M_i:i \in I}$ be a collection of modules. If we give the Cartesian product $\prod M_i$ the obvious addition and multiplication, then we say it is the \textbf{direct product}. It is clear that 
\begin{align*}
\bset{(x_i)_{i \in I} \in \prod_{i \in I}M_i:x_i \neq 0\text{ for finitely many }i.}
\end{align*}
forms a submodule of the direct product. We denote this submodule by $\bigoplus M_i$, and call it the  \textbf{direct sum}.  Obviously, if the index set $I$ is finite, then the direct product and direct sum are identical.  \\

By \textbf{free modules}, we mean modules of the form $\bigoplus_{i \in I}M_i$ where $M_i \cong R$. We denote the free module $\bigoplus_{i \in I}M_i$ by $R^{(I)}$. \\




Given an ideal $\mathfrak{a}$ of $R$, some  $R$-module $M$ and some  $R$-submodule  $N$ of  $M$, the \textbf{product of the $R$-submodule $N$  by the ideal $\mathfrak{a}$}  is the set of finite sum $\sum a_i x_i$ where $a_i \in \mathfrak{a}$ and $x_i \in N$. We denote such set by  $\mathfrak{a}N$, and $\mathfrak{a}N$ clearly forms a $R$-submodule of $M$. \\
\section{Tensor Product of Modules}
Let $R$ be some ring. Given a finite collection $\set{M_1,\dots ,M_n}$ of $R$-modules, by the term \textbf{tensor product space}, we mean a $R$-module denoted by $\bigotimes M_i$ and a $R$-multilinear map $\otimes : \prod M_i \rightarrow \bigotimes M_i$ that satisfies the \textbf{universal property}: For each multilinear map $f:\prod M_i \rightarrow P$, there exists unique linear map $\tilde{f}:\bigotimes M_i \rightarrow P$ such that the diagram 
% https://q.uiver.app/#q=WzAsMyxbMiwyLCJOIl0sWzAsMCwiXFxwcm9kIE1faSJdLFsyLDAsIlxcb3RpbWVzIE1faSJdLFsxLDIsIlxcb3RpbWVzIl0sWzEsMCwiZiIsMl0sWzIsMCwiZiIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
\[\begin{tikzcd}
	{\prod M_i} && {\bigotimes   M_i} \\
	\\
	&& P 
	\arrow["\otimes ", from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["\tilde{f} ", dashed, from=1-3, to=3-3]
\end{tikzcd}\]
commutes. This definition is unique up to isomorphism: If $\bigotimes 'M_i$ is also a tensor product, then there exists some module isomorphism from $\bigotimes  M_i$ to $\bigotimes  'M_i$ that sends $m_1 \otimes  \cdots \otimes  m_n$ to $m_1 \otimes  ' \cdots \otimes  ' m_n$. One common construction of the tensor product space is to quotient the free module $R^{(\prod M_i)}$ with the submodule spanned by the set:
\begin{align*}
  \bigcup_{i=1}^n &\Big[\bset{(x_1,\dots, rx_i ,\dots, x_n)-r(x_1,\dots ,x_n)}\\
 & \cup \bset{(x_1,\dots ,x_i +x_i',\dots  ,x_n)- (x_1,\dots ,x_i,\dots  ,x_n)-(x_1,\dots ,x_i',\dots ,x_n)}  \Big]
\end{align*}
Denoting this spanned submodule by $D$, our tensor product space $\bigotimes M_i$ is now $R^{(\prod M_i)}\quotient D$, and because of the forms of the generators of $D$, the tensor product map $\otimes  :\prod M_i \rightarrow \bigotimes  M_i$ defined by 
\begin{align*}
x_1\otimes  \cdots \otimes  x_n \triangleq [(x_1,\dots ,x_n)] 
\end{align*}
is clearly multilinear. Because free module $R^{(\prod M_i)}$ is a direct sum, it is clear that $\bigotimes M_i$ is generated by the \textbf{basic elements}\footnote{Elements of the form $x_1\otimes  \cdots \otimes  x_n$}, and because of such, for every multilinear map $f:\prod M_i \rightarrow P$, the induced map $\tilde{f}: \bigotimes M_i \rightarrow P$ must be unique. To actually induce $\tilde{f}$, one first extend $f$ to the whole free module $\overline{f}:R^{(\prod M_i)}\rightarrow P$ by setting $\overline{f}(\sum r (x_1,\dots ,x_n))\triangleq \sum rf(x_1,\dots ,x_n)$, and see that because $\overline{f}$ vanishes on the generators of $D$, we may induce some mapping from $\bigotimes M_i$ to $P$ that clearly has the desired action of $\tilde{f}$ on the basic elements. \\

Note that the \textbf{tensor-horn adjunction} isomorphism 
\begin{align*}
\operatorname{Hom}(M\otimes N,P) \cong  \operatorname{Hom}(M,\operatorname{Hom}(N,P))
\end{align*}
maps $f \in \operatorname{Hom}(M\otimes N,P)$ to   $\tilde{f}\in \operatorname{Hom}(M,\operatorname{Hom}(N,P))$ with the action
\begin{align*}
  \tilde{f}(m)n\triangleq f(m\otimes n)
\end{align*}
\section{Rings and Modules of Fraction}
\section{Primary Decomposition Theorem}


\chapter{Scripts}
\section{Script 3}
A \textbf{primary decomposition} of an ideal $I$ is an expression of $I$ as a finite intersection of primary ideals
 \begin{align*}
I= \bigcap_{i=1}^n Q_i
\end{align*}
Moreover, if $\sqrt{Q_i}$ are all distinct and 
\begin{align*}
\bigcap_{j\neq i}Q_j \not \subseteq Q_i\text{ for all }i
\end{align*}
then we say the primary decomposition is \textbf{irredundant}. 
\begin{theorem}
\label{Fut}
\textbf{(First uniqueness theorem for irredundant primary decomposition)} Given some irredundant primary decomposition $I= \bigcap_{i=1}^n Q_i$, we have 
\begin{align}
\label{QiR}
\bset{\sqrt{Q_i}:1\leq i\leq n}= \operatorname{Spec}(R) \cap \bset{\sqrt{(I:x)} \subseteq R: x \in R } 
\end{align}
\end{theorem}
\begin{proof}
Before showing that both sides of \myref{Equation}{QiR} are subsets of each other, we first make the following observation. For all $x \in R$, clearly 
\begin{align*}
  (I:x)= \Big(\bigcap Q_i :x\Big) = \bigcap (Q_i : x)
\end{align*}
Therefore, 
\begin{align}
\label{sIx}
\sqrt{(I:x)}= \bigcap \sqrt{(Q_i:x)}= \bigcap_{k:x \not\in Q_k} \sqrt{Q_k}  
\end{align}
where the last equality is justified by 
\begin{align*}
x \in Q_i \implies (Q_i:x)=R,\quad\text{ and } x \not\in Q_i \implies  \sqrt{(Q_i:x)} = \sqrt{Q_i} 
\end{align*}
We now prove that the left hand side of \myref{Equation}{QiR} is a subset of the right hand side. Fix $i$. By irredundancy of the decomposition, there exists some  $x\in R$ such that $x$ belongs to all $Q_j$ except  $Q_i$. This $x$ by \myref{Equation}{sIx} must satisfies
\begin{align*}
\sqrt{Q_i}  =  \sqrt{(I:x)} 
\end{align*}
Noting that $\sqrt{Q_i}$ must be prime due to $Q_i$ being primary, we have shown the left hand side of \myref{Equation}{QiR} is a indeed a subset of the right hand side. \\

Now, suppose for some $x\in R$ that $\sqrt{(I:x)}$ is prime. Because prime ideal must be proper, we know there must exists some $k$ such that $x\not \in Q_k$. By \myref{Equation}{sIx}, to finish the proof, we only need to show $\sqrt{Q_k}\subseteq \sqrt{(I:x)}$ for some $k$ such that $x \not \in Q_k$. Assume not for a contradiction. Then for all $k$ such that $x \not \in Q_k$, there exists $y_k \in \sqrt{Q_k}$ such that $y_k \not \in \sqrt{(I:x)}$. The product of these $y_k$ is an element of  $\bigcap \sqrt{Q_k}$, thus an element of $\sqrt{(I:x)}$. This with $\sqrt{(I:x)}$ being prime shows that $y_k \in \sqrt{(I:x)}$ for some $k$, a contradiction. 
\end{proof}
Because of \myref{Theorem}{Fut}, we may well define the following notions. Given some decomposable ideal $I$, we say the prime ideals $\set{\sqrt{Q_1},\dots ,\sqrt{Q_n} }$ \textbf{belong} to $I$, and if $\sqrt{Q_i}$ is a minimal element of $\set{\sqrt{Q_1},\dots ,\sqrt{Q_n}}$, then we say $\sqrt{Q_i}$ is a \textbf{minimal} prime ideal belonging to $I$. 
\begin{theorem}
\label{Soz}
  \textbf{(Set of zero-divisors is the union of all prime ideals belonging to $\set{0}$)} If we let $D$ be set of zero-divisors of  $R$, then 
\begin{align*}
D= \bigcup \set{I\in \operatorname{Spec}(R):I\text{ belongs to }\set{0}} 
\end{align*}
\end{theorem}
\begin{proof}
Clearly, 
\begin{align*}
D= \bigcup_{x\neq 0} \sqrt{(\set{0}:x)} 
\end{align*}
This together with \myref{Equation}{sIx} shows that $D$ is a subset of the union of all prime ideals belonging to $\set{0}$. The converse follows directly from \myref{Theorem}{Fut}. 
\end{proof}
We may generalize \myref{Theorem}{Soz} as following. Let $I = \bigcap Q_i$ be an irredundant primary decomposition. Let $\pi  :R \rightarrow R\quotient I$ be the quotient map. Clearly $\set{[0]}= \bigcap \pi  (Q_i)$ forms an irredundant primary decomposition. Therefore, \myref{Theorem}{Soz} implies 
\begin{align*}
\bigcup   \sqrt{\pi  (Q_i)}= \bset{[x] \in R\quotient I: xy \in I\text{ for some }y\neq 0} 
\end{align*}
which implies 
\begin{align*}
\bigcup \sqrt{Q_i} = \bset{x \in R: (I:x) \neq I}
\end{align*}
\begin{theorem}
\textbf{(Proposition 4.8)} Let $S$ be a multiplicatively closed subset of  $A$, and let  $Q$ be a $P$-primary ideal. 
 \begin{align*}
S \cap P \neq \varnothing \implies  S^{-1}Q = S^{-1}A
\end{align*}
and 
\begin{align*}
S \cap P=\varnothing \implies S^{-1}Q\text{ is $P$-primary  and its contraction in $A$ is  $Q$ }
\end{align*}
\end{theorem}
\begin{proof}
If $s \in S \cap P$, then $s^n \in Q$ for some $n>0$, and $\frac{s^n}{1} \in S^{-1}Q$. Note that 
\begin{align*}
\frac{s^n}{1}\cdot \frac{1}{s^n}= \frac{s^n}{s^n}=1
\end{align*}
Suppose $S \cap P=\varnothing$. Note that $S^{-1}Q=Q^e$, so to show the contraction of $S^{-1}Q$ is $Q$, we only have to show 
\begin{align}
\label{g1}
Q^{ec}=Q
\end{align}
Obviously $Q \subseteq Q^{ec}$. We show the opposite. The second part of proposition 3.11 states that 
\begin{align*}
Q^{ec}= \bigcup_{s \in S} (Q:s)
\end{align*}
Because $Q \subseteq P$, if $as \in Q$, then $a \in Q$. Therefore, $a \in (Q:s)\implies  a \in Q$. We have shown  \myref{goal}{g1}. Note that the fifth part of proposition 3.11  states that 
\begin{align*}
\sqrt{S^{-1}Q}=S^{-1}\sqrt{Q}=S^{-1}P   
\end{align*}
It remains to show $S^{-1}Q$ is indeed primary. Let  $\frac{ab}{ss'} = \frac{q}{s''}\in S^{-1}Q$. This implies $(abs'' -qss')t=0$ for some $t \in S$, which implies $ab(s''t)\in Q$. Because $S$ is closed under multiplication and $S \cap P = \varnothing$, we know $(s''t)^n \not\in Q$ for all $n>0$. This implies  $ab \in Q$, which implies $a \in Q$ or some powers of  $b$ is an element of  $Q$. We have shown either  $\frac{a}{s} \in S^{-1}Q$ or some power of  $\frac{b}{s''}$ belongs to $S^{-1}Q$. We have shown $S^{-1}Q$ is indeed primary.
\end{proof}
\section{Script 2}
Let $A$ and  $B$ be two rings. Let  $M$ be an  $A$-module, and let $N$ be a  $(A,B)$-\textbf{bimodule}. By $N$ being a  $(A,B)$-bimodule, we mean that $N$ not only have both structure of $A$-module and $B$-module, but also  satisfy $a(bx)=b(ax)$. Consider the tensor product $M\otimes_A N$. For any $b \in B$, we may define a $A$-bilinear map $M\times N \rightarrow M\otimes_A N$ by 
\begin{align*}
  (m,n)\mapsto m \otimes  bn
\end{align*}
Therefore, by universal property, there exists some unique $A$-linear map $\tilde{b}:M\otimes _A N\rightarrow M\otimes  _A N$. Doing this procedure for each $b \in B$, to claim $M\otimes_A N$ forms a $(A,B)$-bimodule, it remains to check that 
\begin{enumerate}[label=(\alph*)]
  \item $b(x+y)=bx+by$. 
  \item $(b_1+b_2)x=b_1x+b_2x$. 
  \item $(b_1b_2)x=b_1(b_2x)$. 
  \item $1_Bx=x$. 
  \item $a(bx)=b(ax)$. 
\end{enumerate}
\begin{question}{Exercise 2.15}{}
Let $P$ be a  $B$-module. Find an $(A,B)$-bimodule isomorphism  between 
\begin{align*}
  (M\otimes _AN)\otimes _B P \text{ and }M \otimes  _A (N \otimes  _B P)
\end{align*}
\end{question}
\begin{proof}
For each $p \in P$, the $A$-bilinear map from  $M\times N$ to $M \otimes_A (N \otimes _B P)$ defined by $(m,n)\mapsto  m \otimes  (n \otimes  p)$ induce a unique $A$-linear map $f_p:M\otimes _A N \to M\otimes _A(N\otimes _B P)$ that sends $m\otimes  n$ to $m\otimes (n \otimes  p)$. By expressing elements of $M \otimes_A N$ as finite sum of basic elements, one can see that $f_p$ is also  $B$-linear. Therefore, if we define $f:(M\otimes _A N) \times P\rightarrow M \otimes _A (N \otimes  _B P)$ by 
\begin{align*}
f(x,p)\triangleq f_p(x)
\end{align*}
we see that $f$ is $B$-linear in $M\otimes _A N$. Again, by expressing elements of $M \otimes  _A N$ as finite sum of basic elements, one can see that $f$ is also  $B$-linear in  $P$. Therefore, by universal property, there exists some $B$-linear mapping  $\tilde{f}:(M\otimes _A N) \otimes_B  P\rightarrow M \otimes _A (N \otimes  _B P)$  with action:
\begin{align*}
  (m \otimes  n)\otimes p \mapsto   f_p(m\otimes n)=m\otimes  (n \otimes  p)
\end{align*}
Tedious computation by expressing elements of $(M \otimes _A N)\otimes _B P$ into finite sum of basic elements shows that $\tilde{f}$ is also $A$-linear. We have shown $\tilde{f}$ is an $(A,B)$-bimodule homomorphism.  \\

To finish the proof, one first use similar argument to construct some  $(A,B)$-bimodule homomorphism $\tilde{g}: M \otimes_A (N \otimes _B P)\rightarrow (M\otimes _A N)\otimes_B P$ with action: 
\begin{align*}
  m \otimes  (n \otimes  p)\mapsto (m\otimes  n)\otimes  p
\end{align*}
And then, see that $\tilde{g}\circ \tilde{f}\in \operatorname{End}_{(A,B)}[(M\otimes_ AN)\otimes _BP]$ have the identity action on basic elements $x\otimes  p$\footnote{Again, by expressing $x$ as basic element  $x= \sum m_i \otimes  n_i$.} to conclude by universal property that $\tilde{g}\circ \tilde{f}$ is the identity function. 
\end{proof}
\begin{mdframed}
Let $f:A\rightarrow B$ be a ring homomorphism. If $N$ is a  $B$-module, then the  $A$-module structure on  $N$ defined by $an\triangleq f(a)n$ is called \textbf{restriction of scalars}. If $M$ is an $A$-module, then the  $B$-module structure on  $B\otimes _A M$\footnote{$B$ is given an $A$-module structure by restriction of scalar.} defined by 
\begin{align*}
b(b' \otimes  m)\triangleq  bb' \otimes  m
\end{align*}
is called \textbf{extension of scalars}. 
\end{mdframed}
\begin{question}{Proposition 2.16}{}
Let $A,B$ be two rings, and let  $B$ be an  $A$-module, so we have a ring homomorphism $f:A\rightarrow B$ defined by $f(a)\triangleq a1_B$. Let $N$ be a $B$-module, and give $N$ an  $A$-module structure using restriction of scalars with respect to  $f$.\\

Show that if $N$ is finitely generated as a $B$-module and  if $B$ is finitely generated as an  $A$-module, then  $N$ is finitely generated as an $A$-module. 
\end{question}
\begin{proof}
Suppose $n_1,\dots ,n_k$ generate $N$ over  $B$, and suppose  $b_1,\dots ,b_m$ generate $B$ over $A$. We claim  $\set{b_jn_i}$ generates $N$ over $A$. Let 
\begin{align*}
b_i'= \sum_{j=1}^m a_{i,j}b_j
\end{align*}
Compute 
\begin{align*}
\sum_{i=1}^k b_i'n_i&= \sum_{i=1}^k \Big(\sum_{j=1}^m a_{i,j}b_j \Big)n_i \\
&=\sum_{i=1}^k  \sum_{j=1}^m (a_{i,j}b_j)n_i  \\
&=\sum_{i,j} (a_{i,j}b_j) n_i \\
&=\sum_{i,j}a_{i,j}(b_jn_i)
\end{align*}
For justification of last equality, compute 
\begin{align*}
a(bn)=f(a)(bn)=(f(a)b)n=(ab)n
\end{align*}
Remark: similar routine computation shows that $N$ is in fact an  $(A,B)$-bimodule. 
\end{proof}
\begin{question}{Proposition 2.17}{}
Let $f:A\rightarrow B$ be a ring homomorphism, and let $M$ be a finitely generated $A$-module, show that its extension of scalar  $B\otimes_A M$ is finitely generated as a $B$-module.   
\end{question}
\begin{proof}
Let $\set{m_1,\dots ,m_n}$ generates $M$ over $A$. We claim $\set{1_B\otimes m_i}$ generate all the basic elements. Consider 
\begin{align*}
b \otimes \sum a_im_i&= \sum b\otimes a_i m_i \\
&= \sum b (1_B \otimes a_im_i)\\
&=\sum b ( a_i 1_B \otimes  m_i) \hspace{0.5cm}(\because \text{ $B$ is regarded as an  $A$-module when we write }B\otimes _A M)\\
&=\sum b (f(a_i)\otimes m_i)\\
&=\sum bf(a_i)(1\otimes m_i)
\end{align*}
\end{proof}
\begin{mdframed}
Let $M\overset{f}{\longrightarrow }M'$ and $N\overset{g}{\longrightarrow }N'$ be in the category of $A$-module. The function  $h:M\times N \rightarrow M' \otimes  N'$ defined by 
\begin{align*}
h(x,y)\triangleq f(x)\otimes  g(y)
\end{align*}
is clearly $A$-bilinear. Therefore, we may induce some unique $A$-linear map  $f\otimes  g:M\otimes  N\rightarrow M'\otimes  N'$ such that 
\begin{align*}
  (f\otimes  g)(x\otimes  y)=f(x)\otimes  g(y)
\end{align*}
Note that for each $M' \overset{f'}{\longrightarrow }M''$ and $N'\overset{g'}{\longrightarrow }N''$, we have 
\begin{align*}
  (f' \circ f) \otimes  (g' \circ g)= (f'\otimes  g')\circ (f\otimes  g)
\end{align*}
because they agree on the basic elements. 
\end{mdframed}
\begin{question}{Proposition 2.18 (Exaction of Tensor Product)}{}
If 
\begin{align}
\label{Mfg}
M'\overset{f}{\longrightarrow }M\overset{g}{\longrightarrow } M'' \rightarrow  0
\end{align}
is an exact sequence of $A$-modules and homomorphism, then for any $A$-module  $N$, the sequence 
 \begin{align*}
M' \otimes  N \overset{f \otimes 1 }{\longrightarrow } M \otimes  N \overset{g \otimes  1}{\longrightarrow }M'' \otimes  N \rightarrow  0
\end{align*}
is also exact, where $1 \in \operatorname{End}(N)$ is the identity mapping. 
\end{question}
\begin{proof}
  Because $g$ is surjective, we may construct an \textbf{right inverse} $g^{-1}:M''\rightarrow M$. That is, $g \circ g^{-1}(m'')=m''$ for all $m'' \in M''$. To see $g\otimes  1$ is surjective, just observe 
\begin{align*}
  \sum m''_i \otimes  n_i= (g \otimes  1) \Big(\sum g^{-1}(m''_i) \otimes  n_i\Big)
\end{align*}
After computing 
\begin{align*}
(g \otimes  1)\circ (f\otimes  1)= (g\circ f)\otimes  (1 \circ 1)= 0
\end{align*}
we may reduce the problem into proving the factored map 
\begin{align*}
\operatorname{Coker}(f\otimes 1) \overset{\tilde{g}}{\longrightarrow } M'' \otimes  N
\end{align*}
is injective. Consider the map $h:M''\times N \rightarrow \operatorname{Coker}(f\otimes  1)$ defined by 
\begin{align*}
h(m'',n)\triangleq [g^{-1}(m'')\otimes  n]
\end{align*}
Clearly, $h$ is linear in $n$. Using the fact $\operatorname{Im}(f)=\operatorname{Ker}(g)$ and computation  
\begin{align*}
g(g^{-1}(am'')-ag^{-1}(m''))&=0\\
g(g^{-1}(m_1''+m_2'')-g^{-1}(m_1'')-g^{-1}(m_2''))&=0
\end{align*}
we may conclude that $h$ is also linear in  $M''$. Now, because $h$ is bilinear, we may induce some linear $\tilde{h}:M''\otimes  N\rightarrow \operatorname{Coker}(f\otimes  1)$ with action 
\begin{align*}
\tilde{h} (m''\otimes  n)=[g^{-1}(m'')\otimes  n]
\end{align*}
Using universal property, it is east to check that $\tilde{h}\circ \tilde{g} \in \operatorname{End}(\operatorname{Coker}(f\otimes  1))$ is identity mapping. We have shown $\tilde{g}$ is injective. 
\end{proof}
\begin{mdframed}
Note that the exaction of tensor product holds only for sequence of the \myref{form}{Mfg}. One can't delete the zero space at the end and still reach the same conclusion. Consider 
\begin{align*}
0\longrightarrow \Z \overset{f(x)=2x}{\longrightarrow }\Z 
\end{align*}
where the underlying ring is $\Z$. The sequence 
\begin{align*}
0\longrightarrow \Z \otimes \operatorname{Coker}(f) \overset{f\otimes  1}{\longrightarrow } \Z \otimes  \operatorname{Coker}(f)
\end{align*}
is not exact, because 
\begin{align*}
  (f\otimes 1)(x \otimes  [y])=2x \otimes  [y]= x \otimes  [2y]= 0 
\end{align*}
implies $\operatorname{Ker}(f\otimes  1)=\Z \otimes  \operatorname{Coker}(f)$, while 
\begin{align*}
\Z \otimes  \operatorname{Coker}(f)\cong  \operatorname{Coker}(f)\neq 0 
\end{align*}
An $A$-module $N$ is said to be \textbf{flat} if for any exact sequence 
\begin{align*}
\cdots \rightarrow M_{i-1} \overset{f_{i-1}}{\longrightarrow } M_i \overset{f_i}{\longrightarrow }M_{i+1}\rightarrow \cdots
\end{align*}
in the category of $A$-modules, the sequence 
 \begin{align*}
\cdots \rightarrow M_{i-1}\otimes  N \overset{f_{i-1}\otimes  1}{\longrightarrow }M_i \otimes  N \overset{f_i \otimes 1 }{\longrightarrow }M_{i+1}\otimes  N \rightarrow \cdots 
\end{align*}
is also exact. 
\end{mdframed}
\begin{question}{}{}
Show that for an $A$-module  $N$, the following are equivalents 
\begin{enumerate}[label=(\alph*)]
  \item $N$ is flat. 
  \item If $0\rightarrow M'\longrightarrow M\longrightarrow M''\rightarrow  0$ is exact, then $0\rightarrow  M'\otimes N \longrightarrow M\otimes N \longrightarrow M''\otimes N \rightarrow 0$ is also exact. 
  \item If $f:M'\rightarrow M$ is injective, then $f\otimes  1:M'\otimes  N \rightarrow M\otimes N$ is injective. 
  \item If $f:M'\rightarrow N$ is injective and $M,M'$ are finitely generated, then  $f\otimes 1:M'\otimes N\rightarrow M\otimes N$ is injective. 
\end{enumerate}
\end{question}
\begin{proof}
From (a) to (b) is definition. We now prove from (b) to (a). Consider the exact sequence  
\begin{align*}
\cdots \rightarrow M_{i-1} \overset{f_{i-1}}{\longrightarrow } M_i \overset{f_i}{\longrightarrow }M_{i+1}\rightarrow \cdots
\end{align*}
We may split this into a short exact sequence 
\begin{align*}
0\longrightarrow  \operatorname{Im}(f_{i-1})\hookrightarrow M_i \overset{f_i}{\longrightarrow }\operatorname{Im}(f_i)\longrightarrow 0
\end{align*}
By (b), the short sequence
\begin{align*}
0\longrightarrow \operatorname{Im}(f_{i-1})\otimes  N \hookrightarrow M_i \otimes  N \overset{f_i\otimes 1}{\longrightarrow }\operatorname{Im}(f_i)\otimes  N \longrightarrow 0 
\end{align*}
is also exact. This implies 
\begin{align*}
\operatorname{Ker}(f_i\otimes  1)=\operatorname{Im}(f_{i-1})\otimes N=\operatorname{Im}(f_{i-1}\otimes  1)
\end{align*}
We have shown 
\begin{align*}
\cdots \rightarrow M_{i-1} \otimes  N \overset{f_{i-1}\otimes  1}{\longrightarrow } M_i \otimes  N \overset{f_i\otimes  1}{\longrightarrow }M_{i+1}\otimes  N\rightarrow \cdots
\end{align*}
is also exact, thus proving (a). From (b) to (c), we simply let $M''\triangleq \operatorname{Coker}(f)$ and let  $M\rightarrow M''$ be the quotient map. From (c) to (b) follows from right exaction and 
\begin{align*}
\operatorname{Im}(f\otimes 1)=\operatorname{Im}(f)\otimes  N = \operatorname{Ker}(g)\otimes N= \operatorname{Ker}(g\otimes 1) 
\end{align*}
From (c) to (d) is clear. It only remains to show from  (d) to (c). \\

Fix 
\begin{align*}
u = \sum_{i=1}^n x_i \otimes  y_i \in \operatorname{Ker}(f\otimes  1)
\end{align*}
Let $M_0'$ be the submodule of $M'$ generated by $\set{x_1,\dots ,x_n}$, and let $u_0' \in M'_0\otimes  N$ be the element 
\begin{align*}
u_0'\triangleq \sum_{i=1}^n x_i \otimes  y_i \in M'_0 \otimes  N
\end{align*}
By Corollary 2.13, there exists some finitely generated submodule $M_0$ of  $M$ such that $u_0 \in M_0\otimes N$ defined by
 \begin{align*}
u_0\triangleq \sum_{i=1}^n f(x_i) \otimes y_i \in M_0 \otimes  N
\end{align*}
equals to $0$. Note that because $\set{x_1,\dots ,x_n}$ generates $M'_0$ and  $M_0$ contains $\set{f(x_1),\dots ,f(x_n)}$, so $M_0$  contains $f(M'_0)$, and obviously 
\begin{align*}
f|_{M_0'}:M_0'\rightarrow M_0\text{ is injective. }
\end{align*}
We now see from (d) that 
\begin{align*}
f|_{M_0'}\otimes 1:M'_0 \otimes  N\rightarrow M_0 \otimes  N\text{ is injective. }
\end{align*}
Compute 
\begin{align*}
  (f|_{M'_0}\otimes  1)(u_0')= \sum_{i=1}^n f(x_i)\otimes  y_i=u_0=0
\end{align*}
We see $u'_0=\sum_{i=1}^n x_i \otimes  y_i \in M'_0 \otimes  N$ is zero. Now consider  the universal property 
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJNJ18wIFxcdGltZXMgTiAiXSxbMiwwLCJNJ18wIFxcb3RpbWVzIE4iXSxbMiwyLCJNJyBcXG90aW1lcyBOIl0sWzAsMl0sWzAsMV0sWzEsMiwiXFxwaGkiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	{M'_0 \times N } && {M'_0 \otimes N} \\
	\\
	&& {M' \otimes N}
	\arrow[from=1-1, to=1-3]
	\arrow[from=1-1, to=3-3]
	\arrow["\pfi"', dashed, from=1-3, to=3-3]
\end{tikzcd}\]
We may see $u=\pfi(u_0')$ is zero. Finishing the proof. 
\end{proof}
\begin{question}{Exercise 2.20}{}
Let ring $B$ be an  $(A,B)$-bimodule, and let $M$ be a flat  $A$-module. Show that the extension of scalar $B\otimes_A M$ is a flat $B$-module. 
\end{question}
\begin{proof}
Let $g:P'\rightarrow P$ be an injective $B$-module homomorphism.  We are required to show 
\begin{align*}
P' \otimes_B (B \otimes _A M) \overset{g\otimes 1}{\longrightarrow } P \otimes  _B (B \otimes_A M)
\end{align*}
is also injective. We have the isomorphism 
\begin{align*}
P' \otimes  _B (B\otimes  _A M) \cong  (P' \otimes  _B B) \otimes_A M \cong  P' \otimes _A M 
\end{align*}
It now follows from $M$ being flat that  $g\otimes  1$ is injective. 


\end{proof}
\section{Script 1}

I proved and gathered the propositions in my paragraphs. 
\begin{theorem}
\textbf{(Ideal Quotients are well defined)} If we define for each pair $I,S$ of ideals of $R$ their \textbf{ideal quotient} by
\begin{align*}
  (I:S)\triangleq \set{x\in R: xy \in I\text{ for all }y \in S }
\end{align*}
Then $(I:S)$ forms an ideal.  
\end{theorem}
\begin{proof}
To see $(I:S)$ is closed under addition, let $x,z \in I,y \in S,$ and observe 
\begin{align*}
  (x+z)y=xz+yz \in I
\end{align*}
To see $(I:S)$ is a multiplicative black hole, let $u \in (I:S),v \in R,s \in S$ and observe 
\begin{align*}
  (uv)s=v(us)\in I\text{ because }us \in I
\end{align*}
\end{proof}
\begin{theorem}
\textbf{(Description of annihilator)} Given some ideal $I$ of $R$, we use the notation $\operatorname{Ann}(I)$ to denote its \textbf{annihilator} $(\set{0}:I)$. We have 
\begin{align*}
\operatorname{Ann}(I)=\set{x\in R: xy=0\text{ for all }y \in I}
\end{align*}
\end{theorem}
\begin{proof}
Obvious.
\end{proof}
\begin{mdframed}
Given a principal ideal $\langle x\rangle $, we shall always denote its annihilator simply by $\operatorname{Ann}(x)$
\end{mdframed}
\begin{theorem}
\textbf{(Description of the set of zero-divisors)} If we denote  $D$ the set of zero-divisors of $R$, we have 
\begin{align*}
D = \bigcup_{x\neq 0 \in R} \operatorname{Ann}(x )
\end{align*}
\end{theorem}
\begin{proof}
If $d$ is a zero-divisor, then $d \in \operatorname{Ann}(s)$ for the $s\neq 0$ that divides $0$ with  $d$.  If $x\neq 0$ and $y \in \operatorname{Ann}(x)$, then $yx=0$.  
\end{proof}
\begin{theorem}
\textbf{(An example)} Let $R\triangleq \Z,I\triangleq \langle m\rangle$ and $S\triangleq \langle n\rangle $. We have 
\begin{align*}
  (I:S)=\langle q\rangle 
\end{align*}
Where  
\begin{align*}
q= \frac{m}{(m,n)}\text{ and }(m,n)\text{ is the highest common factor of $m$ and $n$. }
\end{align*}
\end{theorem}
\begin{proof}
To show $\langle q\rangle \subseteq (I:S)$, we only have to show $q \in (I:S)$. Let $p$ be arbitrary integer so $pn$ is an arbitrary element of  $S$. Note that 
\begin{align*}
m \mid mp \cdot \frac{n}{(m,n)} =  q (pn) \implies  q(pn) \in I
\end{align*}
Because $pn$ is an arbitrary element of  $S$, we have shown  $q\in (I:S)$. To show $(I:S)\subseteq \langle q\rangle $, let $p \in (I:S)$. Because $p \in (I:S)$, we know $pn\in I$. That is, 
\begin{align*}
m \mid  pn
\end{align*}
Dividing both side with $(m,n)$, we see  
\begin{align*}
q \mid p \cdot \frac{n}{(m,n)} 
\end{align*}
Because $q= \frac{m}{(m,n)}$ is by definition coprime with $\frac{n}{(m,n)}$, we can now deduce 
\begin{align*}
q \mid p 
\end{align*}
as desired.
\end{proof}
\begin{question}{}{}
Let $I,S,T,V_\alpha $ be ideals of ring $R$. Show 
\begin{enumerate}[label=(\alph*)]
  \item $I \subseteq (I:S)$. 
  \item $(I:S)S \subseteq I$. 
  \item $((I:S):T)=(I:ST)=((I:T):S)$. 
  \item $(\bigcap  V_\alpha : S)= \bigcap  (V_\alpha :S)$. 
  \item $(I: \sum V_\alpha )=\bigcap (I:V_\alpha )$. 
\end{enumerate}
\end{question}
\begin{proof}
Proposition (a) is obvious. Proposition (b) is also obvious once we reduce the problem into proving the single sum $xy$ belongs to  $I$ where  $x\in (I:S)$ and $y \in S$. For proposition (c), we first show 
\begin{align*}
\vi{((I:S):T)\subseteq (I:ST)}
\end{align*}
Because ideal is closed under addition, we only have to prove $xst\in I$ where $x\in ((I:S):T), s \in S\text{ and } t \in T$, which follows from noting $xt \in (I:S)$. $\vdone$. Note that  
\begin{align*}
\blue{(I:ST)\subseteq ((I:T):S)}
\end{align*}
is obvious. $\bdone$. Lastly, we show 
\begin{align*}
\vi{((I:T):S)\subseteq ((I:S):T)}
\end{align*}
Let $x\in ((I:T):S),t\in T$ and $s \in S$. We are required to show $xts \in I$, which is obvious since $xs \in (I:T)$. $\vdone$. Proposition (d) is obvious.  Let $x \in (I: \sum V_\alpha )$. Fix $\alpha $ and $r \in V_\alpha $. Because $r\in \sum V_\alpha $, we see $xr\in I$. Let $x$ be in the intersection, it is clear that $x \sum v_\alpha =\sum xv_\alpha \in I$ because $xv_\alpha \in I$.     
\end{proof}
\begin{theorem}
\textbf{(Radicals of ideals are well-defined)} If $I$ is an ideal of $R$, then the  \textbf{radical} of $I$ defined by 
 \begin{align*}
r(I)\triangleq  \set{x\in R: x^n\in I\text{ for some }n>0}
\end{align*}
is also an ideal. 
\end{theorem}
\begin{proof}
  To see $r(I)$ is closed under addition, let $x^n,y^m \in I$, and observe $(x+y)^{n+m}\in I$. To see $r(I)$ is a multiplicative black hole, let $x^n\in I,v \in R$ and observe $(xv)^n=x^nv^n \in I$. 
\end{proof}
\begin{theorem}
\textbf{(Description of Radicals)} Let $\pi : R \rightarrow R \quotient I$ be the quotient map. We have
\begin{align*}
r(I)= \pi ^{-1}(\operatorname{Nil}(R\quotient I)) 
\end{align*}
\end{theorem}
\begin{proof}
Obvious. 
\end{proof}
\begin{question}{}{}
  \begin{enumerate}[label=(\alph*)]
    \item $I \subseteq r(I)$. 
    \item $r(r(I))=r(I)$.  
    \item $r(IS)=r(I\cap S)=r(I)\cap r(S)$
    \item $r(I)=R \iff  I= R$. 
    \item $r(I+S)=r(r(I)+r(S))$. 
    \item If $I$ is prime, then  $r(I^n)=I$ for all $n>0$. 
  \end{enumerate}
\end{question}
\begin{proof}
Proposition (a) and (b) are obvious. The proposition
\begin{align*}
r(IS)\subseteq r(I\cap S) 
\end{align*}
follows from $IS \subseteq I \cap S$. The propositions 
\begin{align*}
r(I \cap S)\subseteq r(I)\cap r(S)\text{ and }r(I) \cap r(S) \subseteq r(IS)
\end{align*}
are clear, thus proving proposition (c). The proposition 
\begin{align*}
I=R \implies  r(I)=R 
\end{align*}
is clear, and its converse follows from $1\in r(I)\implies 1=1^n \in I$, thus proving proposition (d). The proposition 
\begin{align*}
r(I+S)\subseteq r(r(I)+r(S))
\end{align*}
is clear. Let $x^n=y+z$ where  $y^m \in I$ and $z^p \in S$. We see $x^{n(m+p)}\in I+S$. We have shown 
\begin{align*}
r(r(I)+r(S)) \subseteq r(I+S)
\end{align*}
thus proving proposition (e). Let $I$ be prime. We know $I \subseteq r(I)$. To see the converse, let $x^n \in I$. Because $I$ is prime, either  $x$ or  $x^{n-1}$ belongs to $I$. If  $x$ does not belong to  $I$, then  $x^{n-1}$ belongs to $I$, which implies either $x\in I$ or $x^{n-2}\in I$. Applying the same argument repeatedly, we see $x \in I$, thus proving $r(I)\subseteq I$. Because 
\begin{align*}
I \supseteq I^2 \supseteq I^3 \supseteq I^4 \supseteq \cdots   
\end{align*}
we know
\begin{align*}
r(I) \supseteq r(I^2) \supseteq r(I^3) \supseteq r(I^4) \supseteq \cdots  
\end{align*}
Because 
\begin{align*}
x^n \in I \implies  x^{nk} \in I^k \text{ for all }k \inn
\end{align*}
We now also have 
\begin{align*}
r(I) \subseteq r(I^k)\text{ for all }k  \inn
\end{align*}
This proved proposition (e). 
\end{proof}
\begin{theorem}
\textbf{(Description of radical)}  Let $I$ be an ideal of $R$. 
\begin{align*}
r(I)= \bigcap \set{S \in \operatorname{spec}(R): I \subseteq S}
\end{align*}
\end{theorem}

\section{archived}

There are essentially two distinct substructures of a ring. A subset of a ring is called a \textbf{subring} if it is closed under addition and multiplication and contains the multiplicative identity. 

Because the union of a chain of proper ideals is still a proper ideal\footnote{No proper ideals contain $1$.}, we may apply \textbf{Zorn's Lemma} to show that a \textbf{maximal ideal}\footnote{By a maximal ideal, we mean a proper ideal contained by no other proper ideal.} always exists. Equivalently, we may define a proper ideal $I$ to be maximal if and only if $R\quotient I$ is a field.\\ 

\begin{question}{}{}
Show that the sequence 
\begin{align}
\label{Mu}
M'\overset{u}{\longrightarrow }M  \overset{v}{\longrightarrow }M''\longrightarrow 0
\end{align}
is exact if and only if for every module $N$ the sequence 
\begin{align}
\label{Ns}
0\longrightarrow \operatorname{Hom}(M'',N)\overset{\overline{v}}{\longrightarrow }\operatorname{Hom}(M,N) \overset{\overline{u}}{\longrightarrow } \operatorname{Hom}(M',N)
\end{align}
is exact. 
\end{question}
\begin{proof}
Suppose for every module $N$ the \myref{sequence}{Ns} is exact. To show  \myref{sequence}{Mu} is also exact, we are required to show $v$ is surjective and $\operatorname{Im}(u)=\operatorname{Ker}(v)$. To see $v$ is surjective, let $N\triangleq \operatorname{Coker}(v)$, and use the injectivity of $\overline{v}$ to show that the quotient map $\pi: M''\rightarrow N$ is indeed zero. \\

To see $\operatorname{Im}(u)\subseteq \operatorname{Ker}(v)$, let $N\triangleq M''$, consider the identity mapping $\id _{M''}$, and note that 
\begin{align*}
\overline{u}\circ \overline{v} (\id _{M''}) = \id _{M''} \circ v \circ  u = 0
\end{align*}
To see $\operatorname{Ker}(v)\subseteq \operatorname{Im}(u)$, let $N\triangleq  M\quotient \operatorname{Im}(u)$, and let $\pi :M\rightarrow N$ be the quotient map. Obviously $\pi  \in \operatorname{Ker}(\overline{u})=\operatorname{Im}(\overline{v})$, so there exists some $\psi : M''\rightarrow N$ such that $\pi = \psi \circ v $. This implies $\operatorname{Ker}(v)\subseteq \operatorname{Ker}(\pi )=\operatorname{Im}(u)$. \\

Now, suppose \myref{sequence}{Mu} is exact and let $N$ be some module. To show \myref{sequence}{Ns} is exact, we are required to show $\overline{v}$ is injective and $\operatorname{Im}(\overline{v})=\operatorname{Ker}(\overline{u})$. The fact $\overline{v}$ is injective follows from $v$ is surjective.   








\end{proof}
\section{Mail Draft}
Sorry to bother you. At the bottom of page 51 and the top of page 52, Atiyah and MacDonald claim that for every primary decomposition 
\begin{align}
\label{prim}
I = \bigcap_{i=1}^n Q_i
\end{align}
we may use their Lemma 4.3, which states 
\begin{align*}
\sqrt{T_j}=P\text{ for all primary $T_j \in \set{T_1,\dots ,T_m}$ } \implies \sqrt{\bigcap T_j}=P 
\end{align*}
to reduce  the \myref{decomposition}{prim} into a new decomposition 
\begin{align*}
I = \bigcap_{j=1}^r Q_j'
\end{align*}
such that
\begin{align*}
\bset{\sqrt{Q_1'},\dots ,\sqrt{Q_r'}  }\text{ are all distinct }
\end{align*}
I am quite confused about this. Do they mean that if $\sqrt{Q_1}=\sqrt{Q_2}$, we may use $Q_1 \cap Q_2$ to replace $Q_1$ and  $Q_2$? If so, they didn't show that $Q_1\cap Q_2$ will be primary. Obviously, finite intersection of primary ideals need not be primary in general, and the minimal  
\end{document}

\documentclass{report}
\input{preamble}
\input{macros}
\input{letterfonts}

\title{Notes on Commutative Algebra}
\author{Eric Liu}
\date{}
\begin{document}
\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}

\tableofcontents
\pagebreak
\chapter{Definitions} 
\section{Definition of Rings}
The precise meaning of the term \textbf{ring} varies across different books, depending on the context and purpose. In this note, the multiplication of a ring is always associative and commutative, and have an identity. The additive identity is denoted by $0$. From the axioms, we can straightforwardly show that $x\cdot 0 = 0$ for all $x$. Consequently, the multiplicative and additive identities are always distinct unless the ring contained only one element, called  \textbf{zero} in this case.\\

An \textbf{ideal} of a ring $R$ is an additive subgroup $I$ such that $ar \in I$ for all $a \in I,  r \in R$, or equivalently, the kernel of some \textbf{ring homomorphism}\footnote{Ring homomorphisms are mapping between two rings that respects addition, multiplication and  multiplicative identity.}. To see the equivalency, one simply construct the \textbf{quotient ring}\footnote{Consider the equivalence relation on $R$ defined by  $x\sim  y\overset{\triangle}{\iff } x-y \in I$} $R\quotient I$, under which the quotient map $\pi: R \rightarrow R \quotient  I$ is a surjective ring homomorphism whose kernel is the ideal $I$. Remarkably, the mapping defined by 
 \begin{align*}
\operatorname{Ideal }J\text{ of $R$ that contains }I \mapsto \set{[x]\in R\quotient I: x\in J}
\end{align*}
forms a bijection between the collection of the ideals of $R$ containing  $I$ and the collection of the ideals of $R\quotient I$. This fact is commonly referred to as the \textbf{correspondence theorem} for rings. \\

A \textbf{unit} is an element that has a multiplicative inverse. Under our initial requirement that rings are commutative, for a non-zero ring $R$ to be a \textbf{field}, we only need all non-zero elements of $R$ to be units, or equivalently, the only ideals of $R$ to be $\set{0}$ or $R$ itself.\\

We use the term \textbf{proper} to describe strict set inclusion. By a \textbf{maximal ideal}, we mean a proper ideal $I$ contained by no other proper ideals, or equivalently\footnote{By the Correspondence Theorem for Rings.}, a proper ideal $I$ such that $R\quotient I$ is a field.\\

A \textbf{zero-divisor} is an element $x$ that has some non-zero element $y$ such that  $xy=0$. Again, under our initial requirement that rings are commutative, for a non-zero ring $R$ to be an  \textbf{integral domain}, we only need all non-zero elements to be zero-divisors. By a \textbf{prime ideal}, we mean a proper ideal $I$ such that the product of two elements belongs to $I$ only if one of them belong to $I$, or equivalently, a proper ideal $I$ such that $R\quotient I$ is an integral domain.  \\


There are many binary operations defined for ideals.  Given two ideals $I$ and $S$, we define their \textbf{sum} $I+S$ to be the set of all  $x+y$ where  $x\in I$ and $y \in S$, and define their \textbf{product} $IS$ to be the set of all finite sums $\sum x_iy_i$ where  $x_i \in I$ and $y_i\in S$. Note that the ideal multiplications are indeed distributive over addition, and they are both associative, so it make sense to write something like $I_1+I_2+I_3$ or $I_1I_2I_3$. Obviously, the intersection of ideals is still ideal, while the union of ideals generally are not. Moreover, we define their \textbf{quotient} $(I:S)$ to be the set of elements $x$ of $R$ such that $xy \in I$ for all $y \in S$. To simplify matters, we write $(I:x)$ instead of $(I:\langle x\rangle )$. \\ 

For all subsets $S$ of some ring $R$, we may \textbf{generate} an ideal by setting it to be the set of all finite sum  $\sum rs$ such that $r\in R$ and $s \in S$, or equivalently, the smallest ideal of $R$ containing $S$. An ideal is called \textbf{principal} and denoted by $\langle x\rangle $ if it can be generated by a single element $x$. \\

An element $x$ is called \textbf{nilpotent} if $x^n=0$ for some  $n\inn$. The set of all nilpotent elements obviously form an ideal, which we call \textbf{nilradical} and denote by $\operatorname{Nil}(R)$. Here, we give a nice description of the nilradical. 
\begin{theorem}
\textbf{(Equivalent Definition for Nilradical)} We use the term \textbf{spectrum} of $R$ and the notation  $\operatorname{spec}(R)$ to denote the set of prime ideals of $R$. We have 
 \begin{align*}
\operatorname{Nil}(R)=\bigcap \operatorname{spec}(R)
\end{align*}
\end{theorem}
\begin{proof}
$\operatorname{Nil}(R)\subseteq \bigcap \operatorname{Spec}(R)$ is obvious. Suppose $x \in \bigcap \operatorname{Spec}(R) \setminus  \operatorname{Nil}(R)$. Let $\Sigma$ be the set of ideals $I$ such that $x^n\not\in I$ for all $n>0$. Because unions of chains in $\Sigma$ belong to $\Sigma$ and $0 \in \Sigma$, by Zorn's Lemma, there exists some maximal element $I \in \Sigma$. Because $x\not \in I$, to close out the proof, we only have to show $I$ is prime.\\

Let $yz \in I$. Assume for a contradiction that $y\not\in I$ and $z\not\in I$. By maximality of $I$, both ideal $I+ \langle y\rangle$ and ideal $I+\langle z\rangle$ do not belong to $\Sigma$. This implies $x^n \in I+ \langle y\rangle$ and $x^m \in I + \langle z\rangle $ for some $n,m>0$, which cause a contradiction to $I \in \Sigma$, since $x^{n+m} \in I + \langle yz\rangle =I$. 
\end{proof}
Let $I$ be an ideal of the ring $R$. By the term \textbf{radical} of $I$, we mean $\sqrt{I}\triangleq \set{ x \in R : x^n \in I \text{ for some } n > 0 }$, which is equivalent to  the preimage of $\operatorname{Nil}(R \quotient  I)$ under the quotient map and equivalent\footnote{This follows from the fact that the correspondence between the ideals of $R$ and the ideals of $R \quotient  I$ can be restricted to a bijection between $\operatorname{Spec}(R)$ and $\operatorname{Spec}(R \quotient  I)$.} to the intersection of all prime ideals of $R$ that contain $I$. \\

It should be noted that there is a "less is more" philosophy in our wording and notations for product, quotient and radical of ideals. For any ideal $I,Q$, we have 
 \begin{align*}
IQ \subseteq I \subseteq \sqrt{I}  \text{ and }I \subseteq (I:Q)
\end{align*}
For ease in the section on fraction of rings and modules, we close this section by introducing two concept. Let $f:A\rightarrow B$ be some ring homomorphism. If $E$ is a subset of $A$, we call the ideal in  $B$ generated by $f(E)$ the \textbf{extension} of $E$, which we denote by  $E^e$. If  $E$ is a subset of  $B$, we call the ideal in  $A$ generated by  $f^{-1}(E)$ the \textbf{contraction} of $E$, which we denote by $E^c$. Clearly, if  $E$ is an ideal in $B$, then $E^c=f^{-1}(E)$. 
\section{Definition of Modules and Algebra}
Let $A$ be some ring. By an $A$-\textbf{module}, we mean an abelian group $M$ together with a $A$-scalar multiplication. Given another $A$-module $N$, we use the notation $\operatorname{Hom}(M,N)$ to denote the space of \textbf{$A$-module homomorphism} from  $M$ to $N$. It is clear that the obvious assignment of $A$-scalar multiplication and addition makes $\operatorname{Hom}(M,N)$ a $A$-module.\\

Let $M$ be an $A$-module, and let $N$ be a subset of  $M$. We say $N$ is a $A$-\textbf{submodule} if $N$ forms an additive subgroup and is closed under $A$-scalar multiplication. Just like how ideals is proved to always be the kernel of some ring homomorphism, to see submodules is always the kernel of some $A$-module homomorphism, we simply construct the \textbf{quotient module} $M\quotient N$, and get the quotient map $\pi :M\rightarrow M\quotient N$ that is a $A$-module homomorphism with kernel $N$, and get also the bijection
\begin{align*}
A\text{-submodule $S$ of  $M$ that contains  $N$}\mapsto \set{[x]\in M \quotient N: x \in S}
\end{align*}
 between the collection of the $A$-submodules of $M$ that contains  $N$ and the collection of the $A$-submodule of  $M\quotient  N$. This is called the \textbf{correspondence theorem} for modules.\\


Again similar to the other algebraic structure, we have the \textbf{third isomorphism theorem} for modules. Let $N \subseteq M \subseteq L$ be three modules. It is obvious that $M\quotient N$ is a subset of $L\quotient N$, and moreover, $M\quotient  N$ forms a submodule of  $L\quotient N$. We have an isomorphism $\pfi:(L\quotient N)\quotient (M\quotient N)\to L\quotient M$ defined by $(l+N)+ (M\quotient N)\mapsto l+M$. To simplify matters, from now on we use the term "module" in place of "$A$-module" until the end of this section. \\




Let $\set{M_i:i \in I}$ be a collection of modules. If we give the Cartesian product $\prod M_i$ the obvious addition and multiplication, then we say it is the \textbf{direct product}. It is clear that 
\begin{align*}
\bset{(x_i)_{i \in I} \in \prod_{i \in I}M_i:x_i \neq 0\text{ for finitely many }i.}
\end{align*}
forms a submodule of the direct product. We denote this submodule by $\bigoplus M_i$, and call it the  \textbf{direct sum}.  Obviously, if the index set $I$ is finite, then the direct product and direct sum are identical.  \\


Given a subset $E$ of  $M$, clearly its \textbf{span}, the set of finite sum $\sum rx$ where $x \in E$, forms a submodule. Interestingly, depending on the view one wish to take, there are multiple common notation for spans of $E$. To view modules as generalization of vector spaces, one may write  $\operatorname{span}(E)$, to view module as generalizations of rings, one may write $\langle E\rangle$, and to adapt the algebraic convention, one may also write $\sum_{x \in E}Ax$. \\ 


We say  $M$ is \textbf{finitely generated} if $M$ can be spanned by some finite set $\set{x_1,\dots ,x_n}\subseteq M$. Clearly,  $(a_1,\dots ,a_n)\mapsto \sum a_ix_i$ forms a surjective homomorphism from $A^n$ to $M$, which implies $M$ is isomorphic to some quotient of $A^n$. This behavior, albeit seems unimportant for now, will later prove to be useful for it guarantees that finitely generated module over rings of some certain properties carry the same property.\footnote{For example, this shows that finitely generated module over Noetherian ring is Noetherian. See \myref{Section}{FGN}} \\

By the \textbf{Jacobson radical} $\operatorname{Jacob}(A)$ of $A$, we mean the intersection of all maximal ideals of $A$. Given an ideal $\mathfrak{a}$ of $A$, some  module $M$ and some  submodule  $N$ of  $M$, the \textbf{product $\mathfrak{a}N$ of the submodule $N$  by the ideal $\mathfrak{a}$} is the submodule of $M$ consisting of finite sum $\sum a_i x_i$ where $a_i \in \mathfrak{a}$ and $x_i \in N$. We may now state  \customref{Nakayama}{Nakyama's Lemma}. 
\begin{lemma}
\label{Nakayama}
\textbf{(Nakayama)} Let $M$ be a finitely generate $A$-module, and  $\mathfrak{a}$ an ideal of $A$ contained by the Jacobson radical of  $A$. If  $\mathfrak{a}M=M$, then $M=0$. 
\end{lemma}
\begin{proof}
Assume for a contradiction that $M\neq 0$. Let $u_1,\dots ,u_n$ be a minimal set of generators of $M$. Write $u_n=a_1u_1+\cdots + a_n  u_n$ where $a_i \in \mathfrak{a}$. This give us 
\begin{align}
\label{1anun}
  (1-a_n) u_n= a_1u_1+\cdots + a_{n-1}u_{n-1}
\end{align}
We know that $1-a_n$ must be a unit, otherwise by Zorn's Lemma\footnote{Note that union of proper ideals is always proper because otherwise one of them would have contain $1$.} there exists a maximal ideal $\mathfrak{m}$ containing  $1-a_n$, which is impossible since  $a_n \in \operatorname{Jacob}(A)$ would have implies $1 \in \mathfrak{m}$. Because $1-a_n$ is a unit, by \myref{Equation}{1anun}, $u_n$ can be generated by  $\set{u_1,\dots ,u_{n-1}}$, a contradiction to the minimality of $\set{u_1,\dots ,u_n}$. 



\end{proof}
\section{Localization}
Let $A$ be a ring. We say  $S\subseteq A$ is a \textbf{multiplicatively closed subset} of $A$ if  $S$ contains $1$ and is closed under multiplication. We say a ring $B$ and a homomorphism $f:A\rightarrow B$ satisfies the \textbf{universal property of localization of $A$ by $S$} if
\begin{enumerate}[label=(\alph*)]
  \item $f(S) \subseteq B^{\times}$. 
  \item $f(a)=0\implies as=0$  for some $s \in S$. 
  \item $B= \set{f(a)f(s)^{-1}: a \in A\text{ and }  s \in S}$
\end{enumerate}
Suppose $A\overset{f}{\longrightarrow }B$ satisfies the universal property of localization of $A$ by  $S$. A routine check shows that  for any ring homomorphism $g:A\rightarrow C$ that maps $S$ into  $C^{\times}$, the ring homomorphism $\tilde{g}:B\rightarrow C$ well-defined by $\tilde{g}(f(a)f(s)^{-1})\triangleq g(a)g(s)^{-1} $ is the unique ring homomorphism such that the diagram
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJBIl0sWzIsMCwiQiJdLFsyLDIsIkMiXSxbMCwyLCJnIiwyXSxbMCwxLCJmIl0sWzEsMiwiXFx0aWxkZXtmfSIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
\[\begin{tikzcd}
	A && B \\
	\\
	&& C
	\arrow["f", from=1-1, to=1-3]
	\arrow["g"', from=1-1, to=3-3]
	\arrow["{\tilde{g}}", dashed, from=1-3, to=3-3]
\end{tikzcd}\]
commutes. Just like the universal properties for other mathematical objects, one many check\footnote{The proof is exactly the same as the ones for other mathematical objects.} that if  $A\overset{f'}{\longrightarrow }B'$ also satisfies the universal property of localization of $A$ by $S$, then $B \cong B'$. Immediately, we need to ask: Does there really exists some $A \overset{f}{\longrightarrow }B$ that satisfies the universal property of localization of $A$ by $S$? The answer if of course affirmative: Define an equivalence relation on  $A \times S$ by 
\begin{align*}
  (a,s)\sim  (b,t) \overset{\triangle}{\iff } (at-bs)u=0\text{ for some }u \in S
\end{align*}
Denoting the set of equivalence classes by $S^{-1}A$ and denoting the equivalence class of $(a,s)$ by $\frac{a}{s}$, we have a ring structure on $S^{-1}A$ from defining 
\begin{align*}
 \frac{a}{s}+ \frac{b}{t}\triangleq \frac{at+bs}{st} \text{ and } \frac{a}{s}\cdot \frac{b}{t}\triangleq \frac{ab}{st}
\end{align*}
Clearly, the \textbf{canonical} ring homomorphism $A\longrightarrow S^{-1}A;a \mapsto \frac{a}{1}$ satisfies the universal property of localization of $A$ by  $S$, and just as out notation and intuition suggest, $S^{-1}A=0$ if $0 \in S$. \\

If $P$ is a prime ideal of  $A$, we often just call  $A_P\triangleq (A\setminus P)^{-1}A$ the \textbf{localization of $A$ at $P$}. A nonzero ring is said to be a \textbf{local ring} if it has only one maximal ideal. One may check that a ring $A$ is local if and only if it is the localization of some ring $B$ at some prime ideal  $P$ of  $B$\footnote{If $A$ is local, then it is the localization of itself at its unique maximal ideal. If $A=B_P$, then the set of non-units $\set{\frac{p}{s}\in B_P:p \in P}$ is clearly the only maximal ideal of $A$.}, thus the naming of "local ring". \\





Let $I\subseteq A$ be some ideal, clearly its extension is the \textbf{localization of $I$ by $S$} defined by $S^{-1}I= \set{\frac{i}{s}\in S^{-1}A:i \in I}$. We use the notation $S(I)$ to denote the contraction of $S^{-1}I$. For \customref{UoP}{the section on uniqueness of primary decomposition}, we first prove some basic properties of localization of ideals. 
\begin{theorem}
\label{Pol}
\textbf{(Properties of localization of ideals)} Let $A$ be a ring, and let  $S$ be some multiplicatively closed subset of  $A$. 
 \begin{enumerate}[label=(\alph*)]
  \item If $I$ is an ideal in  $A$, then  
    \begin{align*}
    S(I)=\bigcup_{s \in S} (I:s)
    \end{align*} 
    \item If $I$ is an ideal in $A$, then 
\begin{align*}
\sqrt{S^{-1}I}=S^{-1}\sqrt{I}        
\end{align*}
\item If $I_1,\dots ,I_n$ are ideals in $A$, then 
   \begin{align*}
  S^{-1}(I_1 \cap \cdots \cap I_n)= S^{-1}I_1 \cap  \cdots \cap S^{-1} I_n
  \end{align*}
\end{enumerate}
\end{theorem}
\begin{proof}
We first prove part (a). Let $t \in (I:s)$ for some $s$. Because  $\frac{t}{1}= \frac{st}{s} \in S^{-1}I$, we see $t \in I^{ec}$. Let $t \in I^{ec}$, so $\frac{t}{1}= \frac{i}{s}$ for some $i \in I,s \in S$. Observe $ ts s'=is' \in I$ for some $s'$ to conclude $t \in (I:s s')$, and we are done. We now prove part (b). It is clear that $S^{-1}\sqrt{I}\subseteq \sqrt{S^{-1}I}$. Let $\frac{a}{s}\in \sqrt{S^{-1}I}$, so $\frac{a^n}{s^n}=\frac{i}{s'}\in S^{-1}I$ for some $n,i,s'$. Let $s''$ satisfies  $a^n s' s''= is^n s'' \in I$. Observations of $\frac{a}{s}= \frac{a s' s''}{s s' s''}$ and $a s' s'' \in \sqrt{I}$ finish the proof.  We now prove part (c). It is clear that $S^{-1}(I_1 \cap  \cdots \cap I_n)\subseteq S^{-1}I_1 \cap \cdots S^{-1}I_n$. Let $\frac{a}{s}\in S^{-1}I_1 \cap \cdots \cap  S^{-1}I_n$. For each $j\in \set{1,\dots ,n}$, we may find $s_j,s_j'\in S,i_j \in I$ such that  $as_js_j'=s i_j s_j' \in I_j$. Writing 
 \begin{align*}
\frac{a}{s}= \frac{as_1s_1' s_2 s_2' \cdots s_n s_n'}{s s_1 s_1' s_2 s_2' \cdots  s_n s_n'}  \in S^{-1}(I_1\cap  \cdots \cap I_n)
\end{align*}
and we are done. 
\end{proof}
\section{Integral Dependence}
Let $A$ be a subring of some ring  $B$. We say  $x \in B$ is \textbf{integral over} $A$ if  $x$ is a root of some monic polynomial with coefficients in $A$. 
\begin{theorem}
\label{CHTffgm}
\textbf{(Cayley-Hamilton Theorem for finitely generated module)} Suppose $\mathfrak{a}\subseteq A$ is an ideal, and $M$ is a finitely generated $A$-module. If $\pfi \in \operatorname{End}(M)$ satisfies $\operatorname{Im}\pfi \subseteq \mathfrak{a}M$, then there exists some $a_0,\dots ,a_{n-1} \in \mathfrak{a}$ such that 
\begin{align*}
  \pfi^n + a_{n-1}\pfi^{n-1}+\cdots + a_0= 0
\end{align*}
\end{theorem}
\begin{proof}
Let $\set{m_1,\dots , m_n}$ generate $M$. Because $\operatorname{Im}(\pfi)\subseteq \mathfrak{a}M$, we may write 
\begin{align*}
 \pfi(m_i)= \sum_{j=1}^n a_{ij}m_j,\quad \text{where }a_{ij}\in \mathfrak{a}
\end{align*}
Clearly, for each $i$, we have 
\begin{align*}
\sum_{j=1}^n (\delta_{ij}\pfi - a_{ij}\textbf{1})m_i=0, 
\end{align*}
where $\textbf{1} \in \operatorname{End}(M)$ is the identity operator and $\delta_{ij}$ is the Kronecker delta. Defining $R\triangleq A[\pfi]\subseteq \operatorname{End}(M)$, we may now view $\delta_{ij}\pfi - a_{ij}\textbf{1}$ as an $n\times n$ matrix, whose entries are elements of ring $R$. Because $R$ is a commutative unital ring, there exist $R$-matrix $X$ \textbf{adjugate} to $(\delta_{ij}\pfi-a_{ij}\textbf{1})$, i.e., $X (\delta_{ij}\pfi-a_{ij}\textbf{1})=\operatorname{det}(\delta_{ij}\pfi-a_{ij}\textbf{1})I$, where $I$ is the identity  $R$-matrix. This implies that 
\begin{align*}
\operatorname{det} (\delta_{ij}\pfi-a_{ij}\textbf{1}) m_k=0,\quad \text{ for all }k \in \set{1,\dots ,n}
\end{align*}
Noting that $\operatorname{der}(\delta_{ij}\pfi - a_{ij}\textbf{1})$ is an $\mathfrak{a}$-polynomial in $\pfi$ and $M=\langle m_1,\dots ,m_n\rangle $, our proof is done. 
\end{proof}
\customref{CHTffgm}{Cayley-Hamilton Theorem for finitely generated module} allow us to give the following equivalent definitions of integral dependence, which are the keys for defining integral closure.  
\begin{theorem}
\label{EDfid}
\textbf{(Equivalent Definitions for integral dependence)} Let $A$ be a subring of $B$, and let $x \in B$. The following are equivalent: 
\begin{enumerate}[label=(\roman*)]
  \item $x\in B$ is integral over $A$.  
  \item $A[x]$ is a finitely generated $A$-module. 
  \item $A[x]$ is contained in a subring $C$ of $B$ such that $C$ as the obvious $A$-module is finitely generated. 
\end{enumerate}
\end{theorem}
\begin{proof}
  $(\text{i})\implies (\text{ii})\implies (\text{iii})$ is clear. We now prove $(\text{iii})\implies (\text{i})$. Define an $A$-module endomorphism  $\pfi: C\rightarrow C$ by $c\mapsto xc$. By \customref{CHTffgm}{Cayley-Hamilton Theorem for finitely generated module}, $\pfi^n + a_{n-1}\pfi^{n-1}+\cdots + a_0=0$.  In other words, $(x^n+a_{n-1}x^{n-1}+\cdots + a_0)c=0$ for all $c \in C$. Consider the case when $c=1$, and we are done.  
\end{proof}
\begin{corollary}
\label{DoIC}
\textbf{(Definition of Integral Closure)} If $A$ is a subring of  $B$, then the set of elements of $B$ which are integral over $A$ forms a subring of $B$ containing  $A$. 
\end{corollary}
\begin{proof}
Let $x,y\in B$ be integral over $A$. We are required to prove  $x\pm y,xy$ are also integral over $A$. The first step of the proof is to observe that $A[x+y],A[x-y],A[xy]$ are both contained by the ring $A[x,y]$, which is a subring of $C$. Therefore, we only have to show $A[x,y]$ as an $A$-module is finitely generated.\\

Now, note that $A[x,y]=(A[x])[y]$. Clearly $y$ is integral over  $A[x]$, so we know  $A[x,y]=(A[x])[y]$ is a finitely generated $A[x]$-module. Moreover, because $x$ is integral over $A$, we also know  $A[x]$ is a finitely generated $A$-module. Let $A[x,y]$ as an $A[x]$-module be generated by $\set{z_1,\dots ,z_n}$, and let $A[x]$ as an $A$-module be generated by $\set{v_1,\dots ,v_k}$. It is easy to check that, indeed, $A[x,y]$ as an $A$-module is generated  by $\set{z_iv_j \in A[x,y]: 1 \leq i \leq n,1\leq j\leq k}$. 
\end{proof}
Let $A$ be a subring of  $B$. Because of \myref{Corollary}{DoIC}, when we talk about the \textbf{integral closure of $A$ in $B$}, the set of elements of $B$ integral over $A$, we know we are indeed talking about a ring. If $B$ itself is the integral closure of $A$ in $B$, we say  $A$ is \textbf{integrally closed} in $B$. \\

For the proof of  \myref{Corollary}{ToIC}, note that induction and argument similar to the second paragraph of the proof of \myref{Corollary}{DoIC} shows that if $x_1,\dots ,x_n$ are all integral over $A$, then  $A[x_1,\dots ,x_n]$ as an $A$-module is finitely generated.
\begin{corollary}
\label{ToIC}
\textbf{(Transitivity of Integral Closure)} Let $B$ be a subring of  $C$, and  $A$ a subring of $B$. If $A$ is integrally closed in $B$ and  $B$ is integrally closed in $C$, then  $A$ is integrally closed in $C$.
\end{corollary}
\begin{proof}
Let $x \in C$. Because $B$ is integrally closed in $C$, we know 
 \begin{align*}
x^n+b_{n-1}x^{n-1}+ \cdots + b_0=0,\quad \text{for some }b_0,\dots ,b_{n-1} \in B
\end{align*}
By \myref{Theorem}{EDfid}, we are only required to show $A[b_0,\dots ,b_{n-1},x]$ as an $A$-module is finitely generated. Clearly, $x$ is integral over the subring $A[b_0,\dots ,b_{n-1}]$, so by \myref{Theorem}{EDfid}, we know $A[b_0,\dots ,b_{n-1},x]$ as an $A[b_0,\dots ,b_{n-1}]$-module is finitely generated. The proof then follows from noting $A[b_0,\dots ,b_{n-1}]$ is finitely generated as an $A$-module since all  $b_0,\dots ,b_{n-1}$ are all integral over $A$.  
\end{proof}
\section{The Nonsense Lemmas}
Let $R$ be some ring. Given a sequence of $R$-modules and $R$-modules homomorphism 
\begin{align*}
\cdots \longrightarrow M_{k-1} \overset{f}{\longrightarrow } M_k \overset{g}{\longrightarrow } M_{k+1} \longrightarrow \cdots 
\end{align*}
we say the sequence is \textbf{exact} at $M_k$ if  $\operatorname{Im}(f)=\operatorname{Ker}(g)$, and we say a sequence is \textbf{exact} if it is exact at each of its module. By a \textbf{short} exact sequence, we mean exact sequence of the form 
\begin{align*}
0 \longrightarrow   M' \longrightarrow M \longrightarrow M'' \longrightarrow  0
\end{align*}

\begin{lemma}
\label{FL}
\textbf{(Five Lemma)}
% https://q.uiver.app/#q=WzAsMTAsWzAsMCwiQSJdLFsyLDAsIkIiXSxbNCwwLCJDIl0sWzYsMCwiRCJdLFs4LDAsIkUiXSxbMCwyLCJBJyJdLFsyLDIsIkInIl0sWzQsMiwiQyciXSxbNiwyLCJEJyJdLFs4LDIsIkUnIl0sWzAsMSwiZiJdLFsxLDIsImciXSxbMiwzLCJoIl0sWzMsNCwiaiJdLFs1LDYsInIiXSxbNiw3LCJzIl0sWzcsOCwidCJdLFs4LDksInUiXSxbMCw1LCJsIiwxXSxbMSw2LCJtIiwxXSxbMiw3LCJuIiwxXSxbMyw4LCJwIiwxXSxbNCw5LCJxIiwxXV0=
Given a commutative diagram in the category of $R$-module: 
\[\begin{tikzcd}
	A && B && C && D && E \\
	\\
	{A'} && {B'} && {C'} && {D'} && {E'}
	\arrow["f", from=1-1, to=1-3]
	\arrow["l"{description}, from=1-1, to=3-1]
	\arrow["g", from=1-3, to=1-5]
	\arrow["m"{description}, from=1-3, to=3-3]
	\arrow["h", from=1-5, to=1-7]
	\arrow["n"{description}, from=1-5, to=3-5]
	\arrow["j", from=1-7, to=1-9]
	\arrow["p"{description}, from=1-7, to=3-7]
	\arrow["q"{description}, from=1-9, to=3-9]
	\arrow["r", from=3-1, to=3-3]
	\arrow["s", from=3-3, to=3-5]
	\arrow["t", from=3-5, to=3-7]
	\arrow["u", from=3-7, to=3-9]
\end{tikzcd}\]
If the two rows are exact, $m,p$ are isomorphism, $l$ is surjective and  $q$ is injective, then $n$ is also an isomorphism. The proof of Five Lemma follows immediately from the two Four Lemma, and their proof are both just diagram chasing. For demonstration, we present a proof for the \customref{FFL}{first four lemma}. 
\end{lemma}
\begin{lemma}
\label{FFL}
\textbf{(First Four Lemma)} Given a commutative diagram in the category of $R$-module:
% https://q.uiver.app/#q=WzAsOCxbMiwwLCJCIl0sWzQsMCwiQyJdLFs2LDAsIkQiXSxbMiwyLCJCJyJdLFs0LDIsIkMnIl0sWzYsMiwiRCciXSxbMCwyLCJBJyJdLFswLDAsIkEiXSxbMCwxLCJnIl0sWzEsMiwiaCJdLFszLDQsInMiXSxbNCw1LCJ0Il0sWzAsMywibSIsMV0sWzEsNCwibiIsMV0sWzIsNSwicCIsMV0sWzYsMywiciJdLFs3LDYsImwiLDFdLFs3LDAsImYiXV0=
\[\begin{tikzcd}
	A && B && C && D \\
	\\
	{A'} && {B'} && {C'} && {D'}
	\arrow["f", from=1-1, to=1-3]
	\arrow["l"{description}, from=1-1, to=3-1]
	\arrow["g", from=1-3, to=1-5]
	\arrow["m"{description}, from=1-3, to=3-3]
	\arrow["h", from=1-5, to=1-7]
	\arrow["n"{description}, from=1-5, to=3-5]
	\arrow["p"{description}, from=1-7, to=3-7]
	\arrow["r", from=3-1, to=3-3]
	\arrow["s", from=3-3, to=3-5]
	\arrow["t", from=3-5, to=3-7]
\end{tikzcd}\]
If the two rows are exact, $m,p$ are injective,  $l$ is surjective, then $n$ is injective.  
\end{lemma}
\begin{proof}
Let $c \in C$ such that $n(c)=0$. We are required to show $c=0$. Using the hypothesis, we may deduce 
\begin{align*}
n(c)=0 \implies t\circ n(c)=0 \implies p\circ h(c)=0 \implies  h(c)=0 \implies c=g(b)
\end{align*}
for some $b \in B$. Observing that $s(m(b))=n \circ g(b)=n(c)=0$, we see $m(b)=r(a')$ for some $a'\in A'$. Because $l$ is surjective, $a'=l(a)$ for some $a \in A$. Now, because  
\begin{align*}
m \circ f(a)=r\circ l(a)=r(a')=m(b)
\end{align*}
by injectivity of $m$, we may deduce  $b=f(a)$. This together with first row being exact shows that 
\begin{align*}
c=g(b)=g\circ f(a)=0 
\end{align*}
\end{proof}
\begin{lemma}
\textbf{(Second Four Lemma)} Given a commutative diagram in the category of $R$-modules: 
% https://q.uiver.app/#q=WzAsOCxbMCwwLCJCIl0sWzIsMCwiQyJdLFs0LDAsIkQiXSxbNiwwLCJFIl0sWzAsMiwiQiciXSxbMiwyLCJDJyJdLFs0LDIsIkQnIl0sWzYsMiwiRSciXSxbMCwxLCJnIl0sWzEsMiwiaCJdLFsyLDMsImoiXSxbNCw1LCJzIl0sWzUsNiwidCJdLFs2LDcsInUiXSxbMCw0LCJtIiwxXSxbMSw1LCJuIiwxXSxbMiw2LCJwIiwxXSxbMyw3LCJxIiwxXV0=
\[\begin{tikzcd}
	B && C && D && E \\
	\\
	{B'} && {C'} && {D'} && {E'}
	\arrow["g", from=1-1, to=1-3]
	\arrow["m"{description}, from=1-1, to=3-1]
	\arrow["h", from=1-3, to=1-5]
	\arrow["n"{description}, from=1-3, to=3-3]
	\arrow["j", from=1-5, to=1-7]
	\arrow["p"{description}, from=1-5, to=3-5]
	\arrow["q"{description}, from=1-7, to=3-7]
	\arrow["s", from=3-1, to=3-3]
	\arrow["t", from=3-3, to=3-5]
	\arrow["u", from=3-5, to=3-7]
\end{tikzcd}\]
If the two rows are exact, $m,p$ are surjective,  $q$ is injective, then  $n$ is surjective. As a special case of the \customref{FL}{Five Lemma}, we now have the \customref{SFL}{Short Five Lemma}.  
\end{lemma}
\begin{lemma}
\label{SFL}
\textbf{(Short Five Lemma)} Given a commutative diagram in the category of $R$-modules: 
% https://q.uiver.app/#q=WzAsMTAsWzIsMCwiQiJdLFs0LDAsIkMiXSxbNiwwLCJEIl0sWzIsMiwiQiciXSxbNCwyLCJDJyJdLFs2LDIsIkQnIl0sWzAsMiwiMCJdLFswLDAsIjAiXSxbOCwyLCIwIl0sWzgsMCwiMCJdLFswLDFdLFsxLDJdLFszLDRdLFs0LDVdLFswLDMsIm0iLDFdLFsxLDQsIm4iLDFdLFsyLDUsInAiLDFdLFs3LDBdLFs1LDhdLFsyLDldLFs2LDNdXQ==
\[\begin{tikzcd}
	0 && B && C && D && 0 \\
	\\
	0 && {B'} && {C'} && {D'} && 0
	\arrow[from=1-1, to=1-3]
	\arrow[from=1-3, to=1-5]
	\arrow["m"{description}, from=1-3, to=3-3]
	\arrow[from=1-5, to=1-7]
	\arrow["n"{description}, from=1-5, to=3-5]
	\arrow[from=1-7, to=1-9]
	\arrow["p"{description}, from=1-7, to=3-7]
	\arrow[from=3-1, to=3-3]
	\arrow[from=3-3, to=3-5]
	\arrow[from=3-5, to=3-7]
	\arrow[from=3-7, to=3-9]
\end{tikzcd}\]
If the two rows are exact and $m,p$ are isomorphisms, then $n$ is an isomorphism.  
\end{lemma}
\section{Tensor Product of Modules}
By \textbf{free modules}, we mean modules of the form $\bigoplus_{i \in I}M_i$ where $M_i \cong R$. We denote the free module $\bigoplus_{i \in I}M_i$ by $R^{(I)}$. \\





Let $R$ be some ring. Given a finite collection $\set{M_1,\dots ,M_n}$ of $R$-modules, by the term \textbf{tensor product space}, we mean a $R$-module denoted by $\bigotimes M_i$ and a $R$-multilinear map $\otimes : \prod M_i \rightarrow \bigotimes M_i$ that satisfies the \textbf{universal property}: For each multilinear map $f:\prod M_i \rightarrow P$, there exists unique linear map $\tilde{f}:\bigotimes M_i \rightarrow P$ such that the diagram 
% https://q.uiver.app/#q=WzAsMyxbMiwyLCJOIl0sWzAsMCwiXFxwcm9kIE1faSJdLFsyLDAsIlxcb3RpbWVzIE1faSJdLFsxLDIsIlxcb3RpbWVzIl0sWzEsMCwiZiIsMl0sWzIsMCwiZiIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dXQ==
\[\begin{tikzcd}
	{\prod M_i} && {\bigotimes   M_i} \\
	\\
	&& P 
	\arrow["\otimes ", from=1-1, to=1-3]
	\arrow["f"', from=1-1, to=3-3]
	\arrow["\tilde{f} ", dashed, from=1-3, to=3-3]
\end{tikzcd}\]
commutes. This definition is unique up to isomorphism: If $\bigotimes 'M_i$ is also a tensor product, then there exists some module isomorphism from $\bigotimes  M_i$ to $\bigotimes  'M_i$ that sends $m_1 \otimes  \cdots \otimes  m_n$ to $m_1 \otimes  ' \cdots \otimes  ' m_n$. One common construction of the tensor product space is to quotient the free module $R^{(\prod M_i)}$ with the submodule spanned by the set:
\begin{align*}
  \bigcup_{i=1}^n &\Big[\bset{(x_1,\dots, rx_i ,\dots, x_n)-r(x_1,\dots ,x_n)}\\
 & \cup \bset{(x_1,\dots ,x_i +x_i',\dots  ,x_n)- (x_1,\dots ,x_i,\dots  ,x_n)-(x_1,\dots ,x_i',\dots ,x_n)}  \Big]
\end{align*}
Denoting this spanned submodule by $D$, our tensor product space $\bigotimes M_i$ is now $R^{(\prod M_i)}\quotient D$, and because of the forms of the generators of $D$, the tensor product map $\otimes  :\prod M_i \rightarrow \bigotimes  M_i$ defined by 
\begin{align*}
x_1\otimes  \cdots \otimes  x_n \triangleq [(x_1,\dots ,x_n)] 
\end{align*}
is clearly multilinear. Because free module $R^{(\prod M_i)}$ is a direct sum, it is clear that $\bigotimes M_i$ is generated by the \textbf{basic elements}\footnote{Elements of the form $x_1\otimes  \cdots \otimes  x_n$}, and because of such, for every multilinear map $f:\prod M_i \rightarrow P$, the induced map $\tilde{f}: \bigotimes M_i \rightarrow P$ must be unique. To actually induce $\tilde{f}$, one first extend $f$ to the whole free module $\overline{f}:R^{(\prod M_i)}\rightarrow P$ by setting $\overline{f}(\sum r (x_1,\dots ,x_n))\triangleq \sum rf(x_1,\dots ,x_n)$, and see that because $\overline{f}$ vanishes on the generators of $D$, we may induce some mapping from $\bigotimes M_i$ to $P$ that clearly has the desired action of $\tilde{f}$ on the basic elements. \\

Note that the \textbf{tensor-horn adjunction} isomorphism 
\begin{align*}
\operatorname{Hom}(M\otimes N,P) \cong  \operatorname{Hom}(M,\operatorname{Hom}(N,P))
\end{align*}
maps $f \in \operatorname{Hom}(M\otimes N,P)$ to   $\tilde{f}\in \operatorname{Hom}(M,\operatorname{Hom}(N,P))$ with the action
\begin{align*}
  \tilde{f}(m)n\triangleq f(m\otimes n)
\end{align*}
\section{Chain Condition}
Given some collection $\Sigma$ of sets, we say $\Sigma$ satisfies the \textbf{ascending chain condition, a.c.c.}, if for each chain $x_1 \subseteq x_2 \subseteq  \cdots$ there exists $n$ such that $x_n=x_{n+1}=\cdots$, and we say $\Sigma$ satisfies the \textbf{descending chain condition, d.c.c.}, if for each chain $x_1 \supseteq x_2 \supseteq \cdots $ there exists $n$ such that $x_n=x_{n+1}= \cdots$. Let $M$ be some module. We say  $M$  is  \textbf{Noetherian} if the collection of submodules of $M$ satisfies  a.c.c., and we say $M$ is  \textbf{Artinian} if the collection of submodules  satisfies d.c.c. Thanks to axiom of choice, module $M$ is Noetherian if and only if every nonempty collection of submodules of $M$ has a maximal element if and only if every submodule of $M$ is finitely generated. \\

Given a finite \textbf{chain} of submodules 
\begin{align*}
M_0 \subset M_1 \subset \cdots \subset M_n 
\end{align*}
we say this chain is of \textbf{length} $n$. Under the obvious assignment of order on the collection of all finite chains of submodules of $M$, by a  \textbf{composition series} of $M$, we mean a maximal finite chain. Clearly, a finite chain 
\begin{align*}
0= M_0 \subset \cdots \subset M_n= M
\end{align*}
is maximal if and only if  $M_k\quotient M_{k-1}$ are simple. 
\begin{theorem}
\label{Lom}
\textbf{(Length of modules is well defined)} Every composition series of a module $M$ have the same length. 
\end{theorem}
\begin{proof}
Suppose $M$ has a composition series, and let $l(M)$ denote the least length of a composition series of $M$. We wish to show every chain has length smaller than $l(M)$. Before such, we first prove 
\begin{align}
\label{NsM}
N \subset M \implies  l(N)< l(M)
\end{align}
Let $M_0 \subset \cdots \subset M_n=M$ be a composition series of least length. Define $N_k \triangleq N \cap M_k$ for all $k \in \set{0,\dots ,n}$. Consider the obvious homomorphism $N_k \quotient N_{k-1} \rightarrow M_k \quotient M_{k-1}$. We see that either $N_k \quotient N_{k-1} \cong M_k \quotient M_{k-1}$ or $N_k = N_{k-1}$. This implies that the chain $N_0 \subset \cdots \subset N_n$ will be a composition series of $N$ after the unnecessary terms are removed. It remains to show there are unnecessary terms in $N_0 \subset \cdots \subset N_n$. Assume not for a contradiction. Because $N_1 \subseteq M_1$ and $N_1 \quotient \set{0} \cong   M_1 \quotient \set{0}$, we have $N_1 = M_1$. Repeating the same argument, we have  $N=N_n=M_n=M$, a contradiction. We have proved \myref{statement}{NsM}.\\

Now, let $M_0' \subset \cdots \subset M_r'$ be some composition series of $M$. The proof then follows from using \myref{statement}{NsM} to deduce 
\begin{align*}
l(M)=l (M_r') > \cdots > l(M_0')=0 \implies r\leq l(M)
\end{align*}
\end{proof}
Because of \myref{Theorem}{Lom}, we may well define the \textbf{length} $l(M)$ of module. For obvious reason, if module $M$ has no composition series, we say $M$ has infinite length and write $l(M)=\infty$. Clearly, if $M$ is of finite length, then $M$ is both Noetherian and Artinian. Conversely, if $M$ is both Noetherian and Artinian, then by the maximal element definition of Noetherian, there exists a decreasing sequence $M=M_0 \supset M_1 \supset M_2 \supset \cdots $, which by d.c.c. must be finite.   

\chapter{IDK where u belong}
\section{Valuation Rings}
Let $A$ be a ring, and let $S \subseteq A$ be a multiplicatively closed subset that contains no zero-divisors. Clearly, in $S^{-1}A$, 
\begin{align*}
\frac{a}{s}=\frac{b}{t}\text{ if and only if }at=bs. 
\end{align*}
This implies that the canonical ring homomorphism $A \rightarrow S^{-1}A$ is injective, and it thus make sense for us to identify $A$ as a subring of $S^{-1}A$. In particular, if $D$ is an integral domain, then we consider $D$ to be a subring of its \textbf{field of fraction} $(D^*)^{-1}D$. Let $K$ be a field and  $D$ a subring of  $K$. If for all  $x \in K$, either $x \in D$ or $x^{-1} \in D$, then the mapping $F\longrightarrow \operatorname{Frac}(D)$ defined by  
\begin{align*}
x\mapsto \begin{cases}
  \frac{x}{1}& \text{ if $x \in D$ }\\
  \frac{1}{x^{-1}}& \text{ if $x\not\in D$ }
\end{cases}
\end{align*}
forms a field isomorphism. Because of this identification, for each integral domain $D$, it make sense to say $D$ is a  \textbf{valuation ring (of some field)} whenever  $x \in \operatorname{Frac}(D)\implies x\in D\text{ or }x^{-1}\in D$. \\




Given a field $K$ and an totally ordered abelian group $\Gamma $, we say $\nu : K\rightarrow \Gamma \cup \set{\infty}$ is a \textbf{valuation} if it satisfies:
\begin{enumerate}[label=(\alph*)]
  \item $\nu ^{-1}(\infty)= \set{0}$. 
  \item $\nu  (xy)=\nu  (x)+ \nu  (y)$. 
  \item $\nu  (x+y)\geq \min  \set{\nu (x),\nu  (y)}$, with the equality holds true if $\nu (x)\neq \nu  (y)$. 
\end{enumerate}
Let $D$ be an integral domain. We say $D$ is a \textbf{valuation ring} if for each $x \in \operatorname{Frac}(D)$, either $x \in D$ or $x^{-1} \in D$. 
\begin{theorem}
\textbf{(Equivalent Definitions of valuation rings)} Let $D$ be an integral domain. The following are equivalent 
\begin{enumerate}[label=(\roman*)]
  \item $D$ is a valuation ring. 
  \item The principal ideals of $D$ are totally ordered by inclusion. 
  \item The ideals of $D$ are  totally ordered by inclusion.  
  \item There is a totally ordered abelian group $\Gamma $ and a valuation $\nu : \operatorname{Frac}(D)\rightarrow \Gamma \cup \set{\infty}$ such that $D= \set{x \in \operatorname{Frac}(D): \nu  (x)\geq 0 \in \Gamma }$. 
  \item $D$ is a local Bezout Domain.  
\end{enumerate}
\end{theorem}
\begin{proof}
It is easy to prove $(\text{i})\implies (\text{ii})\implies (\text{iii})\implies (\text{i})$. For $(\text{i})\implies (\text{iv})$, let $D^{\times}$ be the set of units of $D$. Clearly,  $D^{\times}$ is a normal subgroup of $(\operatorname{Frac}D)^*$. Because $D$ is a valuation ring, we may well define a total order on $\Gamma \triangleq (\operatorname{Frac}D)^* \quotient D^\times$ by 
\begin{align*}
[x]\geq [y]\overset{\triangle}{\iff } xy^{-1} \in D
\end{align*}
It is routine to check that $\nu  : \operatorname{Frac}(D)\rightarrow \Gamma \cup  \set{\infty}$ defined by 
\begin{align*}
\nu (x)\triangleq \begin{cases}
  [x]& \text{ if $x\neq 0$ } \\
  \infty& \text{ if $x=0$ }
\end{cases}
\end{align*}
is a valuation such that $D= \set{x\in \operatorname{Frac}(D):\nu  (x)\geq 0 \in \Gamma }$. j 
\end{proof}
Because of ideals of valuation ring are totally ordered by inclusion, clearly valuation rings are always local rings.  
\section{Discrete Valuation Rings}
Let $K$ be a field. A \textbf{discrete valuation $\nu :K\rightarrow \Gamma \cup  \set{\infty}$} is a valuation such that $\Gamma =\Z$. Clearly, the set of $x\in K$ such that $\nu  (x)\geq 0$ forms a ring\footnote{$\nu (1)=\nu  (-1)=0$.}, called the \textbf{discrete valuation ring} of $\nu $, since indeed it is a valuation ring.    
\section{Fractional "Ideal"}

Notably, if $S$ contains  $0$, then  $S^{-1}A$ is zero ring, so when we talk about the \textbf{filed of fraction} $K$ of an integral domain $A$, we mean  $(A\setminus 0)^{-1}A$. Given an $A$-submodule $M$ of  $K$, if $xM \subseteq A$ for some $x\neq 0 \in A$, unfortunately we say $M$ is a \textbf{fractional ideal} of $A$ even though $M$ needs not to be a subset of $A$. However, if $I$ is an ideal of $A$, then clearly  $I$ is also a fractional ideal of $A$.\\

If $M\subseteq K$ is a  finitely generated $A$-submodule, then $M$ is a fractional ideal of $A$, since if $M=\langle \frac{b_1}{a_1},\dots , \frac{b_n}{a_n}\rangle $, then $(a_1\cdots a_n)M\subseteq A$. We say an $A$-submodule  $M \subseteq K$ is \textbf{invertible} if there exists some $A$-submodule $N \subseteq \F$ such that  $MN=A$ where $ MN\triangleq \set{m_1 n_1 + \cdots + m_kn_k \in \F: m_i \in M,n_i\in N}$. 
\section{Local Property}


If we say a module property $X$ is a  \textbf{local property}, we mean that for every $A$-module $M$ and prime ideal  $P \subseteq A$, $M$ satisfies  $X$ if and only if  $M_P$ satisfies  $X$, and if we say a ring property $X$ is a \textbf{local property}, we mean that for every ring $A$ and prime ideal $P \subseteq A$, $A$ satisfies  $X$ if and only if $A_P$ satisfies $X$.\\
\chapter{Some Theorems}
\section{Uniqueness of Primary Decomposition}
\label{UoP}
Let $A$ be a ring. We say a proper ideal $Q$ is \textbf{primary} if for each $xy \in Q$, either $x \in Q$ or $y^n \in Q$ for some $n>0$. Equivalently, a proper ideal $I$ is primary if and only if every zero-divisors in $A \quotient  Q$ is nilpotent. Clearly, the radical $P=\sqrt{Q} $ of a primary ideal $Q$ is prime. In such case, we say $Q$ is $P$\textbf{-primary}. A \textbf{primary decomposition} of an ideal $I$ is an expression of $I$ as a finite intersection of primary ideals
 \begin{align*}
I= \bigcap_{i=1}^n Q_i
\end{align*}
Such primary decomposition is said to be \textbf{irredundant} if $\sqrt{Q_i}$ are all distinct and no $Q_i$ is unnecessary in the sense that 
\begin{align*}
\bigcap_{j\neq i}Q_j \not \subseteq Q_i\text{ for all }i. 
\end{align*}
An ideal $I$ is said to be  \textbf{decomposable} if there exists some primary decomposition of $I$. Because finite intersection of $P$-primary ideals is again  $P$-primary, every decomposable ideal has an irredundant primary decomposition.  
\begin{theorem}
\label{Fut}
\textbf{(First uniqueness theorem for irredundant primary decomposition)} Given some irredundant primary decomposition $I= \bigcap_{i=1}^n Q_i$, we have 
\begin{align}
\label{QiRa}
\bset{\sqrt{Q_ia}:1\leq i\leq n}= \operatorname{Spec}(R) \cap \bset{\sqrt{(I:x)} \subseteq R: x \in R } 
\end{align}
\end{theorem}
\begin{proof}
Before showing that both sides of \myref{equation}{QiRa} are subsets of each other, we first make the following observation. For all $x \in R$, clearly 
\begin{align*}
  (I:x)= \Big(\bigcap Q_i :x\Big) = \bigcap (Q_i : x)
\end{align*}
Therefore, 
\begin{align}
\label{sIxa}
\sqrt{(I:x)}= \bigcap \sqrt{(Q_i:x)}= \bigcap_{k:x \not\in Q_k} \sqrt{Q_k}  
\end{align}
where the last equality is justified by 
\begin{align*}
x \in Q_i \implies (Q_i:x)=R,\quad\text{ and } x \not\in Q_i \implies  \sqrt{(Q_i:x)} = \sqrt{Q_i} 
\end{align*}
We now prove that the left hand side of \myref{equation}{QiRa} is a subset of the right hand side. Fix $i$. By irredundancy of the decomposition, there exists some  $x\in R$ such that $x$ belongs to all $Q_j$ except  $Q_i$. This $x$ by \myref{equation}{sIxa} must satisfies
\begin{align*}
\sqrt{Q_i}  =  \sqrt{(I:x)} 
\end{align*}
Noting that $\sqrt{Q_i}$ must be prime due to $Q_i$ being primary, we have shown the left hand side of \myref{Equation}{QiR} is a indeed a subset of the right hand side. \\

Now, suppose for some $x\in R$ that $\sqrt{(I:x)}$ is prime. Because prime ideal must be proper, we know there must exists some $k$ such that $x\not \in Q_k$. By \myref{equation}{sIxa}, to finish the proof, we only need to show $\sqrt{Q_k}\subseteq \sqrt{(I:x)}$ for some $k$ such that $x \not \in Q_k$. Assume not for a contradiction. Then for all $k$ such that $x \not \in Q_k$, there exists $y_k \in \sqrt{Q_k}$ such that $y_k \not \in \sqrt{(I:x)}$. The product of these $y_k$ is an element of  $\bigcap \sqrt{Q_k}$, thus an element of $\sqrt{(I:x)}$. This with $\sqrt{(I:x)}$ being prime shows that $y_k \in \sqrt{(I:x)}$ for some $k$, a contradiction. 
\end{proof}
Because of \customref{Fut}{the first uniqueness theorem}, we may well define the \textbf{inner spectrum} of decomposable ideal $I$, independent of choice of irredundant decomposition, to be 
\begin{align*}
\bset{\sqrt{Q_1},\dots ,\sqrt{Q_n}}
\end{align*}
where 
\begin{align*}
I= \bigcap_{i=1}^n Q_i\text{ is some irredundant primary decomposition. }
\end{align*}
Given such irredundant primary decomposition, we say $Q_i$ is an  \textbf{isolated primary component} if $\sqrt{Q_i}$ is minimal in the inner spectrum.  
\begin{lemma}
\label{P48}
\textbf{(preparation lemma for second uniqueness theorem)} Let $S$ be a multiplicatively closed subset of  $A$, and let  $Q$ be a $P$-primary ideal. If $S$ and  $P$ are disjoint, then  $S^{-1}Q$ is $S^{-1}P$-primary and $S(Q)=Q$. If  $S$ and  $P$ meet, then  $S^{-1}Q=S^{-1}A$. 
\end{lemma}
\begin{proof}
Suppose $S$ and $P$  are disjoint. Clearly we have $Q\subseteq S(Q)$, so to show $S(Q)=Q$, we only have to show $S(Q)\subseteq Q$. Let $a \in S(Q)$. The first part of \myref{Theorem}{Pol} states that $a \in (Q:s)$ for some $s \in S$. Because $Q \subseteq P$, this implies $a \in Q$. We have shown $S(Q)=Q$. Note that the second part of \myref{Theorem}{Pol} states that 
\begin{align*}
\sqrt{S^{-1}Q}=S^{-1}\sqrt{Q}=S^{-1}P  
\end{align*}
so for the case when $S$ and  $P$ are disjoint, it only remains to prove  $S^{-1}Q$ is indeed primary, which is routine and even unnecessary for the \customref{Sut}{Second uniqueness theorem below}. \\

Suppose $s \in S \cap P$. Let $s^n \in Q$. The fact that $S^{-1}Q=S^{-1}A$ follows from the fact $\frac{s^n}{1}$ is a unit with inverse $\frac{1}{s^n}$. 
\end{proof}
\begin{theorem}
\label{Sut}
\textbf{(Second uniqueness theorem for isolated primary component)} The isolated primary components of a decomposable ideal $I$ is uniquely determined by $I$, independent of the irredundant decomposition. 
\end{theorem}
\begin{proof}
Let $P$ be a minimal element of the inner spectrum of $I$, and let $I=\bigcap_{i=1}^n Q_i$ be an arbitrary irredundant primary decomposition, where $\sqrt{Q_1}=P$. Clearly $S\triangleq A\setminus P$ is multiplicatively closed. Because the definition of $S$ is independent of the choice of the primary decomposition, we are only required to prove the goal
\begin{align*}
\label{QSI}
Q_1=S(I)
\end{align*}
Because $S$ and  $P$ are disjoint, we may apply \myref{Lemma}{P48} to reduces this goal into 
\begin{align*}
S^{-1}Q_1= S^{-1}I
\end{align*}
Noting that $\sqrt{Q_i}$ meets $S=A \setminus \sqrt{Q_1} $ for every $i>1$ due to the minimality of $\sqrt{Q_1}$, we conclude our proof using \myref{Lemma}{P48} and the third part of \myref{Theorem}{Pol}:
\begin{align*}
S^{-1}I = \bigcap_{i=1}^n S^{-1}Q_i=S^{-1}Q_1
\end{align*}
\end{proof}
\section{Existence of Primary Decomposition in Noetherian ring}
Let $A$ be a ring, and let  $I\subseteq A$ be some ideal. We say $I$ is  \textbf{irreducible} if whenever $I$ is expressed as an intersection of two ideals, $I$ equals to one of them. Clearly, to show every ideal in Noetherian ring is decomposable, we only need to show the following two lemmas. 
\begin{lemma}
In Noetherian ring $A$, every ideal is a finite intersection of irreducible ideals.  
\end{lemma}
\begin{proof}
Assume not for a contradiction. Let $I$ be a maximal element of the collection $\Sigma$ of all ideals that can not be expressed as finite intersections of irreducible ideals. Clearly, $I$ must be reducible, so there exists some $I=J_1 \cap J_2$ such that $I\subset J_1$ and $I\subset J_2$. Because $J_1,J_2 \not \in \Sigma$, we may express them both as finite intersection of irreducible ideals. This implies that we may express $I$ as a finite intersection of irreducible ideals, a contradiction. 
\end{proof}
\begin{lemma}
In Noetherian ring $A$, every irreducible ideal is primary.   
\end{lemma}
\begin{proof}
Let $I\subseteq A$ be irreducible. Clearly, the zero ideal in  $A\quotient I$ is irreducible, and if the zero ideal in $A \quotient I$ is primary, then $I$ is also primary. Because of such, we may WLOG suppose $I$ is zero.  Let $xy=0$ and $y\neq 0$. We are required to show $x^n=0$. Clearly we have the chain  $\operatorname{Ann}(x)\subseteq \operatorname{Ann}(x^2) \subseteq \cdots $, and by a.c.c., there exists some $n$ such that $\operatorname{Ann}(x^n)=\operatorname{Ann}(x^{n+1})= \cdots $. We now show 
\begin{align}
\label{xny}
  \langle x^n\rangle \cap \langle y\rangle =0
\end{align}
Let $a \in \langle x^n\rangle \cap \langle y\rangle $. Because $a \in \langle y\rangle $ and $xy=0$, we know  $ax=0$. Writing $a=bx^n$, we now see $b \in \operatorname{Ann}(x^{n+1})=\operatorname{Ann}(x^n)$. This implies $a=bx^n=0$. We have shown  \myref{Equation}{xny}.\\

Finally, because the zero ideal is irreducible, we must have $\langle x^n\rangle =0$ or $\langle y\rangle =0$. Because $y\neq 0$, we may conclude $x^n=0$.  
\end{proof}
\section{Equivalent Definitions of DVR}
\section{Unique factorization Theorem for ideals in Noetherian domain of Krull dimension 1}
Before the main course, we first develop some basic notion. We say two ideals are \textbf{coprime} if their sum equals to the whole ring. Note that two prime ideals need not be coprime. If $K$ is a field, then $\langle x\rangle ,\langle y\rangle $ are not coprime in $K[x,y]$. 
\begin{proposition}
\textbf{(Product of coprime ideals is the intersection)} Let $I_k$ be a finite collection of pairwise coprime ideals. We have  $\prod I_k= \bigcap I_k$. 
\end{proposition}
\begin{proof}
The proof relies on induction of total number of the pairwise coprime ideals. The base case is when there are only two, says, $I$ and  $J$. Clearly  $IJ \subseteq I \cap J$. To prove the converse, observe for $c \in I \cap J$, there exists $1=i+j$ so that  $c=ci+cj$, where $ci,cj \in I \cap J$. 
\end{proof}



\chapter{Big Theorems}
\section{Hilbert's Basis Theorem}
\label{FGN}
Before we prove the \customref{HBT}{Hilbert's Basis Theorem}, we must first show that finitely generated modules over Noetherian rings is also Noetherian.    
\begin{proposition}
\label{FpNm}
\textbf{(Formal properties of Noetherian modules)} Given a short exact sequence of $A$-modules:  
 \begin{align*}
0 \longrightarrow M' \overset{\alpha }{\longrightarrow } M \overset{\beta }{\longrightarrow } M'' \longrightarrow 0
\end{align*}
$M$ is Noetherian if and only if  $M'$ and $M''$ are both Noetherian.   
\end{proposition}
\begin{proof}
Consider the ascending chain condition definition. For the "if" part, let $L_n$ be an ascending chain of submodules of  $M$, and use \customref{SFL}{short five lemma} on
% https://q.uiver.app/#q=WzAsMTEsWzAsMCwiMCJdLFsyLDAsIlxcYWxwaGFeey0xfShMX24pIl0sWzQsMCwiTF9uIl0sWzYsMCwiXFxiZXRhKExfbikiXSxbOCwwLCIwIl0sWzAsMiwiMCJdLFsyLDIsIlxcYWxwaGFeey0xfShMX3tuKzF9KSJdLFs0LDIsIkxfe24rMX0iXSxbMywyXSxbOCwyLCIwIl0sWzYsMiwiXFxiZXRhKExfe24rMX0pIl0sWzAsMV0sWzEsMiwiXFxhbHBoYSJdLFsyLDMsIlxcYmV0YSJdLFs1LDZdLFs2LDcsIlxcYWxwaGEiXSxbMyw0XSxbNywxMCwiXFxiZXRhIl0sWzEwLDldLFszLDEwLCIiLDEseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJob29rIiwic2lkZSI6InRvcCJ9fX1dLFsyLDcsIiIsMSx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Imhvb2siLCJzaWRlIjoidG9wIn19fV0sWzEsNiwiIiwxLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoiaG9vayIsInNpZGUiOiJ0b3AifX19XV0=
\[\begin{tikzcd}
	0 && {\alpha^{-1}(L_n)} && {L_n} && {\beta(L_n)} && 0 \\
	\\
	0 && {\alpha^{-1}(L_{n+1})} & {} & {L_{n+1}} && {\beta(L_{n+1})} && 0
	\arrow[from=1-1, to=1-3]
	\arrow["\alpha", from=1-3, to=1-5]
	\arrow[hook, from=1-3, to=3-3]
	\arrow["\beta", from=1-5, to=1-7]
	\arrow[hook, from=1-5, to=3-5]
	\arrow[from=1-7, to=1-9]
	\arrow[hook, from=1-7, to=3-7]
	\arrow[from=3-1, to=3-3]
	\arrow["\alpha", from=3-3, to=3-5]
	\arrow["\beta", from=3-5, to=3-7]
	\arrow[from=3-7, to=3-9]
\end{tikzcd}\]
to conclude that $L_n$ must stop at some point.  
\end{proof}
Suppose $A$ is a Noetherian ring. Applying  \myref{Proposition}{FpNm} inductively to 
\begin{align*}
 0\longrightarrow A \longrightarrow A^n \longrightarrow A^{n-1} \longrightarrow 0
\end{align*}
we see the module $A^n$ is also Noetherian, and so any finitely generated module over  $A$, isomorphic to some quotient of $A^n$, is also Noetherian. We may now give a simple proof to Hilbert's Basis Theorem.    
\begin{theorem}
\label{HBT}
\textbf{(Hilbert's Basis Theorem)} If $A$ is Noetherian, than the polynomial ring $A[x]$ is also Noetherian. 
\end{theorem}
\begin{proof}
Let $X$ be an ideal in  $A[x]$. We are required to show that $X$ is finitely generated. Let $I$ be the ideal in $A$  that contains exactly the leading coefficients of elements of  $X$. Because $A$ is Noetherian, we may let $I=  \langle a_1,\dots ,a_n\rangle $ and let $f_1,\dots ,f_n \in X$ have leading coefficients $a_1,\dots ,a_n$. Let $X'\triangleq \langle f_1,\dots ,f_n\rangle \subseteq X$ and let $r\triangleq  \max \set{\operatorname{deg}(f_1),\dots ,\operatorname{deg}(f_n)}$.\\

We first show 
\begin{align}
\label{23X}
X= \Big(X \cap \langle 1,x,\dots ,x^{r-1}\rangle \Big) + X'
\end{align}
Let $f\in X$ with $\operatorname{deg}(f)=m$ and leading coefficients $a$. We wish to show $f \in (X \cap \langle 1,x,\dots ,x^{r-1}\rangle )+X'$. Because $a \in I$, we may find some $u_i \in A$ such that $a= \sum u_i a_i$. Clearly, these $u_i$ satisfy
\begin{align*}
f- \sum u_if_ix^{m-\operatorname{deg}(f_i)} \in X,\quad \text{and }\sum u_i f_ix^{m-\operatorname{deg}(f_i)}\in X'
\end{align*}
and satisfy
\begin{align*}
\operatorname{deg}\Big(f- \sum u_i f_i x^{m-\operatorname{deg}(f_i)}\Big)<m
\end{align*}
Proceeding this way, we end up with $f-g=h$ where  $g\in X'$ and $h \in X \cap \langle 1,x,\dots ,x^{r-1}\rangle $. We have proved \myref{Equation}{23X}. Now, because $X'$ is finitely generated, to show  $X$ is finitely generated, it only remains to show the ideal $X \cap \langle 1,x,\dots ,x^{r-1}\rangle $  is finitely generated, which follows immediately from noting $\langle 1,x,\dots ,x^{r-1}\rangle $ as a module is Noetherian.    
\end{proof}
We close this section by giving a cute corollary of Hilbert's Basis Theorem in classical algebraic geometry. Suppose $E\subseteq R[x_0,\dots ,x_{n-1}]$ is an infinite collection of polynomials. Let $V$ be the set of common roots of these polynomials, i.e., 
\begin{align*}
V \triangleq \set{x\in R^n: f(x)=0 \text{ for all }f \in E}
\end{align*}
Clearly, 
\begin{align*}
V= \set{x \in R^n : f(x)=0\text{ for all }f\in \langle E\rangle }
\end{align*}
Induction with Hilbert's Basis Theorem shows that $R[x_0,\dots ,x_{n-1}]$ is Noetherian, so $\langle E\rangle $ is finitely generated. This allow us to write  $\langle E\rangle = \langle f_1,\dots ,f_n\rangle$ for some finite set of polynomials $f_1, \dots ,f_n \in R[x_0,\dots ,x_{n-1}]$. We now see that the locus $V$ of an infinite collection of polynomials can always be written as a locus of some finite collection of polynomials.  
\section{Nullstellensatz}
\begin{theorem}
\textbf{(Hilbert's Nullstellensatz)} Let $K$ be an algebraically closed field, and let $I$ be an ideal of  $K[t_1,\dots ,t_n]$. Define 
\begin{align*}
V\triangleq \set{x\in K^n : f(x)=0\text{ for all }f \in I}
\end{align*}
If we let $X$ be the ideal 
\begin{align*}
X \triangleq \set{ g \in K[t_1,\dots,t_n] : g(x)=0\text{ for all }x\in V }
\end{align*}
then $X=\sqrt{I}$. 
\end{theorem}
\begin{proof}

\end{proof}

\chapter{Scripts}
\section{Script 3}
A \textbf{primary decomposition} of an ideal $I$ is an expression of $I$ as a finite intersection of primary ideals
 \begin{align*}
I= \bigcap_{i=1}^n Q_i
\end{align*}
Moreover, if $\sqrt{Q_i}$ are all distinct and 
\begin{align*}
\bigcap_{j\neq i}Q_j \not \subseteq Q_i\text{ for all }i
\end{align*}
then we say the primary decomposition is \textbf{irredundant}. 
\begin{theorem}
\label{Fut}
\textbf{(First uniqueness theorem for irredundant primary decomposition)} Given some irredundant primary decomposition $I= \bigcap_{i=1}^n Q_i$, we have 
\begin{align}
\label{QiR}
\bset{\sqrt{Q_i}:1\leq i\leq n}= \operatorname{Spec}(R) \cap \bset{\sqrt{(I:x)} \subseteq R: x \in R } 
\end{align}
\end{theorem}
\begin{proof}
Before showing that both sides of \myref{Equation}{QiR} are subsets of each other, we first make the following observation. For all $x \in R$, clearly 
\begin{align*}
  (I:x)= \Big(\bigcap Q_i :x\Big) = \bigcap (Q_i : x)
\end{align*}
Therefore, 
\begin{align}
\label{sIx}
\sqrt{(I:x)}= \bigcap \sqrt{(Q_i:x)}= \bigcap_{k:x \not\in Q_k} \sqrt{Q_k}  
\end{align}
where the last equality is justified by 
\begin{align*}
x \in Q_i \implies (Q_i:x)=R,\quad\text{ and } x \not\in Q_i \implies  \sqrt{(Q_i:x)} = \sqrt{Q_i} 
\end{align*}
We now prove that the left hand side of \myref{Equation}{QiR} is a subset of the right hand side. Fix $i$. By irredundancy of the decomposition, there exists some  $x\in R$ such that $x$ belongs to all $Q_j$ except  $Q_i$. This $x$ by \myref{Equation}{sIx} must satisfies
\begin{align*}
\sqrt{Q_i}  =  \sqrt{(I:x)} 
\end{align*}
Noting that $\sqrt{Q_i}$ must be prime due to $Q_i$ being primary, we have shown the left hand side of \myref{Equation}{QiR} is a indeed a subset of the right hand side. \\

Now, suppose for some $x\in R$ that $\sqrt{(I:x)}$ is prime. Because prime ideal must be proper, we know there must exists some $k$ such that $x\not \in Q_k$. By \myref{Equation}{sIx}, to finish the proof, we only need to show $\sqrt{Q_k}\subseteq \sqrt{(I:x)}$ for some $k$ such that $x \not \in Q_k$. Assume not for a contradiction. Then for all $k$ such that $x \not \in Q_k$, there exists $y_k \in \sqrt{Q_k}$ such that $y_k \not \in \sqrt{(I:x)}$. The product of these $y_k$ is an element of  $\bigcap \sqrt{Q_k}$, thus an element of $\sqrt{(I:x)}$. This with $\sqrt{(I:x)}$ being prime shows that $y_k \in \sqrt{(I:x)}$ for some $k$, a contradiction. 
\end{proof}
Because of \myref{Theorem}{Fut}, we may well define the following notions. Given some decomposable ideal $I$, we say the prime ideals $\set{\sqrt{Q_1},\dots ,\sqrt{Q_n} }$ \textbf{belong} to $I$, and if $\sqrt{Q_i}$ is a minimal element of $\set{\sqrt{Q_1},\dots ,\sqrt{Q_n}}$, then we say $\sqrt{Q_i}$ is an \textbf{isolated} prime ideal belonging to $I$. 
\begin{theorem}
\label{P46}
\textbf{(Proposition 4.6)} Let $I$ be a decomposable ideal. Any prime ideal $P \supseteq I$ contains an isolated prime ideal belonging to $I$. 
\end{theorem}
\begin{proof}
Let 
\begin{align*}
\bigcap_{i=1}^n Q_i = I \subseteq P
\end{align*}
We have 
\begin{align*}
\bigcap_{i=1}^n \sqrt{Q_i} =\sqrt{\bigcap_{i=1}^n Q_i}\subseteq \sqrt{P} =P 
\end{align*}
Because $P$ is prime, we see that there must exists some  $i \in \set{1,\dots ,n}$ such that $\sqrt{Q_i}\subseteq P$, otherwise, we may construct some $\prod x_i \in \bigcap \sqrt{Q_i}\setminus P$ by selecting $x_i \in \sqrt{Q_i}\setminus P $. If $\sqrt{Q_i}$ is isolated, we are done. If not, then there exists some isolated ideal $\sqrt{Q_j}$ such that $\sqrt{Q_j}\subseteq \sqrt{Q_i} $ and we are done. 
\end{proof}
The second remark gives an example of two distinct irredundant primary decomposition of an ideal. Let $\langle x^2,xy\rangle \subseteq \F [x,y]$. We have 
\begin{align*}
\langle x^2,xy\rangle= \langle x\rangle \cap \langle x,y\rangle^2 = \langle x\rangle \cap \langle x^2,y\rangle   
\end{align*}
where 
 \begin{align*}
y \not\in \langle x,y\rangle^2 
\end{align*}
Also, note from \myref{Theorem}{P46} that 
\begin{align*}
\operatorname{Nil}(R)=\bigcap \text{ all minimal primes ideal belonging to }\set{0}
\end{align*}
\begin{theorem}
\label{Soz}
  \textbf{(Set of zero-divisors is the union of all prime ideals belonging to $\set{0}$)} If we let $D$ be set of zero-divisors of  $R$, then 
\begin{align*}
D= \bigcup \set{I\in \operatorname{Spec}(R):I\text{ belongs to }\set{0}} 
\end{align*}
\end{theorem}
\begin{proof}
Clearly, 
\begin{align*}
D= \bigcup_{x\neq 0} \sqrt{(\set{0}:x)} 
\end{align*}
This together with \myref{Equation}{sIx} shows that $D$ is a subset of the union of all prime ideals belonging to $\set{0}$. The converse follows directly from \myref{Theorem}{Fut}. 
\end{proof}
We may generalize \myref{Theorem}{Soz} as following. Let $I = \bigcap Q_i$ be an irredundant primary decomposition. Let $\pi  :R \rightarrow R\quotient I$ be the quotient map. Clearly $\set{[0]}= \bigcap \pi  (Q_i)$ forms an irredundant primary decomposition. Therefore, \myref{Theorem}{Soz} implies 
\begin{align*}
\bigcup   \sqrt{\pi  (Q_i)}= \bset{[x] \in R\quotient I: xy \in I\text{ for some }y\neq 0} 
\end{align*}
which implies 
\begin{align*}
\bigcup \sqrt{Q_i} = \bset{x \in R: (I:x) \neq I}
\end{align*}
\begin{theorem}
\textbf{(Proposition 4.8)} Let $S$ be a multiplicatively closed subset of  $A$, and let  $Q$ be a $P$-primary ideal. 
 \begin{align*}
S \cap P \neq \varnothing \implies  S^{-1}Q = S^{-1}A
\end{align*}
and 
\begin{align*}
S \cap P=\varnothing \implies S^{-1}Q\text{ is $P$-primary  and its contraction in $A$ is  $Q$ }
\end{align*}
\end{theorem}
\begin{proof}
If $s \in S \cap P$, then $s^n \in Q$ for some $n>0$, and $\frac{s^n}{1} \in S^{-1}Q$. Note that 
\begin{align*}
\frac{s^n}{1}\cdot \frac{1}{s^n}= \frac{s^n}{s^n}=1
\end{align*}
Suppose $S \cap P=\varnothing$. Note that $S^{-1}Q=Q^e$, so to show the contraction of $S^{-1}Q$ is $Q$, we only have to show 
\begin{align}
\label{g1}
Q^{ec}=Q
\end{align}
Obviously $Q \subseteq Q^{ec}$. We show the opposite. The second part of proposition 3.11 states that 
\begin{align*}
Q^{ec}= \bigcup_{s \in S} (Q:s)
\end{align*}
Because $Q \subseteq P$, if $as \in Q$, then $a \in Q$. Therefore, $a \in (Q:s)\implies  a \in Q$. We have shown  \myref{goal}{g1}. Note that the fifth part of proposition 3.11  states that 
\begin{align*}
\sqrt{S^{-1}Q}=S^{-1}\sqrt{Q}=S^{-1}P   
\end{align*}
It remains to show $S^{-1}Q$ is indeed primary. Let  $\frac{ab}{ss'} = \frac{q}{s''}\in S^{-1}Q$. This implies $(abs'' -qss')t=0$ for some $t \in S$, which implies $ab(s''t)\in Q$. Because $S$ is closed under multiplication and $S \cap P = \varnothing$, we know $(s''t)^n \not\in Q$ for all $n>0$. This implies  $ab \in Q$, which implies $a \in Q$ or some powers of  $b$ is an element of  $Q$. We have shown either  $\frac{a}{s} \in S^{-1}Q$ or some power of  $\frac{b}{s''}$ belongs to $S^{-1}Q$. We have shown $S^{-1}Q$ is indeed primary.
\end{proof}
\section{Script 2}
Let $A$ and  $B$ be two rings. Let  $M$ be an  $A$-module, and let $N$ be a  $(A,B)$-\textbf{bimodule}. By $N$ being a  $(A,B)$-bimodule, we mean that $N$ not only have both structure of $A$-module and $B$-module, but also  satisfy $a(bx)=b(ax)$. Consider the tensor product $M\otimes_A N$. For any $b \in B$, we may define a $A$-bilinear map $M\times N \rightarrow M\otimes_A N$ by 
\begin{align*}
  (m,n)\mapsto m \otimes  bn
\end{align*}
Therefore, by universal property, there exists some unique $A$-linear map $\tilde{b}:M\otimes _A N\rightarrow M\otimes  _A N$. Doing this procedure for each $b \in B$, to claim $M\otimes_A N$ forms a $(A,B)$-bimodule, it remains to check that 
\begin{enumerate}[label=(\alph*)]
  \item $b(x+y)=bx+by$. 
  \item $(b_1+b_2)x=b_1x+b_2x$. 
  \item $(b_1b_2)x=b_1(b_2x)$. 
  \item $1_Bx=x$. 
  \item $a(bx)=b(ax)$. 
\end{enumerate}
\begin{question}{Exercise 2.15}{}
Let $P$ be a  $B$-module. Find an $(A,B)$-bimodule isomorphism  between 
\begin{align*}
  (M\otimes _AN)\otimes _B P \text{ and }M \otimes  _A (N \otimes  _B P)
\end{align*}
\end{question}
\begin{proof}
For each $p \in P$, the $A$-bilinear map from  $M\times N$ to $M \otimes_A (N \otimes _B P)$ defined by $(m,n)\mapsto  m \otimes  (n \otimes  p)$ induce a unique $A$-linear map $f_p:M\otimes _A N \to M\otimes _A(N\otimes _B P)$ that sends $m\otimes  n$ to $m\otimes (n \otimes  p)$. By expressing elements of $M \otimes_A N$ as finite sum of basic elements, one can see that $f_p$ is also  $B$-linear. Therefore, if we define $f:(M\otimes _A N) \times P\rightarrow M \otimes _A (N \otimes  _B P)$ by 
\begin{align*}
f(x,p)\triangleq f_p(x)
\end{align*}
we see that $f$ is $B$-linear in $M\otimes _A N$. Again, by expressing elements of $M \otimes  _A N$ as finite sum of basic elements, one can see that $f$ is also  $B$-linear in  $P$. Therefore, by universal property, there exists some $B$-linear mapping  $\tilde{f}:(M\otimes _A N) \otimes_B  P\rightarrow M \otimes _A (N \otimes  _B P)$  with action:
\begin{align*}
  (m \otimes  n)\otimes p \mapsto   f_p(m\otimes n)=m\otimes  (n \otimes  p)
\end{align*}
Tedious computation by expressing elements of $(M \otimes _A N)\otimes _B P$ into finite sum of basic elements shows that $\tilde{f}$ is also $A$-linear. We have shown $\tilde{f}$ is an $(A,B)$-bimodule homomorphism.  \\

To finish the proof, one first use similar argument to construct some  $(A,B)$-bimodule homomorphism $\tilde{g}: M \otimes_A (N \otimes _B P)\rightarrow (M\otimes _A N)\otimes_B P$ with action: 
\begin{align*}
  m \otimes  (n \otimes  p)\mapsto (m\otimes  n)\otimes  p
\end{align*}
And then, see that $\tilde{g}\circ \tilde{f}\in \operatorname{End}_{(A,B)}[(M\otimes_ AN)\otimes _BP]$ have the identity action on basic elements $x\otimes  p$\footnote{Again, by expressing $x$ as basic element  $x= \sum m_i \otimes  n_i$.} to conclude by universal property that $\tilde{g}\circ \tilde{f}$ is the identity function. 
\end{proof}
\begin{mdframed}
Let $f:A\rightarrow B$ be a ring homomorphism. If $N$ is a  $B$-module, then the  $A$-module structure on  $N$ defined by $an\triangleq f(a)n$ is called \textbf{restriction of scalars}. If $M$ is an $A$-module, then the  $B$-module structure on  $B\otimes _A M$\footnote{$B$ is given an $A$-module structure by restriction of scalar.} defined by 
\begin{align*}
b(b' \otimes  m)\triangleq  bb' \otimes  m
\end{align*}
is called \textbf{extension of scalars}. 
\end{mdframed}
\begin{question}{Proposition 2.16}{}
Let $A,B$ be two rings, and let  $B$ be an  $A$-module, so we have a ring homomorphism $f:A\rightarrow B$ defined by $f(a)\triangleq a1_B$. Let $N$ be a $B$-module, and give $N$ an  $A$-module structure using restriction of scalars with respect to  $f$.\\

Show that if $N$ is finitely generated as a $B$-module and  if $B$ is finitely generated as an  $A$-module, then  $N$ is finitely generated as an $A$-module. 
\end{question}
\begin{proof}
Suppose $n_1,\dots ,n_k$ generate $N$ over  $B$, and suppose  $b_1,\dots ,b_m$ generate $B$ over $A$. We claim  $\set{b_jn_i}$ generates $N$ over $A$. Let 
\begin{align*}
b_i'= \sum_{j=1}^m a_{i,j}b_j
\end{align*}
Compute 
\begin{align*}
\sum_{i=1}^k b_i'n_i&= \sum_{i=1}^k \Big(\sum_{j=1}^m a_{i,j}b_j \Big)n_i \\
&=\sum_{i=1}^k  \sum_{j=1}^m (a_{i,j}b_j)n_i  \\
&=\sum_{i,j} (a_{i,j}b_j) n_i \\
&=\sum_{i,j}a_{i,j}(b_jn_i)
\end{align*}
For justification of last equality, compute 
\begin{align*}
a(bn)=f(a)(bn)=(f(a)b)n=(ab)n
\end{align*}
Remark: similar routine computation shows that $N$ is in fact an  $(A,B)$-bimodule. 
\end{proof}
\begin{question}{Proposition 2.17}{}
Let $f:A\rightarrow B$ be a ring homomorphism, and let $M$ be a finitely generated $A$-module, show that its extension of scalar  $B\otimes_A M$ is finitely generated as a $B$-module.   
\end{question}
\begin{proof}
Let $\set{m_1,\dots ,m_n}$ generates $M$ over $A$. We claim $\set{1_B\otimes m_i}$ generate all the basic elements. Consider 
\begin{align*}
b \otimes \sum a_im_i&= \sum b\otimes a_i m_i \\
&= \sum b (1_B \otimes a_im_i)\\
&=\sum b ( a_i 1_B \otimes  m_i) \hspace{0.5cm}(\because \text{ $B$ is regarded as an  $A$-module when we write }B\otimes _A M)\\
&=\sum b (f(a_i)\otimes m_i)\\
&=\sum bf(a_i)(1\otimes m_i)
\end{align*}
\end{proof}
\begin{mdframed}
Let $M\overset{f}{\longrightarrow }M'$ and $N\overset{g}{\longrightarrow }N'$ be in the category of $A$-module. The function  $h:M\times N \rightarrow M' \otimes  N'$ defined by 
\begin{align*}
h(x,y)\triangleq f(x)\otimes  g(y)
\end{align*}
is clearly $A$-bilinear. Therefore, we may induce some unique $A$-linear map  $f\otimes  g:M\otimes  N\rightarrow M'\otimes  N'$ such that 
\begin{align*}
  (f\otimes  g)(x\otimes  y)=f(x)\otimes  g(y)
\end{align*}
Note that for each $M' \overset{f'}{\longrightarrow }M''$ and $N'\overset{g'}{\longrightarrow }N''$, we have 
\begin{align*}
  (f' \circ f) \otimes  (g' \circ g)= (f'\otimes  g')\circ (f\otimes  g)
\end{align*}
because they agree on the basic elements. 
\end{mdframed}
\begin{question}{Proposition 2.18 (Exaction of Tensor Product)}{}
If 
\begin{align}
\label{Mfg}
M'\overset{f}{\longrightarrow }M\overset{g}{\longrightarrow } M'' \rightarrow  0
\end{align}
is an exact sequence of $A$-modules and homomorphism, then for any $A$-module  $N$, the sequence 
 \begin{align*}
M' \otimes  N \overset{f \otimes 1 }{\longrightarrow } M \otimes  N \overset{g \otimes  1}{\longrightarrow }M'' \otimes  N \rightarrow  0
\end{align*}
is also exact, where $1 \in \operatorname{End}(N)$ is the identity mapping. 
\end{question}
\begin{proof}
  Because $g$ is surjective, we may construct an \textbf{right inverse} $g^{-1}:M''\rightarrow M$. That is, $g \circ g^{-1}(m'')=m''$ for all $m'' \in M''$. To see $g\otimes  1$ is surjective, just observe 
\begin{align*}
  \sum m''_i \otimes  n_i= (g \otimes  1) \Big(\sum g^{-1}(m''_i) \otimes  n_i\Big)
\end{align*}
After computing 
\begin{align*}
(g \otimes  1)\circ (f\otimes  1)= (g\circ f)\otimes  (1 \circ 1)= 0
\end{align*}
we may reduce the problem into proving the factored map 
\begin{align*}
\operatorname{Coker}(f\otimes 1) \overset{\tilde{g}}{\longrightarrow } M'' \otimes  N
\end{align*}
is injective. Consider the map $h:M''\times N \rightarrow \operatorname{Coker}(f\otimes  1)$ defined by 
\begin{align*}
h(m'',n)\triangleq [g^{-1}(m'')\otimes  n]
\end{align*}
Clearly, $h$ is linear in $n$. Using the fact $\operatorname{Im}(f)=\operatorname{Ker}(g)$ and computation  
\begin{align*}
g(g^{-1}(am'')-ag^{-1}(m''))&=0\\
g(g^{-1}(m_1''+m_2'')-g^{-1}(m_1'')-g^{-1}(m_2''))&=0
\end{align*}
we may conclude that $h$ is also linear in  $M''$. Now, because $h$ is bilinear, we may induce some linear $\tilde{h}:M''\otimes  N\rightarrow \operatorname{Coker}(f\otimes  1)$ with action 
\begin{align*}
\tilde{h} (m''\otimes  n)=[g^{-1}(m'')\otimes  n]
\end{align*}
Using universal property, it is east to check that $\tilde{h}\circ \tilde{g} \in \operatorname{End}(\operatorname{Coker}(f\otimes  1))$ is identity mapping. We have shown $\tilde{g}$ is injective. 
\end{proof}
\begin{mdframed}
Note that the exaction of tensor product holds only for sequence of the \myref{form}{Mfg}. One can't delete the zero space at the end and still reach the same conclusion. Consider 
\begin{align*}
0\longrightarrow \Z \overset{f(x)=2x}{\longrightarrow }\Z 
\end{align*}
where the underlying ring is $\Z$. The sequence 
\begin{align*}
0\longrightarrow \Z \otimes \operatorname{Coker}(f) \overset{f\otimes  1}{\longrightarrow } \Z \otimes  \operatorname{Coker}(f)
\end{align*}
is not exact, because 
\begin{align*}
  (f\otimes 1)(x \otimes  [y])=2x \otimes  [y]= x \otimes  [2y]= 0 
\end{align*}
implies $\operatorname{Ker}(f\otimes  1)=\Z \otimes  \operatorname{Coker}(f)$, while 
\begin{align*}
\Z \otimes  \operatorname{Coker}(f)\cong  \operatorname{Coker}(f)\neq 0 
\end{align*}
An $A$-module $N$ is said to be \textbf{flat} if for any exact sequence 
\begin{align*}
\cdots \rightarrow M_{i-1} \overset{f_{i-1}}{\longrightarrow } M_i \overset{f_i}{\longrightarrow }M_{i+1}\rightarrow \cdots
\end{align*}
in the category of $A$-modules, the sequence 
 \begin{align*}
\cdots \rightarrow M_{i-1}\otimes  N \overset{f_{i-1}\otimes  1}{\longrightarrow }M_i \otimes  N \overset{f_i \otimes 1 }{\longrightarrow }M_{i+1}\otimes  N \rightarrow \cdots 
\end{align*}
is also exact. 
\end{mdframed}
\begin{question}{}{}
Show that for an $A$-module  $N$, the following are equivalents 
\begin{enumerate}[label=(\alph*)]
  \item $N$ is flat. 
  \item If $0\rightarrow M'\longrightarrow M\longrightarrow M''\rightarrow  0$ is exact, then $0\rightarrow  M'\otimes N \longrightarrow M\otimes N \longrightarrow M''\otimes N \rightarrow 0$ is also exact. 
  \item If $f:M'\rightarrow M$ is injective, then $f\otimes  1:M'\otimes  N \rightarrow M\otimes N$ is injective. 
  \item If $f:M'\rightarrow N$ is injective and $M,M'$ are finitely generated, then  $f\otimes 1:M'\otimes N\rightarrow M\otimes N$ is injective. 
\end{enumerate}
\end{question}
\begin{proof}
From (a) to (b) is definition. We now prove from (b) to (a). Consider the exact sequence  
\begin{align*}
\cdots \rightarrow M_{i-1} \overset{f_{i-1}}{\longrightarrow } M_i \overset{f_i}{\longrightarrow }M_{i+1}\rightarrow \cdots
\end{align*}
We may split this into a short exact sequence 
\begin{align*}
0\longrightarrow  \operatorname{Im}(f_{i-1})\hookrightarrow M_i \overset{f_i}{\longrightarrow }\operatorname{Im}(f_i)\longrightarrow 0
\end{align*}
By (b), the short sequence
\begin{align*}
0\longrightarrow \operatorname{Im}(f_{i-1})\otimes  N \hookrightarrow M_i \otimes  N \overset{f_i\otimes 1}{\longrightarrow }\operatorname{Im}(f_i)\otimes  N \longrightarrow 0 
\end{align*}
is also exact. This implies 
\begin{align*}
\operatorname{Ker}(f_i\otimes  1)=\operatorname{Im}(f_{i-1})\otimes N=\operatorname{Im}(f_{i-1}\otimes  1)
\end{align*}
We have shown 
\begin{align*}
\cdots \rightarrow M_{i-1} \otimes  N \overset{f_{i-1}\otimes  1}{\longrightarrow } M_i \otimes  N \overset{f_i\otimes  1}{\longrightarrow }M_{i+1}\otimes  N\rightarrow \cdots
\end{align*}
is also exact, thus proving (a). From (b) to (c), we simply let $M''\triangleq \operatorname{Coker}(f)$ and let  $M\rightarrow M''$ be the quotient map. From (c) to (b) follows from right exaction and 
\begin{align*}
\operatorname{Im}(f\otimes 1)=\operatorname{Im}(f)\otimes  N = \operatorname{Ker}(g)\otimes N= \operatorname{Ker}(g\otimes 1) 
\end{align*}
From (c) to (d) is clear. It only remains to show from  (d) to (c). \\

Fix 
\begin{align*}
u = \sum_{i=1}^n x_i \otimes  y_i \in \operatorname{Ker}(f\otimes  1)
\end{align*}
Let $M_0'$ be the submodule of $M'$ generated by $\set{x_1,\dots ,x_n}$, and let $u_0' \in M'_0\otimes  N$ be the element 
\begin{align*}
u_0'\triangleq \sum_{i=1}^n x_i \otimes  y_i \in M'_0 \otimes  N
\end{align*}
By Corollary 2.13, there exists some finitely generated submodule $M_0$ of  $M$ such that $u_0 \in M_0\otimes N$ defined by
 \begin{align*}
u_0\triangleq \sum_{i=1}^n f(x_i) \otimes y_i \in M_0 \otimes  N
\end{align*}
equals to $0$. Note that because $\set{x_1,\dots ,x_n}$ generates $M'_0$ and  $M_0$ contains $\set{f(x_1),\dots ,f(x_n)}$, so $M_0$  contains $f(M'_0)$, and obviously 
\begin{align*}
f|_{M_0'}:M_0'\rightarrow M_0\text{ is injective. }
\end{align*}
We now see from (d) that 
\begin{align*}
f|_{M_0'}\otimes 1:M'_0 \otimes  N\rightarrow M_0 \otimes  N\text{ is injective. }
\end{align*}
Compute 
\begin{align*}
  (f|_{M'_0}\otimes  1)(u_0')= \sum_{i=1}^n f(x_i)\otimes  y_i=u_0=0
\end{align*}
We see $u'_0=\sum_{i=1}^n x_i \otimes  y_i \in M'_0 \otimes  N$ is zero. Now consider  the universal property 
% https://q.uiver.app/#q=WzAsMyxbMCwwLCJNJ18wIFxcdGltZXMgTiAiXSxbMiwwLCJNJ18wIFxcb3RpbWVzIE4iXSxbMiwyLCJNJyBcXG90aW1lcyBOIl0sWzAsMl0sWzAsMV0sWzEsMiwiXFxwaGkiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=
\[\begin{tikzcd}
	{M'_0 \times N } && {M'_0 \otimes N} \\
	\\
	&& {M' \otimes N}
	\arrow[from=1-1, to=1-3]
	\arrow[from=1-1, to=3-3]
	\arrow["\pfi"', dashed, from=1-3, to=3-3]
\end{tikzcd}\]
We may see $u=\pfi(u_0')$ is zero. Finishing the proof. 
\end{proof}
\begin{question}{Exercise 2.20}{}
Let ring $B$ be an  $(A,B)$-bimodule, and let $M$ be a flat  $A$-module. Show that the extension of scalar $B\otimes_A M$ is a flat $B$-module. 
\end{question}
\begin{proof}
Let $g:P'\rightarrow P$ be an injective $B$-module homomorphism.  We are required to show 
\begin{align*}
P' \otimes_B (B \otimes _A M) \overset{g\otimes 1}{\longrightarrow } P \otimes  _B (B \otimes_A M)
\end{align*}
is also injective. We have the isomorphism 
\begin{align*}
P' \otimes  _B (B\otimes  _A M) \cong  (P' \otimes  _B B) \otimes_A M \cong  P' \otimes _A M 
\end{align*}
It now follows from $M$ being flat that  $g\otimes  1$ is injective. 


\end{proof}
\section{Script 1}

I proved and gathered the propositions in my paragraphs. 
\begin{theorem}
\textbf{(Ideal Quotients are well defined)} If we define for each pair $I,S$ of ideals of $R$ their \textbf{ideal quotient} by
\begin{align*}
  (I:S)\triangleq \set{x\in R: xy \in I\text{ for all }y \in S }
\end{align*}
Then $(I:S)$ forms an ideal.  
\end{theorem}
\begin{proof}
To see $(I:S)$ is closed under addition, let $x,z \in I,y \in S,$ and observe 
\begin{align*}
  (x+z)y=xz+yz \in I
\end{align*}
To see $(I:S)$ is a multiplicative black hole, let $u \in (I:S),v \in R,s \in S$ and observe 
\begin{align*}
  (uv)s=v(us)\in I\text{ because }us \in I
\end{align*}
\end{proof}
\begin{theorem}
\textbf{(Description of annihilator)} Given some ideal $I$ of $R$, we use the notation $\operatorname{Ann}(I)$ to denote its \textbf{annihilator} $(\set{0}:I)$. We have 
\begin{align*}
\operatorname{Ann}(I)=\set{x\in R: xy=0\text{ for all }y \in I}
\end{align*}
\end{theorem}
\begin{proof}
Obvious.
\end{proof}
\begin{mdframed}
Given a principal ideal $\langle x\rangle $, we shall always denote its annihilator simply by $\operatorname{Ann}(x)$
\end{mdframed}
\begin{theorem}
\textbf{(Description of the set of zero-divisors)} If we denote  $D$ the set of zero-divisors of $R$, we have 
\begin{align*}
D = \bigcup_{x\neq 0 \in R} \operatorname{Ann}(x )
\end{align*}
\end{theorem}
\begin{proof}
If $d$ is a zero-divisor, then $d \in \operatorname{Ann}(s)$ for the $s\neq 0$ that divides $0$ with  $d$.  If $x\neq 0$ and $y \in \operatorname{Ann}(x)$, then $yx=0$.  
\end{proof}
\begin{theorem}
\textbf{(An example)} Let $R\triangleq \Z,I\triangleq \langle m\rangle$ and $S\triangleq \langle n\rangle $. We have 
\begin{align*}
  (I:S)=\langle q\rangle 
\end{align*}
Where  
\begin{align*}
q= \frac{m}{(m,n)}\text{ and }(m,n)\text{ is the highest common factor of $m$ and $n$. }
\end{align*}
\end{theorem}
\begin{proof}
To show $\langle q\rangle \subseteq (I:S)$, we only have to show $q \in (I:S)$. Let $p$ be arbitrary integer so $pn$ is an arbitrary element of  $S$. Note that 
\begin{align*}
m \mid mp \cdot \frac{n}{(m,n)} =  q (pn) \implies  q(pn) \in I
\end{align*}
Because $pn$ is an arbitrary element of  $S$, we have shown  $q\in (I:S)$. To show $(I:S)\subseteq \langle q\rangle $, let $p \in (I:S)$. Because $p \in (I:S)$, we know $pn\in I$. That is, 
\begin{align*}
m \mid  pn
\end{align*}
Dividing both side with $(m,n)$, we see  
\begin{align*}
q \mid p \cdot \frac{n}{(m,n)} 
\end{align*}
Because $q= \frac{m}{(m,n)}$ is by definition coprime with $\frac{n}{(m,n)}$, we can now deduce 
\begin{align*}
q \mid p 
\end{align*}
as desired.
\end{proof}
\begin{question}{}{}
Let $I,S,T,V_\alpha $ be ideals of ring $R$. Show 
\begin{enumerate}[label=(\alph*)]
  \item $I \subseteq (I:S)$. 
  \item $(I:S)S \subseteq I$. 
  \item $((I:S):T)=(I:ST)=((I:T):S)$. 
  \item $(\bigcap  V_\alpha : S)= \bigcap  (V_\alpha :S)$. 
  \item $(I: \sum V_\alpha )=\bigcap (I:V_\alpha )$. 
\end{enumerate}
\end{question}
\begin{proof}
Proposition (a) is obvious. Proposition (b) is also obvious once we reduce the problem into proving the single sum $xy$ belongs to  $I$ where  $x\in (I:S)$ and $y \in S$. For proposition (c), we first show 
\begin{align*}
\vi{((I:S):T)\subseteq (I:ST)}
\end{align*}
Because ideal is closed under addition, we only have to prove $xst\in I$ where $x\in ((I:S):T), s \in S\text{ and } t \in T$, which follows from noting $xt \in (I:S)$. $\vdone$. Note that  
\begin{align*}
\blue{(I:ST)\subseteq ((I:T):S)}
\end{align*}
is obvious. $\bdone$. Lastly, we show 
\begin{align*}
\vi{((I:T):S)\subseteq ((I:S):T)}
\end{align*}
Let $x\in ((I:T):S),t\in T$ and $s \in S$. We are required to show $xts \in I$, which is obvious since $xs \in (I:T)$. $\vdone$. Proposition (d) is obvious.  Let $x \in (I: \sum V_\alpha )$. Fix $\alpha $ and $r \in V_\alpha $. Because $r\in \sum V_\alpha $, we see $xr\in I$. Let $x$ be in the intersection, it is clear that $x \sum v_\alpha =\sum xv_\alpha \in I$ because $xv_\alpha \in I$.     
\end{proof}
\begin{theorem}
\textbf{(Radicals of ideals are well-defined)} If $I$ is an ideal of $R$, then the  \textbf{radical} of $I$ defined by 
 \begin{align*}
r(I)\triangleq  \set{x\in R: x^n\in I\text{ for some }n>0}
\end{align*}
is also an ideal. 
\end{theorem}
\begin{proof}
  To see $r(I)$ is closed under addition, let $x^n,y^m \in I$, and observe $(x+y)^{n+m}\in I$. To see $r(I)$ is a multiplicative black hole, let $x^n\in I,v \in R$ and observe $(xv)^n=x^nv^n \in I$. 
\end{proof}
\begin{theorem}
\textbf{(Description of Radicals)} Let $\pi : R \rightarrow R \quotient I$ be the quotient map. We have
\begin{align*}
r(I)= \pi ^{-1}(\operatorname{Nil}(R\quotient I)) 
\end{align*}
\end{theorem}
\begin{proof}
Obvious. 
\end{proof}
\begin{question}{}{}
  \begin{enumerate}[label=(\alph*)]
    \item $I \subseteq r(I)$. 
    \item $r(r(I))=r(I)$.  
    \item $r(IS)=r(I\cap S)=r(I)\cap r(S)$
    \item $r(I)=R \iff  I= R$. 
    \item $r(I+S)=r(r(I)+r(S))$. 
    \item If $I$ is prime, then  $r(I^n)=I$ for all $n>0$. 
  \end{enumerate}
\end{question}
\begin{proof}
Proposition (a) and (b) are obvious. The proposition
\begin{align*}
r(IS)\subseteq r(I\cap S) 
\end{align*}
follows from $IS \subseteq I \cap S$. The propositions 
\begin{align*}
r(I \cap S)\subseteq r(I)\cap r(S)\text{ and }r(I) \cap r(S) \subseteq r(IS)
\end{align*}
are clear, thus proving proposition (c). The proposition 
\begin{align*}
I=R \implies  r(I)=R 
\end{align*}
is clear, and its converse follows from $1\in r(I)\implies 1=1^n \in I$, thus proving proposition (d). The proposition 
\begin{align*}
r(I+S)\subseteq r(r(I)+r(S))
\end{align*}
is clear. Let $x^n=y+z$ where  $y^m \in I$ and $z^p \in S$. We see $x^{n(m+p)}\in I+S$. We have shown 
\begin{align*}
r(r(I)+r(S)) \subseteq r(I+S)
\end{align*}
thus proving proposition (e). Let $I$ be prime. We know $I \subseteq r(I)$. To see the converse, let $x^n \in I$. Because $I$ is prime, either  $x$ or  $x^{n-1}$ belongs to $I$. If  $x$ does not belong to  $I$, then  $x^{n-1}$ belongs to $I$, which implies either $x\in I$ or $x^{n-2}\in I$. Applying the same argument repeatedly, we see $x \in I$, thus proving $r(I)\subseteq I$. Because 
\begin{align*}
I \supseteq I^2 \supseteq I^3 \supseteq I^4 \supseteq \cdots   
\end{align*}
we know
\begin{align*}
r(I) \supseteq r(I^2) \supseteq r(I^3) \supseteq r(I^4) \supseteq \cdots  
\end{align*}
Because 
\begin{align*}
x^n \in I \implies  x^{nk} \in I^k \text{ for all }k \inn
\end{align*}
We now also have 
\begin{align*}
r(I) \subseteq r(I^k)\text{ for all }k  \inn
\end{align*}
This proved proposition (e). 
\end{proof}
\begin{theorem}
\textbf{(Description of radical)}  Let $I$ be an ideal of $R$. 
\begin{align*}
r(I)= \bigcap \set{S \in \operatorname{spec}(R): I \subseteq S}
\end{align*}
\end{theorem}

\section{archived}

There are essentially two distinct substructures of a ring. A subset of a ring is called a \textbf{subring} if it is closed under addition and multiplication and contains the multiplicative identity. 

Because the union of a chain of proper ideals is still a proper ideal\footnote{No proper ideals contain $1$.}, we may apply \textbf{Zorn's Lemma} to show that a \textbf{maximal ideal}\footnote{By a maximal ideal, we mean a proper ideal contained by no other proper ideal.} always exists. Equivalently, we may define a proper ideal $I$ to be maximal if and only if $R\quotient I$ is a field.\\ 

\begin{question}{}{}
Show that the sequence 
\begin{align}
\label{Mu}
M'\overset{u}{\longrightarrow }M  \overset{v}{\longrightarrow }M''\longrightarrow 0
\end{align}
is exact if and only if for every module $N$ the sequence 
\begin{align}
\label{Ns}
0\longrightarrow \operatorname{Hom}(M'',N)\overset{\overline{v}}{\longrightarrow }\operatorname{Hom}(M,N) \overset{\overline{u}}{\longrightarrow } \operatorname{Hom}(M',N)
\end{align}
is exact. 
\end{question}
\begin{proof}
Suppose for every module $N$ the \myref{sequence}{Ns} is exact. To show  \myref{sequence}{Mu} is also exact, we are required to show $v$ is surjective and $\operatorname{Im}(u)=\operatorname{Ker}(v)$. To see $v$ is surjective, let $N\triangleq \operatorname{Coker}(v)$, and use the injectivity of $\overline{v}$ to show that the quotient map $\pi: M''\rightarrow N$ is indeed zero. \\

To see $\operatorname{Im}(u)\subseteq \operatorname{Ker}(v)$, let $N\triangleq M''$, consider the identity mapping $\id _{M''}$, and note that 
\begin{align*}
\overline{u}\circ \overline{v} (\id _{M''}) = \id _{M''} \circ v \circ  u = 0
\end{align*}
To see $\operatorname{Ker}(v)\subseteq \operatorname{Im}(u)$, let $N\triangleq  M\quotient \operatorname{Im}(u)$, and let $\pi :M\rightarrow N$ be the quotient map. Obviously $\pi  \in \operatorname{Ker}(\overline{u})=\operatorname{Im}(\overline{v})$, so there exists some $\psi : M''\rightarrow N$ such that $\pi = \psi \circ v $. This implies $\operatorname{Ker}(v)\subseteq \operatorname{Ker}(\pi )=\operatorname{Im}(u)$. \\

Now, suppose \myref{sequence}{Mu} is exact and let $N$ be some module. To show \myref{sequence}{Ns} is exact, we are required to show $\overline{v}$ is injective and $\operatorname{Im}(\overline{v})=\operatorname{Ker}(\overline{u})$. The fact $\overline{v}$ is injective follows from $v$ is surjective.   








\end{proof}
\section{Mail Draft}
Sorry to bother you. At the bottom of page 51 and the top of page 52, Atiyah and MacDonald claim that for every primary decomposition 
\begin{align}
\label{prim}
I = \bigcap_{i=1}^n Q_i
\end{align}
we may use their Lemma 4.3, which states 
\begin{align*}
\sqrt{T_j}=P\text{ for all primary $T_j \in \set{T_1,\dots ,T_m}$ } \implies \sqrt{\bigcap T_j}=P 
\end{align*}
to reduce  the \myref{decomposition}{prim} into a new decomposition 
\begin{align*}
I = \bigcap_{j=1}^r Q_j'
\end{align*}
such that
\begin{align*}
\bset{\sqrt{Q_1'},\dots ,\sqrt{Q_r'}  }\text{ are all distinct }
\end{align*}
I am quite confused about this. Do they mean that if $\sqrt{Q_1}=\sqrt{Q_2}$, we may use $Q_1 \cap Q_2$ to replace $Q_1$ and  $Q_2$? If so, they didn't show that $Q_1\cap Q_2$ will be primary. Obviously, finite intersection of primary ideals need not be primary in general, and the minimal  
\section{Question}

\end{document}

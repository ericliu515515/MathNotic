\documentclass{report}
\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{NCKU 112.1}\\Rudin}
\author{\huge{Eric Liu}}
\date{}
\begin{document}
\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak
\chapter{The Real and Complex Number System}
\section{Introduction}
\fbox{\begin{minipage}{39em}
In this section, we will define the concept of ordered sets, and give a close look of the completeness property of real numbers, by showing the "uncompleteness" of rational numbers. First, we prove an elementary and classic theorem of rational numbers.        
\end{minipage}}
\begin{theorem}
\label{1.1.1}
There exists no rational $p$ such that $p^2=2$
\end{theorem}
\begin{proof}
\As{there is, and we write $p$ in the form $p=\frac{a}{b}$, where $a,b\inz\text{ and one of $a,b$ is odd}$}. Observe that $p^2=2\implies a^2=2b^2\implies 2\text{ divides }a\implies 2\text{ divides }b\tCaC$
\end{proof}

\fbox{\begin{minipage}{39em}
For the sake of our discussion below, we will use $\Q^+$ instead of $\Q$ as our universal. Now, we divide the "rational numbers line" in half at the point $\sqrt{2}$, and have two subdivisions $A=\set{x\inq^+ : x^2<2},B=\set{x\inq^+:x^2>2}$ 
\end{minipage}}

\begin{axiom}
\label{1.1.2}
Let $S$ be an ordered set and $X$ be a subset of $S$. Axiomatically define
\begin{equation}
\max X\in X\text{ and }\forall x\in X, x\leq \max X
\end{equation}
\begin{equation}
\min X\in X \text{ and }\forall x\in X, \min X\leq x 
\end{equation}
\end{axiom}
\begin{theorem}
\label{1.1.3}
  $\max A\text{ and }\min B$ both doesn't exist.
\end{theorem}
\begin{proof}
We wish to construct a function $q(p)$ on $\Q^+$ such that for all $p \inq^+$, we have $p^2<2\implies p^2<q^2<2$ and have $2<p^2\implies 2<q^2<p^2$. Notice $p<q\iff p^2<q^2$, so we can translate the wanted property of $q$ into
\begin{align}
  p^2<2 & \implies p<q \text{ and }q^2<2\\
  p^2>2 & \implies q<p\text{ and }2<q^2
\end{align}
Let $a,b$ be two function of $p$ on $\Q^+$. To satisfy the above properties, we can let the below equation first be true and then solve for $a,b$.
\begin{align}
  q-p&=\frac{2-p^2}{a}\\
  q^2-2 &= \frac{p^2-2}{b}
\end{align}
Now we solve for $a,b$
\begin{gather}
q-p=\frac{2-p^2}{a}\text{ and }q^2-2=\frac{p^2-2}{b}
\implies q= \frac{2-p^2}{a}+p\text{ and }q^2=\frac{p^2-2}{b}+2\\
\liff [\frac{2-p^2}{a}+p]^2=\frac{p^2-2}{b}+2\\
\liff \frac{(2-p^2)^2}{a^2}+\frac{2p(2-p^2)}{a}+p^2=\frac{p^2-2}{b}+2\\
\liff (p^2-2)^2(\frac{1}{a^2})+(p^2-2)(-\frac{2p}{a}+1-\frac{1}{b})=0\\
\liff \frac{p^2-2}{a^2}-\frac{2p}{a}+1-\frac{1}{b}=0\text{ (because $p^2-2\neq 0$) }\\
\liff \frac{p^2-2-2ap+a^2}{a^2}=\frac{1}{b}\\
\liff b=\frac{a^2}{p^2-2-2ap+a^2}=\frac{a^2}{(p-a)^2-2}
\end{gather}
Define $a:=p+c$ where $c^2>2$, and we are finished.
\end{proof}
\fbox{\begin{minipage}{39em}
Now, we come back to define the concept of ordered set.
\end{minipage}}
\begin{definition}
\label{1.1.4}
\textbf{(Totally Ordered Set Axioms)} $S$ is an totally ordered set, sometimes simply called  ordered set depend on the context, if there is a relation $\sim$ on it that satisfy 
\begin{equation}
\forall x\in S, x\sim x
\end{equation}
\begin{equation}
\forall x,y\in S, x\sim y\text{ or }y\sim x
\end{equation}
\begin{equation}
  \forall x,y,z\in S, x\sim y \text{ and }y\sim z\implies x\sim z
\end{equation}
\begin{equation}
\forall x,y\in S, x\sim y\text{ and }y\sim x \implies x=y
\end{equation}
From now on, we write this relation as $\leq $ and if we write  $x\geq y$, we mean $y\leq x$.
\end{definition}
\fbox{\begin{minipage}{39em}
To discuss the uncompleteness of rational numbers, which is an ordered set, we first define a few concepts brought by concept of ordered set.
\end{minipage}}
\begin{definition}
\label{1.1.5}
Let $S$ be an ordered set and $E\subseteq S$. $E$ is bounded above if 
\begin{equation}
\exists a\in S, \forall b\in E, a\geq b 
\end{equation}
In this case, we say $a$ is an upper bound of $E$ and $E$ is bounded above by $a$. On the other hand, $E$ is bounded below by $c$ if
\begin{equation}
\forall b\in E, c\leq b
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
Before we give the definition of supremum, aka least upper bound, we first prove a theorem about it.
\end{minipage}}
\begin{theorem}
\label{1.1.6}
If $x$ is the smallest upper bound of a bounded above nonempty set  $E$, then any number smaller than  $x$ is not an upper bound of  $E$, and every upper bound of  $E$ is greater than or equal  to $x$.
\end{theorem}

\begin{proof}

Let $A$ be the set of upper bounds of  $E$. Arbitrarily pick an $m$ such that $m<x$. \As{$\forall z\in E, m>z$}. We see $m\in A$, and because $x=\min A$, we see $x\leq m\tCaC$. \As{$\exists n\in A, n<x$}. Then $\exists z\in E, n<z$, which implies $n\not\in A\tCaC$
\end{proof}
\begin{corollary}
\label{1.1.7}
 Any number smaller than the greatest lower bound is a lower bound, and any number greater than the greatest lower bound is not a lower bound.
\end{corollary}
\begin{definition}
\label{1.1.8}
\textbf{(Definition of Supremum and Infimum)} Let $A,B$ respectively be the set of upper bounds of  $E$ and the set of lower bounds of  $E$. We define
\begin{equation}
\sup E:=\min A
\end{equation}
and
\begin{equation}
\inf E:=\max B
\end{equation}
if they ever exist.
\end{definition}
\begin{theorem}
\label{1.1.9}
Let $A$ be a subset of ordered set  $S$. If  $\max A$ exists, then $\max A=\sup A$. Similarly, if $\min A$ exists, then $\min A=\inf A$
\end{theorem}
\begin{proof}
$\max A$ is an upper bound and $\min  A$ is an lower bound hold true by definition. Any number smaller than $\max A$ can not be an upper bound since $\max A\inA$. Similarly, and number greater than $\min A$ can not be an lower bound since $\min A\inA$  
\end{proof}
\fbox{\begin{minipage}{39em}
Now, we look back to our subdivisions $A=\set{x\inq^+: x^2<2},B=\set{x\inq^+: x^2>2}$. We first show that $B$ is exactly the set of all upper bounds of $A$.
\end{minipage}}
\begin{theorem}
\label{1.1.10}
Given $A=\set{x\inq^+: x^2<2},B=\set{x\inq^+: x^2>2}$. We have
\begin{equation}
B=\set{x\inq^+ : \forall y\in A, y\leq x}
\end{equation}
\end{theorem}
\begin{proof}
Arbitrarily pick $x\in B$, and we see $\forall y\in A, y^2<2<x^2$. Then $\forall y\in A,y<x$. This implies $B\subseteq \set{x\inq^+:\forall y\in A, y\leq x}$. Let $x$ satisfy $\forall y\in A, y\leq x$. \As{$x^2<2$}. We immediately see $x=\max A$, but $\max A$ doesn't exist \CaC
\end{proof}
\fbox{\begin{minipage}{39em}
    By \myref{Theorem}{1.1.3}, we then can see that $\sup A$ does not exist. Now, we give this idea a name.
\end{minipage}}
\begin{definition}
\label{1.1.11}
  \textbf{(Definition of Completed Ordered Set)}
An ordered set $S$ satisfy least-upper-bound property if
 \begin{equation}
E\subseteq S\text{ and }E\neq \varnothing\implies \sup E\text{ exists }
\end{equation}
Also, we say $S$ is completed.
\end{definition}
\fbox{\begin{minipage}{39em}
$\sup A$ does not exists indicate that $\Q$ as an ordered set doesn't satisfy the least-upper-bound property. Before we close this section, we reveal the face of the twin brother of the least-upper-bound property. In fact, it is more like property itself in the mirror, since they are equivalent.
\end{minipage}}
\begin{theorem}
\label{1.1.12}
  \textbf{(LUB$\iff $GLB)} $S$ satisfy the least-upper-bound property if and only if  $S$ satisfy the greatest-lower-bound property.
\end{theorem}
\begin{proof}
  From left to right, consider a bounded below set $E$.  Let $L$ be the set of lower bounds of  $E$. We know $\sup L$ exists and every elements of $E$ is an upper bound of $L$, so $\sup L$ is an lower bound of $E$. Then $\sup L=\inf E$. The other direction use the same method. 
\end{proof}
\section{Ordered Fields}
\fbox{\begin{minipage}{39em}
In this section, we first give the definition of ordered fields, and prove basic result concerning positivity. Notice in this section that $x,y,z$ are all in  $\F$.
\end{minipage}}
\begin{axiom}
\label{1.2.1}
\textbf{(Ordered Field Axioms)} An ordered field $\F$ is a field that is not only a ordered set, but also satisfy the following axioms
\begin{equation}
y<z\implies x+y<x+z
\end{equation}
\begin{equation}
x>0\text{ and }y>0\implies xy>0
\end{equation}
\end{axiom}
\begin{theorem}
\label{1.2.2}
\textbf{(Negate reverse positivity)} $(x>0\iff -x<0)\text{ and }(x<0\iff -x>0)$
\end{theorem}
\begin{proof}
  Observe $x>0\implies x+(-x)>0+(-x)\implies -x<0$, and $x<0\implies x+(-x)<0+(-x)\implies -x>0$. Clearly, $x=0\implies -x=0$. Then the Theorem follows.
\end{proof}

\begin{theorem}
\label{1.2.3}
  
\textbf{(Multiply a negative number reverse positivity)} Given $y<0$, we have
\begin{equation}
  (x>0\iff xy<0)\text{ and }(x<0\iff xy>0)
\end{equation}
\end{theorem}
\begin{proof}
Observe $x>0\implies x(-y)>0\implies -xy>0\implies xy<0$, and 
$x<0\implies (-x)(-y)>0\implies xy>0$. Clearly, $x=0\implies xy=0$. Then the Theorem follows. 
\end{proof}
\begin{theorem}
\label{1.2.4}
\textbf{(Multiply on both side)}  Given $y<z$, we have
\begin{equation}
  (x>0\iff xy<xz)\text{ and }(x<0\iff xy>xz)
\end{equation}
\end{theorem}
\begin{proof}
First observe $y<z\implies z-y>0$. Now observe $x>0\implies x(z-y)>0\implies xz-xy>0\implies xz>xy$. 
Observe  $x<0\implies x(z-y)<0\implies xz<xy$. Obviously $x=0\implies  xy=xz$. Then the Theorem follows.
\end{proof}
\begin{theorem}
\label{1.2.5}
  \textbf{(Squares are nonnegative)} $x\neq 0\implies x^2>0$
\end{theorem}
\begin{proof}
  If $x>0$, then $x^2>0$ follows from the axiom. If $x<0$, then $x^2>0$ follows from \myref{Theorem}{1.2.2}
\end{proof}

\begin{corollary}
\label{1.2.6}
$1>0$
\end{corollary}

\begin{theorem}
\label{1.2.7}
\textbf{(Inverse preserve positivity)} $(x>0\iff \frac{1}{x}>0)\text{ and }(x<0\iff \frac{1}{x}<0)$ 
\end{theorem}
\begin{proof}
If $x>0$ but $\frac{1}{x}<0$, then $1<0$. The same logic applies to  $\frac{1}{x}>0\implies x>0$. Because $\frac{1}{0}$ does not exist, the theorem follows.
\end{proof}
\fbox{\begin{minipage}{39em}
If we were to define $x^{-2}:=x^{-1}x^{-1}$, we must realize $0^{-1}$ does not exist and realize we have not yet prove some common inequalities concerning integer powers. Notice that the following inequalities require base to be positive.  
\end{minipage}}

\begin{definition}
\label{1.2.8}
\textbf{(Definition of Inverse)} For all nonzero $x$ and naturals $p$, we define $x^{-p}:=(x^{-1})^p$, and define $x^0:=1$ 
\end{definition}
\begin{theorem}
\label{1.2.9}
  
\textbf{(Inequality when base is fixed)} Given a positive $a$ and two integer  $x,y$ where  $x<y$, we have
\begin{equation}
\begin{cases}
  a^x<a^y\iff a>1\\
  a^x=a^y \iff a=1 \\
  a^x>a^y \iff 0<a<1  
\end{cases}
\end{equation}
\end{theorem}
\begin{proof}
By \myref{Theorem}{1.2.4}, observe $1<a\iff  1<a<a^2\iff   1<a<a^2<a^3\iff  \cdots  \iff  1<a<\cdots <a^{y-x}\iff  a^x<a^y$. If $a=1$, we know  $a^x=1=a^y$. Again by \myref{Theorem}{1.2.4}, observe $0<a<1\iff  a^2<a<1\iff  \cdots \iff  a^{y-x}<\cdots <1\iff  a^{y}<a^{x}$. 
\end{proof}
\begin{theorem}
\label{1.2.10}
\textbf{(Inequality when integer power is fixed)} Given $0<b<c$ and  $z\inz$, we have 
\begin{equation}
\begin{cases}
  b^z<c^z \iff 0<z\\
  b^z=c^z \iff 0=z\\
  b^z>c^z\iff 0>z
\end{cases}
\end{equation}
\end{theorem}
\begin{proof}
  If $z>0$, then by \myref{Theorem}{1.2.4}, observe $0<b<c\implies 0<b^2<bc<c^2\implies b^3<b^2c<bc^2<c^3\implies \cdots \implies b^z<c^z $. Obviously, $0=z\implies b^z=1=c^z$. If $z<0$, then $b^z=(\frac{1}{b})^{-z}$ and $c^z=(\frac{1}{c})^{-z}$ by definition. Observe $b<c\implies 1=\frac{1}{b}b<\frac{1}{b}c=\frac{c}{b}\implies \frac{1}{c}<\frac{1}{b}$. By the logic above, we deduce $c^z=(\frac{1}{c})^{-z}<(\frac{1}{b})^{-z}=b^z$. Then the Theorem follows. 
\end{proof}
\begin{theorem}
\label{1.2.11}
\textbf{(Positivity of integer power)} If $a>0$, then $\forall x\inz,a^x>0$. If  $a<0$, then  $a^x>0\iff 2|x$
\end{theorem}
\begin{proof}
The former result is a direct consequence of \myref{Axiom}{1.2.1} and \myref{Theorem}{1.2.7}. The latter result is a direct consequence of \myref{Theorem}{1.2.3} and \myref{Theorem}{1.2.5}  
\end{proof}
\fbox{\begin{minipage}{39em}

Notice that if the base is negative, the corresponding inequalities can all be deduced by the above theorems with a little effort, although the results are quite messy. \\

Now we prove some arithmetic properties concerning nonzero base, unlike the above inequalities concerning only positive base. Notice that those properties of natural power inherited by integer power can be proven inductively, and that the base $x$ can be any nonzero number.        
\end{minipage}}
\begin{theorem}  
\label{1.2.12}
 \textbf{(Arithmetic property of integer power)} For all nonzero $x$ and integers $p,q$, we have 
 \begin{equation}
x^{p+q}=x^px^{q}
\end{equation}
\end{theorem}
\begin{proof}
  If $p,q$ are both positive, the Theorem is proven by induction. If $p,q$ are both negative, observe $x^px^q=(x^{-1})^{-p}(x^{-1})^{-q}=(x^{-1})^{-(p+q)}=x^{p+q}$, where the last equality hold true because $p+q<0$. If $p>0>q\text{ and }p+q>0$, observe $x^px^q=x^p(x^{-1})^{-q}=x^{p-(-q)}=x^{p+q}$. If $p>0>q\text{ and }p+q<0$, observe $x^px^q=x^p(x^{-1})^{-q}=(x^{-1})^{-(q+p)}=x^{p+q}$, where the last equality hold true because $p+q<0.$ 
\end{proof}
\begin{theorem}
\label{1.2.13}
\textbf{(Arithmetic property of integer power)} For all nonzero $x$ and integers $p,q$, we have
\begin{equation}
  x^{pq}=(x^p)^q=(x^q)^p
\end{equation}
\end{theorem}
\begin{proof}
  If $p,q$ are both positive or if any of $p,q$ are zero, the proof is trivial. If $p<0<q$, observe $(x^p)^q=((x^{-1})^{-p})^q=(x^{-1})^{-pq}=x^{pq}$, where the last equality hold true because $pq<0$, and observe $(x^q)^p=((x^q)^{-1})^{-p}=((x^{-1})^{q})^{-p}=(x^{-1})^{-qp}=x^{qp}$, where the second equality hold true can be proven by induction.    
\end{proof}
\begin{theorem}
\label{1.2.14}
\textbf{(Arithmetic property of integer power)} For all nonzero $x,y$ and integer  $p$, we have
 \begin{equation}
x^py^p=(xy)^p
\end{equation}
\end{theorem}
\begin{proof}
If $p\geq 0$, the proof is trivial. If $p<0$, then $x^py^p=(x^{-1})^{-p}(y^{-1})^{-p}=(x^{-1}y^{-1})^{-p}=((xy)^{-1})^{-p}=(xy)^p$.
\end{proof}

\section{Real Numbers Field}
\fbox{\begin{minipage}{39em}
Although the title of this section is "Real Numbers Field", here, we will not construct the real numbers field, nor use any common property of real numbers. In fact, we will not even use the symbol $\R$ in this section, since we are merely proving theorems about an ordered field with least-upper-bound property. We don't know if there exists any ordered field with least-upper-property. Let's say there does; yet, we don't know if such structure is unique. Let's say it is unique; yet, we don't know if that structure have relation with $\R$. Here, we will use the symbol $\F$ to denote an ordered field with least-upper-bound property. One should realize that we can use algorithm to define a subset containing $1\inF$ that is isomorphic to $\N$, and thereby we abuse the notation to denote that subset $\N$. A subfield of $\F$ isomorphic to $\Q$ can also be defined after we define $\Z$, so we also thereby abuse the notation to denote that subfield  $\Q$.         
\end{minipage}}
\begin{theorem}
\label{1.3.1}
$\N$ is unbounded above.
\end{theorem}
\begin{proof}
 \As{$\N$ is bounded above}. Because $1>0$, we know $\sup \N -1<\sup \N$. Then $\sup \N -1$ is not an upper bound of $\N$. Arbitrarily pick any $m \inn$ greater than $\sup \N -1$. We see $m>\sup \N-1\implies m+1>\sup \N$, where $m+1\inn\tCaC$
\end{proof}
\begin{corollary}
\label{1.3.2}
Both $\Z\text{ and }\Q$ are unbounded both above and below.
\end{corollary}
\begin{corollary}
\label{1.3.3}
  
\textbf{(Divided by $1$)} Given any $x\inF$, there exists $n\inz$ such that $n\leq x<n+1$
\end{corollary}
\begin{proof}
If $x>0$, let $S=\set{n\inn: n>x}$. Notice $S=\varnothing$ implies $\N$ is bounded above by $x$, so $S$ is nonempty. Then by well-ordering principle, we know $\min S$ exists. We now show \vi{$\min S-1\leq x<\min S$}. Observe that $\min S\in S\implies x<\min S$. \As{$\min S-1>x$}. We immediately see $\min S-1\in S\tCaC\vdone$.\\

If $x<0$, let $S=\set{n\inn:n\geq -x}$. Again, $S=\varnothing$ implies $\N$ is bounded above by $-x$, so $S$ is nonempty. Then by well-ordering principle, we know $\min S$ exists. We now show \blue{$-\min S\leq x<-\min S+1$}. Observe that $\min S\inS\implies \min S\geq -x\implies x\geq -\min S$. \As{$-\min S+1\leq x$}. Then $\min S-1\geq -x>0$; thus $\min S-1\inS\tCaC\bdone$\\

If $x=0$, then we let $n=0$. 
\end{proof}
\begin{theorem}
\label{1.3.4}
\textbf{(Archimedean Property)} Given $x,y\inF\text{ and }0<x$, there exists $n\inn$ such that $nx>y$ 
\end{theorem}
\begin{proof}
 Because $\N$ is unbounded above, we know  $\frac{y}{x}$ can not be an upper bound of $\N$, so we know  $\exists n\inn,n>\frac{y}{x} $. Then because $x>0$, we can deduce $nx>y$.
\end{proof}
\begin{theorem}
\label{1.3.5}
\textbf{($\Q$ is dense in $\F$)} Given $x,y\inF\text{ and }x<y$, we know there exists $p \inq$ such that $x<p<y$
\end{theorem}
\begin{proof}
Every rational, positive or negative, can be expressed in the form $\frac{m}{n}$ for some integer $m$ and naturals $n$. We seek to find some integer $m$ and $n$ such that $x<\frac{m}{n}<y$. Notice that $x<\frac{m}{n}<y\iff nx<m<ny$. Because $m$ has to be an integer, we know for $nx<m<ny$ to hold true, we must first have $ny-nx>1$. Because $y-x>0$, by Archimedean Property, there exists $n\inn$ such that $ny-nx=n(y-x)>1$. By \hyperref[1.3.3]{Corollary 1.3.3}, we know there exists $m \inz$ such that $m\leq  ny<m+1$.\\

Notice $m=ny$ if and only if $ y\inq$. So we can split the proof into two cases.\\

\vi{Case 1: $y\inq$}\\

We see that the set $\set{r\inq:r<y}$ have supremum $y$, since $y\inq$. Then $x<y$ tell us $x$ is not an upper bound of the set, then we can pick some rational $r$ in the set greater than $x$, so $x<r<y\vdone$.\\

\blue{Case 2: $y\not\inq$}\\ 

We know $m<ny<m+1$. $ny<m+1$ tell us $nx<ny-1<m$, so $nx<m<ny\bdone$ 
\end{proof}
\begin{theorem}
\label{1.3.6}
\textbf{(Positive root of power uniquely exists)} For all natural $n$ and $y>0$, there exists a unique positive $x$ such that $x^n=y$
\end{theorem}
\begin{proof}
By \hyperref[1.2.10]{Theroem 1.2.10}, we know two different positive numbers $0<x<x'$ are different when raised to the power of $n$, being $0<x^n<(x')^{n}$, so if such positive power exists, it must be unique.\\

We have handled the uniqueness part of the proof. Denote $E:= \set{m \inF^+: m^n<y}\text{ and }x:=\sup E$. Now we do the existence part by proving \vi{$x$ exists} and  \blue{$x^n=y$}.\\

To show \vi{ $x=\sup \set{m \inF^+: m^n<y}$ exists}, we only have to show the set $\set{m \inF^+: m^n<y}$ is nonempty and bounded above. In other word, we wish to construct function $a\inF^+$ and $b$ of $y$ such that for all positive input $y>0$, we have $a^n<y$ and $(0<m^n<y\longrightarrow m<b)$. In the followings, the domain of $a$ and $b$ are only positives.\\

First we construct $a$. By \myref{Theorem}{1.2.9}, we know if $a<\min \set{1,y}$ , then $a^n<a<y$, so we construct $a$ such that $0<a<\min \set{1,y}$. Notice that $a$ must be positive because we are constructing a number in $E$, where $E$ contain only positives. Express $a$ in the form  $a=\frac{p}{q}$ where $p,q$ are both function of $y$. In the process of  construction, We must be careful to make sure $a$ exists for all positive $y$.\\

To satisfy $0<a$, we need only guarantee $p,q$ are always of the same sign for all positive $y$. If such $p,q$ exists, we can change both sign of  $p,q$ when they are negative, and get two positive function. So, we can just require $p,q$ to be positive for all positive $y$.\\      

To satisfy $a<1$, observe $a<1\iff \frac{p}{q}<1\iff p<q$. The easiest construction is to let $q=p+c$ where $c$ is positive.\\

To satisfy $a<y$, observe $a<y\iff \frac{p}{q}<y\iff p(y-1)+cy=qy-p>0$. The easiest construction is to let $p(y-1)+cy=y^2$, which is possible, if we let $p=y$ and $c=1$. In this case $p=y>0$ and $q=y+1>0$, and  $a=\frac{y}{y+1}$. We finished proving $E$ is nonempty. \textbf{(Notice $c=y^2,p=y^3,q=y^3+y^2,a=\frac{y^3}{y^3+y^2}$ also do the trick)}\\

Now we construct $b$. By \myref{Theorem}{1.2.10}, we know if $0<b\text{ and }0<m^n<b^n$, then $m<b$, so we construct $b$ such that $y<b^n$ which lead to $0<m^n<y<b^n$ if  $m^n<y$. Because $y>0$, this is fairly easy. Simply let $b=y+1$, so we have $b>1\text{ and }b>y$; thus by \myref{Theorem}{1.2.9}, we have $b^n>b>y$, finishing proving $E$ is bounded above, where  $b=y+1$ is an upper bound. $\vdone$ \\

To show \blue{$x^n=y$}, we show $x^n\geq y$ and $x^n\leq y$. We will assume that $x^n<y$ or $x^n>y$, but before we do such, let's see what property from which can we possibly draw contradiction. Notice that because we just prove the existence of the supremum of $E$, we haven't use the fact that $x=\sup E$ in anywhere of our proof. We know
\begin{equation}
x=\sup E\iff \forall d>0,
\begin{cases}
x+d\not\in E\text{ ($x$ is an upper bound) }\\
\text{ and }\\
x-d \text{ is not an upper bound of $E$ (the \emph{least} upper bound)}
\end{cases}    
\end{equation}
So, you see, we wish to construct  a small and positive $h\text{ and }k$ such that if we assume $x^n<y\text{ or }x^n>y$ we can draw $x+h\in E$ or $x-k$ is an upper bound of $E$. \textbf{(We are going to assume $\sup E$ is smaller or greater than $\sqrt[n]{y}$)} \\

Observe $x+h\inE\iff (x+h)^n<y\iff (x+h)^n-x^n<y-x^n$, and observe $x-k$ is an upper bound of $E\iff (m^n<y\longrightarrow m<x-k)\iff (m\geq x-k\longrightarrow m^n\geq y)\iff (m\geq x-k\longrightarrow x^n-m^n\leq x^n-y)$.\\

Notice that the act of  subtracting  $x^n$ at the both side of the inequality play an important role in our proof: not only does the act allow us to use the identity $a^n-b^n=(a-b)(a^{n-1}+a^{n-2}b+\cdots +b^{n-1})$, and the act also tell us between $x+h \in E\text{ and }x-k$ is an upper bound of $E$, which contradiction statement should we draw from $x^n>y$. If $y-x^n<0$, then  $y-x^n<0<(x+h)^n-x^n$, so we can not possibly draw $x+h\inE$ from $x^n>y$. \textbf{(If $\sup E>\sqrt[y]{n}$, then it is too big, we can find a smaller upper bound of $E$)}\\

\As{$x^n>y$}. We wish to construct positive $k$ such that \teal{$m\geq x-k \longrightarrow x^n-m^n\leq x^n-y$}, so we can draw the contradiction $x-k$ is an upper bound of $E$. \\ 

Notice that $m\geq x-k\implies x^n-m^n\leq x^n-(x-k)^n$, so if $x^n-(x-k)^n\leq x^n-y$, our proof at this part is finished. Now our job is to single out the $k$ in the inequality to give an condition such that $x^n-(x-k)^n\leq x^n-y$ hold if the condition hold. It is easy to see that computing the polynomial of $k$ on left hand side of inequality and to prove such positive $k$ exists for all $n$ is almost impossible. Thus, we take a possible but actually non-existing risk in our next step of the proof. Use the $a^n-b^n$ identity and that $x-k<x$ to deduce
\begin{equation}
x^n-(x-k)^n=k(x^{n-1}+x^{n-2}(x-k)+\cdots +(x-k)^{n-1})\leq knx^{n-1}
\end{equation}
So, if we have $knx^{n-1}\leq x^n-y$, which is equivalent to $k\leq \frac{x^n-y}{nx^{n-1}}$, our proof is partially finished. Notice that $x^n-y>0\text{ and }nx^{n-1}>0$, so $\frac{x^n-y}{nx^{n-1}}>0$; thus the positive $k$ exists.  $\tdone\tCaC$\textbf{(The reason I use the word "possible risk" is that if we use an identity that show us $x^n-(x-k)^n$ smaller than a quantity greater than $x^n-y$, the proof can not be done.)} \\

\As{$x^n<y$}. We wish to construct positive $h$ such that \teal{$(x+h)^n-x^n<y-x^n$}, so we can draw the contradiction $x+h\in E$.\\

Again, we use the same identity to deduce
 \begin{equation}
   (x+h)^n-x^n=h((x+h)^{n-1}+(x+h)^{n-2}x+\cdots +x^{n-1})<hn(x+h)^{n-1}
\end{equation}
To single out the $h$ in the  $hn(x+h)^{n-1}$, notice that we can take the risk to add the constraint $h<1$ at the end of our construction to have $(x+h)^n-x^n<hn(x+h)^{n-1}<hn(x+1)^{n-1}$. Then, if we have $hn(x+1)^{n-1}<y-x^n$, which is equivalent to $h<\frac{y-x^n}{n(x+1)^{n-1}} $, our proof is finished. To sum up, any $h$ satisfy  $h<\min \set{1,\frac{y-x^n}{n(x+1)^{n-1}}}$ does the trick, and such $h$ exists, since  $0<\min \set{y-x^n,n(x+1)^{n-1}}$. $\tdone\tCaC\bdone$   
\end{proof}
\fbox{\begin{minipage}{39em}
If you want a proof with less of my commentary, here you go.
\end{minipage}}
\begin{proof}
  Observe $\min \set{1,\frac{y}{2}}\in E$ and $\max \set{1,y}$ is an upper bound of $E$, so $\sup E$ exists.  Denote $x:=\sup E$. \As{$x^n>y$}. Observe $x-k\text{ is an upper bound of $E$ }\iff m^n<y\longrightarrow m<x-k\iff m\geq x-k\longrightarrow m^n\geq y$. We know $(x-k)^n\geq y\iff x^n-(x-k)^n\leq x^n-y$, and know $x^n-(x-k)^n\leq knx^{n-1}$. If we let $0<k\leq \frac{x^n-y}{nx^{n-1}}$, then $x-k$ is an upper bound of  $E\tCaC.$ \As{$x^n<y$}. Observe $x+h\inE\iff (x+h)^n-x^n<y-x^n$. We know that $(x+h)^n-x^n<hn(x+h)^{n-1}$ and that if $h<1$, we have  $hn(x+h)^{n-1}<hn(x+1)^{n-1}$. So we let  $h=\min \set{1,\frac{y-x^n}{n(x+1)^{n-1}}}$, and we can see $x+h\inE\tCaC$. 
\end{proof}
\begin{definition}
\label{1.3.7}
The number $x$ in \hyperref[1.3.6]{Theorem 1.3.6} is written  $x=\sqrt[n]{y}$ or $x=y^{\frac{1}{n}}$.
\end{definition}
\fbox{\begin{minipage}{39em}
The above theorem is by far the trickiest we have seen. Often the theorem is proven only in special case $\sqrt{2}$ as a classical example in the first class of analysis. Here, we prove a general result. The following theorem is to make sure the definition of rational power make sense . In last section we prove some inequalities concerning integer power. Here, we prove those inequalities are inherited by rational power. Of course, the arithmetic properties of rational power, also inherited from those of integer power, will be proven after these inequalities.   \\ 


About the coverage of definition, notice that we didn't and won't define $y^{\frac{1}{n}}$ when $y$ is negative. Also, notice that for all nonzero rational $s$, we can define $0^s=0$. 
\end{minipage}}
\begin{theorem}
\label{1.3.8}
Given $m,p\inz\text{ and }n,q\inn\text{ and }a>0\text{ and }\frac{m}{n}=\frac{p}{q}$, we have 
\begin{equation}
(a^m)^{\frac{1}{n}}=(a^p)^{\frac{1}{q}}
\end{equation}
\end{theorem}
\begin{proof}
Observe
\begin{align}
  x&= (a^m)^{\frac{1}{n}}\\
  \liff x^n&=a^m\\
  \liff (x^n)^q&=(a^m)^q\\
\liff x^{nq}&= a^{mq}=a^{np} \rap{because $n,m,q\inz$}\\
  \liff (x^q)^n&=(a^p)^n \rap{again, because $n,p,q\inz$}\\
  \liff x^q&=a^p\rap{by \hyperref[1.3.6]{Theorem 1.3.6}}\\
  \liff x&=(a^p)^{\frac{1}{q}}\rap{by \hyperref[1.3.6]{Theroem 1.3.6}}\\
  \liff (a^m)^{\frac{1}{n}}&=x=(a^p)^{\frac{1}{q}} 
\end{align}
\end{proof}
\begin{definition}
\label{1.3.9}
\textbf{(Definition of Rational Powers)} Given a rational $r=\frac{p}{q}$, where $q\inn$. For all $a$, we define $a^r=(a^p)^{\frac{1}{q}}$
\end{definition}
\begin{theorem}
\label{1.3.10}
\textbf{(Inequality when base is fixed)} Given a positive $a$ and two rational  $x,y$ where  $x<y$, we have
 \begin{equation}
\begin{cases}
  a^x<a^y\iff a>1\\
  a^x=a^y\iff a=1\\
  a^x>a^y\iff 0<a<1
\end{cases}
\end{equation}
\end{theorem}
\begin{proof}
  Express $x,y$ in the form $x=\frac{q}{p},y=\frac{n}{m}$ where $q,n\inz\text{ and }m,p\inn$. Notice $x<y\implies \frac{q}{p}<\frac{n}{m}\implies mq<np$. Observe
  \begin{align}
    a^x<a^y &\implies a^{\frac{q}{p}}<a^{\frac{n}{m}}\\
  &\implies a^q=(a^{\frac{q}{p}})^p<(a^{\frac{n}{m}})^p\rap{by \myref{Theorem}{1.2.10}}\\
  &\implies a^{mq}=(a^q)^m<((a^{\frac{n}{m}})^p)^m=((a^{\frac{n}{m}})^m)^p=(a^n)^p=a^{np}\\
  &\implies a>1\rap{by \myref{Theorem}{1.2.9}} 
  \end{align}
  Notice that the above implication still hold true if $<$ is replaced by $>$ and $>$ is replaced by  $<$, and notice that the above implication still hold true if $<$ and  $>$ are all replaced by $=$, so we in fact have three implications. The Theorem follows from the three implication.
   
\end{proof}
\begin{theorem}
\label{1.3.11}
\textbf{(Inequality when rational power is fixed)} Given $0<b<c$ and  $z\inq$, we have
\begin{equation}
\begin{cases}
  b^z<c^z \iff 0<z\\
  b^z=c^z \iff 0=z\\
  b^z>c^z\iff 0>z
\end{cases}
\end{equation}
\end{theorem}
\begin{proof}
Express $z=\frac{q}{p}$, where $q$ is an integer and $p$ is a natural. Notice $q\text{ and }z$ are of the same sign. Observe by \myref{Theorem}{1.2.10}, we have $b^{\frac{q}{p}}<c^{\frac{q}{p}}\implies b^q=(b^{\frac{q}{p}})^p<(c^{\frac{q}{p}})^p=c^q\implies 0<q$.\\

  Notice that the above implication still hold true if $<$ is replaced by $>$ and $>$ is replaced by  $<$, and notice that the above implication still hold true if $<$ and  $>$ are all replaced by $=$, so we in fact have three implications. The Theorem follows from the three implication.
\end{proof}
\fbox{\begin{minipage}{39em}
Now we prove the arithmetic properties of rational power concerning only positive base. Notice there is no definition of a negative raised to the power of a rational. \red{From Here}
\end{minipage}}
\begin{theorem}
\label{1.3.12}
 \textbf{(Arithmetic property of rational power)} Given $r,s\inq\text{ and }a>0$, we have
\begin{equation}
a^{r+s}=a^ra^s
\end{equation}
\end{theorem}
\begin{proof}
Express $r,s$ in the form $r=\frac{p}{q},s=\frac{m}{n}$ where $q,n\inn\text{ and }p,m \inz$. Observe
\begin{align}
  (a^{r+s})^{nq}&=(a^{\frac{np+mq}{nq}})^{nq}\\
  &=a^{np+mq} 
\end{align}
Then observe
\begin{align}
  (a^ra^s)^{nq}&= (a^{\frac{p}{q}}a^{\frac{m}{n}})^{nq} \\
  &= (a^{\frac{p}{q}})^{nq}(a^{\frac{m}{n}})^{nq}\rap{by \myref{Theorem}{1.2.14}}\\
  &=((a^{\frac{p}{q}})^q)^n((a^{\frac{m}{n}})^n)^q\\
&=(a^p)^n(a^m)^q\\
&= a^{np+mq}=(a^{r+s})^{nq}\rap{\myref{Theorem}{1.2.12}\text{ and }\myref{Theorem}{1.2.13}} 
\end{align}
Then by \myref{Theorem}{1.3.6}, we can deduce $a^ra^s=a^{r+s}$ 
\end{proof}
\begin{theorem}
\label{1.3.13}
\textbf{(Arithmetic property of rational power)} Given $r,s\inq\text{ and }a>0$, we have
\begin{equation}
  (a^r)^s=a^{rs}
\end{equation}
\end{theorem}
\begin{proof}
Express $r,s$ in the form $r=\frac{p}{q},s=\frac{m}{n}$ where $q,n\inn\text{ and }p,m \inz$. Observe
\begin{align}
  (a^{rs})^{nq}&=(a^{\frac{mp}{nq}})^{nq}\\
  &= a^{mp}
\end{align}
Then observe
\begin{align}
  ((a^r)^s)^{nq}&=(((a^{\frac{p}{q}})^{\frac{m}{n}})^n)^q\\
  &=((a^{\frac{p}{q}})^m)^q\\
 &=(a^{\frac{p}{q}})^{mq}\\
  &=((a^{\frac{p}{q}})^q)^m \\
  &=(a^p)^m=a^{mp}=(a^{rs})^{nq}  
\end{align}
\end{proof}
\begin{corollary}
\label{1.3.14}
$a^{\frac{q}{p}}=(a^{\frac{1}{p}})^q$
\end{corollary}
\begin{theorem}
\label{1.3.15}
\textbf{(Arithmetic property of rational power)} Given $r\inq$ and $a,b>0$, we have
 \begin{equation}
a^rb^r=(ab)^r
\end{equation}
\end{theorem}
\begin{proof}
Express $r$ in the form  $r=\frac{q}{p}$, and observe $(a^rb^r)^p=(a^r)^p(b^r)^p=(a^{\frac{q}{p}})^p(b^{\frac{q}{p}})^p=a^qb^q=(ab)^q=((ab)^r)^p$. 
\end{proof}
\section{Irrational Power}
\fbox{\begin{minipage}{39em}
    After the rational power, we now try to define irrational power. In most of the textbooks, irrational power as a rigorous definition often come after the definition of Euler number, but here, we define the irrational power with a technique not so advanced and to be fair quite cumbersome compared to the approaches in most textbooks. Of course, the common inequalities and arithmetic properties of irrational power will be presented, although their order of presentation is different to how we present in the section before. 
\end{minipage}}
\begin{lemma}
\label{1.4.1}
For $b,x\inF$, define  $B(x):=\set{b^t:t\inq,t\leq x}$. Then for all $x\inF$, $b>1$ implies  $\sup B(x)$ exists, and $0<b\leq 1$ implies $\inf B(x)$ exists.
\end{lemma}
\begin{proof}
  For all $x$,  we know $B(x)$ is nonempty, since if not, $\Q$ is bounded below. Because $\Q$ is nonbounded above, we can pick a rational  $y$ greater than $x$. If $b>1$, we deduce  $\forall b^t\inB(x),b^t\leq b^y $; thus $b^y$ is an upper bound of  $B(x)$. If $0<b<1$, we deduce $\forall b^t\in B(x),b^y\leq b^t$; thus $b^y$ is an lower bound of $B(x)$. If $b=1$, just notice  $B(x)=\set{1}$.     
\end{proof}
\begin{definition}
\label{1.4.2}
\textbf{(Irrational Power Definition)} For all $b,x\inF$, define $B(x)$ as in \myref{Lemma}{1.4.1}, and for all $x\inF$, if $b>1$, define $b^x:=\sup B(x)$, and if $0<b\leq 1$, define $b^x:=\inf B(x)$ 
\end{definition}
\fbox{\begin{minipage}{39em}
The above definition is in fact not very appropriate, since we have already define $b^x$ where  $x\inq$. We don't know if the above definition is consistent with our old definition. The next theorem is to show it is.  
\end{minipage}}
\begin{theorem}
\label{1.4.3}
  \textbf{(Consistency of power definitions)} Given $r\inq$, if $b>1$, then  $b^r=\sup B(r)$, and if $b<1$, then  $b^r=\inf B(r)$
\end{theorem}
\begin{proof}
If $b>1$, deduce  $b^r=\max  B(r)=\sup B(r)$. If $b<1$, deduce $b^r=\min B(r)=\inf B(r)$.  
\end{proof}
\fbox{\begin{minipage}{39em}
Now, we are going to prove one common inequalities. The other will be proven after some work. 
\end{minipage}}


\begin{theorem}
\label{1.4.4}
\textbf{(Inequality when base is fixed)} Given a positive $b$ and $x<y$, we have
 \begin{equation}
\begin{cases}
  b^x<b^y\iff b>1\\
  b^x=b^y\iff b=1\\
  b^x>b^y\iff 0<b<1
\end{cases}
\end{equation}
\end{theorem}
\begin{proof}
  By \myref{Theorem}{1.3.5}, we can pick a rational $q$ such that  $x<q<y$. We have $b^q\in B(y)$. We now consider three possible situations.\\



  If $b>1$, then $b^q\leq \sup B(y)$. Because $\forall b^t\inB(x), t\leq x<q$, we can  deduce $\forall b^t\in B(x), b^t<b^q$; that is, $b^q$ is an upper bound of $B(x)$. Notice that there exists rational between $x<q$, so  $b^q$ can not be the least upper bound of  $B(x)$.  Then we can deduce $\sup B(x)< b^q\leq \sup B(y)$.\\

  If $b=1$, then  $b^x=1=b^y$.\\

  If  $b<1$, then $\inf B(y)\leq b^q$. Because $\forall b^t\in B(x), t\leq x<q$, we can deduce $\forall b^t\in B(x), b^t>b^q$ ; that is, $b^q$ is an lower bound of  $B(x)$. Notice that there exists rational between $x<q$, so  $b^q$ can not be the greatest lower bound of  $B(x)$. Then we can deduce $\inf B(y)\leq b^q< \inf B(x)$.\\

  The Theorem follows from the three implications of the three situation. 
\end{proof}

\begin{lemma}
\label{1.4.5}
Let $S,U$ and be two bounded above subset of  $\F$, containing only nonnegative numbers. Define $SU:=\set{su:s\inS,u\inU}$. We have    
\begin{equation}
\sup SU=\sup S \sup U 
\end{equation}
and have 
\begin{equation}
\inf SU=\inf S\inf U
\end{equation}
where the infimum part hold true even if $S,U$ are not bounded above 
\end{lemma}
\begin{proof}
Because $S,U$ contain only nonnegative numbers, we know $s\leq \sup S$ and $u\leq \sup U$ implies $su\leq \sup S \sup U$, so $\sup S \sup U$ is an upper bound of $SU$. Now we show \vi{$\sup S \sup U$ is the \textit{least} upper bound of $SU$}.\\

\As{there is an upper bound $x$ of $AB$ smaller than $\sup A \sup B$}. Express $x$ in the form  $x=\sup S \frac{x}{\sup S}$. Because $x<\sup S \sup U $, we know $\frac{x}{\sup S}<\sup U$, which implies there is a number  $u\inU$ greater than $\frac{x}{\sup S}$. Observe $u>\frac{x}{\sup S}\implies \frac{x}{u}<\sup S$, which implies that there is a number $s\in S$ greater than  $\frac{x}{u}$. Observe  $\frac{x}{u}<s\implies x<su \tCaC\vdone$\\ 

Clearly, we know $s\geq \inf  S$ and $u\geq \inf  U$ implies $su\geq \inf  S \inf  U$, so $\inf  S \inf  U$ is an lower bound of $SU$. Now we show \blue{$\sup S \sup U$ is the \textit{greatest} lower bound of $SU$}.\\

\As{there is an lower bound $x$ of $AB$ greater than $\sup A \sup B$}. Express $x$ in the form  $x=\inf  S \frac{x}{\inf  S}$. Because $x>\inf  S \inf  U $, we know $\frac{x}{\inf  S}>\inf  U$, which implies there is a number  $u\inU$ less than $\frac{x}{\inf  S}$. Observe $u<\frac{x}{\inf  S}\implies \frac{x}{u}>\inf  S$, which implies that there is a number $s\in S$ less than  $\frac{x}{u}$. Observe  $\frac{x}{u}>s\implies x>su \tCaC\bdone$  
\end{proof}

\begin{theorem}
\label{1.4.6}
\textbf{(Arithmetic property)} Given $r,s\inF$ and $0<a$, we have
\begin{equation}
  a^{r+s}=a^ra^s
\end{equation}
\end{theorem}

\begin{proof}  
We prove \vi{$A(r+s)=\set{xy:x\inA(r)\text{ and }y\inA(s)}$}. Denote the set on right side $E$. Observe that $xy\in E \implies \exists q\leq r\inq,x=a^q\text{ and }\exists m\leq s\inq,y=a^m\implies xy=a^{q+m} \text{ where $q+m\leq r+s$}\implies xy\in A(r+s)$. Then we know $E\subseteq A(r+s)$. Given $a^d\in A(r+s)$, we know $d\leq r+s$, so if we express $a^d=a^ra^{d-r}$, we are sure $a^{d-r}\in A(s)$ and $a^r\in A(r)$, which implies $a^d\in E$. Then we can deduce $A(r+s)\subseteq E$.$\vdone$\\

By \myref{Lemma}{1.4.5}, our proof is finished.
\end{proof}
\fbox{\begin{minipage}{39em}
Now, we introduce an idea to aid our proof of inequality.
\end{minipage}}
\begin{definition}
\label{1.4.7}
\textbf{(Definition of order homomorphism)} Let $S$ be an subset of  $\F$, the function  $\phi :S \rightarrow  \F $ is an \textit{order homomorphism}, if for all $a,b\in S$, we have 
\begin{equation}
  a<b\implies \phi (a)<\phi (b)
\end{equation}
Two subset $U,V$ are said to be  \textit{order isomorphic}, if there exists an bijective order homomorphism from one to another.
\end{definition}
\begin{lemma}
\label{1.4.8}
Let $S,U$ be two order isomorphic bounded above subset of  $\F$, containing only nonnegative numbers, where $\phi :S\rightarrow U$ is an order isomorphism. Let $US_\phi = \set{s\phi (s):s\in S}$. We have
\begin{equation}
\sup S \sup U= \sup US_\phi 
\end{equation}
and have
\begin{equation}
\inf S\inf U=\inf US_\phi 
\end{equation}
where the infimum part hold true even if $S,U$ are not bounded above.
\end{lemma}
\begin{proof}
For all $s\phi (s)$ in $US_\phi $, we know $0\leq s\leq \sup S$ and $0\leq \phi (s)\leq \sup U$, so we can deduce $s\phi (s)\leq \sup S\sup U$. We have proven that $\sup S\sup U$ is an upper bound of $US_\phi $. We now prove it is the least. \As{there exists an upper bound $x$ of $US_\phi $ smaller than $\sup S\sup U$}. Because $\frac{x}{\sup U}<\sup S$, we know there exists $s\inS$ such that $x<(\sup U)s$. Then because $\frac{x}{s}<\sup U$, we know there exists $\phi (s')\in U$ such that $x<s\phi (s')$. If $s<s'$, then we see  $x<s\phi (s')<s'\phi (s')\in US_\phi $. If $s>s'$, then we see  $x<s\phi (s')<s\phi (s)$. If $s=s'$, then we see $x<s\phi (s')=s\phi (s)\tCaC$\\


For all $s\phi (s)$ in $US_\phi $, we know $s\geq \inf  S$ and $ \phi (s)\geq \inf  U$, so we can deduce $s\phi (s)\geq \inf  S\inf  U$. We have proven that $\inf  S\inf  U$ is an lower bound of $US_\phi $. We now prove it is the greatest. \As{there exists an lower bound $x$ of $US_\phi $ greater than $\inf  S\inf  U$}. Because $\frac{x}{\inf  U}>\inf  S$, we know there exists $s\inS$ such that $x>(\inf  U)s$. Then because $\frac{x}{s}>\inf  U$, we know there exists $\phi (s')\in U$ such that $x>s\phi (s')$. If $s<s'$, then we see  $x>s\phi (s')>s\phi (s)\in US_\phi $. If $s>s'$, then we see  $x>s\phi (s')>s'\phi (s')$. If $s=s'$, then we see $x>s\phi (s')=s\phi (s)\tCaC$      
\end{proof}

\begin{theorem}
\label{1.4.9}
\textbf{(Arithmetic property)} Given $b,c>0$ and  $z\inF$, we have
\begin{equation}
b^zc^z=(bc)^z
\end{equation}
\end{theorem}
\begin{proof}
 From now, we will use $C(z)$ to denote $\set{c^u: u\inq, u\leq z}$. Define $\phi :B(z)\rightarrow C(z)$ as $b^t\mapsto c^t$. Observe that if $b,c$ are both greater than $1$, then  $b^t<b^m\implies t<m\implies c^t<c^m$, and that if $b,c$ are both less than $1$, then  $b^t<b^m\implies t>m\implies c^t<c^m$. So If $b,c$ are both greater than $1$ or both less than $1$,  then $\phi$ is an order isomorphism. Notice that $\set{(bc)^u:u\inq, u\leq z}=\set{b^t \phi(b^t):t\inq, t\leq z}=C(z)B(z)_\phi$. Then by \myref{Lemma}{1.4.8}, our proof is finished. We now show \vi{$(b^{-1})^zb^z=1$}.\\

WOLG, let $b<1$. Denote $H:=\set{b^t:t\inq,t\leq z},E:=\set{b^{-t}:t\inq,t\leq z}$, so $b^z=\inf H\text{ and }(b^{-1})^z=\sup E$. \As{$(\sup E)(\inf H)>1$}. Notice $\sup E>\frac{1}{\inf H}$ implies that there exists $t\leq z$ such that $b^{-t}>\frac{1}{\inf H}$, which leads to $\inf H>b^t\tCaC$. \As{$(\sup E)(\inf H)<1$}. Notice $\inf H<\frac{1}{\sup E}$ implies that there exists $t\leq z$ such that $b^{-t}<\frac{1}{\sup E}$, which leads to $\sup E<b^t\tCaC\vdone$\\     

 If $b<1<c$ and $bc>1$, observe that $(bc)^z(b^{-1})^z=c^z\implies (bc)^z=(bc)^z(b^{-1})^zb^z=b^zc^z$. If $b<1<c$ and  $bc<1$, observe that $(bc)^z(c^{-1})^z=b^z\implies (bc)^z=(bc)^z(c^{-1})^zc^z=b^zc^z $  
\end{proof}
\begin{theorem}
\label{1.4.10}
\textbf{(Inequality when power is fixed)} Given $0<b<c$ and  $z\inF$, we have
\begin{equation}
\begin{cases}
  b^z<c^z \iff 0<z\\
  b^z=c^z \iff 0=z\\
  b^z>c^z\iff 0>z
\end{cases}
\end{equation}
\end{theorem}
\begin{proof}
By \myref{Theorem}{1.4.4}, $z>0\implies (\frac{c}{b})^z>(\frac{c}{b})^0=1\implies c^z>b^z$, and $z=0\implies b^z=1=c^z$, and $z<0\implies (\frac{c}{b})^z<(\frac{c}{b})^0=1$ 
\end{proof}

\fbox{\begin{minipage}{39em}
Before the last arithmetic property, we first prove the existence of logarithm, which play an important role in the proof of last arithmetic property.
\end{minipage}}
\begin{theorem}
\label{1.4.11}
\textbf{(Existence of logarithm)} For all positive  $b,y$ where $b\neq 1$, there exists an unique  $x\inF $ such that $b^x=y$  
\end{theorem}
\begin{proof}
The uniqueness part have been handled by \myref{Theorem}{1.4.4}. Now we split the proof into two cases: \vi{$b>1$} and \blue{$b<1$}\\

Case 1: \vi{$b>1$}\\

Define $A:=\set{w:b^w<y}$ and $x=\sup A$.\\

We first prove the identity \teal{for all positive integer $m$ and  $c>1$, we have $c-1\geq (c^{\frac{1}{m}}-1)m$}\\

Let $d=c^{\frac{1}{m}}$, so we have $c-1=d^m-1=(d-1)(d^{m-1}+d^{m-1}+\cdots +1)\geq (d-1)m=(c^{\frac{1}{m}}-1)m\tdone$\\


\As{$b^x>y$}. Let $t=\frac{b^x}{y}$ and $\frac{b-1}{t-1}<n=m$ and $b=c$ to use the identity, so we have  $b-1\geq n(b^{\frac{1}{n}}-1)$. Then we have $\frac{b-1}{n}\geq b^{\frac{1}{n}}-1$. Notice that $b^x>y\implies t-1>0$, so because $n>\frac{b-1}{t-1}$, we then have $t-1>\frac{b-1}{n}\geq b^{\frac{1}{n}}-1$, which implies $t> b^{\frac{1}{n}}$.\\

 Observe $b^{x-\frac{1}{n}}=\frac{b^x}{b^{\frac{1}{n}}}>\frac{b^x}{t}=y$. Then $x-\frac{1}{n}$ is an upper bound of $A\tCaC$.\\


\As{$b^x<y$}. Let $t=\frac{y}{b^x}$ and let $\frac{b-1}{t-1}<n=m$ and $b=c$ to use the identity, so we have  $b-1\geq n(b^{\frac{1}{n}}-1)$. Then we have $\frac{b-1}{n}\geq b^{\frac{1}{n}}-1$. Notice that $b^x<y\implies t-1>0$, so because $n>\frac{b-1}{t-1}$, we then have $t-1>\frac{b-1}{n}\geq b^{\frac{1}{n}}-1$, which implies $t>b^{\frac{1}{n}}$.\\

Observe $b^{x+\frac{1}{n}}=b^xb^{\frac{1}{n}}<b^xt=y$. Then $x+\frac{1}{n}\inA\tCaC\vdone$\\

Case 2: \blue{$b<1$}\\

Define $B:=\set{w:b^w<y}$ and $x:=\inf B$.\\

We first prove the identity \teal{for all positive integer $m$ and $0<c<1$, we have  $c-1\leq (c^{\frac{1}{m}}-1)m$}\\

Let $d=c^{\frac{1}{m}}$, so we have $c-1=d^m-1=(d-1)(d^{m-1}+d^{m-2}+\cdots +1)\leq (d-1)m=(c^{\frac{1}{m}}-1)m\tdone$.\\

\As{$b^x>y$}. Let $t=\frac{y}{b^x}$ and $\frac{b-1}{t-1}<n=m\text{ and }b=c$ to use the identity, so we have $b-1\leq (b^{\frac{1}{n}}-1)n$. Then we have $\frac{b-1}{n}\leq b^{\frac{1}{n}}-1$. Notice that $b^x>y\implies t-1<0$, so because $n>\frac{b-1}{t-1}$, we then have $t-1<\frac{b-1}{n}\leq b^{\frac{1}{n}}-1$, which implies $t<b^{\frac{1}{n}}$.\\

Observe $b^{x+\frac{1}{n}}=b^xb^{\frac{1}{n}}>b^xt=y$. Then $x+\frac{1}{n}$ is an lower bound of $B\tCaC$.\\

\As{$b^x<y$}. Let $t=\frac{b^x}{y}\text{ and }\frac{b-1}{t-1}<n=m\text{ and }b=c$ to use the identity, so we have $b-1\leq (b^{\frac{1}{n}}-1)n$. Then we have $\frac{b-1}{n}\leq b^{\frac{1}{n}}-1$. Notice that $b^x<y\implies t-1<0$, so because $n>\frac{b-1}{t-1}$, we then have $t-1<\frac{b-1}{n}\leq b^{\frac{1}{n}}-1$, which implies $t<b^{\frac{1}{n}}$.\\

Observe $b^{x-\frac{1}{n}}=\frac{b^x}{b^{\frac{1}{n}}}<\frac{b^x}{t}=y$. Then $x-\frac{1}{n}\inB\tCaC\bdone$
\end{proof}
\begin{definition}
\label{1.4.12}
\textbf{(Definition of logarithm)} Define $\log_b y:=x$, where $x,b,y$ are in \myref{Theorem}{1.4.11}.
\end{definition}
\begin{lemma}
\label{1.4.13}
Given $0<x<rs$ and $0<r$ and  $0<s$, there exist positive rational $u<s$ and positive rational $t<r$ such that   $x<tu<rs$. 
\end{lemma}
\begin{proof}
  $0<x<rs \implies \frac{x}{s}<r$. Then there exists rational $t$ such that  $\frac{x}{s}<t<r$, which implies $\frac{x}{t}<s$. Then there exists rational $u$ such that $\frac{x}{t}<u<s$. Then $x<tu<rs$.
\end{proof}
\begin{theorem}
\label{1.4.14}
\textbf{(Arithmetic property)} Given $r,s\inF\text{ and }a>0$, we have
\begin{equation}
  (a^r)^s=a^{rs}
\end{equation}
\end{theorem}
\begin{proof}
  The proof is very very long. We first denote three important sets:
\begin{equation}
T:=\set{a^t:t\inq,t\leq r}
\end{equation}
\begin{equation}
U:=\set{(a^r)^u:u\inq,u\leq s}
\end{equation}
\begin{equation}
X:=\set{a^x:x\inq,x\leq rs}
\end{equation}

  So, we have 
\begin{equation}
a^r=(\sup \text{ or }\inf )T
\end{equation}
\begin{equation}
(a^r)^s=(\sup \text{ or }\inf )U
\end{equation}
\begin{equation}
a^{rs}=(\sup \text{ or }\inf )X
\end{equation}
Notice that from now, when variables $t,u,x$ and their variants $t',u',x'$ are mentioned, they are rational and respectively less than or equal to $r,s,rs$. \\



  Now, we split the proof into sixteen cases: $a$ may be smaller or greater than $1$; $r,rs$ may be positive or negative; $rs$ is rational or irrational. \\



  We first do all 8 cases of $rs\not\inq$. Notice that $rs\not\inq\implies x<rs$.\\  


  The easiest case first:  \vi{$a>1\text{ and }r>0\text{ and }s>0\text{ and }rs\not\inq$}.\\

  \As{$a^{rs}>(a^r)^s$}; that is, $\sup X>\sup U$. Then $\exists x,\forall u,a^x>(a^r)^u=(\sup T)^u$.  Let $u>0$, so we have $\forall t, a^{\frac{x}{u}}>a^t$. By \myref{Lemma}{1.4.13} \CaC. \As{$a^{rs}<(a^r)^s$}; that is, $\sup X<\sup U$. Then $\exists u,\forall x,(\sup T)^u=(a^r)^u>a^x$. Because $a^r>1$, we know $u>0$, since $u<0\implies (a^r)^u<1$. Then we have  $\exists u,\forall x,\sup T>a^{\frac{x}{u}}$, so we have $\exists u,\forall x,\exists t,a^t>a^{\frac{x}{u}}$. But we see that for all $u$, we can let  $x>ru$, so $a^{\frac{x}{u}}>a^r.\tCaC\vdone$   \\



  The second case: \blue{$a>1\text{ and }r>0\text{ and }s<0\text{ and }rs\not\inq$}.\\

  \As{$a^{rs}>(a^r)^s$}; that is, $\sup X>\sup U$. Then $\exists x,\forall u, a^x>(a^r)^u=(\sup T)^u$. Because $u\leq s<0$, we have $\exists x,\forall u,a^{\frac{x}{u}}<\sup T$. Then, we have $\exists x,\forall u,\exists t,a^{\frac{x}{u}}<a^t$. Express $x=rm$, and let $0>s>u>m$, so we have  $\frac{x}{u}=\frac{rm}{u}>r\tCaC$. \As{$a^{rs}<(a^r)^s$}; that is, $\sup X<\sup U$. Then $\exists u,\forall x,a^x<(a^r)^u=(\sup T)^u$. Because $u\leq s<0$, we have $\exists u,\forall x, a^{\frac{x}{u}}>\sup T$. Then, we have $\exists u,\forall x,\forall t, a^{\frac{x}{u}}>a^t$. If $s\not\inq$, then we notice that because $u<s<0$, we have $r(\frac{s}{u})<r$. Pick $t$ such that $r(\frac{s}{u})<t<r$, so we have $rs>tu$. Then pick $x$ such that $0>rs>x>tu$, and observe $a^{\frac{x}{u}}<a^t\tCaC$. If $s\inq$, then it is possible to happen $u=s$. Then $a^{\frac{x}{u}}=a^{\frac{x}{s}}>a^{\frac{rs}{s}}=a^r\geq a^t\tCaC\bdone$  \\



  \\




The third case: \vi{$a>1\text{ and }r<0\text{ and }s>0\text{ and }rs\not\inq$}\\

\As{$a^{rs}>(a^r)^s$}; that is, $\sup X>\inf  U$. Then $\exists x,\exists u,a^x>(a^r)^u=(\sup T)^u $. Notice that $u\leq 0\implies (a^r)^u\geq 1>a^x$, so $u$ must be positive. Then we have $\exists x,\exists u,a^{\frac{x}{u}}>\sup T$. Then, we have $\exists x,\exists u,\forall t,a^{\frac{x}{u}}>a^t$. Notice that $\frac{x}{u}<\frac{rs}{u}<r$, so there  exists $t$ such that  $a^{\frac{x}{u}}<a^t\tCaC.$ \As{$a^{rs}<(a^r)^s$}; that is, $\sup X<\inf U$. Let $\sup X<m<\inf U$, and let $n=\log_a m$, so $a^{rs}<a^n<\inf  U$. Pick a rational $k$ so that  $a^{rs}<a^k<a^n<\inf U$. Then we know for all positive $u$, we have $a^{\frac{k}{u}}<a^r=\sup T$. This give us $\forall u>0,\exists t,a^k<a^{tu}$. Because $rs<k$, we know  $s>\frac{k}{r}$. Let $s>u'>\frac{k}{r}$. Then we see $\forall t,u't<u'r<k\tCaC\vdone$\\

The forth case: \blue{$a>1\text{ and }r<0\text{ and }s<0\text{ and }rs\not\inq$}\\

\As{$a^{rs}>(a^r)^s$}; that is, $\sup X>\inf U$. Then $\exists x,\exists u,a^x>(a^r)^u$. Because $u\leq s<0$, we have $\exists x,\exists u, a^{\frac{x}{u}}<a^r=\sup T$. Then $\exists x,\exists u,\exists t, a^x>a^{tu}$. Observe $tu\geq ru\geq rs>x\tCaC$. \As{$a^{rs}<(a^r)^s$}; that is, $\sup X<\inf U$. Let $\sup X<m<\inf U$, and let $n=\log_a m$, so $a^{rs}<a^n<\inf  U$. Pick a rational $k$ so that  $a^{rs}<a^k<a^n<\inf U$. Then, $\forall u, a^{\frac{k}{u}}>a^r=\sup T$. This implies $\forall u,\forall t,a^k<a^{tu}$. Because $rs<k$, we know  $s>\frac{k}{r}$. Let $s>u'>\frac{k}{r}$. Then $u'r<k$, which implies $r>\frac{k}{u'}$. Let $r>t'>\frac{k}{u'}$. Then we see $t'u'<k\tCaC\bdone$\\

The next four cases where $a<1$ use the same logic, and  reference to \myref{Theorem}{1.4.9}.\\

The forth to eighth cases:  \vi{$a<1\text{ and }rs\not\inq$}\\

By the above four cases, we know $((\frac{1}{a})^r)^s=(\frac{1}{a})^{rs}$. Observe $a^{rs}(\frac{1}{a})^{rs}=1^{rs}=1$, and observe $(a^r)^s((\frac{1}{a})^r)^s=(a^r(\frac{1}{a})^r)^s=((1)^r)^s=1\vdone$.\\

The final eight cases:  \blue{$rs\inq$}\\

If $r,s$ are both rational, the proof reference to \myref{Theorem}{1.3.13}. Notice that if only one of $r,s$ is rational, then  $rs$ is irrational, so we can assume  $r,s$ are both irrational. Observe by the eight cases above, $(a^{rs})^{\frac{1}{s}}=a^r$, so by \myref{Definition}{1.3.9}, $(a^r)^s=((a^{rs})^{\frac{1}{s}})^s=a^{rs}\bdone$\\

Notice that outside of the sixteen cases above, if $a=1\text{ or }s=0\text{ or }s=0$, the proof is trivial.

\end{proof}
\section{Euclidean Space}
\fbox{\begin{minipage}{39em}
In this section, we will use the notion of vector space to define Euclidean space, so we will first prove a simple and fundamental theorem about vector space. 
\end{minipage}}
\begin{theorem}
\label{1.5.1}
Let $V$ be a vector space over arbitrary filed $\F$ and of dimension $n$. We have that  $V$ is isomorphic to  $\F^n$  
\end{theorem}
\begin{proof}
For people who don't know, $\F^n$ in most textbooks is defined as a vector space consisting of $n$-tuples, and $n$-tuples can be defined as follows for any natural $n$.\\

 \begin{gather}
   (c,d):=\set{\set{c},\set{c,d}}\\
   (b,c,d):=(b,(c,d))=\set{\set{b},\set{b,(c,d)}}=\set{\set{b},\set{b,\set{\set{c},\set{c,d}}}}\\
   (a,b,c,d):=(a,(b,c,d))=\cdots 
\end{gather}


  Let $\set{v_1,\dots,v_n}$ be a basis for $V$, and define $\phi: \set{v_1,\dots ,v_n} \rightarrow \F^n$ by $c_1v_1+\cdots+c_nv_n\mapsto (c_1,\dots,c_n)$. Notice that $\phi$ can verified to be linear and bijective by using the theorem that every vector in $V$ can be uniquely expressed as a linear combination of  $v_1,\dots ,v_n$.  
\end{proof}
\fbox{\begin{minipage}{39em}
Notice that the existence and uniqueness of real numbers field will be handled in Section 1.7,1.8,1.9, and from now on, let's just pretend that there exists an unique completed ordered field, which we call Real Numbers Field and denote $\R$.\\


In this section, we will introduce the definition of Euclidean space and Cauchy-Schwarz inequality in Euclidean space. 
\end{minipage}}
\begin{definition}
\label{1.5.2}
\textbf{(Definition of absolute value)} Let $x\inR$. We define the absolute value $\abso{x}$ of $x$ by
\begin{equation}
\abso{x}:=\begin{cases}
  x & \text{ if $x>0$ }\\
  -x& \text{ if $x\leq 0$  }
\end{cases} 
\end{equation}
\end{definition}
\begin{theorem}
\label{1.5.3}
$\forall x\inr,\abso{x}=\sqrt{x^2} $
\end{theorem}
\begin{proof}
If $x>0$, then  $\abso{x}>0\text{ and }\abso{x}^2=x^2$. If $x\leq 0$, then $\abso{x}\geq 0\text{ and }\abso{x}^2=(-x)^2=x^2$. 
\end{proof}
\begin{definition}
\label{1.5.4}
\textbf{(Definition of $L_p$ norm, or, $p$-norm)} Let $p\geq 1\inR$, and let $\vecta{x}\inr^n$
\begin{equation}
\norm{\vecta{x}}_p:=(\sum_{i=1}^{n}\abso{x_i}^p)^{\frac{1}{p}} 
\end{equation}
\end{definition}
\begin{definition}
\label{1.5.5}
\textbf{(Definition of Euclidean $n$-space)}
When we use the word \textit{Euclidean $n$-Space}, we mean $\R^n$ as a vector space equipped with a function $\gen{\cdot,\cdot}:\R^n\times\R^n\rightarrow \R$ called \textin{Euclidean inner product} defined by
\begin{equation}
\gen{\vecta{x},\vecta{y}}:=\sum_{i=1}^{n}x_iy_i
\end{equation}
and equipped with $2$-norm
\begin{equation}
\norm{\vecta{x}}:=\norm{\vecta{x}}_2=(\sum_{i=1}^{n}\abso{x_i}^2)^{\frac{1}{2}} 
\end{equation}

$2$-norm is also called \textit{Euclidean norm}  or  $L_2$ norm. Most time we use the notation $\vecta{x}\cdot\vecta{y}$ in place of $\gen{\vecta{x},\vecta{y}}$  and the notation $\abso{\vecta{x}}$ in place of $\norm{\vecta{x}}$, for abbreviation. Notice that by \myref{Theorem}{1.5.3}, when $\vecta{x}=(x_1)\inr^1$, we have $\abso{\vecta{x}}=\abso{x_1}$, so we don't have to worry about the compatibility of abbreviation.  Lastly, we can use \myref{Theorem}{1.5.3}, to verify $\abso{\vecta{x}}=(\vecta{x}\cdot\vecta{x})^{\frac{1}{2}}$ in Euclidean Space. 
\end{definition}
\fbox{\begin{minipage}{39em}
Although the common usage of notation $\R^n$ only refer to the set without any structure, but from now, we will use $\R^n$ to denote Euclidean  $n$-space.\\

Notice that Euclidean 3-space is a great tool to describe the physical world, and the idea of Euclidean norm and Euclidean inner product captures the essence of length and angle really well as we will explain in later section and chapter.\\

Lastly, we close this section with a proof of Cauchy-Schwarz inequality in Euclidean space, and leave some important properties of Euclidean norm and Euclidean inner product to next section.  
\end{minipage}}
\begin{theorem}
\label{1.5.6}
\textbf{(Special Case of Schwarz inequality)}  Let  $\vecta{x},\vecta{y}\inR^n$. We have  
 \begin{equation}
\abso{\vecta{x}}\abso{\vecta{y}}\geq \abso{\vecta{x}\cdot \vecta{y}}
\end{equation}
The equality hold only if $\exists \ld\inr, \vecta{x}=\ld\vecta{y}$
\end{theorem}
\begin{proof}
Let $f(t)=\sum_{i=1}^{n}(x_it-y_i)^2$, so we have
\begin{align}
f(t)&=\sum (x_it-y_i)^2\\
&=\sum x_i^2t^2-2x_iy_it+y_i^2 \\
&=t^2\sum x_i^2 -2t\sum x_iy_i+\sum y_i^2\\
&=\abso{\vecta{x}}^2t^2-2(\vecta{x}\cdot\vecta{y})t+\abso{\vecta{y}}^2
\end{align}
$f(t)$ is an nonnegative quadratic polynomial of $t$, since $f(t)$ is a sum of squares. Then $D(f)\leq 0$; that is $4(\vecta{x}\cdot\vecta{y})^2-4\abso{\vecta{x}}^2\abso{\vecta{y}}^2\leq 0$, which implies $(\vecta{x}\cdot\vecta{y})^2\leq \abso{\vecta{x}}^2\abso{\vecta{y}}^2$, and further implies $\abso{\vecta{x}\cdot \vecta{y}}\leq \abso{\vecta{x}}\abso{\vecta{y}}$     \\

If $\abso{\vecta{x}}\abso{\vecta{y}}=\abso{\vecta{x}\cdot\vecta{y}}$, Then $D(f)=0$, that is, there exists a unique $t'\inr$ such that $f(t')=0$. Then we see $0=f(t')=\sum (x_it'-y_i)^2$, which implies $\forall i, y_i=x_it'$
\end{proof}
\renewcommand{\inC}{\in\C}
\section{Complex Numbers}
\begin{theorem}
\label{1.6.1}
If we define vector multiplication in $\R^2$  as
 \begin{equation}
 \vecta{xy}=(x_1y_1-x_2y_2,x_1y_2+x_2y_1)
\end{equation}\\
, then $\R^2$ become a field.
\end{theorem}
\begin{proof}
The whole proof is long and tedious, here we only present some that are worth mentioning.\\
\begin{equation}
\vecta{y}\vecta{x}=(y_1x_1-y_2x_2,y_1x_2+y_2x_1)=(x_1y_1-x_2y_2,x_1y_2+x_2y_1)=\vecta{x}\vecta{y}
\end{equation}
\begin{align}
  (\vecta{x}\vecta{y})\vecta{z}&=(x_1y_1-x_2y_2,x_1y_2+x_2y_1)(z_1,z_2)\\
  &=(x_1y_1z_1-x_2y_2z_1-x_1y_2z_2-x_2y_1z_2,x_1y_1z_2-x_2y_2z_2+x_1y_2z_1+x_2y_1z_1)\\
  &=(x_1(y_1z_1-y_2z_2)-x_2(y_2z_1+y_1z_2),x_1(y_1z_2+y_2z_2)+x_2(y_1z_1-y_2z_2))\\
  &=(x_1,x_2)(y_1z_1-y_2z_2,y_1z_2+y_2z_1)=\vecta{x}(\vecta{y}\vecta{z})
\end{align}
\begin{equation}
  (1,0)\vecta{x}=(1,0)(x_1,x_2)=(x_1,x_2)\text{ and }\vecta{x}(1,0)=(x_1,x_2)(1,0)=(x_1,x_2)
\end{equation}
\begin{align}
\vecta{x}(\frac{x_1}{x_1^2+x_2^2},\frac{-x_2}{x_1^2+x_2^2})&=(\frac{x_1^2+x_2^2}{x_1^2+x_2^2},\frac{-x_1x_2+x_1x_2}{x_1^2+x_2^2})\\
&=(1,0)
\end{align}
\begin{align}
\vecta{x}(\vecta{y}+\vecta{z})&=(x_1,x_2)(y_1+z_1,y_2+z_2)\\
&=(x_1y_1+x_1z_1-x_2y_2-x_2z_2,x_2y_1+x_2z_1+x_1y_2+x_1z_2)\\
&=(x_1y_1-x_2y_2,x_1y_2+x_2y_1)+(x_1z_1-x_2z_2,x_2z_1+x_1z_2)\\
&=\vecta{xy}+\vecta{xz}
\end{align}
\end{proof}
\fbox{\begin{minipage}{39em}
The fact that the field in \myref{Theorem}{1.6.1} is isomorphic to the customary  $\C$ can be easily verified by checking $(a,b)\mapsto a+bi$ is field isomorphism. We now define $\C$ in this way. Notice that this definition is an abuse of notation, since in this way, $\R\not\in\C$. The motivation behind this definition is to emphasize the geometric nature of $\C$.      
\end{minipage}}
\begin{definition}
\label{1.6.2}
\textbf{(Definition of Complex Numbers)} We define $\C$ as the field in  \myref{Theorem}{1.6.1}. We write $(a,b)$ as $a+bi$ and $(a,-b)$ as $a-bi$. We define $\text{Re}(a+bi):=a$ and $\text{Im}(a+bi):=b$. We say the real part of  $a+bi$ is  $a$ and the imaginary part of  $a+bi$ is  $b$. We define the absolute of value of complex number as its length when it is treated as a vector in complex plane, which in our definition is a Euclidean space. Precisely, we define $\abso{a+bi}:=(a^2+b^2)^{\frac{1}{2}}=\abso{(a,b)}$. Moreover, we define the conjugate as  $\overline{a+bi}=a-bi$. We abuse the notation so that $a+0i\inr\subseteq\C$. 
\end{definition}
\begin{theorem}
\label{1.6.3}
Let $z,w\inC$. We have
\begin{equation}
\overline{(\overline{z})}=z
\end{equation}
\begin{equation}
\overline{z+w}=\overline{z}+\overline{w} 
\end{equation}
\begin{equation}
\overline{zw}=(\overline{z})(\overline{w})
\end{equation}
\begin{equation}
  \overline{z^n}=(\overline{z})^n
\end{equation}
\begin{equation}
z+\overline{z}=2\text{Re}(z)\text{ and }z-\overline{z}=2i\text{Im}(z)
\end{equation}
\begin{equation}
\abso{\overline{z}}=\abso{z}
\end{equation}
\begin{equation}
\abso{zw}=\abso{z}\abso{w}
\end{equation}
\begin{equation}
\abso{z^n}=\abso{z}^n
\end{equation}
\end{theorem}
\begin{proof}
We prove only the following. Let $z=z_1+z_2i$ and $w=w_1+w_2i$. We have
 \begin{align}
   \overline{(\overline{z})(\overline{w})}&=\overline{(z_1-z_2i)(w_1-w_2i)}\\
   &=\overline{z_1w_1-z_2w_2-(z_2w_1+z_1w_2)i}\\
   &=z_1w_1-z_2w_2+(z_2w_1+z_1w_2)i\\
   &=zw
\end{align}
\begin{equation}
\abso{\overline{z}}=(z_1^2+(-z_2)^2)^{\frac{1}{2}}=(z_1^2+z_2^2)^{\frac{1}{2}}=\abso{z}
\end{equation}
\begin{align}
\abso{zw}&=\abso{z_1w_1-z_2w_2+(z_2w_1+z_1w_2)i}\\
&=[(z_1w_1-z_2w_2)^2+(z_2w_1+z_1w_2)^2]^{\frac{1}{2}}\\
&=[(z_1w_1)^2+(z_2w_2)^2-2z_1z_2w_1w_2+(z_2w_1)^2+(z_1w_2)^2+2z_1z_2w_1w_2]^{\frac{1}{2}}\\
&=[z_1^2w_1^2+z_2^2w_1^2+z_1^2w_2^2+z_2^2w_2^2]^{\frac{1}{2}}\\
&=[(z_1^2+z_2^2)(w_1^2+w_2^2)]^{\frac{1}{2}}=(z_1^2+z_2^2)^{\frac{1}{2}}(w_1^2+w_2^2)^{\frac{1}{2}}=\abso{z}\abso{w}
\end{align}
\end{proof}
\fbox{\begin{minipage}{39em}
In last section we define the Euclidean norm. Here, we give the axioms for norm function and verify that Euclidean norm satisfy all of them. Notice that the four axioms of norm function each describe a property of length in Euclidean space, which is so "obviously true" if we use a non-rigorous approach in geometry. 
\end{minipage}}
\begin{axiom}
\label{1.6.4}
\textbf{(Axioms for norm function)} Let $V$ be a vector space over  $\F\subseteq\C$. A norm, or norm function, $p:V\rightarrow \R$ is a function that satisfy 
\begin{equation}
  \forall \vecta{x,y}\inV, p(\vecta{x}+\vecta{y})\leq p(\vecta{x})+p(\vecta{y})  \text{( Triangle inequality)}
\end{equation}
\begin{equation}
\forall \vecta{x}\inV,\forall \ld\inF, p(\ld\vecta{x})=\abso{\ld}p(\vecta{x})\text{ ( Absolute homogenity) }
\end{equation}
\begin{equation}
\forall \vecta{x}\inV,p(\vecta{x})\geq 0\text{( Nonnegativity)}
\end{equation}
\begin{equation}
\forall \vecta{x}\inV, p(\vecta{x})=0\implies \vecta{x}=\vecta{0} \text{ ( Positive definiteness) }
\end{equation}

\end{axiom}
\begin{theorem}
\label{1.6.5}
Euclidean norm satisfy the four axioms.
\end{theorem}
\begin{proof}
We started from the last sentence of \myref{Definition}{1.5.5}, for which we have $\abso{\vecta{x}+\vecta{y}}=((\vecta{x}+\vecta{y})\cdot(\vecta{x}+\vecta{y}))^{\frac{1}{2}}$. Observe
\begin{align}
\abso{\vecta{x}+\vecta{y}}^2&=(\vecta{x}+\vecta{y})\cdot(\vecta{x}+\vecta{y})\\
&=\vecta{x}\cdot(\vecta{x}+\vecta{y})+\vecta{y}\cdot(\vecta{x}+\vecta{y})\\
&=\abso{\vecta{x}}^2+\abso{\vecta{y}}^2+2(\vecta{x}\cdot\vecta{y})
\end{align}
and observe
\begin{equation}
  (\abso{\vecta{x}}+\abso{\vecta{y}})^2=\abso{\vecta{x}}^2+\abso{\vecta{y}}^2+2\abso{\vecta{x}}\abso{\vecta{y}}
\end{equation}
by \myref{Theorem}{1.5.6}, we then have $\abso{\vecta{x}+\vecta{y}}^2\leq (\abso{\vecta{x}}+\abso{\vecta{y}})^2$. The triangle inequality follows.\\

Observe
\begin{align}
\abso{\ld\vecta{x}}&=(\sum (\ld x_i)^2)^{\frac{1}{2}}\\
&=(\ld ^2\sum x_i^2)^{\frac{1}{2}}\\
&=\abso{\ld }(\sum x_i^2)^{\frac{1}{2}}\\
&=\abso{\ld }\abso{\vecta{x}}
\end{align}
Notice that $\abso{\vecta{x}}=\sum x_i^2\geq 0$ and notice that $\abso{\vecta{x}}=0\implies \sum x_i^2=0\implies \forall i,x_i=0\implies \vecta{x}=\vecta{0}$
\end{proof}
\fbox{\begin{minipage}{39em}
In later chapters, we will introduce norms defined in different ways and spaces. For example, in Euclidean space we can define  $\norm{\vecta{x}}:=\max (\abso{x_1},\abso{x_2},\dots ,\abso{x_n})$. One can check this definition does satisfy four axioms. Also, notice that because  $\C$ is an Euclidean 2-space,  by \myref{Theorem}{1.6.5}, the four axioms of norm function also apply to the absolute of complex numbers.\\

Next, we introduce the three axioms for inner product. 
\end{minipage}}
\begin{axiom}
\label{1.6.6}
\textbf{(Axioms for inner product)} Let $V$ be a vector space over $\F$, where $\F$ is either $\R$ or $\C$. An inner product $\gen{\cdot,\cdot}:V\times V\rightarrow \F $ is a function that satisfy the following three axioms: 
\begin{equation}
\forall \vecta{x,y}\inV,\gen{\vecta{x},\vecta{y}}=\overline{\gen{\vecta{y},\vecta{x}}}\text{ ( Conjugate Symmetry)}
\end{equation}
\begin{equation}
\forall \vecta{x,y,z}\inV, \forall a,b\inF, \gen{a\vecta{x}+b\vecta{y},\vecta{z}}=a\gen{\vecta{x},\vecta{z}}+b\gen{\vecta{y},\vecta{z}} \text{ ( Linearity in first argument)} 
\end{equation}
\begin{equation}
\vecta{x}\neq \vecta{0}\longrightarrow \gen{\vecta{x},\vecta{x}}>0 \text{ ( Positive Definitness) }  
\end{equation}
Notice that to satisfy the third axiom, we first have to guarantee that $\forall \vecta{x}\inV,\gen{\vecta{x},\vecta{x}}\inr$. This is implied by the first axiom, since $\gen{\vecta{x},\vecta{x}}=\overline{\gen{\vecta{x},\vecta{x}}}$ 
\end{axiom}
\begin{theorem}
\label{1.6.7}
Euclidean inner product satisfy the three axioms. 
\end{theorem}
\begin{proof}
Let $\vecta{x},\vecta{y},\vecta{z}\inR^n$, and $a,b\inr$. Observe
\begin{equation}
\vecta{x}\cdot\vecta{y}=\sum x_iy_i=\sum y_ix_i=\vecta{y}\cdot\vecta{x}=\overline{\vecta{y}\cdot\vecta{x}}
\end{equation}
\begin{equation}
  (a\vecta{x}+b\vecta{y})\cdot\vecta{z}=\sum (ax_i+by_i)z_i=a\sum x_iz_i + b\sum y_iz_i=a(\vecta{x}\cdot\vecta{z})+b(\vecta{y}\cdot\vecta{z})
\end{equation}
\begin{equation}
\vecta{x}\cdot\vecta{x}=\sum x_i^2\geq 0
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
    In 2 or 3 dimension, Euclidean inner product captures the essence of angle really well, as one may remember $\vecta{x}\cdot\vecta{y}=\abso{\vecta{x}}\abso{\vecta{y}}\cos\theta $. However, to rigorously explain why $\sum x_iy_i=\abso{\vecta{x}}\abso{\vecta{y}}\cos\theta $ is for now impossible, since we haven't define  $\cos$. Notice that one can define $\cos$ using Taylor series.\\

Normally, one doesn't use the notation $\vecta{x}\cdot\vecta{y}$ in place of $\gen{\vecta{x},\vecta{y}}$, since these two notations have completely two different meaning in modern mathematics. The former is called dot product, defined only in Euclidean space and defined only by $\vecta{x}\cdot\vecta{y}:=\sum x_iy_i$. The latter is a wide notation of every function that satisfy the three axioms. Obviously the former is only an example of the latter, and we only use $\vecta{x}\cdot\vecta{y}$ in place of $\gen{\vecta{x},\vecta{y}}$, when the latter in context is equivalent to the former, e.g. Euclidean inner product.\\

A quite meaningless example of an inner product is $\gen{\vecta{x},\vecta{y}}:=0$. A more complicated example of an inner product is for space of continuous complex valued function from real interval $[a,b]$ defined by $\gen{f,g}:=\int_a^b f(t)\overline{g(t)}dt$\\

In last section, we "verified" that in Euclidean space, we have $\norm{\vecta{x}}=\gen{\vecta{x},\vecta{x}}^{\frac{1}{2}}$. Now, we prove that every inner product induce a norm, using Parallelogram Law. However, here we have to emphasize that \textit{even though every inner product space come with a norm, not any normed space come with an inner product}.
\end{minipage}}
\begin{definition}
\label{1.6.8}
\textbf{(Parallelogram Law)} We say a normed space $V$ satisfy Parallelogram Law if for all $\vecta{x},\vecta{y}\inV$, we have
 \begin{equation}
\norm{\vecta{x}+\vecta{y}}^2+\norm{\vecta{x}-\vecta{y}}^2=2(\norm{\vecta{x}}^2+\norm{\vecta{y}}^2)
\end{equation}
\end{definition}
\begin{lemma}
\label{1.6.9}
\textbf{(Arising from inner product $\longrightarrow $ Satisfying Parallelogram Law)} For an inner product space, if we define $\norm{\vecta{x}}=\gen{\vecta{x},\vecta{x}}^{\frac{1}{2}}$, then we have 
\end{lemma}
\begin{proof}
Notice that $\gen{\vecta{a},\vecta{b}+\vecta{c}}=\gen{\vecta{a},\vecta{b}}+\gen{\vecta{a},\vecta{c}}$ and observe 
\begin{align}
\norm{\vecta{x}+\vecta{y}}^2+\norm{\vecta{x}-\vecta{y}}^2&=\gen{\vecta{x}+\vecta{y},\vecta{x}+\vecta{y}}+\gen{\vecta{x}-\vecta{y},\vecta{x}-\vecta{y}}\\
&=\gen{\vecta{x},\vecta{x}+\vecta{y}}+\gen{\vecta{y},\vecta{x}+\vecta{y}}+\gen{\vecta{x},\vecta{x}-\vecta{y}}-\gen{\vecta{y},\vecta{x}-\vecta{y}}\\
&=2\gen{\vecta{x},\vecta{x}}+2\gen{\vecta{y},\vecta{y}}+\gen{\vecta{x},\vecta{y}}+\gen{\vecta{y},\vecta{x}}-\gen{\vecta{x},\vecta{y}}-\gen{\vecta{y},\vecta{x}}\\
&=2\gen{\vecta{x},\vecta{x}}+2\gen{\vecta{y},\vecta{y}}=2(\norm{\vecta{x}}^2+\norm{\vecta{y}}^2)
\end{align}
\end{proof}
\begin{theorem}
\label{1.6.10}
Every inner product give rise to a definition of norm $\norm{\vecta{x}}=\gen{\vecta{x},\vecta{x}}^{\frac{1}{2}}$
\end{theorem}
\begin{proof}
Let $V$ be an inner product space and define  $\norm{\vecta{x}}:=\gen{\vecta{x},\vecta{x}}^{\frac{1}{2}}$. \As{there exists $\vecta{x},\vecta{y}$ such that $\norm{\vecta{x}+\vecta{y}}>\norm{\vecta{x}}+\norm{\vecta{y}}$}. Observe
\begin{equation}
\norm{\vecta{x}+\vecta{y}}^2>\norm{\vecta{x}}^2+\norm{\vecta{y}}^2+2\norm{\vecta{x}}\norm{\vecta{y}}
\end{equation}
Notice $\gen{-\vecta{a},-\vecta{a}}=-\gen{\vecta{a},-\vecta{a}}=\overline{-\gen{-\vecta{a},\vecta{a}}}=\overline{\gen{\vecta{a},\vecta{a}}}=\gen{\vecta{a},\vecta{a}}$ and observe
\begin{align}
  \norm{\vecta{x}-\vecta{y}}^2&>\norm{\vecta{x}}^2+\norm{-\vecta{y}}^2+2\norm{\vecta{x}}\norm{-\vecta{y}}\\
  &= \norm{\vecta{x}}^2+\norm{\vecta{y}}^2+2\norm{\vecta{x}}\norm{\vecta{y}}
\end{align}
So we have
\begin{equation}
\norm{\vecta{x}+\vecta{y}}^2+\norm{\vecta{x}-\vecta{y}}^2>2(\norm{\vecta{x}}^2+\norm{\vecta{y}}^2)+4\norm{\vecta{x}}\norm{\vecta{y}}\geq 2(\norm{\vecta{x}}^2+\norm{\vecta{y}}^2)
\end{equation}
This \CaC to \myref{Lemma}{1.6.8}.\\

Observe
\begin{equation}
\norm{\ld \vecta{x}}=(\gen{\ld \vecta{x},\ld \vecta{x}})^{\frac{1}{2}}=(\ld \overline{\ld }\gen{\vecta{x},\vecta{x}})^{\frac{1}{2}}=(\ld \overline{\ld })^{\frac{1}{2}}(\gen{\vecta{x},\vecta{x}})^{\frac{1}{2}}=\abso{\ld }\norm{\vecta{x}}
\end{equation}
Nonnegativity and Positive definiteness of norm function follows from Positive definiteness of inner product and $\gen{\vecta{0},\vecta{0}}=0$. 
\end{proof}
\fbox{\begin{minipage}{39em}
For the last sentence of the last paragraph, we here state it in precision: Let $f(x,y)$ be an inner product, then the function $g(x)=\sqrt{f(x,x)}$ satisfy the norm axiom, but if let $l(x)$ be a norm function, it doesn't always exists a function  $h(x,y)$ such that $l(x)=\sqrt{h(x,x)}\text{ and }h$ satisfy the inner product axioms.\\

An amazing fact is that for a normed space $V$ over $\R$ or  $\C$,  if $V$ satisfy Parallelogram Law, then we can define an inner product on  $V$ by  $\gen{\vecta{x},\vecta{y}}:=\begin{cases}
  \frac{\norm{\vecta{x}+\vecta{y}}^2-\norm{\vecta{x}-\vecta{y}}^2}{4}& \text{ if over $\R$ }\\
  \frac{\norm{\vecta{x}+\vecta{y}}^2-\norm{\vecta{x}-\vecta{y}}^2}{4}+i \frac{\norm{i\vecta{x}-\vecta{y}}^2-\norm{i\vecta{x}+\vecta{y}}^2}{4}& \text{ if over $\C$ }
\end{cases}$ so that this inner product not only satisfy all the axioms for inner product, we also have $\norm{\vecta{x}}=(\gen{\vecta{x},\vecta{x}})^{\frac{1}{2}}$.\\

So, in other word, a norm is induced by an inner product if and only if the norm satisfy the Parallelogram Law. Isn't this amazing? For the proof of only if part, we put it in complicated exercises.\\

We close this section with a special case of Cauchy-Schwarz inequality and the most general Cauchy-Schwarz inequality.
\end{minipage}}
\begin{theorem}
\label{1.6.11}
\textbf{(Cauchy-Schwarz inequality in $\C^n$)} Let $\vecta{v}=(v_1,\dots ,v_n)\inC^n$ and $\vecta{w}=(w_1,\dots ,w_n)\inC^n$ 
 \begin{equation}
   \abso{\sum v_j\overline{w_j}}\leq (\sum \abso{v_j}^2)^{\frac{1}{2}}(\sum \abso{w_j}^2)^{\frac{1}{2}} 
\end{equation}
and the equality hold if and only if  $\exists \ld \inC,\vecta{w}=\ld\vecta{v}$\\

Also, if we define inner product on $\C^n$ as $\gen{\vecta{v},\vecta{w}}:=\sum v_j\overline{w_j}$ and induce norm as $\norm{\vecta{v}}:=\gen{\vecta{v},\vecta{v}}^{\frac{1}{2}}$, the special case of Cauchy-Schwarz inequality in $\C^n$ can also be shortened to
 \begin{equation}
\abso{\gen{\vecta{v},\vecta{w}}}\leq (\norm{\vecta{v}})(\norm{\vecta{w}})
\end{equation}
\end{theorem}
\begin{proof}
Define $A:=\sum \abso{v_j}^2=\norm{\vecta{v}}^2,B:=\sum \abso{w_j}^2=\norm{\vecta{w}}^2,C:=\sum v_j\overline{w_j}=\gen{\vecta{v},\vecta{w}}$\\

Notice that $B=0$ implies $\forall j,w_j=0$, then two sides of inequality are both $0$ and  $\ld=0$. We have proven the case of $B=0$, now we prove the case of  $B>0$. Keep in mind that $A,B\inR$ and observe
\begin{align}
\sum \abso{Bv_j-Cw_j}^2&=\sum (Bv_j-Cw_j)\overline{(Bv_j-Cw_j)}\\
&=\sum (Bv_j-Cw_j)(B\overline{v_j}-\overline{C}\overline{w_j})\\
&=\sum B^2\abso{v_j}^2-BC\overline{v_j}w_j-B\overline{C}v_j\overline{w_j}+C\overline{C}\abso{w_j}^2\\
&=B^2A-BC\overline{C}-B\overline{C}C+C\overline{C}B\\
&=B^2A-BC\overline{C}\\
&=B(AB-\abso{C}^2) 
\end{align}

Because $B>0$, then we can deduce
\begin{equation}
\sum \abso{v_j}^2\sum \abso{w_j}^2 - \abso{\sum v_j\overline{w_j}}^2=AB-\abso{C}^2=\frac{1}{B}\sum \abso{Bv_j-Cw_j}^2\geq 0
\end{equation}
So we can deduce
\begin{equation}
\sum \abso{v_j}^2\sum \abso{w_j}^2\geq \abso{\sum v_j\overline{w_j}}^2
\end{equation}
Square both side then the Theorem follows.\\

Notice that the equality hold true if and only if $\sum \abso{Bv_j-Cw_j}^2=0$, which is equivalent to $\forall j, w_j=\frac{B}{C}v_j$, and equivalent to $\vecta{w}=\frac{B}{C}\vecta{v}$, where $\ld =\frac{B}{C}=\frac{\norm{\vecta{w}}^2}{\gen{\vecta{v},\vecta{w}}}$
\end{proof}
\begin{theorem}
\label{1.6.12}
\textbf{(General Cauchy-Schwarz inequality)} For all inner product space $V$ where the norm is induced by the inner product, we have
\begin{equation}
\abso{\gen{\vecta{v},\vecta{w}}}\leq (\norm{\vecta{v}})(\norm{\vecta{w}})
\end{equation}
and the equality hold if and only if  $\vecta{w}=\ld \vecta{v}$
\end{theorem}
\begin{proof}
Define $A:=\norm{\vecta{v}}^2,B:=\norm{\vecta{w}}^2,C:=\gen{\vecta{v},\vecta{w}}$\\

Notice that $B=0$ implies $\vecta{w}=\vecta{0}$, which further implies $\gen{\vecta{v},\vecta{w}}=\overline{\gen{\vecta{0},\vecta{v}}}=\overline{\gen{\vecta{a}-\vecta{a},\vecta{v}}}=\overline{\gen{\vecta{a},\vecta{v}}-\gen{\vecta{a},\vecta{v}}}=0$, so two side of the inequality are both  $0$ and the equality hold true, where $\ld =0$. We have proven the case of $B=0$. Now we prove the case of $B>0$\\

Keep in mind that $A,B\inR$ and observe
\begin{align}
\norm{B\vecta{v}-C\vecta{w}}^2&=\gen{B\vecta{v}-C\vecta{w},B\vecta{v}-C\vecta{w}}\\
&=\gen{B\vecta{v},B\vecta{v}}-\gen{C\vecta{w},B\vecta{v}}-\gen{B\vecta{v},C\vecta{w}}+\gen{C\vecta{w},C\vecta{w}}\\
&=B^2\gen{\vecta{v},\vecta{v}}-CB\gen{\vecta{w},\vecta{v}}-B\overline{C}\gen{\vecta{v},\vecta{w}}+C\overline{C}\gen{\vecta{w},\vecta{w}}\\
&=B^2A-CB\overline{C}-B\overline{C}C+C\overline{C}B\\
&=B(AB-\abso{C}^2)
\end{align}
Because $B>0$, we can deduce 
 \begin{equation}
\norm{\vecta{v}}^2\norm{\vecta{w}}^2-\abso{\gen{\vecta{v},\vecta{w}}}^2=AB-\abso{C}^2=\frac{\norm{B\vecta{v}-C\vecta{w}}^2}{B}\geq 0
\end{equation}
So we can deduce
\begin{equation}
\norm{\vecta{v}}^2\norm{\vecta{w}}^2\geq \abso{\gen{\vecta{v},\vecta{w}}}^2
\end{equation}
Square both side then the Theorem follows. 
\end{proof}
\begin{corollary}
\label{1.6.13}
\textbf{(Verification of Triangle Inequality)} Let $V$ be an inner product space where the norm is induced by the inner product, we have 
 \begin{equation}
   \norm{\vecta{v}+\vecta{w}}\leq\norm{\vecta{v}}+\norm{\vecta{w}}
\end{equation}
where the equality hold true only when $\gen{\vecta{v},\vecta{w}}\geq 0$ and $\vecta{v},\vecta{w}$ are linearly dependent.
\end{corollary}
\begin{proof}
Observe
\begin{align}
\norm{\vecta{v}+\vecta{w}}^2&=\gen{\vecta{v}+\vecta{w},\vecta{v}+\vecta{w}}\\
&=\norm{\vecta{v}}^2+\gen{\vecta{v},\vecta{w}}+\gen{\vecta{w},\vecta{v}}+\norm{\vecta{w}}^2\\
&=\norm{\vecta{v}}^2+\norm{\vecta{w}}^2+\gen{\vecta{v},\vecta{w}}+\overline{\gen{\vecta{v},\vecta{w}}}\\
&=\norm{\vecta{v}}^2+\norm{\vecta{w}}^2+2\text{Re}(\gen{\vecta{v},\vecta{w}})\\
&\leq \norm{\vecta{v}}^2+\norm{\vecta{w}}^2+2\abso{\gen{\vecta{v},\vecta{w}}}\\
&\leq \norm{\vecta{v}}^2+\norm{\vecta{w}}^2+2(\norm{\vecta{v}})(\norm{\vecta{w}})\\
&=(\norm{\vecta{v}}+\norm{\vecta{w}})^2
\end{align}
\end{proof}
\section{Existence of Real Numbers - Dedekind Cut*}
\section{Existence of Real Numbers - Decimal*}
\section{Uniqueness of Real Numbers*}
\section{Exercises}
\begin{question}{}{}
Given a nonzero rational $r$ and an irrational $x$, prove that $r+x$ and $rx$ are irrational. 
\end{question}
\begin{question}{}{}
Prove that no rational $r$ satisfy  $r^2=12$
\end{question}
\begin{question}{}{}
Let $E$ be a nonempty subset of an ordered set; suppose $\alpha$ is a lower bound and $\beta$ is an upper bound of $E$. Prove $\alpha<\beta$ 
\end{question}
\begin{question}{}{}
Let $A$ be a nonempty subset of real numbers which is bounded below.  Define $-A:=\set{-x: x\inA}$. Prove that
\begin{equation}
\inf A=-\sup (-A)
\end{equation}
\end{question}
\begin{question}{}{}
Prove that no ordered relation can be defined on $\C$ so that $\C$ become an ordered field.
\end{question}
\begin{question}{}{}
Let $w=u+vi$ and  $a=(\frac{\abso{w}+u}{2})^{\frac{1}{2}}$ and $b=(\frac{\abso{w}-u}{2})^{\frac{1}{2}}$ \\

Verify that if $v\geq 0$, then  $w=(a+bi)^2$, and that if $v<0$, then $w=(a-bi)^2$\\

Prove that every complex number have at least $2$ square roots.
\end{question}
\begin{question}{}{}
Let $z_1,\dots ,z_n\inC$. Prove that
\begin{equation}
\abso{\sum z_j}\leq \sum \abso{z_j}
\end{equation}
\end{question}
\begin{question}{}{}
Let $x,y\inC$. Prove that
 \begin{equation}
\abso{\abso{x}-\abso{y}}\leq \abso{x-y}
\end{equation}
\end{question}
\begin{question}{}{}
Let $z\inC\text{ and }\abso{z}=1$. Compute
\begin{equation}
\abso{1+z}^2+\abso{1-z}^2
\end{equation}
\end{question}
\begin{question}{}{}
Let $\vecta{x}\inR^k\text{ and }\vecta{x}\neq \vecta{0}$. When $k=1$,  prove that there does not exists $\vecta{y}\inR^k$, such that $\vecta{x}\cdot\vecta{y}$. When $k\geq 2$, prove that there exists infinitely amount of $\vecta{y}\inR^k$ such that $\vecta{x}\cdot\vecta{y}=0$ 

\end{question}
\begin{question}{}{}
Let $k\geq 3, \vecta{x},\vecta{y}\inR^k,\abso{\vecta{x}-\vecta{y}}=d>0\text{ and }r>0$. Prove that if $2r<d$, then there exists no  $z\inR^k$ such that $\abso{\vecta{z}-\vecta{x}}=\abso{\vecta{z}-\vecta{y}}=r$. Prove that if $2r=d$, there exists exactly one $\vecta{z}\inR^k$ that satisfy $\abso{\vecta{z}-\vecta{x}}=\abso{\vecta{z}-\vecta{y}}=r$. Prove that if $2r>d$, then there are infinitely many $\vecta{z}\inR^k$ that satisfy $\abso{\vecta{z}-\vecta{x}}=\abso{\vecta{z}-\vecta{y}}=r$. Prove that if $k=2$ and  $2r>d$, then there exists exactly $2$ unique  $\vecta{z}\inR^k$ such that $\abso{\vecta{z}-\vecta{x}}=\abso{\vecta{z}-\vecta{y}}=r$. Prove that if $k=1$ and $2r>d$ then there exists no $\vecta{z}\inR^k$ that satisfy $\abso{\vecta{z}-\vecta{x}}=\abso{\vecta{z}-\vecta{y}}=r$
\end{question}

\section{Complicated Exercises}
In \myref{Axiom}{1.2.1}, we present the two ordered field axioms:
\begin{equation}
y<z\longrightarrow x+y<x+z
\end{equation}
\begin{equation}
x>0\text{ and }y>0\longrightarrow xy>0
\end{equation}\\
If we define the order for $\R$ completely in reverse, that is; for any $x,y$, where originally we  have  $x\leq y$, we now define $x\geq y$, then we can see the new order relation does not satisfy the second axiom, i.e. $x>0\text{ and }y>0\rightarrow xy>0$, by observing $-1>0\implies 1=(-1)^2<0$
\begin{question}{
  Uniquely Orderd}{}
Prove that $\Q$ and $\R$ are uniquely ordered field; that is, any order relation defined on $\Q$ and  $\R$ must be exactly the same as how we usually define it to satisfy the two ordered field axioms. Notice that you have to first come up with a way to describe our usual ways for ordering $\Q\text{ and }\R$ in your proof and make sure that the description do let us tell weather $x< y$ or $y< x$ for all $x,y$.       
\end{question}
Next question refers to \myref{Definition}{1.6.8}
\begin{question}{}{}
  Give an example of a normed vector space $V$ such that for all inner product that can be defined on $V$, there exists  $\vecta{x}\inV$ such that $\norm{\vecta{x}}\neq \sqrt{\gen{\vecta{x},\vecta{x}}}$, and show that this normed space does not satisfy Parallelogram Law.\\

Prove a norm is induced by some inner product if and only if the norm satisfy Parallelogram Law.
\end{question}
\begin{question}{}{}
Let $\vecta{a},\vecta{b}\inR^n\text{ and }m \inR^+$. Find $\vecta{c}\inR^n\text{ and }r>0$ such that
\begin{equation}
\abso{\vecta{x}-\vecta{a}}=m\abso{\vecta{x}-\vecta{b}}\iff \abso{\vecta{x}-\vecta{c}}=r
\end{equation}
\end{question} 
\begin{question}{}{}
State and prove the Pythagorean Law in Euclidean $n$-space, where  $n\geq 2$
\end{question}
\chapter{Basic Topology}
\section{ZF}
\fbox{\begin{minipage}{39em}
This section is written as a confirmation of knowledge. For a even more rigorous treatment, one can look for another note where the discussion of ZF is put after that of formal system and zeroth and first order logic.\\

Notice that in our discussion, the domain of discourse are sets. Plain speaking, every variable should be interpreted as set. In this section, we never interpret symbol $x$ as a real number (we never use symbol $x$ to denote a real number), and we never interpret symbol $G$ as a group  (we never use symbol $G$ to denote a group). Whatever variable symbol we use, we interpret the symbol a set (we use the symbol to denote a set), albeit $x,G\text{ or }h$.\\

However, if you wish, you can still interpret the symbol $x$ as a number or structure or any mathematical object or even cats, but I doubt there exists any interpretation that isn't set won't make people feel weird.\\   

Notice that ZF is a first order logic theory. We must first declare the following 
\end{minipage}}
\begin{definition}
\label{2.1.1}
\textbf{(Atomic Formula)} In our discussion in this section, there are precisely two atomic formulas:
\begin{equation}
x\inA
\end{equation}
and
\begin{equation}
A=B
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
The above definition may be confusing if one has no basic knowledge for formal system. I here highly recommend the first two chapters of the excellent book \textit{Elementary Formal System } written by Smullyan, and one can understand what does the words "formula" and "axiom" mean. \\

Now we start our discussion of ZF.
\end{minipage}}
\begin{axiom}\textbf{(Axiom of Extension)}
\label{2.1.2}
\begin{equation}
\forall x(x\inA \longleftrightarrow x\inB)\longrightarrow A=B
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
TBH, I have no clue why this axiom is named axiom of extension. This axiom axiomatically define equality (between sets).\\

The practice of putting the word \textit{between sets} in a  parenthesis in the above paragraph serve as a reminder that the domain of discourse of our discussion should be interpreted as the class of all sets.\\ 

ZF in our discussion is a theory where the only two non-logical symbol is $\in\text{ and }=$. In our discussion, whenever the symbols $\subseteq,\cup ,\cap, \neq$ appear, one should immediately realize the sentence in which the symbols appear is an interpretation.\\

In ZF, we never define $A \subseteq B$. We never define $A\neq B$. We never define $A \cup B$. We merely construction a formal sentence that one feel it make sense to  interpret as $A \subseteq B$ or the English sentence "$A$ is a subset of  $B$.". 
\end{minipage}}
\begin{definition}
\label{2.1.3}
\textbf{(Interpretation)} We can interpret the formal sentence $\forall x(x\in A\longrightarrow x\in B)$ as informal sentence $A \subseteq B$. If we ever say $A \subseteq B$, we mean $\forall x(x\in A\longrightarrow  x\in B)$
\end{definition}
\begin{definition}
\label{2.1.4}
\textbf{(Interpretation)} We can interpret the formal sentence $\exists x((x\in A \land \neg x\in B)\lor(x \in B \land \neg x \in A))$ as the sentence $A\neq B$.
\end{definition}
\begin{axiom}
\label{2.1.5}
\textbf{(Axiom of Subset)} Let $P$ be a predicate. The axiom states
\begin{equation}
\forall A\exists B\forall x(x\inB\longleftrightarrow x\inA\land P(x))
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
Because of axiom of subset, when we informally says $B=\set{x\inA: P(x)}$ in our argument, we know $B$ exists if  $P$ is a predicate. Notice that Russell's paradox rely on the construction of such set: $\set{y:P(y)}$ where predicate $P(x)$  is defined by $\neg x=x$. The axiom of subset only allow us to construct  "subset" (not set) filled with elements satisfying certain predicate.\\

Also, the axiom of subset allow us to construct intersection of two sets. Consider the set $\set{x\inA:P(x)}$ where $P(x)$ is defined by $x\inB$.\\

Notice that one at this point can trivially and formally deduce the existence of two sets that are ought to be interpreted as $A\cap B$ and $B\cap A$, and formulate a formal sentence that is ought to be interpreted as "$A\cap B$ is unique" and another formal sentence that is ought to be interpreted as "$A\cap B=B\cap A$", and deduce these two formal sentences.\\   

One can also formulate and deduce the formal sentence of "intersection operation is associative" as an exercise.\\

Now, before we introduce the next axiom, we first declare  that the symbol $\varnothing$ is in our alphabet.
\end{minipage}}
\begin{axiom}
\label{2.1.6}
\textbf{(Axiom of Existence of Empty Set)}
\begin{equation}
\exists \varnothing\forall y\neg (y\in \varnothing)
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
In some people's formation of ZF, the axiom of existence of empty set isn't necessary, since it is possible to construct the empty set with axiom of subset. If we already know that the universe is nonempty, we can arbitrarily pick a set $A$ and construct  $\set{x\inA:P(x)}$ where $P(x)$ is defined $\neg x=x$.\\

At this point, one can try to formulate the formal sentence of "empty set is unique and is a subset of every set" and formally deduce such using axiom of extension.\\


We now introduce an axiom to construct new set.
\end{minipage}}
\begin{axiom}
\label{2.1.7}
\textbf{(Axiom of Pairing)}
\begin{equation}
\forall x\forall y\exists A\forall v(v\inA\longleftrightarrow v=x \lor v=y)
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
    By axiom of pairing, one can deduce the formal sentence of "$\set{x,y}$ exists if $x,y$ exist".\\  

    Notice that we can also deduce the formal sentence of "$\set{x}$ exists if $x$ exists".
\end{minipage}}
\begin{axiom}
\label{2.1.8}
\textbf{(Axiom of Union)}
\begin{equation}
\forall A\exists B \forall x(x\in B\longleftrightarrow \exists C(C\inA\land x\in C))
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
By axiom of union, one can deduce the formal sentence of "$\bigcup X$ exists, if $X$ exist".\\

Also, one can try to formulate and deduce the formal sentence of "For all set  $X$, we know  $\bigcup X$ is unique", that of "For all sets $x,y$, we know $x \cup y=y \cup x$" and that of "For all sets $x,y,z$, we know  $(x\cup y)\cup z=x\cup (y\cup z)$".\\    

Now we introduce a new axiom to construct even more sets.
\end{minipage}}
\begin{axiom}
\label{2.1.9}
\textbf{(Axiom of Power Set)} 
\begin{equation}
\forall A\exists B\forall x(x\in B \longleftrightarrow \forall y(y\in x\longrightarrow y\in A))
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
The axiom of power set can be interpreted as that every set has at least one power set (and it can be proved that there exists only one for every set and that if two set have the same power set then the two set are the same). Normally and informally, we denote the power set of $x$ as $\mathcal{P}(x)$\\  

Now we introduce the standard way to "construct a model for natural numbers", that is, to "formally formulate sets that can be interpreted as natural numbers". The construction is straight forward: we interpret $\varnothing$ as $0$, and  while interpreting $x$ as a natural, interpret $x\cup \set{x}$ as $x+1$.\\

This construction seems to satisfy Peano axioms, but a problem will emerge when one trying to verify: one can construct any natural number, for instance $3$, by constructing  $\set{\varnothing,\set{\varnothing},\set{\varnothing,\set{\varnothing}}}$, but one can not construct the set of all natural numbers, that is, informally writing, $\N=\set{0,1,2,3,\dots }=\set{\varnothing, \set{\varnothing},\set{\varnothing,\set{\varnothing}},\set{\varnothing,\set{\varnothing},\set{\varnothing,\set{\varnothing}}},\dots }$.\\

The construction of the set $\N$, rely on the next axiom (while the construction of no element in $\N$ rely on the next axiom). In fact, the formulation of any infinite set rely on the next axiom. Without this axiom, we can not formulate any infinite set (after we construct the predicate $P(x)$ to be interpreted as "$P(x)$ is true if $x$ is infinite").
\end{minipage}}
\begin{axiom}
\label{2.1.10}
\textbf{(Axiom of Infinity)} 
\begin{equation}
\exists I(\varnothing \in I \land \forall y(y\in I\longrightarrow y\cup \set{y}\in I))
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
Notice that every set interpreted as a natural number can be proved to belong to the set $I$ in  \myref{Axiom}{2.1.10}. In other (informal) words, the set interpreted as $\N$ is a subset of $I$.\\

Before we formulate such subset of  $I$, we first state the five Peano Axioms, outside of our formal system. One can and should read the following five axioms algebraically, not formally.  
\end{minipage}}
\begin{axiom}
\label{2.1.11}
\textbf{(Peano Axioms, outside of our formal system)} We say $\gen{U,S}$, where $S$ is a function, is a model of Peano axioms if    
\begin{equation}
 0\in U\text{ (First Peano axiom) }
\end{equation}
\begin{equation}
a \in U \implies S(a)\in U\text{ (Second Peano axiom) }
\end{equation}
\begin{equation}
\forall x \in U, S(x)\neq 0 \text{ (Third Peano axiom) }
\end{equation}
\begin{equation}
S(a)=S(b)\implies a=b\text{ (Forth Peano axiom) }
\end{equation}
\begin{equation}
0  \in X\text{ and } \forall u \in U, u\in X\longrightarrow S(u)\in X\implies U\subseteq X \text{ (Induction axiom) }
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
Before reading the proof of the following theorem, notice that the set $\set{y\in\bigcup  x:\forall z(z\in x\longrightarrow y\in x)}$ is what we mean by $\bigcap  x$, and notice that the set $\set{a\in x: \neg a\in y}$ is what we mean by $x\setminus y$.\\

One can try to completely formalize $\bigcap x\text{ and }x\setminus y$  
\end{minipage}}
\begin{theorem}
\label{2.1.12}
\textbf{(Existence of Model of Natural Numbers in ZF)}
We first define five predicate resembling the five Peano axioms.
\begin{equation}
P_1(x):=\varnothing\in x
\end{equation}
\begin{equation}
P_2(x):=\forall a(a\in x\longrightarrow a\cup \set{a}\in x)
\end{equation}
\begin{equation}
P_3(x):=\forall a(a\in x\longrightarrow a\cup \set{a}\neq \varnothing)
\end{equation}
\begin{equation}
P_4(x):=\forall a\forall b(a\in x \land b\in x \land a\cup \set{a}=b\cup \set{b}\longrightarrow a=b)
\end{equation}
\begin{equation}
  P_5(x):=\forall a([\forall b(b\in a\longrightarrow b \in x)\land \varnothing\in a\land \forall b(b\in a\longrightarrow b\cup \set{b}\in a)]\longrightarrow x=a)
\end{equation}
Reminder: Notice that the notation $\cup $ is not in our formal language, I use the notation only for abbreviation.\\

The theorem states:
\begin{equation}
\exists A(P_1(A)\land P_2(A)\land  P_3(A)\land  P_4(A)\land  P_5(A))
\end{equation}
\end{theorem}
\begin{proof}
  Let $I$ be the set in \myref{Axiom}{2.1.10}. Define $ \call:=\set{X\in\power{I}:\varnothing \in X \land \forall a(a \in X \longrightarrow a\cup \set{a}\in X)} $. From now on, we will call $a\cup \set{a}$ the successor $S(a)$ of $a$ in our proof.\\

Then  $\call$ can be precisely described as the set that contain all subsets $X$ of  $I$ such that the set interpreted as  $0$ is in  $X$ and that the successor of each element in $X$ belong to  $X$.\\

Let $Y=\bigcap \call$. We seek to show that 
\begin{equation}
\teal{P_1(Y)\land P_2(Y) \land P_3(Y) \land P_4(Y)\land P_5(Y)}
\end{equation}
\vi{$P_1(Y)$} and \blue{$P_2(Y)$} are trivial. $\vdone \bdone$\\

\vi{$P_3(Y)$} is also trivial.$\vdone$\\


We now prove $\blue{P_5(Y)}$\\

Let $E \subseteq \bigcap  \call,\varnothing\in E\text{ and }\forall b(b\in E\longrightarrow b \cup \set{b}\in E)$. Notice that $E\subseteq \bigcap \call \implies \forall X\in \call ,E\subseteq X \subseteq I$, so $E\in \call $. Then $\bigcap \call \subseteq E \bdone$\\

We now prove \vi{$P_4(Y)$}\\

Before reading the following, one may want to bear in mind that $\forall x(x\in x\cup \set{x}\text{ and }x\subseteq x\cup \set{x})$ \\

Define $S:=\set{n\in \bigcap \call:\forall m(m \in n \longrightarrow  m\subseteq n) }$. We see that $S\subseteq \bigcap \call $ and that $\set{\varnothing}\in S$, trivially, so by $P_5(Y)$, we only have to show $n \in S \longrightarrow n\cup \set{n}\in S$ to show $S=\bigcap  \call $. To show such, observe that if $n\in S\text{ and }m \in n \cup \set{n}$, then we know $m \in n\text{ or }m \in \set{n}$, which is equivalent to $m \in n \text{ or } m=n$, which implies $m\subseteq n$, since by the definition of $S$, both  $m \in n\text{ and }m=n$ implies $m\subseteq n$. Then we know $n\in S\text{ and }m \in n \cup \set{n}\longrightarrow  m\subseteq n \subseteq n\cup \set{n}$.\\

The above prove that every element of element $n$ of  $\bigcap \call $ is a subset of $n$. \As{$m\neq n\in\bigcap \call $ but $m\cup \set{m}=n\cup \set{n}$}. Because $n\in n \cup  \set{n}=m\cup  \set{m}$ and $n\neq m$, we can deduce $n \in m$, which implies $n\subseteq m$. Using the same method we can also deduce $m \subseteq n\tCaC \vdone$    
\end{proof}
\fbox{\begin{minipage}{39em}
Notice that we didn't prove Peano axioms give a unique structure up to isomorphism. I personally haven't proved it yet, but I guess to prove such  isn't trivial and will require to show structure like $\set{0,1,2,\dots ;a,b}$ where $S(a)=b\text{ and }S(b)=a$ does not satisfy the induction axiom.\\

Say, we have proved the uniqueness of model of Peano axiom. We still haven't show in the universe of ZF, our choice of model for natural number is unique. For all we know, maybe the construction $\varnothing, \set{\varnothing},\set{\set{\varnothing}},\set{\set{\set{\varnothing}}},\dots $ also works. (Hint: Let's say there are other construction for natural numbers, there are still  reasons we pick $\bigcap \call $ as our model, since later you will see $a<b\inn\iff  a\in b\text{ and }a\subset b$)\\

So, it seems like \myref{Theorem}{2.1.12} is relatively weak. This is not the case however. The fact is that, we don't really require anything extra of \myref{Theorem}{2.1.12} to do further discussion.\\

The core concept of Axiom is that we don't care about what a mathematical object is, \textit{we only care about what a mathematical object does}. One should \textit{never} view axiom as something that is apparently true and can not be proved. One should know: in most domains of mathematics,  individually, axioms are simply a convention between one mathematician to another. \textit{Axioms are properties we wish a object to have so that we can make knowledge that is truly important using the property of the object}.\\

For instance, we never care about what are sets. We never care about what is $\N$. We never care about what is  $\R$. We only care about that  $\R$ is completed and we can do induction on $\N$. It doesn't matter if $\N$ contain a cat or Homer Simpson, as long as it satisfy Peano axiom and we can deduce all the Theorem.\\


Notice the construction of natural number: $\varnothing, \set{\varnothing},\set{\varnothing,\set{\varnothing}},\dots $ can each be formally proved to belong to $\bigcap  \call $. We now introduce the last axiom.  
\end{minipage}}
\begin{axiom}
\label{2.1.13}
\textbf{(Axiom of Foundation)}
\begin{equation}
\forall X(X \neq \varnothing \longrightarrow \exists Y (Y\in X \land \forall z(z\in Y \longrightarrow \neg z\in X)))
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
In English, the axiom of foundation states that every nonempty set $X$ has an element $Y$ such that  $X\cap Y=\varnothing$. This axiom is sometimes discarded by people who use ZFC for mathematics not so related to set theory, since in the construction of most mathematical object, this axiom is unnecessary. This is also the reason this axiom is introduced last in this section. But of course, this axiom have purpose. We now introduce some results.  
\end{minipage}}
\begin{theorem}
\label{2.1.14}
\textbf{(No set belong to itself)}
\begin{equation}
\forall x, \neg x\in x
\end{equation}
\end{theorem}
\begin{proof}
\As{$\exists x,x\in x$}. Observe that by the axiom of foundation we have $x\cap \set{x}=\varnothing$, but we also have $x\in x\text{ and }x\in \set{x}$, so $x\in x \cap  \set{x}\tCaC$
\end{proof}
\begin{theorem}
\label{2.1.15}
  \textbf{(No infinitely descending chain of sets)}
  Informally, we can say that the following situation will never happen
  \begin{equation}
  \dots \in x_3 \in x_2 \in x_1
  \end{equation}
  Formally, we say
  \begin{equation}
  \neg \exists X(\forall  x(x\in X \longrightarrow \exists y(y \in X \land y \in x)))
  \end{equation}
  which reads "There does not exist a set $X$ such that for all $x\in X$ there exists a set  $y\in X$ belong to $x$"
\end{theorem}
\begin{proof}
\As{there exists a set $X$ such that for all $x\in X$ there exists $y\in X \cap x$}, we immediately see that for all $x\in X$, the intersection $x\cap X$ is nonempty \CaC.
\end{proof}
\section{Ordinal}
\fbox{\begin{minipage}{39em}
In previous section, we employed a purely set-theoretic formal language to delve into Zermelo-Fraenkel Set Theory. While this methodology is undoubtedly elegant for discussing set theory, it becomes notably cumbersome in mathematical domains with limited connections to set theory. This is mainly because many of the tools we typically rely on (such as functions, groups, real numbers, relations, and more) become unavailable. To utilize them, we must first construct all the sets that are interpreted as these tools, leading to extensive and convoluted formulae.\\

In this section, our goal isn't to rigorously prove everything using a formal language. Instead, we'll explain our proofs in sufficient detail so that, if desired, they can be formalized with minimal additional effort, albeit taking a bit more time.\\

Please note that this section primarily serves as a foundational toolkit for the subsequent sections. We will introduce all the necessary tools, and that's the extent of it.\\

In last section, we use a very philosophical and logical way to discuss. Here, we back to our usual algebraic and analytical way to discuss. We firs introduce axioms for ordered sets. 
\end{minipage}}
\begin{axiom}
\label{2.2.1}
\textbf{(Axiom for Poset)} Let $\leq $ be a relation on set $S$. We say $\gen{S,\leq }$ is partially ordered if   
\begin{equation}
\forall x\in S, x\leq  x \text{ (Reflexive) }
\end{equation}
\begin{equation}
\forall x,y,z\in S, x\leq y\text{ and }y\leq z\implies x\leq z\text{ (Transitive) }
\end{equation}
\begin{equation}
\forall x,y\in S, x\leq y\text{ and }y\leq x\implies x=y \text{ (Antisymmetric) }
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
Notice that poset dose not require every two element to be comparable (trichotomy). Totally ordered set require such. 
\end{minipage}}
\begin{axiom}
\label{2.2.2}
\textbf{(Axiom for Totally Ordered Set)} Let $\leq $ be a relation on set $S$. We say $\gen{S,\leq }$ is totally ordered (or linearly ordered) if 
 \begin{equation}
\forall x\in S, x\leq x\text{ (Reflexive) }
\end{equation}
\begin{equation}
\forall x,y\in S, x\leq  y\text{ or }y\leq x \text{ (Connected) }
\end{equation}
\begin{equation}
\forall x,y,z\in S, x\leq y\text{ and }y\leq z\implies x\leq z \text{ (Transitive) } 
\end{equation}
\begin{equation}
\forall x,y\in S,x\leq y\text{ and }y\leq x\implies x=y\text{ (Antisymmetric) }
\end{equation}
\end{axiom}
\fbox{\begin{minipage}{39em}
We now give the axioms for strictly ordered sets.  
\end{minipage}}
\begin{axiom}
\label{2.2.3}
\textbf{(Axiom for Strictly Totally and Partially Ordered Set)} Let $<$ be a relation on set $S$. We say  $\gen{S,<}$ is strictly totally ordered if 
\begin{equation}
\forall x\in S, x\not < x \text{ (Irreflexive) }
\end{equation}
\begin{equation}
\forall x,y\in S, x<y \implies y\not<x \text{ (Asymmetric) }
\end{equation}
\begin{equation}
\forall x,y,z\inS, x<y\text{ and }y<z\implies x<z \text{ (Transitive) }
\end{equation}
\begin{equation}
\forall x,y\in S, x\neq y \implies x<y\text{ or }y<x \text{ (Connected) }
\end{equation}
$\gen{S,<}$ is strictly partially ordered if satisfy irreflexive, asymmetric and transitive axiom. 
\end{axiom}
\fbox{\begin{minipage}{39em}
Notice that if $S$ is totally ordered, then we can let $S$ be strictly totally ordered by defining  $a<b$ if  $a\leq b\text{ and }a\neq b$, and if $S$ is strictly totally ordered, we can let  $S$ be totally ordered by defining  $a\leq b$ if $a<b\text{ or }a=b$.\\


Again, if $S$ is partially ordered, then we can let $S$ be strictly partially ordered by defining  $a<b$ if  $a\leq b\text{ and }a\neq b$, and if $S$ is strictly partially ordered, we can let  $S$ be partially ordered by defining  $a\leq b$ if $a<b\text{ or }a=b$.\\

We now give definition of some basic notions.  
\end{minipage}}
\begin{definition}
\label{2.2.4}
\textbf{(Definition of Minimal and Maximal)} A maximal element $a$ of a subset $X$ of poset $Y$ or totally ordered set $Y$ is an element that no element $b\in X$ satisfy $a<b$. Minimal element is defined in similar fashion.
\end{definition}
\begin{definition}
\label{2.2.5}
\textbf{(Definition of Well Ordered Set)} A totally ordered set $S$ is said to be well ordered if every nonempty subset $X$ of  $S$ has a minimal element $x$. 
\end{definition}
\fbox{\begin{minipage}{39em}
Notice that $\N$ is well ordered, but all  $\Z,\Q,\Q^+,\set{0}\cup \Q^+,\R$ is not well ordered.\\

We now give the definition of ordinal, which is the core of this section.\\

Notice that there are other ways to define ordinal, but Von Neumann ordinal is the most elegant that can be formalized by our system in section 2.1. 
\end{minipage}}
\begin{definition}
\label{2.2.6}
\textbf{(Definition of Von Neumann Ordinal)} A set $S$ is an ordinal if  $S$ is a strictly totally well ordered set with respect to  $\in$ and every element of $S$ is a subset  of $S$. Precisely,  we say a set $S$ is an ordinal  if satisfy the following:
\begin{equation}
\forall x\in S,x\not\in x\text{ (Irreflexive) }
\end{equation}
\begin{equation}
\forall x,y\in S, x\in y\implies y \not\in x \text{ (Asymmetric) }
\end{equation}
\begin{equation}
\forall x,y,z\in S, x\in y \text{ and } y\in z \implies x\in z\text{ (Trnasitive) }
\end{equation}
\begin{equation}
\forall x,y\in S, x\neq y\implies x\in y\text{ or }y\in x \text{ (Connected) }
\end{equation}
\begin{equation}
\forall V\subseteq S, \exists x\in V,\forall y\in V, x\in y \text{ (Well Order) }
\end{equation}
\begin{equation}
\forall x\in S, x\subseteq S \text{ (Subset) }
\end{equation}
In other words, $S$ is an ordinal if  $\gen{S,\in}$ is strictly totally well ordered and every element of $S$ is a subset of  $S$. 
\end{definition}
\fbox{\begin{minipage}{39em}
Von Neumann's definition of ordinal may seem simple and straight forward, but is in fact very strong. Here we prove properties of Von Neumann ordinal we intend to have by definition.\\

Notice that in ZF, irreflexive and antisymetric is trivially satisfied by axiom of foundation. 
\end{minipage}}
\begin{theorem}
\label{2.2.7}
\textbf{(Every Element of Ordinal is an Ordinal)} If $S$ be an ordinal, then  $A \in S$ is an ordinal.
\end{theorem}
\begin{proof}
Notice that if $A=\varnothing$, then the proof is all trivial, so we only have to consider $A\neq \varnothing$. Because $A \subseteq S$, so transitive,  connected and well ordered is trivially proved.\\




We now prove \vi{$\forall x\in A, x \subseteq A$}.\\

Let $x\in A$, if $x$ are all empty, the proof is trivial. Let $\alpha \in x$, so we have $\alpha \in x \in A$\\

Because $A\in S$, we know $A \subseteq S$, so we know $x \in A \subseteq S$. Then we know $x \subseteq S$, so we know $\alpha \in x \subseteq S$. So we know $\alpha ,x,A$ all belong to $S$, then because $S$ is transitive, we conclude  $\alpha \in A\vdone $
\end{proof}
\begin{theorem}
\label{2.2.8}
\textbf{(Ordinal Successor)}
If $a$ is an ordinal, then  $a\cup \set{a}$ is an ordinal.
\end{theorem}
\begin{proof}
  Notice that $b\in a\cup \set{a}\implies b \in a\text{ or }b\in \set{a}\implies b\in a\text{ or }b=a$. If $b=a\text{ and }b\in a$, we see $a\in a$, so we know $b\in a\cup \set{a}\implies b\in a\text{ exclusively or }b=a$. \\

The proofs for subset part and connected part are relatively simple. Let $x,y\in a \cup \set{a}$. If $x\in a$, then $x \subseteq a\subseteq a\cup \set{a}$. If $x=a$, then  $x=a\subseteq a\cup \set{a}$. Let $x\neq y$. If $x,y$ are both in  $a$, then the proof is finished. If, WOLG, $y=a$, then  $x \in a= y$.\\ 

We now prove \vi{the transitive part}.\\

 Let $x,y,z\in a \cup  \set{a}$ and $x\in y\text{ and }y\in z$. By axiom of foundation, it is impossible more than one of $x,y,z$ equals to  $a$. If $x=a$, then we have $y \in a$, so we see $\cdots a=x\in y\in a\in y \in a $, which implies it is impossible $x=a$. Similarly, we can deduce $y\neq a$. So far, we have proven $x\in a\text{ and }y\in a$. If $z\in a$, then because $a$ is an ordinal, our proof if done. If $z=a$, we see  $x\in a=z\vdone$\\


We now prove \blue{the well ordered part}.\\

Let $V\subseteq a \cup \set{a}$. By axiom of foundation, we know $a$ and $\set{a}$ are disjoint, so if $a\not \in V$, then $V \subseteq a$, and by the definition of $a$, our proof is finished.  If $a \in V$, we see either $a$ is the only element of  $V$ or  there exist element other than $a$ in $V$. If the situation is former, then the proof is trivially finished. If the situation is latter, then we observe $V \setminus \set{a} \subseteq a$, so $V \setminus \set{a}$ has a minimal element $x$, and  $x\in a$ indicate $x$ is also the minimal element of  $V\bdone$ 
\end{proof}
\begin{theorem}
\label{2.2.9}
  \textbf{(Basic Property of Ordinals)} If $a,b$ are ordinals, we have
   \begin{equation}
  a \in b \iff a \subset b
  \end{equation}
\end{theorem}
\begin{proof}
From left to right is relatively simple. If $a\in b$, then we have $a \subseteq b$. By axiom of foundation, we know $a \in b \implies  a\neq  b$, so we have $a \subset b$.\\

$(\longleftarrow)$\\

Let $a \subset b$. We wish to prove $a=x:=\min b\setminus a$, so that $a=\min b\setminus a\in b$. We now prove \vi{$x \subseteq a$} and prove  \blue{$a \subseteq x$}.\\

By definition of $x$, we have $\forall y\in b \setminus a, y\not\in x$. This tell us $b \setminus a$ and $x$ are disjoint. Because $x\subseteq b$, the fact that $b \setminus a$ and $x$ are disjoint tell us that $x \subseteq a\vdone$\\

Let $z\in a$, we wish to prove $z \in x$. Notice that $z \in a \subset b$, so because  $b$ is an ordinal and  $x \in b$, we know either $z\in x\text{ or }z=x\text{ or }x \in z$. \As{$x=z$}. We have  $\min b\setminus a =x =z \in a\tCaC$. \As{$x\in z$}. Because $a$ is an ordinal and  $z\in a$, we have $\min  b \setminus a = x \in z \subseteq a\tCaC$. Now we have $z \in x$ as desired $\bdone$
\end{proof}
\begin{lemma}
\label{2.2.10}
If $A,B$ are ordinals, then  $A \cap B$ is an ordinal.
\end{lemma}
\begin{proof}
Transitive and connected and well ordered of $A\cap B$ trivially inherit from that of $A$. Observe $x\in A \cap  B\implies x \in A\text{ and }x\in B\implies x\subseteq A\text{ and }x\subseteq B\implies x\subseteq A\cap B$, and we are finished.      
\end{proof}
\begin{theorem}
\label{2.2.11}
\textbf{(Trichotomy of Ordinals)} If $a,b$ are ordinals, we have
\begin{equation}
a \subset b \text{ or }a=b\text{ or }b \subset a
\end{equation}
\end{theorem}
\begin{proof}

\As{$a\not \subset b\text{ and }a\neq b\text{ and }b\not \subset a$}. We have $a\setminus b\neq \varnothing\text{ and }b\setminus a\neq \varnothing$, since, say, if $a\setminus b=\varnothing$, we have $a \subseteq b$.\\

By  \myref{Lemma}{2.2.10}, we know $a\cap b$ is an ordinal. Because $a \setminus b\neq \varnothing$, we know $a \cap  b \subset a$, and then by \myref{Theorem}{2.2.9} we have $a \cap  b \in a$. Similarly, we have $a \cap b \in b$. Then we have $a\cap  b \in a \cap  b\tCaC$
\end{proof}
\begin{corollary}
\label{2.2.12}
\textbf{(Trichotomy of Ordinals)} If $a,b$ are ordinals, we have
 \begin{equation}
a \in b\text{ or }a=b\text{ or }b\in a
\end{equation}
\end{corollary}
\begin{corollary}
\label{2.2.13}
\textbf{(The Class of All Ordinal is Totally Ordered)} 
The class of all ordinals is totally ordered by set-membership $\in$. 
\end{corollary}
\begin{proof}
The irreflexive and assymmetric part is trivially satisfied by axiom of foundation. The transitive part is simple: $x\in y\text{ and }y\in z\implies x\in y\subseteq z$. The connected part is just proven by \myref{Corollary}{2.2.12}. 
\end{proof}
\begin{theorem}
\label{2.2.14}
\textbf{(The Class of All Ordinals is Well Ordered)} Every set of ordinals has a $\in$-minimal element.
\end{theorem}
\begin{proof}
If not, then it contradicts to \myref{Theorem}{2.1.15}
\end{proof}
\begin{theorem}
\label{2.2.15}
\textbf{(Burali-Forti Paradox)}
All ordinals do not form a set.\\

Formally speaking,  define $P(S)$ are true if and only if $S$ is an ordinal. Then we have 
\begin{equation}
\neg \exists A\forall x(x \in A\longleftrightarrow P(x))
\end{equation}
\end{theorem}
\begin{proof}
\As{$\Omega$ is the set of all ordinals}. By \myref{Theorem}{2.2.14}, we see $\Omega$ satisfy at least irreflexive, asymmetric, trnasitive, connected and well ordering requirement of ordinal.\\

Let $x \in \Omega$, and $y \in x$. By \myref{Theorem}{2.2.7}, we know $y \in \Omega$, so in fact we have $x \subseteq \Omega$, which prove $\Omega$ is an ordinal. Then we have $\Omega \in \Omega \tCaC$
\end{proof}
\fbox{\begin{minipage}{39em}
Whewww, we have proved a lot of intended properties of ordinal. Notice that although there does not exist a set consist precisely of all ordinals. We still can mention the class of all ordinal by $Ord$.\\

 Notice that $Ord$ is in fact an extension of  $\N$, and it goes like this
  \begin{equation}
  0,1,2,3,\dots ;\omega, \omega+1,\omega +2,\dots
  \end{equation}
\end{minipage}}
\begin{theorem}
\label{2.2.16}
  \textbf{(All Naturals are Ordinals)} All element of  $\bigcap \call$ are ordinals. 
\end{theorem}
\begin{proof}
We prove by induction, which is  the $P_5(\bigcap  \call )$ of \myref{Theorem}{2.1.12}.\\

Notice that $\varnothing$ trivially satisfy all property of ordinals, which finish the proof for base step, and notice that by \myref{Theorem}{2.2.8}, the proof for induction step is also finished.  
\end{proof}
\begin{theorem}
\label{2.2.17}
\textbf{($\N$ as a set is an ordinal)} $\bigcap \call $ is an ordinal. 
\end{theorem}
\begin{proof}
By \myref{Theorem}{2.2.16}, we have proved that $\cap \call $ is a strictly totally ordered set. Notice that every subset of a well ordered set is well order, so it only left to prove the \vi{subset part} of definition of ordinal.\\

We prove by induction. Let $X:=\set{x \in \bigcap \call  : x \subseteq \bigcap \call }$. Base case: $\varnothing \in X$ is trivial. Let $a \in X$. Then we have $a\in \bigcap   \call$ and $a \subseteq \bigcap   \call $, so we have $a \cup \set{a} \subseteq \bigcap \call  \vdone$ 
\end{proof}
\begin{theorem}
\label{2.2.18}
\textbf{(Transfinite Induction)} 
Let $X$ be a nonempty ordinal. For all $x \in X$, we define 
\begin{equation}
S_x:=\set{z \in X: z\in x }
\end{equation}
Let $Y\subseteq X$. If $Y$ satisfy the property:
\begin{equation}
\forall x\in X( S_x \subseteq Y \longrightarrow x \in Y )
\end{equation}
we have $Y=X$
\end{theorem}
\begin{proof}
\As{$Y$ satisfy the property, but $Y\neq X$}. 
We first show \vi{$Y$ is nonempty}.  Because $X$ is an ordinal, we can pick an element $r \in X$ such that $\forall u \in X, r\in u$, so we have $S_r=\varnothing \subseteq Y$. Then because $Y$ satisfy the property, we have  $r \in Y\vdone$\\

Because $X$ is an ordinal, we know there exists  $x_0 \in X\setminus Y$ such that $\forall x\neq x_i\in X\setminus Y, x_0 \in x$.\\

Let $a \neq  x_0 \in X$, we know either $a \in Y$ or $a \in X\setminus Y$, we now prove \blue{$a \in x_0 \implies a \in Y$}. \As{$a \not \in Y$}, we then have $a\in X\setminus Y$, so we have $x_0 \in a \tCaC \bdone$.\\

The \blue{blue part} show that $S_{x_0} \subseteq Y$, so by the property of $Y$, we have  $x_0 \in Y$, but $x_0 \in X \setminus Y \tCaC$.

\end{proof}
\section{Axiom of Choice and its equivalents}

\fbox{\begin{minipage}{39em}
In this section, we aim to establish the equivalence between the Axiom of Choice and Zorn's Lemma. Additionally, we will explore and provide proofs for various applications of Zorn's Lemma. We'll begin by laying down foundational theorems in order theory, which will serve as our lemmas. Using these, we will demonstrate the progression from the Axiom of Choice to Zorn's Lemma. Interestingly, the reverse direction, proving from Zorn's Lemma to the Axiom of Choice, is considerably more straightforward and can be viewed as an "application" of Zorn's Lemma. Towards the end, we will delve into other notable applications of Zorn's Lemma.\\

Notice in this section, $P$ is a non-empty partially ordered set (poset).
\end{minipage}}
\begin{definition}
\label{2.3.1}
\textbf{(Definition of Chain)} We say  $X\subseteq P$ is a chain if $X$ is totally ordered. 
\end{definition}
\begin{definition}
\label{2.3.2}
\textbf{(Definition of Well Ordered Set)} Let $X\subseteq P$. We say  $X$ is well ordered only if $X$ is totally ordered.
\end{definition}
\begin{definition}
\label{2.3.3}
\textbf{(Definition of Upper Bound)} Let $X\subseteq P$. We say $X$ is bounded above by  $t$ if
\begin{equation}
\forall x \in X, x\leq t
\end{equation}
\end{definition}
\begin{definition}
\label{2.3.4}
\textbf{(Definition of Initial Segment)} Let $C$ be a chain of $P$. We say $T$ is an initial segment of $C$ if
\begin{equation}
T\subseteq C \text{ and }\forall  v\in T,\forall u\in C, u \leq v \implies  u \in T
\end{equation}
In this section, we denote the statement: $T$ is an initial segment of  $C$ by $T\subseteq' C$, and we denote $T\subseteq'C\text{ and }T\neq C$ by $T\subset' C$
\end{definition}
\begin{lemma}
\label{2.3.5}
An initial segment of a chain is also a chain
\end{lemma}
\begin{lemma}
\label{2.3.6}
Let  $S \subseteq P$ be well ordered and $t$ be an upper bound of  $S$. We have $S \cup \set{t}$ is also well ordered. 
\end{lemma}
\begin{proof}
Let $V \subseteq S\cup \set{t}\text{ and }V\neq \varnothing$ . If $V\cap S$ is empty, then we know $V=\set{t}$ and the proof is trivially finished. If $V\cap S$ is nonempty, let $x= \min V\cap S$. We know $y\in V\implies y \in V \cap S\text{ or }y=t$. If $y \in V\cap S$, then $x\leq y$ by definition of $x$. If  $y=t$, then  $x\leq t=y$ by $x\in S\text{ and the definition of $t$}$  
\end{proof}
\begin{lemma}
\label{2.3.7}
If $\cc$ is a set of well ordered chains in $P$ where 
 \begin{equation}
X,Y \in \cc \implies X\text{ is an initial segment of $Y$ or $Y$ is an initial segment of  $X$}
\end{equation}
then $\bigcup \cc$ is a well ordered chain 
\end{lemma}
\begin{proof}
Notice that the definition of $\cc$ implies
\begin{equation}
X,Y \in \cc \implies  X \subseteq Y\text{ or }Y\subseteq X
\end{equation}

Let $a,b \in \bigcup \cc $, and let $a \in A \in \cc, b \in B\in\cc$. Observe $A \subseteq B$ or $B \subseteq A\implies a,b \in A\text{ or }a,b \in B$, because $A,B$ are chains, we deduce $a,b$ are  comparable.  All the other properties of totally ordered set inherit from $P$, so we have proven  $\bigcup \cc$ is a chain.\\

We first prove \vi{$\gen{\cc,\subseteq'}$ is totally ordered.}\\

Connected part and antisymmetric part are implied by the definition of $\cc$. One can verify the reflexive part trivially hold true. Let  $A\subseteq'B\subseteq'C\text{ and }a\in A, c \in C\text{ and }c\leq a$. Because $a \in B$ and $B \subseteq' C$, we can deduce $c \in B$ from $c \leq a$. Then we can deduce $c \in A$ from $c \in B\text{ and }A\subseteq' B$, finishing the proof for transitive part $\vdone$\\


Let $V \subseteq \bigcup \cc$. We now prove \blue{$V$ contain a minimal element}.\\

Arbitrarily pick $X\in \cc$ so that $V\cap X$ is nonempty. Because $V \cap X \subseteq X$ and $X$ is well ordered, we know $\min V \cap X$ exists. \As{$\exists v' \in V, v'< \min V \cap  X$}. We know $\min  V\cap  X\in X\in \gen{\cc,\subseteq'}$. Let $S=\set{Z \in \cc : v' \in Z}$. If $X \in S$, then $v'\in V \cap  X$ contradicting to $v' <\min V\cap  X$, so we know $X \not\in S$. Observe $v' \in Z\subseteq ' X \implies  v' \in X $ causing the same contradiction, so we know every element in $S$ is greater than  $X$ with respect to  $\subseteq '$. We know $S$ is non empty, since  $v' \in V \subseteq \bigcup \cc$. Then we can arbitrarily pick $Z\in S$. By definition of initial segment, we can deduce $v' \in X$ from $v'<\min V \cap  X\text{ and } Z\subseteq' X \tCaC\bdone$ 
\end{proof}
\begin{lemma}
\label{2.3.8}
The class of initial segments of a chain is totally ordered by $\subseteq' $
\end{lemma}
\begin{proof}
Antisymmetric, reflexive and transitive parts are implied by definition of $\subseteq'$, as shown in the proof of  \myref{Lemma}{2.3.7}. Now we let $X$ be a chain and let  $A\subseteq' X\text{ and }B\subseteq' X$, and prove \vi{$A \subseteq' B\text{ or }B\subseteq' A$}\\

\As{$A\not\subseteq B\text{ and }B\not\subseteq A$}. Arbitrarily pick $x \in A\setminus B\text{ and }y \in B\setminus A$. We know $x\neq y$, since $y\not\in A\setminus B$. WOLG, let $x<y$. Because $x\in A\subseteq X$, where $y\in B$ and $B\subseteq' X$, so we deduce $x \in B\tCaC$\\

WOLG, let $A \subseteq B$. \As{$A\not\subseteq' B$}. Then there exists $a\in A,b\in B$ such that $b<a\text{ and }b\not\in A$. Yet, we see $A\subseteq' X,b\in X\text{ and }a \in A$, so we can deduce $b \in A\tCaC$ 
\end{proof}
\fbox{\begin{minipage}{39em}
While \myref{Lemma}{2.3.7} might appear to be a potent assertion, implying that the union of a totally ordered (by inclusion) set of well-ordered subsets is itself well-ordered, this is far from the truth. For instance, consider the union of the sets $\set{\set{-1},\set{-1,-2},\set{-1,-2,-3},\dots}$. This union is the set of negative integer, apparently not well-ordered, even though the set $\set{\set{-1},\set{-1,-2},\dots}$ is a set of well-ordered subsets of $\Z$ when ordered by inclusion. This counterexample is even more compelling than our original premise.\\

Next, we'll move on to demonstrating the link from the Axiom of Choice to Zorn's Lemma. But before delving into that, let's first formulate the concept of a function within the ZF set theory.
\end{minipage}}
\begin{definition}
\label{2.3.9}
\textbf{(Construction of Function)} In ZF, we interpret the set
\begin{equation}
\set{\set{a},\set{a,b}}
\end{equation}
as $(a,b)$ 
and we interpret the set 
\begin{equation}
\set{(x,y):x\in X, y \in Y}
\end{equation}
as a function from $X$ to  $Y$. Carefully notice we can construct predicate $Q(f)$ as below to tell if a set should be interpreted as a function.
\begin{equation}
\forall A (A \in f \longrightarrow \forall x (\set{x} \in A\longrightarrow  \exists yH(A,x,y)\lor A=\set{\set{x}})\land  G(f,A,x))
\end{equation}
where predicate $H(A,x,y)$ is defined by
\begin{equation}
x\neq y\land \set{x,y}\in A\land \forall z(z \in A\longrightarrow z=\set{x}\lor z=\set{x,y} )
\end{equation}
and predicate $G(f,A,x)$ is defined by 
\begin{equation}
\forall B (B \in f\longrightarrow B=A\lor \set{x}\not\in B)
\end{equation}
Also, carefully notice we can construct predicate $Q_{f}(x,y)$
\begin{equation}
\exists A\in f(\set{x}\in A\land \set{x,y}\in A)
\end{equation}
which if hold true should be interpreted as $f(x)=y$
\end{definition}
\begin{theorem}
\label{2.3.10}
\textbf{(Axiom of Choice Implies Zorn's Lemma)}
If \begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
\textbf{AC:} For each set of nonempty sets  $Y$, there exists a function $f:Y\rightarrow \bigcup Y$ such that $f(X)\in X$ 
\end{minipage}
\end{center}
Then
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
       \textbf{Zorn's Lemma:} For every partially ordered set $P$ such that every chain is bounded, there exists a maximal element. 
    \end{minipage}
\end{center}
\end{theorem}
\begin{proof}
Because the set of upper bound of chain is always nonempty, we can let $g$ be a function that map each chain $C$ in  $P$ to the set of upper bounds of $C$, and let $h$ be a choice function on image of $g$. Then, we define $f=h\circ g$, so we have  $\forall x \in C, x\leq f(C)$.\\

The above use the axiom of choice. We now define 
\begin{multline}
\cc:=\set{C\subseteq P: C\text{ is well ordered},\min C=p,T\subset' C\longrightarrow f(T)=\min C\setminus T}
\end{multline}
We see $\set{p}\in \cc$, so $\cc$ is nonempty. We first prove \vi{$\gen{\cc,\subseteq'}$ is totally ordered}.\\

Reflexive part, transitive part and antisymmetric part are implied by the definition of $\subseteq'$, as shown in the proof of \myref{Lemma}{2.3.7}. Let $A,B \in \cc$, and define
\begin{equation}
R:=\bigcup \set{T: T \subseteq' A\text{ and }T\subseteq' B}
\end{equation}
Let $x\in R\text{ and }y \in A$. Then we find $T$ such that $x \in T\subseteq' A$. Observe if $y<x$, then $y\in T \subseteq R$. This prove $R\subseteq' A$. Similarly, we can prove $R\subseteq' B$. Then by the definition of $R$, we know  $R$ is greatest common initial segment of  $A\text{ and }B$.\\

\As{$R\subset' A\text{ and }R\subset' B$}. Then we see $f(R)=\min A\setminus R=\min B\setminus R$. Let $a\inA\text{ and }r'\in R\cup \set{f(R)}$. Observe
\begin{equation}
a<r' \implies \begin{cases}
  a<f(R)=\min A\setminus R\\
  a<r \in R\subseteq' A
\end{cases}\implies \begin{cases}
  a \not\in A\setminus R\\
  a \in R
\end{cases}\implies a\in R
\end{equation}
So we have $R\cup \set{f(R)}\subseteq' A$. Similarly we have $R\cup \set{f(R)}\subseteq' B$. Because $f(R)=\min A\setminus R\not\in R$, so we know $R\subset R\cup \set{f(R)}\subseteq R\text{ by definition of $R$ }\tCaC$\\

Because $R\subseteq' A\text{ and }R\subseteq' B$. WOLG, we can let $R=A$, and we see $A=R\subseteq' B\vdone$\\

Let 
\begin{equation}
U:=\bigcup \cc
\end{equation}
We now prove \blue{$U\in \cc$}.\\

Notice that by \myref{Lemma}{2.3.7}, we know $U$ is a well ordered chain. Because $x \in U \implies \exists D,x \in D \in \cc\implies p\leq x$, so $p$ is also the minimal element of  $U$. Then now we only have to prove \blue{$T\subset' U\longrightarrow  f(T)=\min U\setminus T$}. \\

Arbitrarily find $T\subset' U$, and arbitrarily pick $s \in U\setminus T$. By definition of $U$, we know there exists $S\in \cc$ such that $s \in S$.\\

We wish to prove \teal{$S\subseteq' U$}. Arbitrarily pick $v \in U$ less than $s$ and let $v \in V \in\cc$. By \vi{violet part}, we know $S\subseteq' V\text{ or }V\subseteq' S$. If $V\subseteq' S$, then we prove $v<s \implies v \in V\subseteq S$. If $S\subseteq ' V$, then $v<s \implies  v \in S$. Notice both of them mean $S \subseteq' U$, since $v$ is arbitrarily picked from  $U\tdone$.\\



Because $T\subseteq' U\text{ and }S\subseteq' U$, by \myref{Lemma}{2.3.8}, we know either $S\subseteq' T\text{ or }T\subseteq' S$. Notice $s \in S\text{ and }s\in U\setminus T$, so we know $T\subset' S$. Then because $S \in \cc$, we know $f(T)=\min S\setminus T$. Notice that it can be trivially proved  $S\subseteq' U \implies S\setminus T \subseteq' U\setminus T$, so in fact we have $f(T)=\min S\setminus T=\min U\setminus T\bdone$\\

\As{$U$ does not contain a maximal element of  $P$}. We now prove \vi{$U\cup \set{f(U)}\in \cc$}\\

Notice that by \myref{Lemma}{2.3.6}, we know $U\cup \set{f(U)}$ is a well ordered chain, and because $f(U)$ is an upper bound of $U$, we know $p=\min U\cup \set{f(U)}$, so we only have to prove \vi{$T\subset' U\cup \set{f(U)}\longrightarrow f(T)= \min U\cup \set{f(U)}\setminus T} $}.\\

Because $f(U)$ is an upper bound of $U$, we see  $f(U)=\max U\cup \set{f(U)}$, and because $U$ contain no maximal element, we know  $f(U)\not\in U$, that is, $U\subset U\cup \set{f(U)}$.\\

Notice we have $f(U)\not\in T$, since $f(U)\in T\implies T=U\cup \set{f(U)}$. Then observe 
\begin{gather}
f(U)\not \in T\text{ and }T\subset' U \cup \set{f(U)}\\
\implies T\subseteq' U\\
\implies T=U\text{ or }T\subset' U\\
\implies f(T)=f(U)=\min U\cup \set{f(U)}\setminus U=\min U\cup \set{f(U)}\setminus T\\
\text{ or }f(T)=\min U\setminus T=\min U\cup \set{f(U)}\setminus T\vdone
\end{gather}


Then we see $U\cup \set{f(U)}\in \cc\implies U\cup \set{f(U)}\subseteq \bigcup \cc= U \tCaC$
\end{proof}
\fbox{\begin{minipage}{39em}
We will first delve into a straightforward application of Zorn's Lemma. Following that, we'll demonstrate how Zorn's Lemma inherently suggests the Axiom of Choice.
\end{minipage}}
\begin{theorem}
\label{2.3.11}
\textbf{(Zorn's Lemma Implies Every Vector Space Has a Basis)} If
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
       \textbf{Zorn's Lemma:} For every partially ordered set $P$ such that every chain is bounded, there exists a maximal element. 
    \end{minipage}
\end{center}
then 
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
        Every vector space has a basis.
    \end{minipage}
\end{center}
\end{theorem}
\begin{proof}
  Let $V$ be a vector space and let  $\mathcal{X}$ be the set of all linearly independent set of  $V$.  Order  $\mathcal{X}$ by inclusion, we now prove \vi{every chain $\cc$ in $\mathcal{X}$ is bounded above by $\bigcup \cc$}.\\

We first prove \teal{$\bigcup \cc$ is linearly independent}. Arbitrarily pick a finite subset $S$ of  $\bigcup \cc$, and for each vector $s_i \in S$, pick a linearly independent set $S_i \in \cc$ such that $s_i \in S_i$. Let $S_n$ be the maximal element of  $\set{S_i}$ by inclusion. Then we have $S\subseteq S_n$, so $S$ is linearly independent $\tdone$\\

By definition, we have $C\in \cc\implies C \subseteq \bigcup \cc\vdone$.\\

Then by Zorn's Lemma, we know there exist a maximal element $W$ of $\mathcal{X}$. We now prove \blue{$U$ spans  $V$}.\\

\As{there exists $v\in V\setminus \text{span}(U)$}. Then we see $U\subset U\cup \set{v}$ and see $U\cup \set{v}\in \mathcal{X}\tCaC\bdone$
\end{proof}
\fbox{\begin{minipage}{39em}
In direct application of  Zorn's Lemma, especially those involving chains ordered by inclusion, a common tactic is to use the union of a chain as an upper bound. Conceptually, this can be likened to computing the limit or supremum of a monotonically increasing sequence.\\

We now prove that Zorn's Lemma also implies axiom of choice, so we know Zorn's Lemma is equivalent to axiom of choice.
\end{minipage}}
\begin{theorem}
\label{2.3.12}
\textbf{(Zorn's Lemma Implies Axiom of Choice)} If 
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
\textbf{Zorn's Lemma:} For every partially ordered set $P$ such that every chain is bounded above, there exists a maximal element     
    \end{minipage}
\end{center}
Then
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
        \textbf{AC:} For each set of nonempty set  $Y$, there exists a function $f:Y\rightarrow \bigcup Y$ such that $f(X)\in X$ 
    \end{minipage}
\end{center}
\end{theorem}
\begin{proof}
Notice that we prove the theorem in the sense of ZF.\\

  Let $P$ be the set of all function $f$ from subset of  $Y$ to  $\bigcup Y$ such that $f(X)\in X$. In $P$, we define
\begin{equation}
g\leq h\text{ if }g\subseteq h
\end{equation}
Let $\cc$ be a chain in $P$, we  now prove \vi{$\bigcup \cc$ is an upper bound of $\cc$}.\\

Let $A \in \bigcup \cc$, so we know there exists $f \in \cc$, such that $A\in f$, then we know $A$ is indeed a set of the form  $\set{\set{x},\set{x,y}}$.\\

Let $B=\set{\set{x},\set{x,y}}\in \bigcup \cc$. \As{$\exists z, \exists C\in \cc, C=\set{\set{x},\set{x,z}}\in \bigcup \cc$}. Arbitrarily find $B',C'$ such that  $B\in B' \in \cc$ and $C \in C'\in \cc$. Then WOLG, let $B'\subseteq C'$, so we see $B\in C'$ then we see $C'$ is not a function  \CaC. For now we have proven $\bigcup \cc \in P$, then the fact that $\bigcup \cc$ is an upper bound of $\cc$ trivially follows. $\vdone$ \\

Let $f$ be a maximal element of  $P$. \As{Domain of  $f$ is a proper subset of  $Y$}. Then we can arbitrarily select an element $X\in Y\setminus Dom(f)$, and arbitrarily select an element $x\in X$, then define $f'=f\cup \set{\set{X},\set{X,x}}\tCaC$
\end{proof}
\fbox{\begin{minipage}{39em}
In the proof above, there are a couple of crucial observations to make:\\

\textbf{Brevity of the Proof:} The proof is notably more concise than proving that the Axiom of Choice (AC) implies Zorn's Lemma. This conciseness is a reason why some might prefer to take Zorn's Lemma as an axiomatic starting point, even though it's just an equivalent formulation of AC.\\

\textbf{Choice from a Set:} In the concluding section of the proof, we "select" an element from specific sets on two occasions. Beginners might assume that a choice function can only be defined if AC is assumed. However, this isn't the case for a finite collection of sets. One doesn't necessarily need the Axiom of Choice for this.\\

The real potency of the Axiom of Choice lies in its ability to address \textit{situations that demand an infinite sequence of selections, where there's no predefined order or method to the selection process}.\\

In our proof, when we "select" an element, it's from a singular set. Consequently, the domain of this choice function is of cardinality $1$. It's evident that the Axiom of Choice isn't necessary here.\\

To delve into why the Axiom of Choice isn't required for finite situations, consider attempting a formal construction of a choice function for the set $\set{\set{1,2},\set{3,4},\set{5,6}}$.\\

At this point, one may wonder, is it true that no construction of choice function on countable set of nonempty set require Axiom of Choice? This question in simple words want to ask: if a set $ X$ is countable, meaning I have already build a bijective function from $\N$ to $X$, meaning I can well order $X$, and to select an element from one nonempty set is doable as above explained, why can't I recursively do this and have a choice function on $X$? The answer is: To \textit{recursively} do such, what we should do is to construct a function $g$ that maps nonempty set to an element of itself, and recursively define the desired choice function by $f(x)=g(x)$, but one can see this fake "technique" is not only trivial, and more importantly, wrong, since without AC, we don't know if $g$ exists, let alone using $g$ to construct  $f$.
\end{minipage}}
\begin{theorem}
\label{2.3.13}
\textbf{(Zorn's Lemma Implies Well Ordering Theorem)}  
If
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
        \textbf{Zorn's Lemma:} For every partially ordered set $P$ such that every chain is bounded above, there exists a maximal element.
    \end{minipage}
\end{center}
then
\begin{center}
    \begin{minipage}{0.9\linewidth}  
        \centering
       \textbf{Well Ordering Principle:} Every set $X$ can be well ordered.
    \end{minipage}
\end{center}
\end{theorem}
\begin{proof}
Define
\begin{equation}
P:=\set{(A_i,\leq_i): A_i\subseteq X\text{ and }A_i\text{ is well ordered by $\leq_i$ }}
\end{equation}
and we define a partial order $\leq $ for $P$ by
\begin{equation}
  (A_i,\leq_i)\leq (A_j,\leq _j)\text{ if }A_i\subseteq' A_j\text{ with respect to $\leq_j$ and }x_i\leq_i y_i\longrightarrow x_i\leq_j y_i 
\end{equation}
Let $\cc_d$ be a chain of $P$. Define order $\leq_d$ on $\bigcup \cc_d$ by
\begin{equation}
x\leq_d y\text{ if }\exists A_i\in\cc_d, x,y\in A_i\text{ and }x\leq_i y
\end{equation}
we first prove \vi{$\leq_d$ is well defined}, which is just to prove that $\leq_d$ is antisymmetric. Let $x\leq_d y\text{ and }y\leq _dx$, and let $x,y\in A_i\cup A_j$ such that $x\leq_i y\text{ and }y\leq _jx$. Because $\cc$ is a chain, WOLG, let $A_i\leq A_j$, we then have  $x\leq_j y\text{ and }y\leq _jx$, so $x=y\vdone$\\

We now prove  \blue{$\leq_d$ is reflexive, connected and transitive}.\\

For reflexive, notice $x\in \bigcup\cc_d$ implies $\exists A_i\in\cc_d, x \in A_i$, and the rest is trivial. For connected, for $x,y\in \bigcup \cc_d$, let $x\in A_i \in\cc_d\text{ and }y\inA_j\in\cc_d$. Because $\cc$ is a chain, WOLG, we can let $A_i\leq A_j$, and then we see $x,y\in A_j$, so because $A_j$ is totally ordered by $\leq_j$, we know $x,y$ is comparable by  $\leq_d$. For transitive, let $x\leq_d y\leq _d z$, and let $x,y\in A_i\in\cc_d\text{ and }x\leq _iy\text{ and }y,z\inA_j\in\cc_d\text{ and }y\leq _jz$. If $A_j\leq A_i$, we see $x\leq_i y\leq_i z$, then the proof is finished. If $A_i\leq A_j$, we see $x\leq_j y\leq_j z\bdone$.\\

We now prove \vi{$\bigcup \cc_d\in P$}, which is just to prove $\bigcup \cc_d$ is well ordered by $\leq_d$.\\

Let $V\subseteq \bigcup \cc_d$, and arbitrarily pick $A_i\in \cc_d$ such that $A_i\cap V$ is nonempty, because $A_i$ is well ordered by  $\leq _i$, we know there exists an minimal element $v'$ of $A_i\cap V$ with respect to $\leq _i$. Let $v \in V$, if $v\in A_i\cap V$, then by definition of $\leq _d$, we see $v'\leq_d v$. If $v\in V\setminus A_i$, then for each $A_j\in\cc$ containing $v$, we know $A_i\subset A_j$, and because $\cc$ is a chain, we know $A_i\leq A_j$. \As{$v\leq _j v'$}, because $v'\in A_i\subseteq' A_j$, we can deduce $v'\in A_i\tCaC$, so we have $v'<_j v$, which implies $v' <_d v$. We have proved $v'$ is the smallest element of $V\vdone$ \\

We now prove  \blue{$\bigcup \cc_d$ is an upper bound of $\cc_d$ with respect to $\leq $}. Arbitrarily pick $x_i,y_i\in A_i\in \cc_d$,  we immediately see $x_i\leq _iy_i\implies x_i\leq _dy_i$, so we only have to prove $A_i\subseteq' \bigcup \cc_d$ with respect to $\leq _d$. \teal{Let $v_i\in A_i,v_j\in\bigcup \cc_d\text{ and }v_j\leq _dv_i$}. Arbitrarily pick $A_j$ containing  $v_j$ and  \As{$v_j\not\inA_i$}, so we have $A_i<A_j$. Because $v_j\leq_d v_i\text{ and }v_i,v_j\in A_j$, we know $v_j\leq _jv_i$. Then because $A_i\subseteq' A_j$ with respect to $\leq _j$, we have $v_j\in A_i\tCaC$. We have proved $v_j\in A_i$ by rejecting the red assumption. Notice the \teal{premise}. We have proved $A_i\subseteq' \bigcup \cc_d$ with respect to $\leq _d\bdone$\\

Let $(A_k,\leq _k)$ be a maximal element of $P$.  \As{$A_k\subset X$}, we can arbitrarily pick $x\in X\setminus A_k$, and for all $a_k\in A_k$ define $a_k\leq_k x$. By \myref{Lemma}{2.3.6}, we see $(A_k\cup \set{x},\leq _k)$ is well ordered, so $(A_k\cup \set{x},\leq _k)\in P$. To prove $(A_k,\leq _k)<(A_k\cup \set{x},\leq _k)$ is trivial. \CaC
\end{proof}
\section{Cardinality and Cardinal}
\fbox{\begin{minipage}{39em}
In this section, we first present a definition and a theorem as a primer rather than the primary focus. This serves as a foundation to instill confidence in the reader regarding the use of set theory language.
\end{minipage}}
\begin{definition}
\label{2.4.1}
\textbf{(Formulation of Property of Function)}
We use predicate $P(f)$ 
\begin{equation}
\forall A\forall B(A\in f\land B\in f\land \exists x(\set{x}\in A\land \set{x}\in B)\longrightarrow A=B)
\end{equation}
to tell if $f$ is injective, and we use predicate  $P(f,Y)$ 
\begin{equation}
\forall y\exists A\exists B((A=\set{\set{y}}\land A\in f)\lor (A\in f\land B\in A\land y  \in B\land \exists x(x\in B\land x\neq y) ))
\end{equation}
\end{definition}
\begin{theorem}
\label{2.4.2}
\textbf{(Basic Property of Function)} There exists a one-to-one function from $A$ to  $B$ if and only if there exists an onto function from  $B$ to  $A$
\end{theorem}
\fbox{\begin{minipage}{39em}
While it's straightforward to "prove" the theorem, formalization of such proof offers a robust assurance of its correctness. I encourage you to attempt formalization. With that, let's delve into the topic of cardinality, and introduce a highly useful theorem.
\end{minipage}}
\begin{definition}
\label{2.4.3}
\textbf{(Definition of Cardinality)} 
We write 
\begin{equation}
A\leq _c B\text{ or write }B\geq _cA
\end{equation}
If there exists a one-to-one function from $A$ to  $B$, or, equivalently, if there exists an  onto function from $B$ to  $A$. Also, we write 
\begin{equation}
A=_c B
\end{equation}
if there exists a bijective function from $A$ to  $B$  (one-to-one correspondence between $A,B$) 
\end{definition}
\begin{theorem}
\label{2.4.4}
\textbf{(Schroder-Berstein Theorem)} Let $A,B$ be sets. We have 
\begin{equation}
A\leq_c B\text{ and }B\leq _c A\iff  A=_c B
\end{equation}
\end{theorem}
\begin{proof}
Let $f:A\rightarrow B$, $g:B\rightarrow A$ be two one-to-one function.\\

Define $C_0:=A\setminus g(B) $, and for all nonnegative integer $k$, define 
\begin{equation}
C_{k+1}:=g(f(C_k))
\end{equation}
Also, Define
\begin{equation}
C:=\bigcup _{k=0}^{\infty} C_k
\end{equation}
Define
\begin{equation}
h(x):=\begin{cases}
  f(x) & x\in C \\
  g^{-1}(x) & x\inA\setminus C
\end{cases}
\end{equation}
We first prove \vi{$h$ is defined every where on $A$}.\\

Because $C_0\subseteq C$, we know that $A\setminus C \subseteq A\setminus C_0=A \setminus (A\setminus g(B))$. Then we can deduce
\begin{gather}
x\in A \setminus C \implies x\inA \setminus (A \setminus g(B))\\
\liff x\inA\text{ and }x\not\inA \setminus g(B)\\
\liff  x\inA\text{ and }(x\not\inA\text{ or }x\in g(B))\\
\liff (x\inA\text{ and }x\not\in A)\text{ or }(x\inA\text{ and }x\in g(B))\\
\liff x\inA\text{ and }x\in g(B)\\
\liff x\in g(B) \vdone
\end{gather}
We now prove \blue{$h$ is one-to-one}.\\

\As{there exists $x\neq y\inA$ such that $h(x)=h(y)$}. We know $x,y$ are not both in $C$, otherwise  $f$ is not one-to-one. We also know $x,y$ are not both in $A \setminus C$, otherwise $g$ is not a function. WOLG, let $x\in C\text{ and }y\inA \setminus C$, so we have $f(x)=g^{-1}(y)$. Then, we have $y=g(f(x))$. Because $x\in C$ , we know there exists a nonnegative integer $n$ such that $x\in C_n$. Then we see $y\in g(f(C_n))=C_{n+1}\tCaC\bdone$\\

Lastly we prove  \vi{$h$ is onto}.\\

We wish to prove $B=h(A)$, where 
 \begin{equation}
h(A)=f(C)\cup g^{-1}(A \setminus C)\text{ and }h(A)\subseteq B
\end{equation}
So we just prove
\begin{equation}
B\subseteq f(C)\cup g^{-1}(A \setminus C)
\end{equation}
Let $x\in B$. If all $x$ is in  $g^{-1}(A \setminus C)$, then the proof is over. If not, keep in mind that $g(x)\not\in C_0$, since $g(x)\in C_0=A \setminus g(B)$ implies $g(x)\not\in g(B)$ and observe 
\begin{gather}
x\not\in g^{-1}(A \setminus C)\\
\liff g(x)\not\in A \setminus C\\
\liff g(x)\in C \\
\liff \exists n\inn, g(x)\in C_n\\
\liff \exists n\inn, \exists u\in C_{n-1}, g(x)=g(f(u))\\
\liff \exists n\inn,\exists u\in C_{n-1}, x=f(u)\\
\liff x\in f(C) \vdone 
\end{gather}
\end{proof}
\fbox{\begin{minipage}{39em}
Schroder-Berstein Theorem in simple word is just that the relation $\leq_c$ between sets is antisymmetric. One may intuitively think such "simple" consequence should be easy to prove but in fact isn't.\\ 

That the relation $\leq _c$ is reflexive and transitive is trivial to prove. What being said, this does not implies $\leq _c$ is a "total order", since we haven't proved it is connected. 
\end{minipage}}
\begin{theorem}
\label{2.4.5}
\textbf{(Caridinality of All Set are Comparable if Given AC)} If given AC, for all sets $A,B$, we have 
 \begin{equation}
A\leq _c B\text{ or }B\leq _c A
\end{equation}
\end{theorem}
\begin{proof}
Let $P$ be the set of one-to-one function from subset of  $A$ to  $B$. We define order relation on  $P$ by 
\begin{equation}
f\leq g\text{ if }\forall x\in \text{Dom}(f), f(x)=g(x)\text{ and }\text{Dom}(f)\subseteq \text{Dom}(g)
\end{equation}
To prove this do define a order relation is trivial. By Zorn's Lemma, we can pick a maximal element of $f$. If Domain of  $f$ is not  $A$ and range of $f$ is not  $B$,  then we can define a larger function by arbitrarily picking  $x\in A\setminus \text{Dom}(f)$ and $y\in B\setminus \text{Im}(f)$ and defining  $f'(z)=\begin{cases}
  f(z)& \text{ if  }x\in \text{Dom}(f)\\
  y& \text{ if  }z=x
\end{cases}$. It is trivial to prove $f<f'$. 
\end{proof}
\fbox{\begin{minipage}{39em}
So far, we have proved $\leq _c$ is a total order on the class of all sets. Now, we give a necessary and sufficient condition of one set having strictly less cardinality than that of the other.
\end{minipage}}
\begin{definition}
\label{2.4.6}
\textbf{(Definition of Cardinality)} Let  $A,B$ be sets. If $A\geq _c B$ and there does not exist a one-to-one correspondence between $A$ and $B$, which we denote $A \neq _c B$, then we write
\begin{equation}
A>_c B\text{ or write }B<_c A
\end{equation}
\end{definition}
\begin{theorem}
\label{2.4.7}
\textbf{(Basic Property of Cardinality)} For all sets $A,B$, we have  
\begin{equation}
A>_c B\iff \text{ no function from $A$ to $B$ is one-to-one}
\end{equation}
\begin{equation}
A >_c B\iff \text{ no function from $B$ to $A$ is onto }
\end{equation}
\end{theorem}
\begin{proof}
The fact that an one-to-one function from $A$ to $B$ exists if and only if an onto function from $B$ to $A$ exists is proved in the beginning of the section, so we only have to prove the first iff and the proof is finished. From left to right, \As{there exists an one-to-one function from $A$ to $B$}. Because $A >_c B\implies A\geq _c B\implies $ there exists another one-to-one function from $B$ to $A$, so by Schroder-Berstein Theorem, we have $A =_c B\tCaC$. From right to left, \As{the negate of  $A >_c B$}. Notice the negate of $A>_c B$ is no function from  $B$ to $A$ is one-to-one or $A =_c B$. If $A =_c B$, then there exists a bijective, so an one-to-one function from $A$ to $B$. If no function from  $B$ to $A$ is one-to-one, and no function from $A$ to $B$ is one-to-one, then the cardinality of $A,B$ is incomparable \CaC  
\end{proof}
\fbox{\begin{minipage}{39em}

Notice that we haven't define the cardinality in a "constructive" manner. We defined cardinality by defining relation between sets. We now define cardinal, not cardinality, in a constructive manner compatible to our old definition.
\end{minipage}}
\begin{definition}
\label{2.4.8}
\textbf{(Von Neumann Cardinal Assignment)} We now assign each set $X$ to a cardinal
 \begin{equation}
\abso{X}=\min  \set{\sigma\in\text{ Ord }:\text{ and }\sigma =_c X}
\end{equation}
And we say an ordinal is a cardinal if the ordinal if an caridnality of some sets. 
\end{definition}
\begin{theorem}
\label{2.4.9}
\textbf{(Every Set Can be Assigned to a Cardinal if Given AC, Needed to be formalized)} For arbitrary set $X$, there exists an ordinal of same cardinality. More precisely, every well order set (some set can not be well ordered without AC) can be assigned a cardinal.
\end{theorem}
\begin{proof}
By AC, we can well order $X$. Define function $f$ that map ordinal to  element in $X$ by
 \begin{equation}
f(0):=\min X\text{ and }f(\alpha ):=\min X\setminus \set{f(\beta ):\beta <\alpha }
\end{equation}

\As{$\forall \alpha \in\text{Ord }, f[\alpha ]\subset X$}. Then we know $\text{Ord$=$Dom}(f)$, and then we can formally construct a inverse function $f^{-1}$, and formally construct the set that is the image of $f^{-1}$, which we know is Ord. \CaC
\end{proof}
\begin{theorem}
\label{2.4.10}
\textbf{(Compatibility between Von Neumann Cardinal and Ordinal)} For all set $A,B$, we have
 \begin{equation}
A<_c B \implies  \abso{A}\in \abso{B}\text{ and } A=_c B\implies \abso{A}=\abso{B}\text{ and }n\in \bigcap  \call \implies \abso{n}=n
\end{equation}
where infimum is with respect to strict well order $\in$ on the class of ordinals. 
\end{theorem}
\begin{proof}
\As{$\abso{B}\in \abso{A}$}. Notice that trivially we can prove the relation $=_c$ on the class of all sets is symmetric, so we have $A<_c B$, since if $A=_c B$, we should by definition have $\abso{B}=\abso{A}$. Notice $\abso{B}\in \abso{A}\implies \abso{B}\subset \abso{A}$, so we have an one-to-one function from $\abso{B}$ to $\abso{A}$ by mapping each element of $B$ to itself, then we have $\abso{B}\leq_c \abso{A}$, notice that by definition we have $B=_c \abso{B}\leq _c \abso{A}=_c A$. Then we can construct function by composition to show $B\leq _c A\tCaC$.\\




We prove by induction. Base case is simple: notice $\varnothing=_c \varnothing$ implies $\varnothing \in \set{\sigma \in\text{Ord}:\sigma =_c \varnothing}$, so we have $\abso{\varnothing}=\varnothing$. For induction case, let $k\in \bigcap \call \text{ and }\abso{k}=k$, we wish to prove \vi{$k\cup \set{k}=\min \set{\sigma\in\text{Ord}:\sigma=_c k\cup \set{k}}$}. Trivial, we have $k\cup \set{k}\in \set{\sigma\in\text{Ord}:\sigma=_c k \cup \set{k}}$. We first prove \teal{$k$ is the greatest ordinal in  $k\cup \set{k}$}. Let $m \in k\cup \set{k}$. \As{$k \in m$}. Then by definition of ordinal we  have  $k\subseteq m$, and because $k \in m$, we then have $k\cup \set{k}\subseteq m$. On the other side, notice by definition of ordinal we have $m\subseteq k\cup \set{k}$, so in summary we have $m=k\cup \set{k}\tCaC\tdone$. So, we see if $k\cup \set{k}$ is not the smallest element of $\set{\sigma:\sigma=_c k\cup \set{k}}$, then $k$ belong to  $\set{\sigma:\sigma=_c k \cup \set{k}}$. We now prove $k\neq_c k\cup \set{k}$ by induction. Base case is trivial: $\varnothing\neq _c \set{\varnothing}$. We now prove $k\neq _c k \cup \set{k}\longrightarrow k\cup \set{k}\neq _c k\cup \set{k}\cup \set{k \cup \set{k}}$. \As{there exists a bijective function $f$ from $k \cup  \set{k}$ to $k\cup \set{k}\cup \set{k \cup \set{k}}$ }. Then we can define a bijective function $g(x):k\rightarrow k\cup \set{k}$ by $\begin{cases}f(k)& \text{ if  }x=f^{-1}(\set{k\cup \set{k}})\\
  f(x)& \text{ if  }x\neq f^{-1}(\set{k\cup \set{k}})
\end{cases}\tCaC\vdone$
\end{proof}
\fbox{\begin{minipage}{39em}
The theorem discussed above is fundamental to the theory of ordinals and cardinals. However, it is infrequently employed in the discussions of real analysis. This is because, using the elementary methods of set description, the sets under consideration often possess cardinalities equivalent to either $\mathbb{N}$, $\mathbb{R}$, or are finite.\\

We now present the standard definition of \textit{infinite} in the language of set theory, a definition widely accepted in most analysis texts. Subsequently, we introduce the concept of \textit{Dedekind-infinite}. This definition harnesses our intuition: that shifting every term in an infinite sequence is permissible. It's important to note that the traditional definition of \textit{infinite} and that of \textit{Dedekind-infinite} are not always equivalent. However, if the Axiom of Choice (AC) holds true, then these definitions become equivalent. Since most people in the mathematical community accept AC, the two definitions are often treated as equivalent in practice.
\end{minipage}}
\begin{definition}
\label{2.4.11}
\textbf{(Definition of Infinite)} We say a set $A$ is finite if there exists an ordinal $\sigma$ in $\bigcap  \call $ such that $\abso{A}=\sigma$, and we say $A$ is infinite if $A$ is not finite. 
\end{definition}
\begin{definition}
\label{2.4.12}
  \textbf{(Definition of Dedekind Infinite)} Let $A$ be a set. We say $A$ is Dedekind-infinite if there exists a proper subset of $A$ that have the same cardinality as $A$, and we say $A$ is Dedekind-finite if $A$ is not Dedekind-infinite.
\end{definition}
\begin{theorem}
\label{2.4.13}
\textbf{(Equivalence of Infinite and Dedekind Infinite under AC)} Under AC, a set $A$ is infinite if and only if  $A$ is Dedekind-infinite.
\end{theorem}
\begin{proof}
We first prove \vi{$A$ is finite  $\implies A$ is Dedekind-finite} by induction. Base case is trivial, since $\varnothing$ doesn't even have  proper subsets. For induction case, let $k\in \bigcap \call $ be Dedekind-finite. \As{$\exists m\subset k\cup \set{k},m=_c k\cup \set{k}$}. If $m$ contain  $k$, then we have  $m\setminus \set{k}\subseteq k\text{ and }m\setminus \set{k}=_c k$, where we use the same technique in proof of \myref{Theorem}{2.4.10}. So we know $m\subseteq k$. Then we have $k\cup \set{k}=m\leq_k k\tCaC\vdone$.\\

We now prove \teal{$A$ is infinite  $\implies A$ is Dedekind-infinite}. Define function 
\begin{equation}
f:\N\rightarrow \power{\power{A}}, n\mapsto \set{X:\power{A}:\abso{X}=n}
\end{equation}
We first prove \vi{for all naturals  $n$, we have  $f(n)$ is nonempty} by induction.\\

$f(1)$ is nonempty since we can arbitrarily select an element and use axiom of pairing to construct a singleton subset. If $f(k)$ is nonempty, we can arbitrarily select an element $X$ from $f(k)$ and to see if $A=X$ then $A$ is finite, so we can arbitrarily select an element from $A\setminus X$ and attach to $X$ to show  $f(k+1)$ is nonempty.  $\vdone$\\

We now \blue{construct a bijective from $A$ to a proper subset missing one element by constructing a countable subset $U$ of $A$ and map each element  in $U$ to its successor}.\\

By AC, we know there exists a function $g(n)$ such that $\forall n\inn, g(n)\in f(n)$. Let $U=\bigcup g[\N]$. Define $h:U\rightarrow \N$ by mapping elements in $g(n)$ to elements in $\set{x \inn: \frac{(n-1)n}{2}<x\leq \frac{n(n+1)}{2}}$. $h$ is onto, since  $U=\bigcup g[\N]$, and because $\abso{g(n)}=n=\abso{x\inn:\frac{(n-1)n}{2}x\leq \frac{n(n+1)}{2}}$, we know $h$ is one-to-one. Now we define function $B:A\rightarrow A\setminus \set{h^{-1}(1)}$, where $y$ is the element in  $U$ that was mapped to  $1$ by
\begin{equation}
B(x)=\begin{cases}
  x& \text{ if  }x\not\in U\\
  h^{-1}(h(x)+1)& \text{ if  }x\inU\bdone\tdone
\end{cases}
\end{equation}
\end{proof}
\begin{corollary}
\label{2.4.14}
\textbf{($\N$ is the "smallest" infinite set)} Every infinite set have either same or greater cardinality than $\N$ 
\end{corollary}
\begin{proof}
Consider the set $U$ in proof above.
\end{proof}
\begin{corollary}
\label{2.4.15}
\textbf{(Another Definition of Infinity)} A set is infinite if and only if it has cardinality equal to or greater than $\N$
\end{corollary}
\fbox{\begin{minipage}{39em}
Now, we will demonstrate a few theorems specific to countable cardinalities. While these can be generalized to encompass all cardinalities using more advanced set theory tools, our final theorem will be applicable to all cardinalities without exception.
\end{minipage}}
\begin{definition}
\label{2.4.16}
\textbf{(Definition of Countable)} We say a set is countable if the set has cardinality less than or equal to $\N$
\end{definition}
\begin{theorem}
\label{2.4.17}
\textbf{(Finite Cartesian Product of Countable Set is Countable)} For all naturals $n$, we have $\abso{\N^n}=\abso{\N}$ 
\end{theorem}
\begin{proof}
  Because we can map $p\mapsto (p,1,\dots ,1)$, we know $\abso{\N}\leq \abso{\N^n}$. Because we know $\abso{X_m:=\set{(p_1,\dots, p_n) \in \N^n :\sum p_i=m}}=H^n_{m-n}$, we can map each element in $X_m$ one-to-one into  $(\sum_{i=3}^{m-1} H^n_{i-n},\sum ^m_{i=3}H^n_{i-n}]$, so we know $\abso{\N^n}\leq \abso{\N}$
\end{proof}
\begin{theorem}
\label{2.4.18}
\textbf{(Countable Union of Countable Set is Countable)} Let $S=\set{E_n:n\inn}$ be a countable set of countable sets. We have $\bigcup S$ is countable.  
\end{theorem}
\begin{proof}
For each $n\inn$, because $E_n$ is countable, we can define  bijective $f_n:\N\rightarrow E_n$. Define $g:\N \rightarrow  \bigcup S$ by
\begin{equation}
g(x)=f_{m-(h-2)}(h)\text{ where }m=\max \set{n\inn: \frac{(n+1)n}{2}< x}\text{ and }h=x-\frac{(m+1)m}{2}
\end{equation}
We now prove \vi{$g$ is onto}.\\

Let $x\in \bigcup S$, we know $\exists p\inn, x\in E_p$, so we know $\exists p,q\inn, x=f_p(q)$. One can verify $g(q+\frac{(p+q-2)^2+(p+q-2)}{2})=f_p(q)=x$ where $m=p+q-2\text{ and }n=q\vdone$
\end{proof}
\begin{theorem}
\label{2.4.19}
\textbf{(Every Nonempty Set Has Cardinality Strictly Less than Its Power Set)} If $A$ is nonempty, then  $\abso{A}<\abso{\power{A}}$.
\end{theorem}
\begin{proof}
Let $f$ be a function from $A$ to  $\power{A}$. Define $T=\set{a\in A:a\not\in f(a)}$. Observe $b \in T\implies b\not\in f(b)\implies T\neq f(b)$ and observe $b\not\in T\implies b\in f(b)\implies T\neq f(b)$, so $T\in \power{A}\setminus f[A]$.  
\end{proof}
\section{Different but Equivalent Ways to Define A Topology}
\fbox{\begin{minipage}{39em}
This section illustrates three methods to define a topology. However, in practice, the approach using open sets is predominantly employed.
\end{minipage}}
\begin{definition}
\label{2.5.1}
\textbf{(Definition of Topology, via Open Set)} Given a set $X$, which called a topological space, if we say a family $\mathfrak{O}$  of subsets of $X$ is a topology on $X$, then we mean
\begin{gather}
X, \varnothing \in \mathfrak{O}\\
A,B\in\mathfrak{O}\implies A\cap B\in\mathfrak{O}\\
\mathfrak{U}\subseteq \mathfrak{O}\implies \bigcup \mathfrak{U}\in \mathfrak{O}
\end{gather}
If a subset of $X$ belong to  $\mathfrak{O}$, we say it is an open set, and if a subset of $X$ is an complement of an open set, we say it is an closed set.
\end{definition}
\fbox{\begin{minipage}{39em}
The method above is the usual way to define a topology. Next, we'll look at some properties of closed sets. Keep in mind that the related properties for open sets are basic axioms
\end{minipage}}
\begin{theorem}
\label{2.5.2}
\textbf{(Property of Closed Sets)} Let $\mathfrak{F}$ be the family of precisely all closed sets in a topological space. We have
\begin{gather}
X,\varnothing \in \mathfrak{F}\\
A,B\in\mathfrak{F}\implies A\cup  B\in\mathfrak{F}\\
\mathfrak{B}\subseteq \mathfrak{F}\implies \bigcap \mathfrak{B}\in \mathfrak{F}
\end{gather}
\end{theorem}
\begin{proof}
\begin{equation}
X=\varnothing^c\text{ and }\varnothing=X^c\in \mathfrak{F}
\end{equation}
\begin{equation}
A,B\in \mathfrak{F}\implies A^c,B^c \in \mathfrak{O}\implies A^c \cap B^c=(A\cup B)^c \in \mathfrak{O} \implies A\cup  B \in \mathfrak{F}
\end{equation}
\begin{equation}
\mathfrak{B}\subseteq \mathfrak{F}\implies \set{F^c:F \in \mathfrak{B}}\subseteq \mathfrak{O}\implies \bigcup_{F\in \mathfrak{B}}F^c \in \mathfrak{O}\implies \bigcap \mathfrak{B}= (\bigcup_{F \in\mathfrak{B}} F^c)^c \in \mathfrak{F}
\end{equation}
\end{proof}
\begin{theorem}
\label{2.5.3}
\textbf{(Equivalent Ways to Define The Same Topology, Part 1)} Define $f$ on $\power{\power{X}}$ by 
\begin{equation}
f(\mathfrak{A})=\set{A^c:A\in \mathfrak{A}}
\end{equation}
If $\mathfrak{O}$ is a topology on $X$, then  $f(\mathfrak{O})$ are the family of precisely all closed sets on $X$. Also, we have
\begin{equation}
f=f^{-1}
\end{equation}
This mean if we are given a family of closed sets, the family of closed sets given by the topology induced by our original family is our original family.   
\end{theorem}
\begin{proof}
Trivial. 
\end{proof}
\fbox{\begin{minipage}{39em}
Let's move on to the axioms for the neighborhood system. After covering that, we'll demonstrate that these axioms and those for open sets aren't just interconnected – they're essentially the same thing. Notice the proof below uses Zorn's Lemma. 
\end{minipage}}
\begin{definition}
\label{2.5.4}
\textbf{(Definition of Neighborhood Function)} We say a function $\mathcal{N}:X\rightarrow \power{\power{X}}$ is neighborhood function if 
\begin{gather}
\forall x \in X,\mathcal{N}(x)\neq \varnothing\text{ (Existence) }\\
N \in \mathcal{N}(x)\implies x \in N\text{ (Around) }\\
\exists N \in \mathcal{N}(x), N\subseteq M\implies M\in \mathcal{N}(x)\text{ (Super set) }\\
N,M \in \mathcal{N}(x)\implies N \cap M\in \mathcal{N}(x)\text{ (Intersection) }\\
\forall N\in \mathcal{N}(x),\exists M\in \mathcal{N}(x), M \subseteq N\text{ and }\forall y \in M, N \in \mathcal{N}(y)
\end{gather}
The last property reads: every neighborhood $N$ around arbitrary point $x$ contain a neighborhood $M$ around $x$ such that $N$ is a neighborhood of each points of $M$.
\end{definition}
\begin{theorem}
\label{2.5.5}
\textbf{(Equivalent Ways to Define The Same Topology, Part 2)} There exists a one-to-one correspondence between the class of all topology on $X$ and the class of all neighborhood function on $X$.\\

The correspondence can be written in the form of 
\begin{equation} (g(\mathfrak{O}))(x)=\set{N\subseteq X: \exists O\in \mathfrak{O},x\in O\subseteq N}
\end{equation}
The inverse of $g$ will be proved to be
 \begin{equation}
g^{-1}(\mathcal{N})=\set{O:\forall x \in O, O\in \mathcal{N}(x)}
\end{equation}
\end{theorem}
\begin{proof}
  We first prove \vi{$g$ do map topology to neighborhood function}.\\

$g(\mathfrak{O})(x)$ is always nonempty because
\begin{equation}
X \in \mathfrak{O}\implies X\in (g(\mathfrak{O}))(x)
\end{equation}
By definition of $g$, every defined neighborhood around $x$ do contain  $x$. A super set of $N\in (g(\mathfrak{O}))(x)$ belong to $(g(\mathfrak{O}))(x)$, since an open set containing $x$ contained by  $N$ is also contained by the super set.\\

Let $N,M \in (g(\mathfrak{O}))(x)$ and $x \in O_N \subseteq N, x\in O_M \subseteq M$. We have 
\begin{equation}
x \in O_N\cap O_M\subseteq N\cap M
\end{equation}
For each neighborhood $N$ around $x$, the open set containing  $x$ contained by the neighborhood is also a neighborhood around  $x$, since it contain itself and it is an open set.  Then we see $N$ is a neighborhood around each point of the open set, since each point is contained by the open set contained by $N$ $\vdone$\\

We now prove  \blue{$g^{-1}$ do map neighborhood function to topology}.\\

Proving $\varnothing \in g^{-1}(\mathcal{N})$ is trivial. We have $X \in g^{-1}(\mathcal{N})$ because  $\mathcal{N}(x)$ is nonempty for all $x$ and  $X$ is a super set of any neighborhood.\\



Let $A,B\in g^{-1}(\mathcal{N})$. Arbitrarily pick $x$ in $A\cap B$, we know by definition of $g^{-1}$,  $A$ is a neighborhood of  $x$ and so is  $B$. Then by definition of neighborhood function, we know $A\cap B\in \mathcal{N}(x)$. Because $x$ is arbitrary picked from $A\cap B$,  we have proved $A\cap B\in g^{-1}(\mathcal{N})$.\\

Let $\mathfrak{A}\subseteq g^{-1}(\mathcal{N})$. We deduce
\begin{equation}
x \in \bigcup \mathfrak{A}\implies \exists O \in \mathfrak{A}, x \in O \in \mathfrak{A}\subseteq g^{-1}(\mathcal{N})\implies O \in \mathcal{N}(x)\implies O \subseteq \bigcup \mathfrak{A} \in \mathcal{N}(x)
\end{equation}
By definition of $g^{-1}(\mathcal{N})$, the above deduction shows $\bigcup \mathfrak{A}\in g^{-1}(\mathcal{N})\bdone$\\


Lastly, we prove \teal{$g^{-1}$ is the inverse of $g$}. To prove such, we have to first prove \vi{$g^{-1}(g(\mathfrak{O}))=\mathfrak{O}$}. \\


Arbitrarily pick $Z\in \mathfrak{O}$. Deduce 
\begin{equation}
x\in Z \implies \exists Z\in \mathfrak{O},x \in Z\subseteq Z\implies Z\in (g(\mathfrak{O}))(x)
\end{equation}
By definition of $g^{-1}$, our deduction give us $Z\in g^{-1}(g(\mathfrak{O}))$. Because $Z$ is arbitrarily picked from  $\mathfrak{O}$, we have $\mathfrak{O}\subseteq g^{-1}(g(\mathfrak{O}))$.\\

Arbitrarily pick $Y \in g^{-1}(g(\mathfrak{O}))$. Define $\mathfrak{S}:=\set{O\in \mathfrak{O}: O \subseteq Y}$. By definition of $g^{-1}\text{ and }g$, we have
\begin{equation}
y \in Y\implies Y \in (g(\mathfrak{O}))(y)\implies \exists O\in\mathfrak{O}, y \in O\subseteq Y\implies y \in \bigcup \mathfrak{S}
\end{equation}
The last implication hold true because $O\in \mathfrak{S}$ by definition of $\mathfrak{S}$. We have proved $Y\subseteq \bigcup \mathfrak{S}$. Also, trivially by definition of  $\mathfrak{S}$, we have $\bigcup \mathfrak{S}\subseteq Y$. Then we have $Y=\bigcup \mathfrak{S} \in \mathfrak{O}$. Because $Y$ is arbitrarily picked from $g^{-1}(g(\mathfrak{O}))$, we have proved $g^{-1}(g(\mathfrak{O}))\subseteq \mathfrak{O}\vdone$\\

We now prove \blue{$g(g^{-1}(\mathcal{N}))=\mathcal{N}$. More precisely, we want to prove $\forall x, g(g^{-1}(\mathcal{N}))(x)=\mathcal{N}(x)$}\\

Let $x\in X$. Observe
\begin{equation}
Y \in g(g^{-1}(\mathcal{N}))(x)\implies \exists O \in g^{-1}(\mathcal{N}),x \in O \subseteq Y
\end{equation}
Bydefinition of $g^{-1}$, we see $O\in \mathcal{N}(x)$. Then by super set property, we know $Y \in \mathcal{N}(x)$. We have proved $ g(g^{-1}(\mathcal{N}))(x)\subseteq \mathcal{N}(x)$.\\

Arbitrarily pick $N\in \mathcal{N}(x)$. Let 
\begin{equation}
U:=\set{y\in N: N \in \mathcal{N}(y)}
\end{equation}
Deduce
\begin{gather}
y \in U \implies N \in\mathcal{N}(y)\\
\implies \exists M \in \mathcal{N}(y), M \subseteq N, \forall z \in M, N \in \mathcal{N}(z)\\
\implies \forall z\in M, z\in N\text{ and }N\in\mathcal{N}(z)\\
\implies \forall z\in M, z \in U\implies M \subseteq U\implies U\in \mathcal{N}(y)
\end{gather}
We have proved
\begin{equation}
\forall y\in U, U\in \mathcal{N}(y)
\end{equation}
which means
\begin{equation}
U\in g^{-1}(\mathcal{N})
\end{equation}
By definition of $U$, we know
 \begin{equation}
U\subseteq N
\end{equation}
The fact $N$ is chosen from $\mathcal{N}(x)$ let us know $x\in U\subseteq N$, so we can deduce 
\begin{equation}
N\in g(g^{-1}(\mathcal{N}))(x)
\end{equation}
Because $N$ is arbitrarily picked from $\mathcal{N}(x)$, we have $\mathcal{N}(x)\subseteq g(g^{-1}(\mathcal{N}))(x)\bdone\tdone$
\end{proof}
\fbox{\begin{minipage}{39em}
We now give the formal definition of neighborhood while a topology is given, and translate \myref{Theorem}{2.5.5} into language without neighborhood function. 
\end{minipage}}
\begin{definition}
\label{2.5.6}
\textbf{(Definition of Neighborhood)} We say a set $E$ is a neighborhood around a point $x$, if  $E$ contains an  open set containing $x$.
\end{definition}
\begin{corollary}
\label{2.5.7}
\textbf{(Property of Neighborhood, Part 1)} 
\begin{enumerate}[label=(\alph*)]
  \item For all points $x$, there exists a neighborhood around $x$.\\
  \item The super set of a neighborhood around  $x$ is a neighborhood around $x$.\\
  \item The intersection of two neighborhood around  $x$ is a neighborhood around $x$.\\
  \item 
For each neighborhood $N$ around $x$, there exists a smaller neighborhood $M$ around $x$ such that  $N$ is a neighborhood around all points in $N$.
\end{enumerate}
\end{corollary}
\begin{theorem}
\label{2.5.8}
\textbf{(Property of Neighborhood, Part 2)} 
\begin{equation}
  \text{ $E$ is open $\iff E$ is an neighborhood around all points in $E$}
\end{equation}
\end{theorem}
\begin{proof}
From left to right, it trivially follows from our definition of neighborhood.\\

From right to left, we know every point $x$ in  $E$ is contained by an open set contained by $E$. By axiom, the union of such open sets is an open set and contained by $E$. Also, every point in $E$ belong to an open set contained by by $E$, so belong to the union. We have proved  $E$ is the union. 
\end{proof}
\section{Topological Space}
\fbox{\begin{minipage}{39em}
This section isn't an introduction to general topology, but a topological generalization of the next section as a comparison. 
\end{minipage}}
\begin{definition}
\label{2.6.1}
\textbf{(Definition of Closure and Interior Operator)} We define the closure $\overline{E}$ of $E$ to be smallest closed set containing $E$, and define  the interior $E^\circ$ of  $E$ to be the largest open set contained by  $E$. 
\end{definition}
\begin{theorem}
\label{2.6.2}
\textbf{(Basic Property of Closure and Interior Operator)} We have
\begin{equation}
  \overline{E}=E\iff E\in\mathfrak{F}\text{ and }E^\circ=E\iff E\in\mathfrak{O}
\end{equation}
\end{theorem}
\begin{proof}
Trivial. 
\end{proof}
\begin{corollary}
\label{2.6.3}
\textbf{(Basic Property of Closure and Interior Operator)} We have
\begin{equation} \overline{(\overline{E})}=\overline{E}\text{ and }(E^\circ)^\circ=E^\circ
\end{equation}
\end{corollary}
\begin{theorem}
\label{2.6.4}
\textbf{(Basic Property of Closure and Interior Operator)} We have 
 \begin{equation}
   \overline{E\cup F}=\overline{E}\cup \overline{F}\text{ and }(E\cap F)^\circ=E^\circ \cap F^\circ
\end{equation}
\end{theorem}
\begin{proof}
\begin{equation}
E\cup F \subseteq \overline{E}\cup \overline{F}\in \mathfrak{F}\implies \overline{E\cup F}\subseteq \overline{E}\cup \overline{F}
\end{equation}
\begin{equation}
E,F\subseteq \overline{E\cup F}\in\mathfrak{F}\implies \overline{E},\overline{F}\subseteq \overline{E\cup F}\implies \overline{E}\cup \overline{F}\subseteq \overline{E\cup F}
\end{equation}
\begin{equation}
E^\circ \cap F^\circ \subseteq E\cap F \implies E^\circ \cap F^\circ \subseteq (E\cap F)^\circ 
\end{equation}
\begin{equation}
  (E\cap F)^\circ \subseteq E\cap F\subseteq E,F\implies (E\cap F)^\circ \subseteq E^\circ ,F^\circ \implies (E\cap F)^\circ \subseteq E^\circ \cap F^\circ 
\end{equation}
\end{proof}
\begin{theorem}
\label{2.6.5}
\textbf{(Basic Property of Interior and Closure Operator)} We have
\begin{equation}
S\subseteq T \implies S^\circ \subseteq T^\circ\text{ and }\overline{S}\subseteq \overline{T}
\end{equation}
\end{theorem}
\begin{proof}
Trivial.
\end{proof}
\fbox{\begin{minipage}{39em}
Above define the interior and closure by using the term greatest and smallest. If reader feel any ambiguity, just use $\bigcup \set{O\in \mathfrak{O}:O\subseteq E}$ and $\bigcap \set{F\in\mathfrak{F}:E\subseteq F}$.\\

We now define interior point and limit point without using interior and closure. We will also prove the interior we define above as the greatest open set contained by $E$, can in return define interior points. Other than the last section, this is another show case of definitions in general topology that can be defined in multiple different yet equivalent ways. 
\end{minipage}}
\begin{definition}
\label{2.6.6}
\textbf{(Definition of Interior Point)} A point $p$ is an interior point of $E$ if
\begin{equation}
E\in \mathcal{N}(p)
\end{equation}
\end{definition}
\begin{definition}
\label{2.6.7}
\textbf{(Definition of Limit and Isolated Point)} A point $p \in X$ is a limit point of a subset $E$ of $X$, if 
\begin{equation}
\forall O\in \mathfrak{O}:p \in O, \exists u\neq p, u \in O\cap E
\end{equation}
\end{definition}
\begin{theorem}
\label{2.6.8}
\textbf{(Interior Contain Exactly All Interior Points)} We have
\begin{equation}
E^\circ = \set{p:E\in \mathcal{N}(p)}
\end{equation}
which reads: the interior of $E$ is exactly the set of point around which $E$ is neighborhood
\end{theorem}
\begin{proof}
Arbitrarily pick $p$ from $\set{p: E \in \mathcal{N}(p)}$. By definition, we have 
\begin{equation}
\exists O\in \mathfrak{O}, p \in O \subseteq E\text{ where }O\subseteq E^\circ 
\end{equation}
Then we have $p \in E^\circ $. Because $p$ is arbitrarily picked from $\set{p:E \in \mathcal{N}(p)}$, we now have $\set{p:E \in\mathcal{N}(p)}\subseteq E^\circ $. Arbitrarily pick $p'$ from $E^\circ$. We deduce
\begin{equation}
p' \in E^\circ \subseteq E\implies E\in \mathcal{N}(p')\implies p' \in \set{p: E\in \mathcal{N}(p)}
\end{equation}

Because $p'$ is arbitrarily picked from  $E^\circ $, we have $E^\circ \subseteq \set{p:E\in \mathcal{N}(p)}$ 
\end{proof}
\begin{theorem}
\label{2.6.9}
\textbf{(Closure Contain Exactly All Limit Points of $E$ and Points in $E$)} Let $S(E)$ be the set of limit points of $E$. We have
\begin{equation}
\overline{E}= S(E)\cup  E
\end{equation}
\end{theorem}
\begin{proof}
Let $p \in S(E)$. \As{$p\not\in\overline{E}$}. Deduce
\begin{equation}
p \in (\overline{E})^c \in \mathfrak{O}\implies \exists u\neq p, u \in (\overline{E})^c \cap E= \varnothing \tCaC
\end{equation}
 Let $p \in \overline{E}\setminus E$. \As{$\exists O\in\mathfrak{O},p \in O,O\cap E=\varnothing$}. Deduce
\begin{equation}
O \cap E=\varnothing \implies E\subseteq O^c\in\mathfrak{F} \implies p\in \overline{E}\subseteq O^c \implies p \not \in O\tCaC
\end{equation}
\end{proof}
\begin{corollary}
\label{2.6.10}
\textbf{(Every Point in Closure And Not in the Set is a Limit Point)}
\begin{equation}
\overline{E}\setminus E\subseteq S(E)
\end{equation}
\end{corollary}
\fbox{\begin{minipage}{39em}
Other than the above basic fact one must know in general topology. The following show case some properties of limit one may wish to know.
\end{minipage}}
\begin{lemma}
\label{2.6.11}
\textbf{(Point in Closure if and only if No Neighborhood is Disjoint)} We have
\begin{equation}
\overline{E}=\set{p: \forall M\in \mathcal{N}(p), M\cap E\neq \varnothing}
\end{equation}
\end{lemma}
\begin{proof}
We first prove \vi{$\overline{E}\subseteq \set{p:\forall M\in \mathcal{N}(p), M \cap E\neq \varnothing}$}. If $p \in E$, the proof is trivial, so we only consider when $p\in \overline{E}\setminus E$.\\

Deduce
\begin{equation}
p\in \overline{E}\setminus E\implies p\in  S(E)\implies \forall O:p\in  O, O\cap E\neq \varnothing 
\end{equation}
Then we have
\begin{equation}
M \in \mathcal{N}(p) \implies \exists O, p \in O \subseteq M \implies \varnothing\neq  O\cap E \subseteq M \cap E\vdone
\end{equation}
We now prove \blue{$\set{p:\forall M\in \mathcal{N}(p),M\cap E\neq \varnothing}\subseteq \overline{E}$}. If $p\in  E$, the proof is trivial, so we only consider when $p\not\in E$.\\

Deduce
\begin{equation}
\forall O\in \mathfrak{O}, p\in  O\implies O\in \mathcal{N}(p)\implies O\cap E\neq \varnothing
\end{equation}
Because $p\not\in E$, this tell us $O\cap E$ contain a point that isn't $p$, so we have proved  $p\in  S(E)\bdone$ 



\end{proof}
\begin{theorem}
\label{2.6.12}
\textbf{(Point is Limit Point if and only if In the Closure of Set Excluding The Point)} Let $S(E)$ be the set of limit points of $E$, we have  
\begin{equation}
S(E)=\set{p:p \in \overline{E\setminus \set{p}}}
\end{equation}
\end{theorem}
\begin{proof}
We first prove  \vi{$S(E)\subseteq \set{p: p\in \overline{E\setminus \set{p}}}$}. \As{$p\in S(E)\setminus \overline{E\setminus \set{p}}$}. Deduce
\begin{equation}
p\in (\overline{E\setminus \set{p}})^c \in \mathfrak{O}\implies \exists u\neq p: u\in (\overline{E\setminus \set{p}})^c \cap E
\end{equation}
Notice
\begin{equation}
u\in (\overline{E\setminus \set{p}})^c \cap E\implies u\in E\implies u\in E\setminus \set{p}\subseteq \overline{E\setminus \set{p}}\tCaC
\end{equation}
Now we prove \blue{$\set{p:p \in \overline{E\setminus \set{p}}}\subseteq S(E)$}. Deduce
\begin{equation}
p\in \overline{E\setminus \set{p}} \implies \forall M \in \mathcal{N}(p), M\cap (E\setminus \set{p}) \neq \varnothing
\end{equation}
Then because every open set is an neighborhood, we have
\begin{equation}
\forall O: p \in O, O\cap (E\setminus \set{p})\neq \varnothing
\end{equation}
This reads: for each open set containing $p$, there exists a point  $q$ belong to both $O$ and $E$ that isn't  $p$. This shows $p\in  S(E)\bdone$ 

\end{proof}
\fbox{\begin{minipage}{39em}
    The next two definition will be further exploited in the upcoming sections.
\end{minipage}}
\begin{definition}
\label{2.6.13}
\textbf{(Definition of Perfect Set)} A subset $E$ of  $X$ is perfect if  $E$ is closed and every point of  $E$ is a limit point of  $E$.
\end{definition}
\begin{definition}
\label{2.6.14}
\textbf{(Definition of Dense Set)} A subset $E$ is dense in $X$ if $\overline{E}=X$ 
\end{definition}
\section{Metric Space}
\begin{definition}
\label{2.7.1}
\textbf{(Definition of Metric Space)} We say $(X,d:X^2\rightarrow \R)$ is a metric space if for all $x,y,z \in X$, we have
\begin{equation}
d(x,x)=0 
\end{equation}
\begin{equation}
x\neq y\longrightarrow d(x,y)>0\text{ (Positive Definitness) }
\end{equation}
\begin{equation}
d(x,y)=d(y,x)\text{ (Commutative) }
\end{equation}
\begin{equation}
d(x,z)\leq d(x,y)+d(y,z)\text{ (Triangle Inequality) }
\end{equation}
\end{definition}
\begin{theorem}
\label{2.7.2}
\textbf{(Norm Induced Metric Space)} Every norm induce a metric space by 
\begin{equation}
d(\vecta{x},\vecta{y})=\norm{\vecta{x}-\vecta{y}}
\end{equation}
\end{theorem}
\begin{proof}
"Reflexive", positive definiteness are trivially given by axiom of norm. Observe $d(\vecta{x},\vecta{y})=\norm{\vecta{x}-\vecta{y}}=\norm{(-1)(\vecta{y}-\vecta{x})}=(\abso{-1})\norm{\vecta{y}-\vecta{x}}=d(\vecta{y},\vecta{x})$. Observe $d(\vecta{x},\vecta{z})=\norm{\vecta{x}-\vecta{z}}=\norm{\vecta{x}-\vecta{y}+\vecta{y}-\vecta{z}}\leq \norm{\vecta{x}-\vecta{y}}+\norm{\vecta{y}-\vecta{z}}=d(\vecta{x},\vecta{y})+d(\vecta{y},\vecta{z})$
\end{proof}
\fbox{\begin{minipage}{39em}
In fact, there are other way to induce a metric space from a norm: $d(\vecta{x},\vecta{y})=\norm{\vecta{x}}+\norm{\vecta{y}}$. The two norm in definition don't even have to be the same. Although this do show that the class of metric space, the one being study the most is of course what we induce in \myref{Theorem}{2.7.2}.\\

Notice that any subset of a metric space equipped with the original metric is also trivially a metric space.\\

From now, if we mention a metric space without specification, we mean a norm-induced vector metric space.
\end{minipage}}
\begin{definition}
\label{2.7.3}
\textbf{(Definition of Open Ball)} Let $(X,d)$ be a metric space, we say the set
\begin{equation}
B_r(x)=\set{y \in X: d(x,y)<r}
\end{equation}
is the open ball of radius $r$ around  $x$
\end{definition}
\begin{theorem}
\label{2.7.4}
\textbf{(Basic Property of Open Ball)} If $r\leq h$, then  $B_r(x)\subseteq B_h(x)$.
\end{theorem}
\fbox{\begin{minipage}{39em}
The above define what would be called an open ball. Give clear notice that although we use the word "open" ball, we have not proved the notion defined is open. In fact, we have not even defined what would be open.\\

Notice in $\R^1$, the open ball  $B_r(x)$ is just the interval $(x-r,x+r)$, and the interval $(a,b)$ is the open ball $B_{\frac{b-a}{2}}(\frac{a+b}{2})$. Also notice $B_0(x)\neq (x,x)=\varnothing$.\\

The following first define interior points, then define open set from definition of interior points.
\end{minipage}}
\begin{definition}
\label{2.7.5}
\textbf{(Definition of Interior Points and Open)} A point $p$ is an interior point of $E$ if 
\begin{equation}
\exists r\inr^+, B_r(x)\subseteq E
\end{equation}
The set  of interior points of  $E$ is called interior $E^{\circ }$ of $E$. Also, we say $E$ is open if 
\begin{equation}
E^\circ =E
\end{equation}
\end{definition}
\begin{theorem}
\label{2.7.6}
\textbf{(Basic Property of Interior)} For all set $E$, we have  $E^\circ \subseteq E$
\end{theorem}
\fbox{\begin{minipage}{39em}
Now, we prove an "open" ball is indeed open. The proof of such should of course be completely rigorous, but to come up with a proof rely more than rigor. Geometric intuition should help if possible, and such intuition need not be specific.\\

Moreover, \myref{Theorem}{2.7.8} will prove that our definition of open do satisfy the axioms of open sets, which is in the scope of general topology. 
\end{minipage}}
\begin{theorem}
\label{2.7.7}
\textbf{(Open Ball is Open)} Open ball is open.
\end{theorem}
\begin{proof}
Consider  $B_r(x)$. Let $y\in B_r(x)$. Let $q=d(x,y)$. Arbitrarily pick $z\in B_{r-q}(y)$, we have
\begin{equation}
d(x,z)\leq d(x,y)+d(y,z)\leq q+r-q=r
\end{equation}
So we know $z \in B_r(y)$. Because $z$ is arbitrarily picked, we know $B_{r-q}(y)\subseteq B_r(x)$  
\end{proof}
\begin{theorem}
\label{2.7.8}
\textbf{(Verification of Compatibility of Definitions of Open)} 
Let $\mathfrak{O}$ be the family of open set, by our definition of open in metric space $X$, we have
 \begin{equation}
\varnothing , X \in \mathfrak{O}
\end{equation}
\begin{equation}
A, B \in \mathfrak{O}\implies A\cap B\in \mathfrak{O}
\end{equation}
\begin{equation}
\mathfrak{A}\subseteq \mathfrak{O}\implies \bigcup \mathfrak{A}\in\mathfrak{O}
\end{equation}
\end{theorem}
\begin{proof}
Notice $\varnothing^\circ =\varnothing$. Observe
\begin{equation}
\forall x\in X, \forall r\inr^+, B_r(x)\subseteq X \implies X^\circ = X 
\end{equation}
Let $A,B\in \mathfrak{O}$. Arbitrarily pick $y \in A\cap B$. Because $y \in A\text{ and }y\in B$, we know 
\begin{equation}
\exists r_a\inr^+, B_{r_a}(y)\subseteq A\text{ and }
\exists r_b\inr^+, B_{r_b}(y)\subseteq B
\end{equation}
Then, we have
\begin{equation}
B_{\min \set{r_a,r_b}}(y)\subseteq A\cap B
\end{equation}
Because $y$ is arbitrarily picked from  $A\cap B$, we see $A\cap B= (A\cap B)^\circ $.\\

Let $\mathfrak{A}\subseteq \mathfrak{O}$. Arbitrarily pick $y\in \bigcup \mathfrak{A}$. Let $y \in A \in \bigcup \mathfrak{A}$, so we have
\begin{equation}
\exists r_a\inr^+, B_{r_a}(y)\subseteq A\subseteq \bigcup \mathfrak{A}
\end{equation}
Because $y$ is arbitrarily picked from $\bigcup \mathfrak{A}$, we see $\bigcup \mathfrak{A}=(\bigcup \mathfrak{A})$. 
\end{proof}
\fbox{\begin{minipage}{39em}
In learning of mathematics, knowledge of examples is always important. Now, we showcase some open set in metric topology.
\end{minipage}}
\begin{theorem}
\label{2.7.9}
\textbf{(Examples of Open Sets)} The followings are all open sets
\begin{gather}
   (a,b)\text{ in }\R\\
   (-\infty , a)\text{ in }\R\\
   \set{0}\text{ where $\set{0}$ is a trivial metric space}\\
   \set{(x,y)\inr^2: x^2+y^2\neq 1}\text{ ($\R^2$ minus a sphere) }\\
   (a,b)\times (c,d)\text{ in }\R^2\\
   \set{(x,y)\inr^2 : xy\neq 0}\text{ (*any set with finite missing point would do ) }\\
   \R^2 \text{ in } \R^2
\end{gather}
\end{theorem}
\begin{proof}
$(a,b)$ is open ball $B_{\frac{b-a}{2}}$. We have 
\begin{equation}
x<a \implies B_{\frac{a-x}{2}}(x)\subseteq (-\infty, a)
\end{equation}
The trivial $\set{0}$ follows from axiom. Observe
\begin{equation}
\set{(x,y)\inr^2: x^2+y^2\neq 1}=\set{(x,y)\inr^2:x^2+y^2<1\text{ or }x^2+y^2>1}
\end{equation}
Verify for $B_{\abso{\abso{(x,y)}-1}}(x,y)$.\\

For the rectangle, observe 
\begin{equation}
a<x<b\text{ and }c<y<d\implies B_{\min \set{x-a,b-x,y-c,d-y}}(x,y)\subseteq (a,b)\times (c,d)
\end{equation}
For $\set{(x,y)\inr^2:xy\neq 0}$, verify for $B_{\abso{(x,y)}}(x,y)$
\end{proof}
\fbox{\begin{minipage}{39em}
Now we define limit points, then we define closed with the definition of limit points. Then we verify what we defined as closed are indeed closed, in scope of general topology. 
\end{minipage}}
\begin{definition}
\label{2.7.10}
\textbf{(Definition of Limit Points and Closed and Perfect)} A point $p$ is a limit point of $E$ if 
 \begin{equation}
\forall r\inr^+, \exists q\neq p, q\in B_r(p) \cap E
\end{equation}
The set of limit points of  $E$ is denoted $S(E)$. We say $E$ is closed if 
\begin{equation}
S(E)\subseteq E
\end{equation}
and we say $E$ is perfect if 
\begin{equation}
S(E)=E
\end{equation}
\end{definition}
\begin{theorem}
\label{2.7.11}
\textbf{(Verification of Compatibility of Definition of Open and Closed)} 
Let $\mathfrak{O},\mathfrak{F}$ respectively be the family of open sets and family of closed set under our metric definition. We have
\begin{equation}
E\in \mathfrak{O}\iff E^c\in\mathfrak{F}
\end{equation}
\end{theorem}
\begin{proof}
$(\longrightarrow)$\\

\As{$E^c$ is not closed}. We have $S(E^c)\setminus E^c\neq \varnothing$. Let $p\in S(E^c)\setminus E^c$. We have
\begin{equation}
p\in  S(E^c)\implies \forall r\inr^+, \exists q\neq p, q\in B_{r}(p)\cap E^c
\end{equation}
 Notice $p\not\in E^c\implies p\in  E$. Because $E$ is open, we also know
\begin{equation}
\exists r_p\inr^+, B_{r_p}(p)\subseteq E
\end{equation}
Notice
\begin{equation}
B_{r_p}(p)\subseteq E\implies B_{r_p}(p)\cap E^c=\varnothing\tCaC
\end{equation}
$(\longleftarrow)$\\

\As{$E\not\in O$}. By definition of open, we have
\begin{equation}
\exists p \in E, \forall r\inr^+, B_r(p)\setminus E\neq \varnothing
\end{equation}
Notice $B_r(p)\setminus E=B_r(p)\cap E^c\text{ and }p\not\in E^c$, so we in fact have
\begin{equation}
\forall r\inr^+,\exists q\neq p, q \in B_r(p)\cap E^c 
\end{equation}
Then we have $p\in  S(E^c)\setminus E^c\tCaC$
\end{proof}
\begin{corollary}
\label{2.7.12}
\textbf{(Axioms for Closed Sets)} Let $\mathfrak{F}$ be the family of closed sets under our metric definition. We have
\begin{gather}
X,\varnothing \in \mathfrak{F}\\
A,B\in\mathfrak{F}\implies A\cup  B\in\mathfrak{F}\\
\mathfrak{B}\subseteq \mathfrak{F}\implies \bigcap \mathfrak{B}\in \mathfrak{F}
\end{gather}
\end{corollary}
\begin{theorem}
\label{2.7.13}
\textbf{(Property of Limit Points)} Let $p\in  E^c\text{ and }p\not\in S(E)$. We have 
\begin{equation}
\exists r\inr^+, B_r(p)\cap E=\varnothing
\end{equation}
\end{theorem}
\begin{proof}
\As{$\forall r\inr^+,B_r(p)\cap E\neq \varnothing$}. Let $q\in B_r(p)\cap E$. Because $p\not\in E\implies p\not\in B_r(p)\cap E$, we know $q\neq p$. Then this can be written $q\neq p \text{ and }a \in B_r(p)\cap E$, implying $p \in S(E)\tCaC$
\end{proof}
\begin{theorem}
\label{2.7.14}
\textbf{(Property of Limit Points)} Let $p \in S(E)$. We have
\begin{equation}
\forall O\in\mathfrak{O}:p\in  O, \exists q\neq p, q \in O \cap E
\end{equation}
\end{theorem}
\begin{proof}
By $p\in  S(E)$, we mean
\begin{equation}
\forall r\inr^+,\exists q\neq p,q\in B_r(p)\cap E
\end{equation}
Notice
 \begin{equation}
p\in O\implies \exists r\inr^+, B_r(p)\subseteq O
\end{equation}
Combining above, we have
\begin{equation}
\exists q\neq p,q\in B_r(p)\cap E\subseteq O\cap E
\end{equation}
\end{proof}
\fbox{\begin{minipage}{39em}
Again, we now give some examples of closed set. One can see that the proof for some sets are closed if following straight from the limit point definition is extremely long: One have to first find the set of limit points, by checking every points whether for all real number a property stand, and then check if the set of limit points is a subset of $E$. The optimal way is proving the complement is open, since proving something is open is more
\end{minipage}}
\begin{theorem}
\label{2.7.15}
\textbf{(Example of Closed Sets)} The following are all closed sets
\begin{gather}
[a,b]\\
[0,1]\cap \Q \text{ is closed in $\Q$ but not in  $\R$ } \\
[1,\infty) \\
\text{ finite set in $\R^n$ } \\
\Z  \text{ in $\R$ }\\
\R^2 \text{ in  }\R^2
\end{gather}
\end{theorem}
\begin{proof}
  Observe
\begin{gather}
[a,b]^c=(-\infty, a)\cup (b,\infty)\in \mathfrak{O}\\
([0,1]\cap \Q)^c \text{ in $\Q$ is }\set{x\inq: x<0\text{ or }1<x}
\end{gather}
Verify for $B_{\min \set{\abso{x-1},\abso{x}}}(x)$ to check $([0,1]\cap \Q)^c$ is open in $\Q$.\\

Notice by \myref{Theorem}{1.3.5}, we can prove every point in $\R$ is an limit point of $[0,1]\cap \Q$ by selecting a rational number of smaller error than any desired real number.\\

Observe
\begin{equation}
[1,\infty)^{c}=(-\infty,1)\in \mathfrak{O}
\end{equation}
Let $X$ be a finite set in $\R^n$, and let $y\in X^c$. We can verify $B_{\min \set{d(y,x):x\in X}}\subseteq X^c$ to show $X^c$ is open.\\

Let $x\in \R\setminus \Z$, and let $a$ be the greatest integer smaller than  $x$. Verify for  $B_{x-a,a+1-x}(x)\subseteq \R\setminus \Z$.
\end{proof}
\fbox{\begin{minipage}{39em}
Notice that $\R^2$ is both open and closed in $\R^2$, we call this kind of set clopen.\\

    Now, we define closure. Give close attention to the difference of definitions of limit points in this and last section. They look slightly different, but they are equivalent, which can be proved by simple logic.\\


Notice that interior corresponds to open set and closure corresponds to closed sets.\\

Although in last section, we have proved that the smallest closed set is the closure in our definition, and the largest open subset is the interior in our definition. This fact need some logic to glue the two different definition of interior (limit) points together, but it isn't difficult to do such.\\

In this section, we prove the same fact again, but in the scope of metric topology.
\end{minipage}}
\begin{definition}
\label{2.7.16}
\textbf{(Definition of Closure)} We define the closure $\overline{E}$ of $E$ to be
\begin{equation}
\overline{E}=S(E)\cup E
\end{equation}
\end{definition}
\begin{theorem}
\label{2.7.17}
\textbf{(Property of Closure and Interior)} Let $E\subseteq F$. We have
\begin{equation}
E^\circ \subseteq F^\circ\text{ and }S(E)\subseteq S(F)\text{ and }\overline{E}\subseteq \overline{F}
\end{equation}
\end{theorem}
\begin{proof}
The first proof is trivial. Just use the same open ball to argue $p$ is an interior point of $E$ implies that $p$ is an interior point of $F$.\\

Observe 
\begin{equation}
\forall r\inr^+,\exists q\neq p, q\in B_{r}(p)\cap E\subseteq B_{r}(p)\cap F
\end{equation}
This is the second proof. Observe
\begin{equation}
\overline{E}\subseteq E\cup S(E)\subseteq F\cup S(F)\subseteq \overline{F}
\end{equation}
\end{proof}
\begin{theorem}
\label{2.7.18}
\textbf{(Property (definition) of Closure and Interior)} 
\begin{gather}
\text{ $\overline{E}$ is the smallest closed set containing $E$ }\\
\text{ $E^\circ $ is the largest open subset of $E$ }
\end{gather}
\end{theorem}
\begin{proof}
  We first prove \vi{$\overline{E}$ is closed}.\\


Let $p\in S(\overline{E})$. We wish to prove $p\in \overline{E}$. If $p\in  E$, the proof is trivial, so we only have to consider $p\not\in E$. Arbitrarily pick $r$ from $\R^+$. By $p\in  S(\overline{E})$, we have
\begin{equation}
\exists q\neq p, q\in B_r(p)\cap \overline{E}=(B_r(p)\cap E)\cup (B_r(p)\cap S(E))
\end{equation}
If $q \in B_r(p)\cap E$, our proof is finished, so we only have to consider when $q\in B_r(p)\cap S(E)$. By $q\in S(E)$, we have
\begin{equation}
\forall r'\inr^+, \exists q'\neq q, q'\in B_{r'}(q)\cap E
\end{equation}
Then we can pick $r'$ smaller than  $r-d(p,q)$, so we see 
 \begin{equation}
q'\in B_{r'}(q)\subseteq B_r(p)
\end{equation}
since
\begin{equation}
x\in B_{r'}(q)\implies d(x,q)<r'<r-d(p,q)\implies d(x,q)+d(p,q)<r\implies d(x,p)<r
\end{equation}
Notice $q'\in E$ implies $q'\neq p$. This finish the proof, since $q'$ is a point not $p$ in  $B_r(p)\cap E$, where $r$ is arbitrarily picked from $\R^+\vdone$\\

Let closed $F$ contain $E$. We have 
\begin{equation}
S(E)\subseteq S(F)\subseteq F
\end{equation}
Now, we prove  \blue{$E^\circ $ is an open subset of $E$}\\

Let $p\in  E^\circ $. We wish to show 
\begin{equation}
\exists r\inr^+, B_r(p)\subseteq E^\circ 
\end{equation}
In other word, we wish to find $r$ such that
\begin{equation}
d(q,p)<r\longrightarrow q\in E^\circ 
\end{equation}
where $q\in E^\circ $ can be written differently.  \begin{equation}
d(q,p)<r\longrightarrow \exists r_1\inr^+, B_{r_1}(q)\subseteq E
\end{equation}
By definition, we know there exists $r_0$ such that
 \begin{equation}
B_{r_0}(p)\subseteq E
\end{equation}
Pick $r,r_1$ such that  $r+r_1<r_0$. We have
 \begin{equation}
x\in B_{r_1}(q)\implies d(x,q)<r_1\text{ and }d(p,q)<r\implies d(x,p)<r_1+r<r_0\implies x\in B_{r_0}(p)
\end{equation}
The above shows $B_{r_1}(q)\subseteq B_{r_0}(p)\subseteq E\bdone$\\

Let $F$ be an open subset of  $E$, we see
 \begin{equation}
E^\circ \subseteq F^\circ \subseteq F
\end{equation}
\end{proof}
\begin{corollary}
\label{2.7.19}
\textbf{(Property of Closure)}
\begin{equation}
\text{ $E$ is closed $\iff \overline{E}=E$ }
\end{equation}
\begin{equation}
\text{ $E$ is open $\iff E^\circ =E$ }
\end{equation}
\end{corollary}
\fbox{\begin{minipage}{39em}
Lastly, we show some properties of open and closed concerning a set being finite. Notice that the theorem applies to ALL metric space, even the trivial finite metric space.
\end{minipage}}
\begin{theorem}
\label{2.7.20}
\textbf{(ALL Open Ball of An Limit Point Contain Infinite Point of $E$)} We have
 \begin{equation}
p\in S(E)\implies \forall r\inr^+, \abso{B_r(p)\cap E}\geq \abso{\N}
\end{equation}
\end{theorem}
\begin{proof}
Let $p \in S(E)$. \As{$\exists r\inr^+, B_r(p)\cap E=\set{q_1,\dots, q_n} $}. Select $k$ such that
\begin{equation}
d(p,q_k)= \min_{1\leq m\leq n}d(p,q_m)
\end{equation}
Notice we have $\forall q, d(p,q)<r$. Then we can deduce 
\begin{equation}
x \in B_{d(p,q_k)}(p)\cap E\implies x \in B_r(p)\cap E=\set{q_1,\dots, q_n}
\end{equation}
However by our choice of $k$, we have
 \begin{equation}
x\in B_{d(p,q_k)}(p)\cap E\implies \forall q,d(p,x)<d(p,q)\implies x\not \in B_r(p)\cap E\tCaC
\end{equation}
\end{proof}
\begin{corollary}
\label{2.7.21}
\textbf{(Finite Points Set In Metric Topology has no Limit Points)} $\abso{E}<\abso{\N}\implies S(E)=\varnothing$
\end{corollary}
\begin{corollary}
\label{2.7.22}
\textbf{(Finite Points Set In Metric Topology is Always Clopen)} Any finite points set in a metric topological space is clopen. 
\end{corollary}
\begin{proof}
For closed, there is a proof other than just using the above corollary. One can check out \myref{Theorem}{2.7.9}. For open, just verify for $B_{\min \set{d(x,y):y \in O}}(x)$. 
\end{proof}
\begin{theorem}
\label{2.7.23}
\textbf{(A point is limit point if and only if all open ball contain infinite point of $E$)}
\end{theorem}
\section{Compact}
\fbox{\begin{minipage}{39em}
In this section, we will introduce two ideas used in metric space, but not in general topology, although these two notions can be generalized to general topology.\\

We first introduce bounded.
\end{minipage}}
\begin{definition}
\label{2.8.1}
\textbf{(Definition of Bounded)} We say a point set $E$ in metric topology is bounded if there exists $r\inr^+$ such that
\begin{equation}
\forall p,q\in E, d(p,q)<r
\end{equation}
\end{definition}
\begin{definition}
\label{2.8.2}
\textbf{(Definition of Open Cover)} We say a collection $\set{G_\alpha  }$ of an open sets is an open cover of $E$ if 
\begin{equation}
E\subseteq \bigcup \set{G_\alpha }
\end{equation}
\end{definition}
\begin{definition}
\label{2.8.3}
\textbf{(Definition of Compact)} We say a point set $E$ in metric topology is compact if every open cover $E$ contain a finite open subcover.
\end{definition}
\begin{theorem}
\label{2.8.4}
\textbf{(Compact Sets Are Closed)} Every compact set $K$ is closed.
\end{theorem}
\begin{proof}
We prove  \vi{$K^c$ is open}. Let $p\in K^c$. Consider the collection
\begin{equation}
  \set{B_{\frac{d(q,p)}{2}}(q):q \in K}
\end{equation}
This collection is trivially an open cover of $K$. We then can select a finite sub-cover
\begin{equation}
W:=\set{B_{\frac{d(q_i,p)}{2}}(q_i)}
\end{equation}
Consider the ball 
\begin{equation}
B_{\min \set{\frac{d(q_i,p)}{2}}}(p)
\end{equation}
Notice that we can deduce
\begin{equation}
d(q_j,p)<d(q_j,k)+d(k,p)\implies d(k,p)>d(q_j,p)-d(q_j,k)
\end{equation}
Then observe
\begin{gather}
k\in K\subseteq W\implies \exists q_j, k\in B_{\frac{d(q_j,p)}{2}}(q_j)\implies d(q_j,k)<\frac{d(q_j,p)}{2}\\
\implies d(k,p)>d(q_j,p)-\frac{d(q_j,p)}{2}=\frac{d(q_j,p)}{2}\implies k\not\in B_{\min \set{\frac{d(q_i,p)}{2}}}(p) \vdone
\end{gather}
\end{proof}
\begin{theorem}
\label{2.8.5}
\textbf{(Closed Subsets of Compact Sets Are Compact)} Every closed subset of a compact set is compact.
\end{theorem}
\begin{proof}
Let $K$ be compact and $F\subseteq K$ be closed. Arbitrarily pick an open cover $\set{G_\alpha }$ of $F$. We wish to prove there is a finite sub-cover of $F$. Notice that $F^c$ is open, so there are two possible cases:  $\begin{cases}
  \vi{F^c\in \set{G_\alpha }}\\
  \blue{F^c\not\in \set{G_\alpha }}
\end{cases}$\\

In the case  \vi{$F^c\in \set{G_\alpha }$}, Notice  $F\subseteq \bigcup \set{G_{\alpha }}$ by definition of open cover and notice $F^c\subseteq \bigcup \set{G_\alpha }$ by premise, so we can deduce
\begin{equation}
(F\cup F^c)\cap K=(F\cap K)\cup (F^c \cap K)=F \cup (F^c \cap K)\subseteq \bigcup \set{G_\alpha }
\end{equation}
This shows $\bigcup \set{G_\alpha }$ is a open cover of $K$. Then because  $K$ is compact, there exists a finite sub-cover $A$ of $K$, and we see
\begin{equation}
F\subseteq K \subseteq \bigcup A\vdone
\end{equation}
In the case $\blue{F^c\not\in \set{G_\alpha }}$, by the argument above, we know $\set{G_\alpha } \cup \set{F^c}$ is an open cover of $K$, and we know there is a finite sub-cover $N\subseteq\set{G_\alpha } \cup \set{F^c}$. In term, we can write
\begin{equation}
F\subseteq K \subseteq \bigcup N
\end{equation}
If $N$ doesn't contain $F^c$, we know $N\subseteq \set{G_\alpha }$. Then we see $N\subseteq \set{G_\alpha }$ is a finite sub-cover of $K$, partially finishing our proof.\\

If $F^c \in N$, by simple logic, we see
\begin{equation}
F\subseteq (\bigcup N)\setminus F^c=\bigcup (N\setminus \set{F^c}) 
\end{equation}
So $N\setminus \set{F^c}$ is a finite sub-cover of $F\bdone$
\end{proof}
\begin{corollary}
\label{2.8.6}
Let $F$ be closed and  $K$ be compact. We have $F\cap K$ is compact.
\end{corollary}
\fbox{\begin{minipage}{39em}
Above give the basic property that compact must be closed and a method to generate compact set by finding a closed subset of compact set.\\

Now, we give an example that is the "prototype" of compact set. Give very close attention that the definition of $k$-cell is only in Euclidean normed induced metric space. This is because to prove it is compact require using norm.  
\end{minipage}}
\begin{definition}
\label{2.8.7}
\textbf{(Definition of k-cell)} In $(\R^k,d(\vecta{x},\vecta{y})=\abso{\vecta{x}-\vecta{y}})$,  we say $I$ is a $k$-cell, when there exists  $k$ intervals  $\set{[a_1,b_1],\dots , [a_k,b_k]}$ such that
 \begin{equation}
   I=\set{(x_1,\dots , x_k)\in \R^k: \forall j, a_j\leq x_j\leq b_j }
\end{equation}
\end{definition}
\begin{lemma}
\label{2.8.8}
Let $\set{I_i}$ be a sequence of $k$-cells such that
 \begin{equation}
\forall i, I_{i+1}\subseteq I_i
\end{equation}
We have
\begin{equation}
\bigcap \set{I_i}\neq \varnothing
\end{equation}
\end{lemma}
\begin{proof}
Let $I_i$ be 
 \begin{equation}
I_i=\set{(x_1,\dots , x_k)\in \R^n: \forall j, a_{i,j}\leq x_j\leq b_{i,j}}
\end{equation}
Observe
\begin{equation}
  (x_1,\dots , x_k)\in \bigcap \set{I_i}\iff \forall i \inn,\forall 1\leq j\leq k, a_{i,j}\leq x_j\leq b_{i,j}
\end{equation}
Notice that for all $j:1\leq j\leq k$, we have
\begin{equation}
\forall i<l\inn, a_i\leq a_l\leq b_l\text{ and }\forall i>l\inn, a_i\leq b_i\leq b_l
\end{equation}
So we know for all $j:1\leq j\leq k$, the set $\set{b_{i,j}:i\inn}$ is a set of upper bounds of   $\set{a_{i,j}:i\inn}$. Then we have
\begin{equation}
\sup \set{a_{i,j}:i\inn}\leq \inf \set{b_{i,j}:i\inn}
\end{equation}
Then for all $j$, we can pick $x_j$ such that
 \begin{equation}
\sup \set{a_{i,j}:i\inn}\leq x_j\leq \inf \set{b_{i,j}:i\inn}
\end{equation}
Then we see 
\begin{equation}
  (x_1,\dots ,x_k)\bigcap \set{I_i}
\end{equation}
\end{proof}
\begin{theorem}
\label{2.8.9}
\textbf{(k-Cell is Compact)} Every k-cell $I$ is compact.
\end{theorem}
\begin{proof}
Let $I$ be $[a_1,b_1]\times \cdots \times [a_k,b_k]$. Let
\begin{equation}
\delta=(\sum_{j=1}^k (b_j-a_j)^2)^{\frac{1}{2}}=\abso{\vecta{b}-\vecta{a}}
\end{equation}
So, we have
\begin{equation}
\vecta{x},\vecta{y}\in I\implies \abso{\vecta{x}-\vecta{y}}<\delta
\end{equation}
\As{$\set{G_\alpha }$ is an open cover of $I$ containing no finite sub-cover}. Let
\begin{equation}
\forall j, c_j=\frac{a_j+b_j}{2}
\end{equation}
The intervals $[a_j,c_j],[c_j,b_j]$ then determine $2^k$ k-cell $Q_i$ whose union is $I$. Notice that if every $Q_i$ is covered by some open finite sub-cover of $\set{G_\alpha }$, then the union of $2^k$ finite sub-cover that cover each $Q_i$ is a finite sub-cover of whole  $I$, so we know there exists  $Q_i$ such that is covered by no finite sub-cover  of $\set{G_\alpha }$. Denote that $Q_i$ by $I_1$.\\

By the construction of $I_1$, we know for a fact $\set{G_\alpha }$ is an open cover of $I_1$ (it cover $I$) containing no finite sub-cover (by construction). Then we can construct $I_2$ from  $I_1$ the same way we construct $I_1$ from  $I$, and so on.\\
 
Let $I=I_0$. We have 
\begin{equation}
\forall i\inn, I_i\subseteq I_{i-1}\text{ and $I_i$ is not covered by any finite subset of  $\set{G_\alpha }$ }
\end{equation}
We now prove \vi{$\vecta{x},\vecta{y}\in I_n\implies \abso{\vecta{x}-\vecta{y}}\leq 2^{-n}\delta$}\\

Notice
\begin{gather}
\vecta{x},\vecta{y}\in I_n\implies \forall j, \abso{x_j-y_j}\leq 2^{-n}(b_j-a_j)\\
\implies \sum_{j=1}^k (x_j-y_j)^2 \leq \sum_{j=1}^k (2^{-n}(b_j-a_j))^2=2^{-2n}\sum_{j=1}^k (b_j-a_j)^2\\
\implies \abso{\vecta{x}-\vecta{y}}=(\sum_{j=1}^k (x_j-y_j)^2)^{\frac{1}{2}}\leq (2^{-2n}\sum _{j=1}^k (b_j-a_j)^2)^{\frac{1}{2}}=2^{-n}(\sum _{j=1}^k(b_j-a_j)^2)^{\frac{1}{2}}=2^{-n}\delta
\end{gather}
$\vdone$\\

By \myref{Lemma}{2.8.8}, we can pick $\vecta{x}\in \bigcap \set{I_i}$. Because $\set{G_\alpha }$ is an open cover of $I$, we know there exists $G_\beta \in \set{G_\alpha }$ such that $\vecta{x}\in G_\beta $. Because $G_\beta $ is open, we know there exists $r\inr^+$ such that
\begin{equation}
B_r(\vecta{x})\subseteq G_\beta 
\end{equation}
Pick $n$ greater than $\log_2 \frac{\delta}{r}$, so we have
 \begin{equation}
2^n>\frac{\delta}{r}\text{ and }r>2^{-n}\delta
\end{equation}
Recall $\vecta{x}\in I_n$, and observe
\begin{equation}
\vecta{y}\in I_n\implies d(\vecta{x},\vecta{y})\leq 2^{-n}\delta<r
\end{equation}
By our observation, we have
\begin{equation}
I_n \subseteq B_r(\secta{x})\subseteq G_{\beta }
\end{equation}
\CaC to $I_n$ is not covered by any finite subset of $\set{G_\alpha }$
\end{proof}
\fbox{\begin{minipage}{39em}
Next, we give an important theorem, where one part of the theorem hold true for all metric space while the other hold true only for Eculidean norm induced metric space.
\end{minipage}}
\begin{definition}
\label{2.8.10}
\textbf{(Definition of Base)} We say a sub-collection $\mathcal{O}$ of topology $\mathfrak{O}$ on $X$ is a base if
\begin{equation}
\forall x\in X, \forall O\in\mathfrak{O}:x\in O,\exists O'\in \mathcal{O}, x\in O'\subseteq O
\end{equation}
\end{definition}
\begin{theorem}
\label{2.8.11}
\textbf{(Property of Base)} Let $\mathcal{O}$ be a base for topology $\mathfrak{O}$ on $X$. We have 
\begin{equation}
\forall O\in \mathfrak{O}, \exists \mathcal{U}\subseteq \mathcal{O}, O=\bigcup \mathcal{U}
\end{equation}
\end{theorem}
\begin{proof}
Arbitrarily pick an open set $O\in\mathfrak{O}$. We wish to find a sub-collection $\mathcal{U}$ of $\mathcal{O}$ such that $O=\bigcup \mathcal{U}$.\\

Arbitrarily pick $x\in O$. Because $\mathcal{O}$ is a base, we know there exists $O_x\in \mathcal{O}$ such that $x\in O_x\subseteq O$. Collect such sets $O_x$ for each point $x\in X$. We see such collection satisfy our need. 
\end{proof}
\begin{definition}
\label{2.8.12}
\textbf{(Definition of Separable Metric Space)} We say a metric space $X$ is separable if it contains a countable dense subset. That is,
\begin{equation}
\exists E\subseteq X, \abso{E}\leq \abso{\N}\text{ and } X=\overline{E}
\end{equation}
\end{definition}
\begin{theorem}
\label{2.8.13}
\textbf{(Separable Metric Space Contain a Countable Base)} Let $X$ be a separable metric space. There exists an countable base $\mathcal{O}$ of metric topology on $X$
\end{theorem}
\begin{proof}
Let $E$ be a countable dense subset of $X$. We now prove
\vi{
 \begin{equation}
\mathcal{O}:=\set{B_r(p):p\in E\text{ and }r\inq} 
\end{equation}
is a countable base}.\\

Notice $\mathcal{O}=\bigcup \set{\set{B_r(p):r\inq}:p\in E}$ is a countable union of countable sets, so $\mathcal{O}$ is countable. We only have to prove $\mathcal{O}$ is a base.\\

Arbitrarily pick $p\in  X$, and arbitrarily pick open $O$ such that $p \in O$. We wish to prove $O$ contain a smaller open set in $\mathcal{O}$ containing $p$.\\

By definition of open, we know there exists $r\inr^+$ such that $p\in B_r(p)\subseteq O$. Because $E$ is dense, we have either $p\in E\text{ or }p\in  S(E)$. If $p\in  E$, then the proof is done by observing $B_r(p)\in \mathcal{O}$, so we know have to consider when $p\in E\setminus  S(E)$.\\

If $p\in S(E)$, then by definition of limit points, we know there exists $r'\inr^+$ such that
 \begin{equation}
r'<\frac{r}{2}\text{ and }\exists q\in E, q\in B_{r'}(p)
\end{equation}
From above, we can intentionally deduce
\begin{equation}
d(q,p)<r'<\frac{r}{2}
\end{equation}
Because $\Q$ is dense in $\R$, we can select a rational  $n$ such that
 \begin{equation}
d(q,p)<n<\frac{r}{2}
\end{equation}
For all $y\in X$, we can deduce
\begin{equation}
 d(y,q)<n\implies  d(y,p)\leq d(y,q)+d(p,q)<n+r'<r
\end{equation}
So because $n\inq\text{ and }d(q,p)<n$, we have
\begin{equation}
p \in B_n(q)\subseteq B_r(p)\subseteq O\text{ and }B_n(q)\in\mathcal{O}\vdone
\end{equation}
\end{proof}

\begin{theorem}
\label{2.8.14}
\textbf{(Heine-Borel Theorem, part 1)} Given \textit{any} metric space, we have
\begin{gather}
\text{ $K$ is compact  }\\
\liff \text{ every infinite subset $E$ of $K$ has a limit point in $K$}
\end{gather}
\end{theorem}
\begin{proof}
$(\longrightarrow)$\\

Let $E$ be an infinite subset of $K$.  \As{$K$ contain no limit points of $E$}. Recall the definition
\begin{equation}
q\in E'\iff \forall r\inr^+,\exists p\neq q, p\in  B_r(q)\cap E
\end{equation}
If $K$ contain no limit points of $E$, we know
 \begin{equation}
\forall q\in K, \exists r_q\inr^+, B_{r_q}(q)\cap E\subseteq \set{q}
\end{equation}
where the equality hold true when $q\in E$. Let $r_q$ be from above. Observe that
\begin{equation}
\set{B_{r_q}(q): q \in K}
\end{equation}
is an open cover of $K$, thus of  $E$, since $E\subseteq K$.\\

For this open cover, we can see every finite sub-cover contain only finite amount of points of $E$, while  $E$ is infinite. If every finite sub-cover doesn't even cover a subset $E$ of $K$, it doesn't cover whole  $K\tCaC$ to $K$ is compact.\\

$(\longleftarrow)$\\

We first prove \vi{$K$ is  separable}. In a general scope, we say a metric space is separable if it contain a countable dense set. Notice that subsets of a metric space are trivially metric spaces. However, consider $K\subseteq X$. Some subsets of $K$ considered open in $K$ may be considered not open in $X$. For detail about embedded metric space, we will later discuss. Here, we need only to know \textit{if a point $p$ is a limit point of $E$ considered by $K$, then  $p$ is a limit point of  $E$ considered by $X$}. (try to verify it, not difficult)\\

For this reason, to prove $K$ is separable, we only need to \vi{find a countable subset $Q\subseteq K$ such that  $\overline{Q}=K$ in scope of $K$ without any worry}.\\

Let $\delta>0$ and let $a_{\delta, 1}\in K$. We now prove \teal{there exists a finite set  $A_\delta=\set{a_{\delta ,1},a_{\delta ,2}, \dots , a_{\delta, n}}$ such that $K\subseteq \bigcup \set{B_\delta (a_{\delta ,i}):a_{\delta ,i}\in A_{\delta}}$}.\\

To prove such, we construct $A_\delta$ by adding element $a_{\delta,i}$ such that $\forall j<i, d(a_{\delta, j},a_{\delta ,i})\geq \delta$ to $\set{a_{\delta ,1}}$ until impossible. \As{such finite set $A_\delta$ can not be constructed using this method}. In other words, we assume our method of adding points can go on infinitely. Then if take union of all added result at each step, we gain an infinite set $A'=\set{a_{\delta,1},a_{\delta,2},\dots}$ such that
\begin{equation}
\forall a_{\delta,i},a_{\delta,j}\in A', d(a_{\delta, i},a_{\delta , j})\geq \delta
\end{equation}
Arbitrarily pick $p\in  K\setminus A'$, we wish to show there exists $r\inr^+$ such that
\begin{equation}
B_r(p)\cap A'\subseteq \set{p}
\end{equation}
If for all $a_{\delta,i}\in A'$, we have $d(a_{\delta ,i},p)\geq \frac{\delta}{2}$, then we can let $r<\frac{\delta}{2}$ and we are done, so we only have to consider when there exists $a_{\delta,i}$ such that $d(a_{\delta ,i},p)<\frac{\delta}{2}$. Let $r=d(a_{\delta ,i},p)$, we see 
\begin{equation}
a_{\delta ,i}\not\in B_r(p)
\end{equation}
and for all $j\neq i$, we deduce
\begin{equation}
\delta \leq  d(a_{\delta,i},a_{\delta,j})  \leq  d(a_{\delta,i},p)+d(p,a_{\delta,j}) <d(p,a_{\delta,j})+\frac{\delta}{2}
\end{equation}
and deduce
\begin{equation}
r=d(a_{\delta,i},p)<\frac{\delta}{2}=\delta-\frac{\delta}{2}<d(a_{\delta,j},p)
\end{equation}
So 
\begin{equation}
a_{\delta ,j}\not\in B_r(p)
\end{equation}
Then 
\begin{equation}
B_r(p)\cap A'=\varnothing
\end{equation}
In other words, we have proved if we arbitrarily pick  $p\in  K\setminus A'$, then $p$ is not a limit point of  $A'$. Notice that to show no point of $A'$ is limit point of $A'$, just observe when  $r=\delta$. In summary, no points in $K$  is a limit point of $A'$. Recall that $A'$ is infinite, then have  \CaC to the premise of whole theorem, every infinite subset of $K$ has a limit point in $K\tdone$\\

Let $A_\delta$ be the finite set from $\teal{\text{teal part}}$. Consider the collection $A=\bigcup \set{A_1,A_{\frac{1}{2}},A_{\frac{1}{3}},\dots}$. Because $A$ is a countable union of finite sets, we know $A$ is itself countable. We now prove \olive{$A$ is dense} (if have doubt, see the first paragraph of the proof).\\

To prove $\overline{A}=K$, we wish to prove $K\setminus A\subseteq S(A)$. Arbitrarily pick $p\in  K\setminus A$. We wish to show
\begin{equation}
\forall r\inr^+, \exists q\neq p, q\in B_r(p)\cap A
\end{equation}
Arbitrarily pick $r\inr^+$. Select $n\inn$ great enough (greater than $\frac{1}{r}$), so we have
\begin{equation}
r>\frac{1}{n}
\end{equation}
Notice by \teal{teal part}, we have
\begin{equation}
  K\subseteq \bigcup \set{B_{\frac{1}{n}}(a_{\frac{1}{n},i}):a_{\frac{1}{n},i}\in A_{\frac{1}{n}}}
\end{equation}
(above in English means that $K$ is cover by open balls of radius $\frac{1}{n}$, each centering $a_{\frac{1}{n},i}$)\\

Now, because $p\in K$, we know there exists $a_{\frac{1}{n},i}$ such that
\begin{equation}
p\in B_{\frac{1}{n}}(a_{\frac{1}{n},i})
\end{equation}
which tell us 
 \begin{equation}
d(a_{\frac{1}{n},i},p)<\frac{1}{n}<r
\end{equation}
Recall $p$ is arbitrarily picked from $K\setminus A$. We then have
\begin{equation}
a_{\frac{1}{n},i}\neq p \text{ and }a_{\frac{1}{n},i}\in B_{\frac{1}{n}}(p)\cap A\subseteq B_r(p)\cap A\odone\vdone
\end{equation}
 Arbitrarily pick an open cover $\mathcal{G}$. We wish to prove \blue{$\mathcal{G}$ contain a finite sub-cover}.\\

We first prove  \teal{$\mathcal{G}$ contain a countable sub-cover}.\\

Now, by \myref{Theorem}{2.8.13}, we know $K$ has a countable base (In Theorem 2.8.13, we prove that if a metric space is separable, then it has a countable base by constructing the base with open ball. To see $K$ does have a countable base in the scope of $X$, just realize the base constructed with open balls applies to our situation).\\

Let $\mathcal{O}$ be a countable base for $K$.\\

For all $p\in K$, because $\mathcal{G}$ is an open cover, we know 
\begin{equation}
\exists G_p\in  \mathcal{G},p \in G_p
\end{equation}
Then because $G_p$ is open and $\mathcal{O}$ is a base, we know
\begin{equation}
\exists O_p\in  \mathcal{O}, p\in O_p\subseteq G_p
\end{equation}
Then from above relation, we can collect 
\begin{equation}
\mathcal{O}':=\set{O_p\in \mathcal{O}: p\in K,p\in O_p\subseteq G_p}\subseteq \mathcal{O}
\end{equation}
Then we can collect
\begin{equation}
\mathcal{G}':=\set{G_p\in  \mathcal{G}:p\in  K,p\in O_p\subseteq G_p}\subseteq \mathcal{G}
\end{equation}
Because $\mathcal{O}$ is countable and $\abso{\mathcal{G}'}\leq \abso{\mathcal{O}'}$. We know $\mathcal{G}'$ is countable and by its nature of construction, a cover. $\tdone$\\

Now, well order $\mathcal{G'}$ as $\set{G_n:n\inn}$. Notice $\set{G_n:n\inn}$ is a sub-cover of an arbitrary cover $\mathcal{G}$. We only wish to prove \olive{$\set{G_n:n\inn}$ contain a finite sub-cover}.\\

For all $n\inn$, define
\begin{equation}
F_n:=K\setminus \bigcup \set{G_j:j\leq n\inn}
\end{equation}
For all $k\inn$, by definition we have
\begin{equation}
x\in F_k\iff x\in K\text{ and }x\not\in \bigcup \set{G_j:j\leq k\inn}
\end{equation}
Let $l<k$. We have
\begin{equation}
\bigcup \set{G_j:j\leq l\inn}\subseteq \bigcup \set{G_j:j\leq k\inn}
\end{equation}
So we can deduce
\begin{gather}
x\in F_k \iff x\in K\text{ and }x\not\in \bigcup \set{G_j:j\leq k\inn}\\
\implies x\in K\text{ and }x\not\in \bigcup \set{G_j:j\leq l\inn}\iff x\in F_l
\end{gather}
In other words, we have proved $l<k\inn \implies F_k\subseteq F_l$. That is 
\begin{equation}
\cdots\subseteq F_3 \subseteq F_2\subseteq F_1
\end{equation}
We now prove  \orange{$\bigcap \set{F_j:j\inn}=\varnothing$}.\\

\As{$\bigcap \set{F_j:j\inn}\neq \varnothing$}. Then we can find $y$ such that
\begin{equation}
\forall n\inn, y\in F_n
\end{equation}
Notice that by definition
\begin{equation}
y\in F_n\implies y\not\in \bigcup \set{G_j:j\leq n\inn}\implies y\not\in G_n
\end{equation}
So we have
\begin{equation}
\forall n\inn, y\not\in G_n
\end{equation}
This \CaC to that $\set{G_n:n\inn}$ is a cover \ordone\\

\As{$\set{G_n:n\inn}$ contain no finite sub-cover}. Then we know 
\begin{equation}
\forall n\inn, F_n\neq \varnothing
\end{equation}
Otherwise $\set{G_j:j\leq n\inn}$ is a finite sub-cover.\\

Notice it is impossible that
\begin{equation}
\exists m \inn, \forall u>m \inn , F_u=F_m\neq \varnothing 
\end{equation}
Otherwise we can find $x\in F_m$ such that
\begin{gather}
\forall n\inn, n\geq m\text{ or }n<m\implies \forall n\inn, x\in F_m=F_n\text{ or }x\in F_m\subseteq F_n\\
\implies\forall n\inn, x\in F_n\\
\implies \forall n\inn, x\not\in G_n \text{(Notice $x\in G_n\implies x\not\in F_n$)}\\
\implies x\not\in \bigcup \set{G_n:n\inn}
\end{gather}
where $\set{G_n:n\inn}$ is a cover.\\

Then we know 
\begin{equation}
\forall n\inn, \exists m<n\inn, F_m\subset F_n
\end{equation}
So if we collect each point $x_j$ from each possible nonempty $F_j\setminus F_{j+1}$, we have an countable infinite set $\set{x_j}$. By the premise of the whole theorem, we know there exists a limit point $p$ of  $\set{x_j}$.\\

Because $\set{G_n:n\inn}$ is an open cover, we know 
\begin{equation}
\exists m \inn, p\in G_m
\end{equation}
And because $G_m$ is open, we know 
\begin{equation}
\exists r\inr^+, B_r(p)\subseteq G_m
\end{equation}
Because $p$ is an limit point of $\set{x_j}$, by \myref{Theorem}{2.7.20}, we know $B_r(p)$ should contain infinite points of $\set{x_j}$.\\

But we can see for all $n$ greater than $m$, we have
\begin{equation}
x_n\in F_n
\end{equation}
which implies
\begin{equation}
x_n\not \in \bigcup \set{G_j:j\leq n\inn}
\end{equation}
Then we have
\begin{equation}
\forall n>m \inn, x_n\not\in G_m
\end{equation}
Because $B_r(p)\subseteq G_m$, we then see
\begin{equation}
\forall n>m \inn, x_n\not\in B_r(p)
\end{equation}
More crucially, we see
\begin{equation}
B_r(p)\cap \set{x_j}\subseteq \set{x_l:l<m \inn}
\end{equation}
\CaC to \myref{Theorem}{2.7.20} $\odone \bdone$
\end{proof}
\fbox{\begin{minipage}{39em}
The above theorem can be generalized to topological space where limit point is changed to complete limit point, and the proof would require usage of idea of minimal cardinal.\\

We now give another part of Heine-Borel Theorem, which is only in Euclidean metric and $\R^k$ 
\end{minipage}}
\begin{theorem}
\textbf{(Heine-Borel Theorem, part 2)} In $(\R^k, d(\vecta{x},\vecta{y})=\abso{\vecta{x}-\vecta{y}})$, we have
\begin{gather}
K\text{ is closed and bounded }\iff   K\text{ is compact }
\end{gather}
\end{theorem}
\begin{proof}
$(\longrightarrow)$\\

We first prove \vi{each bounded set $E$ is contained by some $k$-cell}.\\

Notice that if the "heights" set 
\begin{equation}
\set{x_j:\vecta{x}\in E}
\end{equation}
is not both bounded above and below, then for all distance $r\inr^+$, we can pick $\vecta{x},\vecta{y}$, such that $\abso{x_j-y_j}>r$. Then we can see 
\begin{equation}
\abso{\vecta{x}-\vecta{y}}>\abso{x_j-y_j}>r
\end{equation}
We have proved for all direction, the "height" is both bounded below and above.\\

Then for each direction, we can pick an upper bound $b_j$ and lower bound $a_j$, so we have
\begin{equation}
E\subseteq [a_1,b_1]\times \cdots \times [a_k,b_k]\vdone
\end{equation}
We know k-cell is compact. Then because $K$ is closed and contained by some k-cell, we know $K$ is compact.\\

$(\longleftarrow)$\\

$K$ is compact implies $K$ is closed, so we only have to prove \blue{$K$ is bounded}.\\

\As{$K$ is not bounded}. We now prove  \teal{$\forall \vecta{x}\in K,\exists \vecta{y}\in K, d(\vecta{y},\vecta{0})>d(\vecta{x},\vecta{0})+1$}.\\

Let $r=d(\vecta{x},0)$. We know 
\begin{equation}
K\setminus B_{2r+1}(\vecta{x})
\end{equation}
must be nonempty, otherwise 
\begin{equation}
\forall \vecta{y},\vecta{z}\in K, d(\vecta{y},\vecta{z})\leq d(\vecta{x},\vecta{y})+d(\vecta{z},\vecta{z})<4r+2
\end{equation}
Then we can pick $\vecta{y}\in K \setminus B_{2r+1}(\vecta{x})$, and observe
\begin{gather}
2r+1< d(\vecta{x},\vecta{y})\leq d(\vecta{x},\vecta{0})+d(\vecta{y},\vecta{0})\leq d(\vecta{y},\vecta{0})+r\\
\implies d(\vecta{y},\vecta{0})>r+1=d(\vecta{x},0)+1\tdone
\end{gather} 
By  \teal{teal part}, we can construct a sequence $\set{\vecta{x}_i:i\inn}$ such that 
\begin{equation}
\forall i\inn, d(\vecta{x}_{i+1},\vecta{0})>d(\vecta{x}_{i},\vecta{0})+1
\end{equation}
We now prove \olive{$\set{\vecta{x}_i:i \inn}$ has no limit point in $\R^k$}.\\

\As{$\set{\vecta{x}_i:i\inn}$ has some limit points in $\R^k$}. Let $p$ be a limit point of $\set{\vecta{x}_i:i \inn}$. Arbitrarily pick $r\inr^+$. By \myref{Theorem}{2.7.20}, we know $B_r(p)$ should contain infinite points of $\set{\vecta{x}_i}$.\\

Observe for all $\vecta{y}\inr^K$, we have
\begin{equation}
d(\vecta{y},p)<r\implies d(\vecta{0},\vecta{y})\leq d(\vecta{0},p)+d(p,\vecta{y})<d(\vecta{0},p)+r
\end{equation}
Let $a=d(\vecta{0},p)$. We have
\begin{equation}
B_r(p)\subseteq B_{a+r}(\vecta{0})
\end{equation}
But because 
\begin{equation}
i>j\implies d(\vecta{x}_i,\vecta{0})-d(\vecta{x}_j,\vecta{0})>1
\end{equation}
For all $n>1\inn$, we have
\begin{equation}
d(\vecta{x}_n,\vecta{0})>n-1
\end{equation}
Let $b$ be the minimal naturals greater than  $a+r$. We have
\begin{equation}
B_{a+r}(\vecta{0})\cap \set{\vecta{x}_i:i\inn}\subseteq \set{\vecta{x}_i:i\leq b\inn}\tCaC\odone
\end{equation}
By the first part of Heine-Borel Theorem, we know $\set{\vecta{x}_i:i\inn}$ has limit points in $K$. Notice that if a point in  $K$ is a limit point of $\set{\vecta{x}_i:\inn}$ in $K$, it is a limit point of $\set{\vecta{x}_i:i\inn}$ in $\R^k\tCaC$ to \olive{olive part}. $\bdone$ 
\end{proof}
\section{Exercises}
\begin{question}{}{}
Let $(X,d)$ be a metric space, and let $x_1,x_2,\dots,x_n \in X$. Prove
\begin{equation}
d(x_1,x_n)\leq \sum_{i=1}^{n-1}d(x_i,x_{i+1})
\end{equation}
\end{question}
\begin{proof}
Let $P(j)$ be the predicate 
\begin{equation}
d(x_1,x_j)\leq \sum_{i=1}^{j-1}d(x_i,x_{i+1})
\end{equation}
We prove $P(n)$ by induction on $j$.\\

Base case: $j=2$. \\
\begin{equation}
d(x_1,x_2)\leq d(x_1,x_2)=\sum_{i=1}^{1}d(x_i,x_{i+1})
\end{equation}\\
By observing above equation, base case is done.\\

Induction Case: $\forall k:k>2\text{ and }n\geq k,P(k)\longrightarrow P(k+1)$ \\

By triangle inequality axiom of metric, we have $d(x_1,x_{k+1})\leq d(x_1,x_k)+d(x_k,x_{k+1})$\\

By $P(k)$, we have $d(x_1,x_k)\leq \sum_{i=1}^{k-1}d(x_i,x_{i+1})$\\

By above two equations, we have
\begin{equation}
d(x_1,x_{k+1})\leq d(x_1,x_k)+d(x_k,x_{k+1})\leq \sum_{i=1}^{k-1}d(x_i,x_{i+1})+d(x_k,x_{k+1})=\sum_{i=1}^k d(x_i,x_{i+1})
\end{equation}
which is $P(k+1)$.\\

So we have deduced from $P(k)$ to $P(k+1)$, which handle the induction case, finishing the whole proof.\\
\end{proof}
\begin{question}{}{}
Refer to Example 2.2(9). Show that $d(x,y)$ is finite for all $x,y \in l_1$ and that d defines a metric for $l_1$.
\end{question}
\begin{proof}
We first prove the \vi{finite part}; more precisely, we prove for any two sequence $\set{x_i},\set{y_i}$ in $l_1$, the limit $\lim_{m\to\infty}\sum_{k=1}^m \abso{x_k-y_k}$ converge.\\

Notice for all $k$, we know  $(\abso{x_k-y_k}),(\abso{x_k}+\abso{y_k})$ are nonnegative, so we know the series $\sum_{k=1}^m \abso{x_k-y_k}$ and the series $\sum_{k=1}^m \abso{x_k}+\abso{y_k}$ monotonically increase, then we only have to the former series is bounded above, then by Theorem of bounded above increasing sequence, the proof will be finished.\\

We wish to prove $\lim_{n\to\infty}\sum_{k=1}^n $  the two inequality  
\begin{equation}
\forall m \inn, \sum_{k=1}^m \abso{x_k-y_k}\leq \sum_{k=1}^m \abso{x_k}+\abso{y_k}\leq   \lim_{n\to\infty}\sum_{k=1}^n \abso{x_k}+\sum _{k=1}^n\abso{y_k}
\end{equation}
The first inequality hold true by triangle inequality, and the second inequality hold true if we can show the limit of a monotonically increasing converge series is an upper bound of the series.\\

\As{it is not an upper bound}; that is, there exists $s \inn$ such that $\sum_{k=1}^s \abso{x_k}+\abso{y_k}> \lim_{n\to\infty}\abso{x_k}+\abso{y_k}$. We denote $L=\sum_{k=1}^s \abso{x_k}+\abso{y_k}-\lim_{n\tof\infty}\sum_{n=1}^k\abso{x_k+y_k}$. Notice $L$ is a positive constant, since  $\sum_{k=1}^s \abso{x_k}+\abso{y_k}> \lim_{n\to\infty}\abso{x_k}+\abso{y_k}$\\

Then because the series monotonically increase we have
\begin{equation}
\forall d>s\inn, \sum_{k=1}^d \abso{x_k}+\abso{y_k}\geq \sum_{k=1}^s \abso{x_k}+\abso{y_k}>\lim_{n\to\infty}\abso{x_k}+\abso{y_k}
\end{equation}
which implies
\begin{equation}
\forall d>s\inn, \sum_{k=1}^d \abso{x_k}+\abso{y_k}-(\lim_{n\to\infty}\sum_{k=1}^n \abso{x_k}+\abso{y_k})\geq L
\end{equation}
which further implies the series $\sum_{k=1}^d \abso{x_k}+\abso{y_k}$ does not converge to $\lim_{n\to\infty} \sum_{k=1}^n \abso{x_k}+\abso{y_k}\tCaC$.\\
\end{proof}
\chapter{Numerical Sequence and Series}
\chapter{Vector Analysis}
\section{Important Inequalities}
\begin{theorem}
\label{4.1.1}
\textbf{(Young's Inequality)} If $a,b\geq 0$ and $p,q>1$ and  $\frac{1}{p}+\frac{1}{q}=1$, then
\begin{equation}
ab\leq \frac{a^p}{p}+\frac{b^q}{q}
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
  ab&=\exp(\ln a+ \ln b)\\
    &=\exp[(\frac{1}{p}\ln a^p)+(\frac{1}{q}\ln b^q)]\\
&\leq \frac{1}{p}\exp(\ln a^p)+\frac{1}{q}\exp(\ln b^q)\\
&= \frac{a^p}{p}+\frac{b^q}{q}
\end{align}
The inequality above hold true because  $\exp$ is concave upward, and $\frac{1}{p}+\frac{1}{q}=1$. 
\end{proof}
\begin{theorem}
\label{4.1.2}
\textbf{(Definition of $p$-norm)} Recall in Chapter 1, we define absolute value on $\R$ and  $\C$. With that definition, we have: for all $0<p \in \R$, the definition
\begin{equation}
  \norm{\vecta{v}}_p:= (\sum \abso{v_i}^p)^{\frac{1}{p}}
\end{equation}
\textit{almost} form a norm.
\end{theorem}
\begin{proof}
Observe 
\begin{align}
\norm{\ld \vecta{v}}_p&=(\sum \abso{\ld v_i}^p)^{\frac{1}{p}} \\
&=[\sum (\abso{\ld }\abso{v_i})^p]^{\frac{1}{p}}\\
&=[\sum (\abso{\ld })^p(\abso{v_i})^p]^{\frac{1}{p}}\\
&=[(\abso{\ld })^p\sum (\abso{v_i})^p]^{\frac{1}{p}}\\
&=[(\abso{\ld })^p]^{\frac{1}{p}}(\sum \abso{v_i}^p)^{\frac{1}{p}}\\
&=\abso{\ld }(\norm{\vecta{v}}_p)
\end{align}
Nonnegative and positive definiteness is trivial. Triangle Inequality \textit{is left to proved}. 
\end{proof}
\begin{theorem}
\label{4.1.3}
\textbf{(Holder's Inequality in $\C^n$)} Let $\vecta{x},\vecta{y}\in \C^n,\frac{1}{p}+\frac{1}{q}=1$. Define $\vecta{xy}$ by $\vecta{xy}_i=\vecta{x}_i\vecta{y}_i$. We have
\begin{equation}
\norm{\vecta{xy}}_1\leq \norm{\vecta{x}}_p\norm{\vecta{y}}_q
\end{equation}
\end{theorem}
\begin{proof}
Normalize 
\begin{equation}
\hat{\vecta{x}}:= \frac{\vecta{x}}{\norm{\vecta{x}}_p}\text{ and }\hat{\vecta{y}}:=\frac{\vecta{y}}{\norm{\vecta{y}}_q}
\end{equation}
So we only wish to prove
\begin{equation}
\norm{\hat{\vecta{x}}\hat{\vecta{y}}}_1\leq 1 
\end{equation}
Notice because $(\sum \abso{\hat{x}_i}^p)^{\frac{1}{p}}=\norm{\hat{\vecta{x}}}_p=\norm{\frac{\vecta{x}}{\norm{\vecta{x}}_p}}_p=\frac{\norm{\vecta{x}}_p}{\norm{\vecta{x}}_p}=1$, and similarly vice versa for $\vecta{y}$, we have \begin{equation}
\sum \abso{\hat{x}_i}^p=1=\sum \abso{\hat{y}_i}^q \end{equation} So by Young's inequality, we have \begin{equation} \norm{\hat{\vecta{x}}\hat{\vecta{y}}}_1= \sum \abso{\hat{x }_i\hat{y}_i}=\sum \abso{\hat{x}_i}\abso{\hat{y}_i}\leq \sum \frac{\abso{\hat{x}_i}^p}{p}+\frac{\abso{\hat{y}_i}^q}{q}=\frac{1}{p}+\frac{1}{q}=1
\end{equation}
\end{proof}
\begin{corollary}
\label{4.1.4}
\textbf{(Minkowskis Inequality in $\C^n$ and $p>1$)} Let $\vecta{x},\vecta{y}\in\C^n$, and let $p\in \R^+\text{ and }p\neq 1$. We have triangle inequality for all supposed $p$-norm
\begin{equation}
p>1\implies  \norm{\vecta{x}+\vecta{y}}_p\leq \norm{\vecta{x}}_p+\norm{\vecta{y}}_p
\end{equation}
\end{corollary}
\begin{proof}
Let $q=\frac{p}{p-1}$, so we have
\begin{equation}
\frac{1}{p}+\frac{1}{q}=\frac{p}{p}=1
\end{equation}
Then we deduce 
\begin{align}
  \norm{\vecta{x}+\vecta{y}}_p^p&=\sum \abso{x_i+y_i}^p\\
&= \sum \abso{(x_i+y_i)^{p}}\\
                                &=\sum \abso{(x_i+y_i)(x_i+y_i)^{p-1}}\\
                                &\leq \sum \abso{x_i(x_i+y_i)^{p-1}}+\abso{y_i(x_i+y_i)^{p-1}}\\
                                &=\norm{\vecta{x}(\vecta{x}+\vecta{y})^{p-1}}_1 + \norm{\vecta{y}(\vecta{x}+\vecta{y})^{p-1}}_1\rap{\text{ Operation is component wise }}\\
&\leq  \norm{\vecta{x}}_p\norm{(\vecta{x}+\vecta{y})^{p-1}}_q+\norm{\vecta{y}}_p\norm{(\vecta{x}+\vecta{y})^{p-1}}_q\rap{\text{ Holder's Inequality }}\\ 
&= \norm{\vecta{x}}_p[\sum (\abso{(x_i+y_i)^{p-1}})^q]^{\frac{1}{q}}+\norm{\vecta{y}}_p[\sum (\abso{(x_i+y_i)^{p-1}})^q]^{\frac{1}{q}}\\
&= \norm{\vecta{x}}_p[\sum (\abso{x_i+y_i}^{p-1})^q]^{\frac{1}{q}}+\norm{\vecta{y}}_p[\sum (\abso{x_i+y_i}^{p-1})^q]^{\frac{1}{q}}\\
&= \norm{\vecta{x}}_p (\sum \abso{x_i+y_i}^p)^{\frac{1}{q}}+\norm{\vecta{y}}_p (\sum \abso{x_i+y_i}^p)^{\frac{1}{q}}\rap{\text{ because $q(p-1)&=p$ }}\\
&= (\norm{\vecta{x}}_p+\norm{\vecta{y}}_p)\norm{\vecta{x}+\vecta{y}}_p^{\frac{p}{q}}
\end{align} 
So 
\begin{equation}
\norm{\vecta{x}+\vecta{y}}_p=\norm{\vecta{x}+\vecta{y}}_p^{p-\frac{p}{q}}\leq \norm{\vecta{x}}_p+\norm{\vecta{y}}_p
\end{equation}
\end{proof}
\begin{definition}
\label{4.1.5}
\textbf{(Definition of $p$-norm)} On $\C^n$,\textit{ if and only if $p>1$}, we say the  $p$-norm is 
\begin{equation}
  \norm{\vecta{v}}_p:= (\sum \abso{v_i}^p)^{\frac{1}{p}}
\end{equation}
\end{definition}
\section{Definition of Differential-able on Euclidean Space} 
\begin{definition}
\label{4.2.1}
\textbf{(Little-o Notation)} If we write $o(g(x))=f(x)$, we mean
\begin{equation}
\lim_{g(x)\to 0}\frac{f(x)}{g(x)}=0
\end{equation}
\end{definition}
\begin{definition}
\label{4.2.2}
\textbf{(Differentiable on $\R$)} We say a real-valued function $f(x)$ on $\R$ is differentiable on $a$ if 
\begin{equation}
\exists L\in \R, \lim_{x \to a}\frac{f(x)-f(a)}{x-a}=L
\end{equation}
Notice $L$ should be viewed as slope (not a number on real number line), or more abstract, a linear transformation from $\R^1$ to  $\R^1$. 
\end{definition}
\begin{definition}
\label{4.2.3}
\textbf{(Differentiable on $2$-Euclidean Space)} We say a real-valued function $f(x,y)$ on $2$-Euclidean space is differentiable at $(a,b)$ if there exists a $1\times 2$ real matrix $\vecta{H}_{(a,b)}$ such that 
\begin{equation}
 \lim_{(x,y)\to (a,b)}\frac{f(x,y)-f(a,b)-(\vecta{H}_{(a,b)}(x,y)-\vecta{H}_{(a,b)}(a,b))}{\norm{(x-a,y-b)}_2}=0
\end{equation}
\end{definition}
\fbox{\begin{minipage}{39em}
In lower dimensions, our understanding of tangency is typically represented by tangent lines and planes. For a function mapping from \( \mathbb{R} \rightarrow \mathbb{R} \), we can define a tangent line as \( T(x) = L(x-a) \). For a function mapping from \( \mathbb{R}^2 \rightarrow \mathbb{R} \), we can define a tangent plane as \( T(x,y) = \mathbf{H}_{(a,b)}(x-a,y-b) \). Notice that these tangential representations fundamentally hinge on linear transformations, embodied by the matrix $\begin{bmatrix}
L
\end{bmatrix}$
and the transformation \( \mathbf{H}_{(a,b)} \).\\

Drawing a function from \( \mathbb{R} \rightarrow \mathbb{R} \) is achieved in \( \mathbb{R}^2 \), and a function from \( \mathbb{R}^2 \rightarrow \mathbb{R} \) is depicted in \( \mathbb{R}^3 \). Thus, a function from \( \mathbb{R}^m \rightarrow \mathbb{R}^n \) would be visualized in \( \mathbb{R}^{m+n} \). One might consider representing a function directly in its co-domain as an alternative. However, this method is flawed. To see this, consider how we plot a \( \mathbb{R} \rightarrow \mathbb{R} \) function in \( \mathbb{R}^2 \): if we tried to represent the tangents of such a function directly on its co-domain (the y-axis), it would simply be a continuous set of all numbers, providing no clear information.\\

This realization underscores the fact that the concept of "tangency" is fundamentally grounded in linear transformations. As we ascend into higher dimensions, our ability to visually represent tangents becomes constrained by our dimensional space. For instance, while we can theoretically define tangents in \( \mathbb{R}^4 \), their visual representation remains elusive, unlike the more tangible planes in \( \mathbb{R}^3 \).
\end{minipage}}
\begin{definition}
\label{4.2.4}
\textbf{(A General Definition of Differentiable of Function from Normed $\R^n$ to  $\R^m$)} Let $\vecta{f}:\R^n\rightarrow \R^m$. We say $\vecta{f}$ is differentiable at $\vecta{a}$ if there exists a linear transformation $\vecta{H}:\R^n\rightarrow \R^m$ such that 
\begin{equation}
\lim_{\vecta{x}\to \vecta{a}}\frac{\norm{\vecta{f}(\vecta{x})-\vecta{f}(\vecta{a})-\vecta{H}(\vecta{x}-\vecta{a})}_{\R^m}}{\norm{\vecta{x}-\vecta{a}}_{\R^n}}=0
\end{equation}
There is no restriction on which norm to use on $\R^n$ and $\R^m$, but the metric implicitly used in the limit symbol is induced by the norm in denominator. The above equation is written
 \begin{equation}
\forall \epsilon, \exists \delta, \forall x,\norm{\vecta{x}-\vecta{a}}_{\R^n}<\delta \longrightarrow \frac{\norm{\vecta{f}(\vecta{x})-\vecta{f}(\vecta{a})-\vecta{H}(\vecta{x}-\vecta{a})}_{\R^m}}{\norm{\vecta{x}-\vecta{a}}_{\R^n}}<\epsilon 
\end{equation}
We also say $\vecta{H}$ is a differential or a derivative of $\vecta{f}$ at $\vecta{a}$
\end{definition}
\fbox{\begin{minipage}{39em}
The core concept of differentiable at a point $\vecta{a}$ is that for all desired error, we can linearly approximate (estimate) $\vecta{a}$, and the error we have will be much less than the difference of the input and $\vecta{a}$.\\


Notice that from now, if we use the norm notation $\norm{\cdot}$ without specification or use the absolute value notation $\abso{\cdot}$, we mean $2$-norm.The $2$-norm is also called "length". 
\end{minipage}}\\

\begin{definition}
\label{4.2.5}
\textbf{(Jacobian Matrix)} For function $\vecta{f}$ from $\R^n$ to $\R^m$. The Jacobian $\vecta{J}_{\vecta{f}}(\vecta{a})$ of $\vecta{f}$ at $\vecta{a}$ is the matrix
 \begin{equation}
   \vecta{J}_{\vecta{f}}(\vecta{a})_{i,j}=\frac{\partial f_i}{\partial x_j}(\vecta{a})
\end{equation}
If we write $\vecta{J}$, we mean a matrix-valued function 
\begin{equation}
  (D\vecta{f})(\vecta{a}):=\vecta{J}(\vecta{a}):=\vecta{J}_{\vecta{f}}(\vecta{a})
\end{equation}
\end{definition}
\begin{theorem}
\label{4.2.6}
\textbf{(If Differentiable, Then Jacobian is a Differential)}
\end{theorem}
\begin{proof}
  \red{missed}
\end{proof}
\begin{theorem}
\label{4.2.7}
\textbf{(Example of Differentiable Function)} 
\begin{equation}
f(x,y)=x^2+2y\text{ is differentiable every where}
\end{equation}
\end{theorem}
\begin{proof}
Notice 
\begin{equation}
\vecta{J}=\begin{bmatrix}
  2x&2
\end{bmatrix}
\end{equation}
For each point $(a,b)$, we let $\vecta{H}:=\vecta{J}(a,b)=\begin{bmatrix}
  2a&2
\end{bmatrix}$, and we have
\begin{equation}
\lim_{\vecta{x}\to \vecta{a}}\frac{f(\vecta{x})-f(\vecta{a})-\vecta{H}(\vecta{x}-\vecta{a})}{\norm{\vecta{x}-\vecta{a}}_{\R^n}}=\lim_{\vecta{x}\to \vecta{a}}\frac{(x-a)^2}{\sqrt{(x-a)^2+(y-b)^2}}
\end{equation}
Notice that we have
\begin{equation}
\lim_{x\to a}\frac{(x-a)^2}{\sqrt{(x-a)^2} }=0
\end{equation}
In $\epsilon,\delta$ language, we have
\begin{equation}
\forall \epsilon,\exists \delta, \forall x, \abso{x-a}<\delta \implies \frac{(x-a)^2}{\sqrt{(x-a)^2} }<\epsilon  
\end{equation}
For all $\epsilon $, we then can pick the $\delta$ above so we have
\begin{equation}
\sqrt{(x-a)^2+(y-b)^2}<\delta \implies \abso{x-a}<\delta\implies \frac{(x-a)^2}{\sqrt{(x-a)^2+(y-b)^2} }\leq  \frac{(x-a)^2}{\sqrt{(x-a)^2} } <\epsilon 
\end{equation}
This prove equation 4.40 approach to 0
\end{proof}
\begin{theorem}
\label{4.2.8}
\textbf{(Example of Differentiable Function)} Let $\vecta{f}:\R^n\rightarrow \R^m$ 
\begin{equation}
\text{ If $\vecta{f}$ is linear, then $\vecta{f}$ is differentiable everywhere }
\end{equation}
\end{theorem}
\begin{proof}
Let $\vecta{H}=\vecta{f}$, then we have 
\begin{equation}
  \lim_{\vecta{x}\to \vecta{a}}\frac{\norm{\vecta{f}(\vecta{x})-\vecta{f}(\vecta{a})-\vecta{H}(\vecta{x}-\vecta{a})}}{\norm{\vecta{x}-\vecta{a}}}=\lim_{\vecta{x}\to \vecta{a}}\frac{\norm{\vecta{f}(\vecta{x}-\vecta{a}-(\vecta{x}-\vecta{a}))}}{\norm{\vecta{x}-\vecta{a}}}=\lim_{\vecta{x}\to \vecta{a}}\frac{\norm{\vecta{f}(\vecta{0})}}{\norm{\vecta{x}-\vecta{a}}}=0
\end{equation}
\end{proof}
\begin{theorem}
\label{4.2.9}
\textbf{(Example of Jacobian Exists, But Non-Differentiable)} 
\begin{equation}
f(x,y)=\begin{cases}
  \frac{xy}{x^2+y^2}& \text{ if  }(x,y)\neq \vecta{0}\\
  0& \text{ if  }(x,y)=\vecta{0}
\end{cases}\text{ exists jacobian but non-differentiable at $\vecta{0}$  }
\end{equation}
\end{theorem}
\begin{proof}
Notice $\vecta{J}(0,0)=\begin{bmatrix}
  0&0
\end{bmatrix}$. Now we prove $f$ is non-differentiable. Observe
\begin{equation}
\lim_{(x,y)\to (0,0)}\frac{f(x,y)-f(0,0)-\vecta{H}(0,0)}{\sqrt{x^2+y^2} }=\frac{f(x,y)}{\sqrt{x^2+y^2} }=\frac{xy}{(x^2+y^2)^{\frac{3}{2}}}
\end{equation}
We know 
\begin{equation}
\lim_{x\to 0}\frac{x^2}{(2x^2)^{\frac{3}{2}}}=\infty
\end{equation}
In $\epsilon,\delta$ language, we have
\begin{equation}
\forall \epsilon, \exists \delta, x=\delta\implies  \frac{x^2}{(2x^2)^{\frac{3}{2}}}>\epsilon 
\end{equation}
Then we have 
\begin{equation}
  \forall \epsilon ,\exists \delta, (x,y)=(\frac{\delta}{\sqrt{2}},\frac{\delta}{\sqrt{2}}) \implies \frac{xy}{(x^2+y^2)^{\frac{3}{2}}}=\frac{\delta^2}{2(\delta^2)^{\frac{3}{2}}}>\epsilon 
\end{equation}
which prove  equation 4.47 does not approach to 0.
\end{proof}
\fbox{\begin{minipage}{39em}
Thm: If differentialbe, then $\vecta{H}_{\vecta{a}}=\vecta{J}(\vecta{a})$.\\

Example: Let $\delta; (0,1)\rightarrow \R^n, f:\R^n \rightarrow \R$ be differentiable. Let $F(t)=f(\delta(t))$. Verify $F'(t)=(Df)(D\delta)$, where $Df$ is is a $1\times n $ matrix and $D\delta $ is a $n\times 1$ matrix.\\

Example: Let $f(u,v,w)=u^2v+wv^2$ and $g(x,y)=(xy,\sin x, e^x)$. Let  $h=f\circ g$. Find $\frac{\partial  h}{\partial x}$.\\

MVT: Let $f:U\subseteq \R^n\rightarrow \R^m$. Suppose $f$ is differentaible on $U$ and $x,y \in U$. Then $\exists c_1,\dots,c_m \in \R$ on the segment joining $x$ and $y$ such that
\begin{equation}
\forall i, f_i(y)-f_i(x)=(Df_i)(c_i)(y-x)
\end{equation}
\end{minipage}}
\begin{theorem}
\label{4.2.10}
\textbf{(Chain Rule)}
\end{theorem}
\fbox{\begin{minipage}{39em}
Given differentiable $\delta:\R \rightarrow \R^n, f:\R^n:\R$. By chain rule, we can observe $F(t):= f\circ \delta (t)$ satisfy $F'=(Df)\circ (D\delta)$, where $Df$ is a $1\times n$ matrix-valued function and $D\delta$ is a $n \times 1$ matrix-valued function.
\end{minipage}}
\begin{theorem}
\label{4.2.11}
\textbf{(Example of Chain Rule)} Let $f(u,v,w)=u^2v+wv^2$ and $\vecta{g}(x,y)=(xy,\sin x,e^x)$. Let $h=f\circ \vecta{g}$. We have
\begin{equation}
\frac{\partial h}{\partial x}=2xy^2\sin x+(x^2y^2+2e^x\sin x) \cos x+ e^x\sin^2 x
\end{equation}
\end{theorem}
\begin{proof}
We have
\begin{align}
  \frac{\partial h}{\partial x}&=\frac{\partial h}{\partial u}\frac{\partial u}{\partial x}+\frac{\partial h}{\partial v}\frac{\partial v}{\partial x}+\frac{\partial h}{\partial w}\frac{\partial w}{\partial x}\\
  &=(2uv)(y)+(u^2+2wv)(\cos x)+(v^2)(e^x)\\
  &=2xy(\sin x)y+(x^2y^2+2e^x \sin x)\cos x+(\sin^2 x)e^x\\
  &=2xy^2\sin x+(x^2y^2+2e^x\sin x) \cos x+ e^x\sin^2 x
\end{align}
\end{proof}
\begin{theorem}
\label{4.2.12}
\textbf{(Mean Value Theorem)} Let $\vecta{f}:U\subseteq \R^n\rightarrow \R^m$. Suppose $\vecta{f}$ is differentiable on $U$ and $\vecta{x},\vecta{y}\in U$. For all $i\in \set{1,\dots , n}$, there exists $0\leq c_i\leq 1$ such that 
\begin{equation}
f_i(\vecta{y})-f_i(\vecta{x})=(Df_i)(\vecta{x}+c_i(\vecta{y}-\vecta{x}))
\end{equation}
\end{theorem}
\fbox{\begin{minipage}{39em}
Directional Derivative.
\end{minipage}}
\begin{definition}
\label{4.2.13}
  \textbf{(Definition of Directional Derivative)} Let $f$ be real valued and defined on a neighborhood of $\vecta{x}_0 \inr^n$ and let $\vecta{v}\inr^n$ with $\norm{\vecta{v}}=1$ Then
  \begin{equation}
    (D_vf)(x_0)=\lim_{t\to 0}\frac{f(x_0+tv)}{t}
  \end{equation}
\red{I} should verify it also equals to
\begin{equation}
  (\frac{d}{dt}f(x_0+tv))(t_0)
\end{equation}
\end{definition}
\begin{theorem}
\label{4.2.14}
\textbf{(Directional Derivative)} Let $U$ be open and $f:U\rightarrow \R^n$ be differentiable at $x_0$. We have
 \begin{equation}
D_vf(x_0)=\vecta{J}_f(x_0)(v)
\end{equation}
\end{theorem}
\begin{proof}
Outline: in the limit of differentiable equation, let $x=x_0+tv$ and see what happen when  $t \to 0$
\end{proof}
\fbox{\begin{minipage}{39em}
Try to write in the form of gradient, and make a line between general theorem and actual computation. 
\end{minipage}}
\begin{theorem}
\label{4.2.15}
\textbf{(Example)} Let
\begin{equation}
f(x,y)=\begin{cases}
  \frac{x^3}{x^2+y^2}& \text{ if  }(x,y)\neq 0\\
  0 & \text{ if  }(x,y)=(0,0)
\end{cases}
\end{equation}
We have $f(x,y)$ is non-differentiable at $v$
\end{theorem}
\begin{proof}
Observe
\begin{align}
D_vf(0)&=\lim_{t \to 0}\frac{f(tv_1,tv_2)-f(0,0)}{t}\\
&=\lim_{t\to0}\frac{v_1^3}{v_1^2+v_2^2}=v_1^3\neq Df(0)(v)
\end{align}
\end{proof}
\begin{definition}
\label{4.2.16}
\textbf{(Definition of Gradient)} Let $f:U\subseteq \R^n \rightarrow \R$. The gradient of $f$ is defined as
\begin{equation}
  \nabla f=(\frac{\partial f}{\partial x_1},\dots ,\frac{\partial f}{\partial x_n})
\end{equation}
Notice that we can verify Gradient is Jacobian, and jacobian is always a derivative. 
\end{definition}
\begin{theorem}
\label{4.2.17}
\textbf{(Gradient)} Vector $\frac{\nabla f(x_0)}{\norm{\nabla f(x_0)}_{\R^n}}$ is normal to? 

\end{theorem}
\begin{theorem}
\label{4.2.18}
\textbf{(Example)} Let $S=\set{(x,y,z):x^2+y^2+z^2=3}$ Find the normal to $S$ at $(1,1,1)$
\end{theorem}
\begin{theorem}
\label{4.2.19}
\textbf{(TEST Example)} Let $S=\set{(x,y,z):x^2-y^2+xyz=1}$. Find the tangent plane of $S$ at $(1,0,1)$ 
\end{theorem}
\fbox{\begin{minipage}{39em}
Integral.
\end{minipage}}
\begin{theorem}
\label{4.2.20}
\textbf{(Integral)} Let 
 \begin{equation}
\forall x \in S, g_1(x)\leq g_2(x)
\end{equation}
Let  
\begin{equation}
A=\set{(x,y)\in \R^n \times \R: \forall x \in S, g_1(x)\leq y\leq g_2(x)}
\end{equation}
Let $f:A \rightarrow \R$ be continuous, we have
\begin{equation}
\int_A f(x,y)d(x,y)=\int_S(\int_{g_1(y)}^{g_2(y)} f(x,y)dy)dx
\end{equation}
This enable us to calculate integral by iteration.  
\end{theorem}
\begin{theorem}
\label{4.2.21}
\textbf{(Example)} Let 
\begin{equation}
A=\set{(x,y)\inr^2 : 0\leq x\leq 1, x\leq y\leq 1}
\end{equation}
Let 
\begin{equation}
f(x,y)=xy
\end{equation}
Compute
\begin{equation}
\int_A f(x,y)dA=\int^1_0 \int^1_x xy dydx
\end{equation}
\end{theorem}
\begin{theorem}
\label{4.2.22}
\textbf{(Example)} Let 
\begin{equation}
A=\set{(x,y)\inr^2 :0\leq x\leq 1, \sqrt{x} \leq y\leq 1}
\end{equation}
Find 
\begin{equation}
\int_A e^{y^3}dA
\end{equation}
\end{theorem}
\begin{theorem}
\label{4.2.23}
\textbf{(Example)} Let 
\begin{equation}
A=\set{(x_1,x_2,x_3):x_1,x_2,x_3 \geq 0, x_1+x_2+x_3\leq 1}
\end{equation}
Let $S=[0,1]\times [0,1]\times [0,1]$. Compute
\begin{equation}
\int_A (x_1+x_2+x_3)^2 dx_1dx_2dx_3
\end{equation}
\end{theorem}
\begin{theorem}
\label{4.2.24}
\textbf{(Example)} Compute $n$-dimensional ball volume.
\end{theorem}
\chapter{Advanced Calculus HW}
\section{HW1}
\begin{question}{}{}
\begin{enumerate}
    \item Prove that the following statements are equivalent: for a given sequence $\{x_n\}$,
    \begin{enumerate}
        \item for every $0 < \epsilon \in \mathbb{Q}$, there exists $N \in \mathbb{N}$ such that $|x_n - x| < \epsilon$ whenever $n \geq N$.
        \item for every $0 < \epsilon \in \mathbb{R}$, there exists $N \in \mathbb{N}$ such that $|x_n - x| < \epsilon$ whenever $n \geq N$.
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}
From $(b)$ to $(a)$, just observe  $\Q \subseteq \R$ and we are done.Now we prove from $(a)$ to $(b)$.\\

Because $\Q$ is dense in  $\R$,  for all $\epsilon \in \R^+$, we can pick $\epsilon' \in \Q$ such that $0<\epsilon '< \epsilon $. By $(a)$,  we know there exists $N\in \N$ such that $\abso{x_n-x}<\epsilon ' <\epsilon $ whenever $n\geq N$. This finish the proof.
\end{proof}
\begin{question}{}{}
2. Let $\{x_n\}_{n=1}^{\infty}$ be a monotone increasing sequence such that 
\[x_{n+1} - x_n \leq \frac{1}{n}.\]
Determine whether the sequence converges. (If yes, prove it; if not, disprove it or give a counterexample.)
\end{question}
\begin{proof}
No, consider $p$-series. The sequence $\set{x_n}_{n=1}^{\infty}$ defined by $x_i:=\sum_{j=1}^i \frac{1}{j}$ is monotone increasing, satisfying the desired property, and from our knowledge, diverge. 
\end{proof}
\begin{question}{}{}
Let $M_{n \times m}$ be the collection of all $n \times m$ matrices with real entries. Define a function $\| \cdot \|: M_{n \times m} \to \mathbb{R}$ by
\[
\| A \| = \sup \left\{ \frac{\|Ax\|_2}{\|x\|_2} : x \in \mathbb{R}^m, x \neq 0 \right\},
\]
where we recall that $\| \cdot \|_2$ is the 2-norm on Euclidean space given by
\[
\| Ax \|_2 = \left( \sum_{i=1}^{k} x_i^2 \right)^{1/2} \quad \text{if } x \in \mathbb{R}^k.
\]
Show that:
\begin{enumerate}
    \item $\| A \| = \sup \left\{ \|Ax\|_2 : x \in \mathbb{R}^m, \norm{x}_2 =1 \right\} = \inf \left\{ M \in \mathbb{R} : \|Ax\|_2 \leq M \|x\|_2 \, \forall x \in \mathbb{R}^m \right\}$.
    \item $\| Ax \|_2 \leq \| A \| \| x \|_2$ for all $x \in \mathbb{R}^m$.
    \item $\| \cdot \|$ defines a norm on $M_{n \times m}$.
\end{enumerate}
\end{question}
\begin{proof}
In this proof, we use $\abso{\cdot}$ to denote $\norm{\cdot}_2$, and if we write $x$ without specification, it belong to  $\R^m$\\

We first show \vi{$\norm{A}= \sup \set{ \abso{Ax}: \abso{x}=1}$}\\

\As{$\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}=\norm{A}>  \sup \set{\abso{Ax} : \abso{x}=1} $}.Then we know $ \sup \set{\abso{Ax}:\abso{x}=1} $ is not an upper bound of $ \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0} $, so we know there exists $x\in \R^m$ such that $\frac{\abso{Ax}}{\abso{x}}>\sup \set{\abso{Ay}:\abso{y}=1}$.\\

Define $\hat{x}:=\frac{x}{\abso{x}}$. We have $\frac{\abso{Ax}}{\abso{x}}=\abso{\frac{Ax}{\abso{x}}}=\abso{A \hat{x}}\leq \sup \set{\abso{Ay}:\abso{y}=1}
$, since $\abso{\hat{x}}=\abso{\frac{x}{\abso{x}}}=\frac{\abso{x}}{\abso{x}}=1\implies \abso{A \hat{x}}\in \set{\abso{Ay}:\abso{y}=1}$. This \CaC.\\

\As{$\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}=\norm{A}<\sup \set{\abso{Ax} : \abso{x}=1} $}. Then we know $\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}$ is not an upper bound of $\sup \set{\abso{Ax}:\abso{x}=1}$, so we know there exists $\hat{x} \in \R^m:\abso{\hat{x}}=1$ such that $\abso{A \hat{x}}>\sup \set{\frac{\abso{Ay}}{\abso{y}}:y\neq 0}$.\\

We see $\abso{A \hat{x}}>\sup \set{\frac{\abso{Ay}}{\abso{y}}:y\neq 0}\geq \frac{\abso{A \hat{x}}}{\abso{\hat{x}}}=\frac{\abso{A \hat{x}}}{1}=\abso{A \hat{x}}\tCaC \vdone$\\

Observe $  \inf \left\{ M \in \mathbb{R} : \|Ax\|_2 \leq M \|x\|_2 \, \forall x \in \mathbb{R}^m \right\}= \inf \set{c \in \R: \forall x\neq 0, c\geq \frac{\abso{Ax}}{\abso{x}}}$, since $\forall M, \abso{A\vecta{0}}\leq M\abso{\vecta{0}}$.\\

Observe that $   \set{c \in \R: \forall x\neq 0, c\geq \frac{\abso{Ax}}{\abso{x}}}$ is the set of upper bound of $\set{\frac{\abso{Ax}}{\abso{x}}:\abso{x}\neq 0}$, so $\inf   \set{c \in \R: \forall x, c\geq \frac{\abso{Ax}}{\abso{x}}}=\norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:\abso{x}\neq 0}$.\\
\end{proof}
\begin{proof}
In this proof, we use $\abso{\cdot}$ to denote $\norm{\cdot}_2$, and if we write $x$ without specification, it belong to  $\R^m$\\

If $x=0$, then we trivially have  $\abso{Ax}=\abso{0}=0\leq \norm{A}\abso{x}=0$, so from now, we only have to consider $x\neq 0$.\\

If $x\neq 0$, we have $\abso{Ax}\leq \norm{A}\abso{x}\iff \frac{\abso{Ax}}{\abso{x}}\leq \norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}$, trivially true.
\end{proof}
\begin{proof}
In this proof, we use $\abso{\cdot}$ to denote $\norm{\cdot}_2$, and if we write $x$ without specification, it belong to  $\R^m$\\

For non-negativity, observe $\forall x\neq 0,\frac{\abso{Ax}}{\abso{x}}\geq 0 \implies \norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:x \in \R^m, x\neq 0}\geq 0$.\\

For definite-positive, observe $A=0\implies \forall x\neq 0, \frac{\abso{Ax}}{\abso{x}}=\frac{\abso{0}}{\abso{x}}=0\implies \norm{A}=0$. Also, if $A\neq 0$, we can pick a column, say $p$-th column, that contain non-zero entry. We see the vector $e\in \R^m$ where the only non-zero entry is the  $p$-th entry being $1$ satisfy $\abso{Ae}>0$, thus $\frac{\abso{Ae}}{\abso{e}}>0$. Because $e\neq 0$, we see $\norm{A}=\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\in\R^m,x\neq 0}\geq \frac{\abso{Ae}}{\abso{e}}>0$.\\

For absolute-homogenity, let $c \in \R\text{ and }A\in M_{n\times m}$. We wish to prove \vi{$\norm{cA}=\sup \set{\frac{\abso{cAx}}{\abso{x}}:x\neq 0}=\abso{c}\sup \set{\frac{\abso{Ax}}{\abso{x}}:x\neq 0}=\abso{c}\norm{A}$}. Notice that $\frac{\abso{cAx}}{\abso{x}}=\frac{\abso{c}\abso{Ax}}{\abso{x}}$, so we only have to prove the more general statement : $c>0 \implies c \sup X= \sup \set{cx:x\in X}$. Notice that $\forall x \in X, c \sup X\geq cx$, so we have $c\sup X\geq \sup \set{cx:x\in X}$. If $c\sup X$ is not the smallest upper bound, we see there exists $cx$ such that $c\sup X<cx$, and we see $\sup X<x$, causing a contradiction, so we do have $c\sup X=\sup \set{cx:x\in X}\vdone$   \\

For triangle-inequality, first observe $\frac{\abso{(A+B)x}}{\abso{x}}=\frac{\abso{Ax+Bx}}{\abso{x}}\leq \frac{\abso{Ax}+\abso{Bx}}{\abso{x}}=\frac{\abso{Ax}}{\abso{x}}+\frac{\abso{Bx}}{\abso{x}}$. \As{$\norm{A+B}>\norm{A}+\norm{B}$}.\\

Because $\norm{A}+\norm{B}$ is not an upper bound of $\set{\frac{\abso{(A+B)x}}{\abso{x}}:x\neq 0}$, we know there exists $x'$ such that  $\frac{\abso{(A+B)x'}}{\abso{x'}}>\norm{A}+\norm{B}$. Further, by definition of $\norm{A},\norm{B}$, we have
\begin{equation}
\frac{\abso{(A+B)x'}}{\abso{x'}}>\frac{\abso{Ax'}}{\abso{x'}}+\frac{\abso{Bx'}}{\abso{x'}}\tCaC
\end{equation}
\end{proof}

\begin{question}{}{}
Suppose that \(S_1, S_2, \ldots, S_n\) are sets in \(\mathbb{R}\) and 
\[ S = \bigcup_{i=1}^{n} S_i. \]
Define \(B_i = \sup S_i\) for \(i = 1, \ldots, n\).

\begin{enumerate}
    \item Show that \(\sup S = \max\{B_1, B_2, \ldots, B_n\} \).
    \item If \(S\) is the union of an infinite collection of \(S_i\), find the relation between \(\sup S\) and \(B_i\).
\end{enumerate}
\end{question}
\begin{proof}
Let $\sup S_j=B_j=\max \set{B_1,\dots, B_n}$. We first show \vi{$\sup S_j$ is an upper bound of $S$}.\\

By definition, we have $\forall x\in S_j,x\leq \sup S_j$ and have $\forall i \neq j, \forall x \in S_i, x\leq \sup S_i\leq \sup S_j $, so we have $\forall x\in S, \exists k \in \set{1,\dots, n}, x \in S_k \implies x\leq \sup S_k\leq \sup S_j\vdone$\\

We now show  \blue{$\sup S_j$ is the least upper bound of $S$}.\\

\As{there exists an upper bound of $S$ smaller than $\sup S_j$}. Denote that upper bound $y$. Because $y$ is smaller than $\sup S_j$, we know $y$ is not an upper bound of $S_j$, so we know there is a number  $z \in S_j$ greater than $y$. Observe that the fact $y$ is an upper bound of $S$ implies  $y$ is greater than or equal to $z \in S_j\subseteq S\tCaC\bdone$
\end{proof}
\begin{proof}
  We prove \vi{$\sup S=\sup \set{B_i}$}.\\

  Notice $\sup S$ is an upper bound of $S_i$, so we have $\forall i, \sup S>\sup S_i=B_i$. This means $\sup S$ is an upper bound of $\set{B_i}$. We have proved $\sup S\geq \sup \set{B_i}$. \As{$\sup S>\sup \set{B_i}$}. Then because $\sup \set{B_i}$ is not an upper bound of $S$, we know there exists  $s \in S$ such that $s>\sup \set{B_i}$. But because $S=\bigcup \set{S_i}$, we know $\exists S_j,s \in S_j$, which give us $s\leq \sup S_j=B_j\leq \sup \set{B_i}\tCaC\vdone$
\end{proof}
\begin{question}{}{}
Let \( A \) be a non-empty set of \( \mathbb{R} \) which is bounded below. Define the set \( -A \) by 
\[ -A \equiv \{-x \in \mathbb{R} : x \in A\}. \]
Prove that
\[ \inf(A) = -\sup(-A). \]
\end{question}
\begin{proof}
Observe $\forall x\in -A, \sup (-A)\geq  x\implies \forall a \in A, -\sup (-A)\leq  a$. So $-\sup (-A)$ is an lower bound of $A$. \As{$-\sup (-A)$ is not the greatest lower bound of $A$} (greatest lower bound exists because bounded below and completeness). Let $b>-\sup (-A)$ be another lower bound of $A$. We have $-b<\sup (-A)$, so we know $-b$ is not an upper bound of $-A$, then we know  $\exists x \in -A, -b<x$. Then we know $\exists a \in A, -b<-a$, which implies $\exists a \in A, b>a$, but $b$ is an lower bound of $A\tCaC$
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \item Let \( A, B \) be non-empty subsets of \( \mathbb{R} \). Define \( A+B \) as 
    \[ A+B = \{ x+y : x \in A, y \in B \}. \]
    Justify if the following statements are true or false by providing a proof for the true statements and giving a counter-example for the false ones.
    \begin{enumerate}
        \item \( \sup(A+B) = \sup A + \sup B \).
        \item \( \inf(A+B) = \inf A + \inf B \).
        \item \( \sup(A \cap B) \leq \min\{\sup A, \sup B\} \).
        \item \( \sup(A \cap B) = \min\{\sup A, \sup B\} \).
        \item \( \sup(A \cup B) \geq \max\{\sup A, \sup B\} \).
        \item \( \sup(A \cup B) = \max\{\sup A, \sup B\} \).
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}
We prove $\sup (A+B)=\sup A+\sup B$. For all $a+b \in A+B$, we by definition have $a\leq \sup A, b\leq \sup B$, so we have $a+b\leq \sup A+\sup B$. This prove $\sup A+\sup B$ is an upper bound of $A+B$. \As{there exists an upper bound $x$ of $A+B$ smaller than $\sup A+\sup B$}. We have $x-\sup B<\sup A$, so we know $x-\sup B$ is not an upper bound of $A$. Then we know  $\exists a'\in A, x-\sup B<a'$. This implies $x-a'< \sup B$, so we know $x-a'$ is not an upper bound of  $B$. Then we know there exists  $b' \in B$ such that $x-a'< b'$. This implies $x<a'+b' \in A+B\tCaC$ to $x$ is an upper bound of  $A+B$
\end{proof}
\begin{proof}
We prove $\inf (A+B)= \inf A +\inf B$. For all $a+b \in A+B$, we by definition have $\inf A\leq a,\inf B\leq b$, so we have $\inf A+\inf B\leq a+b$. This prove $\inf A+ \inf B$ is an lower bound of $A+B$.  \As{there exists an lower bound $x$ of $A+B$ greater than $\inf A+\inf B$}. We have $x- \inf A > \inf B$, so we know $x - \inf A$ is not an lower bound of $B$. Then we know  $\exists b' \in B, x- \inf A > b'$. This implies $x-b'>\inf A$, so we know $x- b'$ is not an lower bound of $A$. Then we know  $\exists a' \in A, x-b'>a'$. So we know $x<a'+b' \in A+B\tCaC$ to $x$ is an lower bound of $A+B$ 
\end{proof}
\begin{proof}
We prove $\sup (A\cap B)\leq \min \set{\sup A,\sup  B}$.\\

WOLG, let $\sup A\leq \sup B$. By definition $x \in A\cap B \implies  x \in A \implies x\leq \sup A$, so we know $\sup A$ is an upper bound of $A\cap B$. This implies $\sup A\cap B\leq \sup (A\cap B)$ 
\end{proof}
\begin{proof}
We show $\sup (A\cap B)= \min \set{\sup A,\sup B}$ is not always correct. Let $A=[0,2]$ and $B=[0,1]\cup [3,4]$. We have $\sup (A\cap B= [0,1])=1\neq \min{\set{\sup A=2,\sup B=4}}$
\end{proof}
\begin{proof}
$\sup A\cup B$ is an upper bound of both $A$ and  $B$, so  $\sup A\cup B>\sup A\text{ and }\sup A\cup B>\sup B$

\end{proof}
\begin{proof}
We prove $\sup (A\cup B)=\max \set{\sup A,\sup B}$. WOLG, let $\sup A\geq \sup B$. \As{$\sup B\leq \sup A<\sup (A\cup B)$}. Let $x$ be a number between  $\sup A\text{ and }\sup A\cup B(x\text{ exists since it can be $\frac{\sup A+\sup (A\cup B)}{2}$ })$. Because $x<\sup (A\cup B)$, we know $x$ is not an upper bound of  $A\cup B$. By definition, we know there exists $z\in A\cup B$ such that $x<z$. We know either $z \in A$ or $z \in B$, but we see $z \in A\implies z\leq \sup A<x$ and we see $z \in B\implies z\leq \sup B\leq \sup A<x\tCaC$
\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{6}
    \item Let \( S \subseteq \mathbb{R} \) be bounded below and non-empty. Show that
    \[ \inf S = \sup\{ x \in \mathbb{R} : x \text{ is a lower bound for } S \}. \]
\end{enumerate}
\end{question}
\begin{proof}
Denote $B=\set{x\in R: x\text{ is a lower bound for $S$ }}$. \As{$\inf S> \sup B$}. Let $\inf S>x>\sup B$. Notice $\inf S>x$ implies there is a lower bound  $b$ of  $S$ greater than  $x$. Observe $b>x\text{ and }b \in B\implies x$ is not an upper bound of $B\tCaC x>\sup B$.\\

\As{$\inf S<\sup B$}. Let $\inf S<x<\sup B$. Notice $\inf S<x$ implies there exists $s' \in S$ such that $s'<x$, and notice $x> \sup B$ implies there exists $b'\in B$ such that $b'>x$. We see  $b'>x>s'$ while  $b'$ is an lower bound of  $S\tCaC$
\end{proof}
\begin{question}{}{}
8. Let \( f \) be a continuous function on \( \mathbb{R} \) and \( D \) is a dense subset in \( \mathbb{R} \). Prove that:
\begin{enumerate}
    \item \( \sup_{x \in D} f(x) = \sup_{x \in \mathbb{R}} f(x) \).
    \item There exists a sequence \( \{x_n\}_{n=1}^{\infty} \) in \( D \) such that 
    \[
    \lim_{n \to \infty} f(x_n) = \sup_{x \in \mathbb{R}} f(x).
    \]
\end{enumerate}
\end{question}
\begin{proof}
Because $D\subseteq \R$, we must have $\sup \set{f(x): x\in D}\leq \sup \set{f(x): x\in \R}$, since any upper bound of the latter will be one of the former.\\

\As{$\sup \set{f(x):x \in D}<\sup \set{f(x):x\in \R}$}. Because $\sup \set{f(x):x\in D}$ is not an upper bound of $\set{f(x):x\in \R}$, we know there exists $x'\in \R$ such that 
\begin{equation}
f(x')>\sup \set{f(x):x\in D}
\end{equation}
We first \vi{construct a sequence $\set{x_i}_{i=1}^\infty$ in $D$ such that} 
\begin{equation}
  \vi{\lim_{i\to \infty}x_i=x'\text{ which reads } \forall \epsilon, \exists N, n>N \longrightarrow \abso{x_n - x'}<\epsilon}
\end{equation}
By Axiom of Choice and the fact that $D$ is dense in  $\R$, we can pick $x_i \in (x'- \frac{1}{i},x' +\frac{1}{i})$, so we have
\begin{equation}
\forall i, \abso{x_i-x'}<\frac{1}{i}
\end{equation}
For all $\epsilon $, we can pick a natural $N>\epsilon $, so we have 
\begin{equation}
n>N\implies \abso{x_n-x'}<\frac{1}{n}<\frac{1}{N}<\frac{1}{\epsilon }\vdone
\end{equation}
We now prove 
\begin{equation}
\blue{\lim_{i\to\infty}f(x_i)=f(x')\text{ which reads }\forall \epsilon , \exists N, n>N\longrightarrow  \abso{f(x_n)-f(x')}<\epsilon }
\end{equation}
Because $f$ is continuous, we have 
\begin{equation}
  \forall \epsilon ,\exists \delta, \forall u\in \R, \abso{u-x'}<\delta\implies \abso{f(u)-f(x')}<\epsilon  
\end{equation}
Then for all $\epsilon $, we can first let $\delta$ satisfy $\abso{u-x}<\delta \implies \abso{f(u)-f(x')}<\epsilon $. Then by the \vi{violet fact} we can pick $N$ such that 
\begin{equation}
n>N\implies \abso{x_n - x'}< \delta \implies \abso{f(x_n)-f(x')}<\epsilon \bdone 
\end{equation}
Let $H=\sup \set{f(x): x\in D}$. Now we prove  
\begin{equation}
  \vi{\lim_{i \to \infty}f(x_i)\leq H}
\end{equation}
\As{$f(x')=\lim_{i \to \infty} f(x_i) >H $}. We know there exists $N$ such that 
\begin{equation}
n>N\longrightarrow \abso{f(x_n)-f(x')}<\abso{H - f(x') }=f(x')-H
\end{equation}
The last equality hold true due to the premise equation (5.2). Notice 
\begin{equation}
\abso{f(x_n)-f(x')}<f(x')-H\implies H-f(x')< f(x_n)-f(x')\implies f(x_n)>H
\end{equation}
so in fact we know there exists $N$ such that 
\begin{equation}
n>N \longrightarrow f(x_n)>H= \sup \set{f(x): x \in D}\tCaC\vdone
\end{equation}
Now, using all our proven facts, we have
\begin{equation}
\sup \set{f(x): x\in D}<f(x')=\lim_{i\to \infty }f(x_i)\leq H=\sup \set{f(x): x \in D}\tCaC
\end{equation}
where the first inequality follows from premise equation (5.2) 
\end{proof}
\begin{proof}
Let $H=\sup \set{f(x): x \in D}$. We first prove
\begin{equation}
\vi{\forall i \in \N, \set{f(x): x \in D\text{ and }H-f(x)<\frac{1}{i}}\neq \varnothing}
\end{equation}
\As{there exists some $n\inn$ such that the set is empty}. We then have
\begin{equation}
\forall x\in D, H\geq f(x)+\frac{1}{n}
\end{equation}
So we have
\begin{equation}
\forall x\in D, H-\frac{1}{2n}\geq f(x)+\frac{1}{2n}>f(x)
\end{equation}
Then we see $H-\frac{1}{2n}$ is an upper bound of $\set{f(x): x \in D}$ smaller than $H\tCaC\vdone$\\

By Axiom of Choice, we can construct a sequence $\set{x_i}_{i=1}^\infty$ by picking $x_i: f(x_i)\in \set{f(x):x \in D\text{ and }H-f(x)<\frac{1}{i}}$. Then we have
\begin{equation}
\forall \epsilon, n> [\frac{1}{\epsilon }]+1\implies n>\frac{1}{\epsilon }\implies \abso{f(x_n)-H}<\frac{1}{n}<\epsilon 
\end{equation}
This written in limit sign is 
\begin{equation}
\lim_{i\to \infty}f(x_i)=H=\sup \set{f(x): x\in D}=\sup \set{f(x):x \inr}
\end{equation}
\end{proof}
\section{HW2}
\begin{question}{}{}

Let \(A \subseteq \mathbb{R}^n\) be an open set and \(B \subset \mathbb{R}^n\) be any set. Then the set 
\[ A + B \equiv \{a + b : a \in A \text{ and } b \in B\} \]
is open.
\end{question}
\begin{proof}
Notice 
\begin{equation}
A+B= \bigcup \set{\set{a+b:a\in A}:b\in B}
\end{equation}
We only have to prove  \vi{for all $b\in B$, the set $A+b:=\set{a+b:a\in A}$ is open}.\\

Fix $b$. Arbitrarily pick $a+b\in A+b$. Because $A$ is open, we know there exists $r\inr^+$ such that
\begin{equation}
B_r(a)\subseteq A
\end{equation}
Let
\begin{equation}
B_r(a)+b:=\set{x+b:x\in B_r(a)}
\end{equation}
We now prove 
\begin{equation}
\teal{B_r(a)+b=B_r(a+b)}
\end{equation}
Arbitrarily pick $x+b\in B_r(a)+b$. We have
\begin{equation}
\abso{(x+b)-(a+b)}=\abso{x-a}<r
\end{equation}
We have proved $B_r(a)+b\subseteq B_r(a+b)$. Arbitrarily pick $y\in B_r(a+b)$. Let $z=y-b$. We have
\begin{equation}
y=z+b\text{ and }\abso{z-a}=\abso{y-(a+b)}<r
\end{equation}
The latter tell us $z \in B_r(a)$, so we have
\begin{equation}
y=z+b \in B_r(a)+b
\end{equation}
Because $y$ is arbitrarily picked from $B_r(a+b)$, we have proved $B_r(a+b)\subseteq B_r(a)+b\tdone$\\

Notice that  $r$ is selected to satisfy
\begin{equation}
B_r(a)\subseteq A
\end{equation}
and it is clear that
\begin{equation}
B_r(a)+b\subseteq A+b
\end{equation}
So we have
\begin{equation}
B_r(a+b)=B_r(a)+b\subseteq A+b
\end{equation}
Notice $a+b$ is arbitrarily picked from $A+b$. Our proof is done  $\vdone$
\end{proof}

\begin{question}{}{}
Show that every open set in \( \mathbb{R} \) is the union of at most countable collection of disjoint open intervals.
\end{question}
\begin{proof}

\end{proof}
\begin{question}{}{}
Let \( A \subseteq B \subseteq \mathbb{R} \). Suppose that \( A \) is a dense subset of \( B \).

1. Prove that \( B \subseteq \overline{A} \).

2. If \( B \) is closed, determine whether \( B = \overline{A} \).
\end{question}
\begin{proof}
$A$ is a dense subset of $B$ means that every point $b\in B\setminus A$ is a limit point of $A$ in the scope of $B$. Notice that $b$ is a limit point of  $A$ in the scope of $B$ also means $b$ is a limit point in the scope of $\R$. Then we have proved $B\setminus A\subseteq A'$. It follows
\begin{equation}
B=A \cup (B\setminus A)\subseteq A\cup A'=\overline{A}
\end{equation}
If $B$ is closed, we have
 \begin{equation}
\overline{A}\subseteq \overline{B}=B
\end{equation}
Then because $B\subseteq \overline{A}$, we have $B=\overline{A}$



\end{proof}
\textbf{Definition 0.1.} A metric space \( X \) is \textit{sequentially compact} if every sequence of points in \( X \) has a convergent sub-sequence converging to a point in \( X \).
\begin{question}{}{}

Let \( A \) and \( B \) be subsets of a metric space \( (M, d) \) and denote \( \text{cl}(A) = \overline{A} \). Show that

1. \( \text{cl}(\text{cl}(A)) = \text{cl}(A) \).

2. \( \text{cl}(A \cup B) = \text{cl}(A) \cup \text{cl}(B) \).

3. \( \text{cl}(A \cap B) \subseteq \text{cl}(A) \cap \text{cl}(B) \). Find an example such that \( \text{cl}(A \cap B) \subsetneq \text{cl}(A) \cap \text{cl}(B) \).
\end{question}
\begin{proof}
Notice that closure is the smallest closed set containing the set.\\

Because $\overline{A}$ is a closed set, we know the smallest closed set containing $\overline{A}$ is $\overline{A}$ itself.\\

Deduce
\begin{equation}
A\subseteq A\cup B\implies \overline{A}\subseteq \overline{A\cup B}
\end{equation}
and deduce
\begin{equation}
B\subseteq A\cup B\implies \overline{B}\subseteq \overline{A\cup B}
\end{equation}
so deduce
\begin{equation}
\overline{A}\cup \overline{B}\subseteq \overline{A\cup B}
\end{equation}
Notice that $\overline{A}\cup \overline{B}$ is a closed set containing both $A$ and  $B$, thus containing $A\cup B$, so because $\overline{A\cup B}$ by definition is the smallest closed set containing $A\cup B$, we have
\begin{equation}
\overline{A\cup B}\subseteq \overline{A}\cup \overline{B}
\end{equation}
\end{proof}
\begin{question}{}{}

Let \( K \) be a sequentially compact set in a metric space \( (M, d) \) and let \( F \subseteq K \) be closed. Prove that \( F \) is sequentially compact.
\end{question}
\begin{proof}

\end{proof}
\textbf{Definition 0.2.} The discrete metric \( d \) on a set \( X \) is defined by
\[
d(x,y) = 
\begin{cases} 
1 & \text{if } x \neq y, \\
0 & \text{if } x = y,
\end{cases}
\]
for any \( x, y \in X \). In this case \( (X,d) \) is called a discrete metric space.
\begin{question}{}{}

Let \( (M, d) \) be a metric space with discrete metric \( d \). Prove that every compact set in \( M \) is finite.
\end{question}
\begin{proof}
\As{$M$ is infinite}. By   
\end{proof}
\begin{question}{}{}

Let \( \{ x_n \}_{n=1}^{\infty} \subseteq \mathbb{R} \) be a convergent sequence with the limit \( x \). Prove that the set \( \{ x_n : n \in \mathbb{N} \} \cup \{ x \} \) is compact.
\end{question}
\begin{proof}

\end{proof}
\begin{question}{}{}

\begin{enumerate}
    \item Let \( A \) and \( B \) be two subsets of a metric space \( (M,d) \). The distance between \( A \) and \( B \) is defined by
    \[
    d(A,B) \equiv \inf\{d(x,y) : x \in A, y \in B\}.
    \]
    \begin{enumerate}
        \item Give an example of two disjoint, nonempty, closed sets \( A \) and \( B \) in \( \mathbb{R}^n \) for which \( d(A, B) = 0 \).
        \item Let \( A, B \) be nonempty sets in \( \mathbb{R}^n \) with \( A \) closed and \( B \) compact. Show that there are points \( a \in A \) and \( b \in B \) such that \( d(a, b) = |a-b| \). Deduce that \( d(A, B) \) is positive if such \( A, B \) are disjoint.
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}

\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{8}
    \item Let \( (M, d) \) be a metric space.
    \begin{enumerate}
        \item Show that the union of a finite number of compact subsets of \( M \) is compact.
        \item Show that the intersection of an arbitrary collection of compact subsets of \( M \) is compact.
    \end{enumerate}
\end{enumerate}
\end{question}
\begin{proof}

\end{proof}
\begin{question}{}{}
\begin{enumerate}
    \setcounter{enumi}{9}
    \item A metric space \( (M,d) \) is said to be \textit{separable} if there is a countable subset \( A \) which is dense in \( M \). Show that every compact set is separable.
\end{enumerate}
\end{question}
\begin{proof}

\end{proof}
\end{document}
